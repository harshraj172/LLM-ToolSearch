{"completion": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"completion": 523, "text": "query: Translate German sales emails to English so that the sales team can address the clients' needs."}
{"completion": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"completion": 428, "text": "query: Create a code snippet to identify the different parts of speech in a given text."}
{"completion": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"completion": 485, "text": "query: Our company is developing an intelligent chatbot in Chinese that can answer questions about a given text passage. Can you help suggest a suitable model?"}
{"completion": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"completion": 306, "text": "query: Craft a horror book cover for an upcoming novel from the author."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: \"\u06af\u0644\u0627\u0628 \u062e\u0627\u0646\u06d2 \u0633\u06d2 \u06a9\u0646\u0648\u0627\u06ba \u067e\u06be\u0648\u0644\u0648\u06ba \u06a9\u06cc \u062e\u0648\u0634\u0628\u0648 \u0622\u062a\u06cc \u06c1\u06d2\u06d4\""}
{"completion": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"completion": 527, "text": "query: We have just finished building the \"Russia to English\" chat translation model for the communication app we are working on. We need to test it with a given Russian text."}
{"completion": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"completion": 729, "text": "query: There is a Korean piece of text that needs to be transformed into audio for an online advertisement."}
{"completion": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"completion": 881, "text": "query: I'd like to use this model to predict carbon emissions, based on the given dataset."}
{"completion": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"completion": 855, "text": "query: We are a power plant analyzing carbon emissions data to find ways to reduce our carbon footprint. Classify and predict the carbon emission level in grams from a given set of data."}
{"completion": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 901, "text": "query: An online gaming platform wants to integrate a pre-trained agent to play CartPole with the player for testing purpose."}
{"completion": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"completion": 57, "text": "query: We are designing a new banner for our website about pets. We want an image to be generated for our banner."}
{"completion": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"completion": 880, "text": "query: Develop a solution to predict CO2 emissions based on data provided by the factory's various sensors."}
{"completion": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"completion": 826, "text": "query: Develop an application that listens to Russian speech and recommends a song with a similar emotion."}
{"completion": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 267, "text": "query: We want to have a picture of a red flower in a meadow."}
{"completion": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"completion": 470, "text": "query: We need to provide automated customer support for Korean users. They often ask questions about product usage or troubleshooting. Help us find their answers."}
{"completion": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 318, "text": "query: I am building AI application which can automatically detect exercises in the gym with the user providing recorded video of exercises, create a model to detect different exercises in a given video."}
{"completion": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"completion": 834, "text": "query: The user wants to automatically trim a podcast and remove the silence parts. Use an API to detect the spoken parts in the podcast."}
{"completion": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"completion": 512, "text": "query: I need to classify an online article in a language different from English; please help me classify this text written in a foreign language."}
{"completion": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"completion": 911, "text": "query: Develop the next-generation robotic hand that can grasp objects in a refined 6D space."}
{"completion": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"completion": 872, "text": "query: To aid in the prevention of climate change, we want to estimate carbon emissions based on various parameters."}
{"completion": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"completion": 653, "text": "query: I want to develop a language translation tool which can handle different languages like English, German, and Spanish."}
{"completion": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 167, "text": "query: I am working on a robotics project and I need to estimate the depth information from a single image to assist in obstacle detection."}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: Create a function that processes an image and outputs the category of the object in the image."}
{"completion": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"completion": 252, "text": "query: Implement an image segmentation model that can detect and segment defects in printed circuit board (PCB) images, such as dry joint, incorrect installation, PCB damage, and short circuit."}
{"completion": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"completion": 307, "text": "query: Our company develops a cat only social media platform and we need a system to create realistic cat images to test our app."}
{"completion": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"completion": 609, "text": "query: Suppose we want to generate creative advertising slogans for promoting an environmentally friendly product."}
{"completion": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 449, "text": "query: I want to build a software to help my team to quickly analyze the sales data of our company in a table format. I need it to answer questions about the data."}
{"completion": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 903, "text": "query: A simple cart needs to balance a pole as long as possible. Implement the functionality to enable the cart to do that."}
{"completion": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"completion": 347, "text": "query: We are a crowd-sourced real-time reporting startup. Using AI to distinguish between an image of a road accident and a traffic jam is of high interest to us."}
{"completion": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"completion": 884, "text": "query: As a restaurant owner, I want to predict the amount of tips my employees would receive based on the customer's total bill, in order to better understand my business."}
{"completion": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"completion": 339, "text": "query: We are a sports broadcasting company; we need to analyze and classify sports events in our videos."}
{"completion": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"completion": 310, "text": "query: Our client wants to use a shoe-generator model for generating potential sneaker designs for their new product line."}
{"completion": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"completion": 934, "text": "query: We are a company creating a multilingual NLP service. We want to restore punctuation to the text obtained from speech recognition results."}
{"completion": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"completion": 128, "text": "query: We run a professional association that organizes conferences. We need to easily find information from the conference program booklet regarding the keynote speaker list."}
{"completion": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"completion": 381, "text": "query: We are building a conversational bot, help us ensure the generated paraphrases sound natural and relevant."}
{"completion": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"completion": 732, "text": "query: The company is working on creating an application that translates spoken language in real-time. The app should support Spanish, English, French, and Italian. "}
{"completion": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"completion": 906, "text": "query: Deploy a model to control a robotic half cheetah to run as fast as it could."}
{"completion": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 249, "text": "query: The urban planning department of our city needs to identify different objects on a satellite map to improve public services."}
{"completion": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"completion": 192, "text": "query: We need a machine learning model that can identify dog breeds in photos in order to improve our dog breed identification app."}
{"completion": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"completion": 176, "text": "query: I am trying to identify whether an image is of a cat or a dog."}
{"completion": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 891, "text": "query: We are an educational technology company creating a reinforcement learning agent for an educational game. Show us the steps to load a pre-trained agent for CartPole."}
{"completion": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 328, "text": "query: We need a system that automatically classifies videos for our streaming platform according to their content."}
{"completion": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"completion": 473, "text": "query: We are building an application that searches through large documents to find answers to questions. Develop a solution that can parse text and answer questions accurately."}
{"completion": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"completion": 554, "text": "query: Provide a solution for the CEO who needs a summary of a long article on her mobile phone."}
{"completion": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 338, "text": "query: We're developing a platform for sports analytics. We need to classify a video which sport is being played."}
{"completion": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"completion": 390, "text": "query: In our English language online learning platform, we want to offer various ways to express the same sentence to improve fluency. Transform the given English sentence."}
{"completion": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 133, "text": "query: The Human Resources department wants to extract the relevant information like name, email, and job title from a r\u00e9sum\u00e9 to improve the hiring process."}
{"completion": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"completion": 129, "text": "query: I have a scanned image of a technical manual from which I want to get a textual description. Can you create a code snippet that takes the text from this image and answers my question about it?"}
{"completion": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"completion": 530, "text": "query: Translate a paragraph from Spanish to English."}
{"completion": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"completion": 369, "text": "query: I want to identify Chinese text labels for a picture of a beach."}
{"completion": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"completion": 882, "text": "query: We are an environmental consultancy company that needs to predict carbon emissions for a client's business."}
{"completion": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"completion": 728, "text": "query: create an ambulance service company, we need text-to-speech for general communication with users in French."}
{"completion": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"completion": 257, "text": "query: We're developing a solution for the municipal government to detect potholes in images automatically for road maintenance. Create a system to detect potholes."}
{"completion": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"completion": 605, "text": "query: We are a book publishing company looking to generate a continuation of a given sentence for our new storybook."}
{"completion": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"completion": 576, "text": "query: The marketing firm is working on publishing Chinese news articles on their website. They need a brief summary of each article for readers."}
{"completion": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 893, "text": "query: Develop a reinforcement learning agent that can play a soccer game with multiple players on each side of the field."}
{"completion": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 364, "text": "query: Design a smart vending machine that can tell products apart just by taking a picture of them."}
{"completion": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"completion": 76, "text": "query: I am an attorney, and I want to extract text from various court document images for reviewing the cases. Can you help me out?"}
{"completion": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 206, "text": "query: Develop a system to count how many cats and dogs are in the image."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: Our security team wants to know if there is violence or other harmful activity happening in the surveillance videos."}
{"completion": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"completion": 730, "text": "query: They want to include Marathi voice over in their advertisments. Help them with the text-to-speech for the Marathi language."}
{"completion": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 74, "text": "query: Our company would like to create an automatic image captioner that could provide relevant and coherent descriptions for social media platform pictures."}
{"completion": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 313, "text": "query: I want to decorate my astronomy room with some high-quality computer-generated images of galaxies. How can I achieve this?"}
{"completion": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"completion": 612, "text": "query: A web-based chat application needs to implement text conversation between the user and the AI virtual assistant. Utilize the Cadet-Tiny model to achieve this functionality."}
{"completion": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"completion": 541, "text": "query: As an English-speaking tour guide in Spain, I often need quick translations between Catalan and Spanish. Can you help me with a language model for this task?"}
{"completion": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 245, "text": "query: Create an image segmentation model that identifies and separates objects and background in a photo taken during a walk in the park."}
{"completion": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"completion": 301, "text": "query: We are conducting a research project for an astronomy magazine's cover. We could use some images of the universe."}
{"completion": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"completion": 540, "text": "query: Translate a machine error message from English to Italian."}
{"completion": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"completion": 674, "text": "query: As a medical researcher, I am working on clinical texts. Help me guess missing words or phrases in these texts."}
{"completion": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"completion": 19, "text": "query: To help my team answer the client's questions more efficiently, I need a question encoder model able to create an embedding for questions to better compare the answers stored in our database."}
{"completion": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"completion": 416, "text": "query: We are currently planning a marketing campaign in Silicon Valley. We need to understand the key entities mentioned in a report."}
{"completion": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 322, "text": "query: Implement a sports activities recognition system for a sports streaming platform to suggest popular videos in various categories like High Jump, Long Jump and Discus Throw, etc."}
{"completion": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"completion": 841, "text": "query: We need a speaker diarization tool for a meeting to identify different speakers and transcribe their speech."}
{"completion": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"completion": 121, "text": "query: The company is working on a document analysis tool and needs to extract answers to specific questions from the text."}
{"completion": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"completion": 453, "text": "query: We are a startup and want to analyze a CSV file of products to identify which product has the highest price."}
{"completion": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"completion": 633, "text": "query: We need to automatically translate user comments on our website from their native language into English."}
{"completion": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"completion": 787, "text": "query: We are AI researchers who are building a tool that translates English speech to Hokkien speech in real time."}
{"completion": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"completion": 860, "text": "query: We are building an AI-based mobile app that can identify species of Iris flowers based on their measurements. Can you give us some insights using your model?"}
{"completion": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"completion": 229, "text": "query: Global Offensive (CS:GO) match."}
{"completion": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"completion": 815, "text": "query: Our customer analyzing company needs a technology that helps our operators to verify speakers' identity."}
{"completion": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"completion": 175, "text": "query: We are developing a home security system that can respond to intrusions by identifying any people in the security camera feed by analyzing their images."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: A customer support agent requires sentences to be rephrased so as to form useful conversational responses on the go."}
{"completion": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 891, "text": "query: We are building a game where the character balances a pole on a cart. Can you please assist us in finding a solution?"}
{"completion": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"completion": 626, "text": "query: I am a writer trying to use a creative model to come up with a full description of a character based on \"Her name is Ella, and she is a detective.\"."}
{"completion": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 305, "text": "query: As an entomologist, I want to generate images of butterflies to use for educational purposes."}
{"completion": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 246, "text": "query: We need to automatically segment vehicles in images from traffic cameras to analyze traffic patterns."}
{"completion": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"completion": 773, "text": "query: Imagine we are a transcription company and want to provide audio transcription services for the Vietnamese market."}
{"completion": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"completion": 136, "text": "query: Our company requires an intelligent system that processes scanned invoices and answers questions about their contents."}
{"completion": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"completion": 780, "text": "query: We are building an application that can separate background noises, voice, speech from an audio file or recording."}
{"completion": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"completion": 841, "text": "query: I need a script to analyze an audio file to detect who is speaking when, for a house security system with multiple microphones broadcasting in real-time."}
{"completion": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"completion": 481, "text": "query: In our education software, we are looking for answering student's questions."}
{"completion": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"completion": 317, "text": "query: Develop a model that can detect and label objects in a video sequence. The objects should be bounding boxes and automatically created object labels."}
{"completion": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"completion": 607, "text": "query: We are building an AI-driven speechwriting tool for the company and are in need of a way to generate a starting point for a speech about technology."}
{"completion": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"completion": 439, "text": "query: We want to create a model for a sports news application that can answer user queries about statistics from a given table."}
{"completion": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"completion": 185, "text": "query: I am a farmer, and I'd like to use a small AI model to classify diseases in beans by analyzing images from my phone."}
{"completion": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 421, "text": "query: My 5-year-old daughter is learning grammar; create a tool that enlightens her about several grammar aspects."}
{"completion": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"completion": 780, "text": "query: We have many recordings with lots of background noise. Is there a solution to remove these noises from the recordings?"}
{"completion": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"completion": 836, "text": "query: We need to process voice recordings and remove silences to save storage space. Write a code that does voice activity detection and removes the silent parts."}
{"completion": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"completion": 528, "text": "query: We need a program to translate English to German so that users can understand when reading about foreign news in German."}
{"completion": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 279, "text": "query: \"It's the little things that make life beautiful.\""}
{"completion": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 753, "text": "query: I have an audio file with spoken language in it. Please help me transcribe the audio to text."}
{"completion": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"completion": 241, "text": "query: Show me how cars, roads and buildings can be segmented in an urban environment."}
{"completion": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"completion": 48, "text": "query: Can you give me a tool that could take the description of a scene and generate an image for me?"}
{"completion": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"completion": 470, "text": "query: I am working on a Korean QA bot for the learning purpose of kids going to primary school. Can you guide me where should I start?"}
{"completion": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"completion": 493, "text": "query: very good, good, average, bad, very bad."}
{"completion": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"completion": 35, "text": "query: Have a new startup focusing on cloud services. I want to create marketing materials with images based on key phrases like \"cloud computing,\" \"secure data storage,\" \"high-speed internet,\" and \"scalable solutions.\" Can you generate images based on these phrases?"}
{"completion": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"completion": 285, "text": "query: We need to restore an old and damaged photo. The damage includes stains and scratches, so we need to refill the missing areas."}
{"completion": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"completion": 31, "text": "query: A car magazine wants to use AI-generated art in their next issue. They are specifically looking for a 1950s-style illustration of classic cars parked at a drive-in movie theater."}
{"completion": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 233, "text": "query: Our company is building a software to analyze satellite images for land use. We need to segment different regions in the images."}
{"completion": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"completion": 50, "text": "query: A fictional story needs beautiful illustrations. Generate an image depicting \"a brave knight fighting a ferocious dragon in a dark forest\"."}
{"completion": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"completion": 719, "text": "query: As a media company, we need a way to convert text to speech for an upcoming podcast project."}
{"completion": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"completion": 681, "text": "query: You are building a code editor tool that needs to autocomplete code snippets for a developer."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: We are a photo editing company, and we need to deblur images using AI."}
{"completion": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"completion": 97, "text": "query: A toy company has asked us to generate a 10-second video of an animated robot playing football."}
{"completion": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"completion": 683, "text": "query: We are working on a chatbot that needs to fill in the missing words using an AI model."}
{"completion": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"completion": 515, "text": "query: We are building an e-learning platform, and I want to classify user queries into categories such as academics, technical issues, payment, and account management."}
{"completion": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"completion": 273, "text": "query: Our client needs to show images of their products in higher resolution to better showcase their features on their website. Enhance the images' resolution."}
{"completion": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 190, "text": "query: As a software engineer at an AI-powered photo sharing app, we need to classify user uploaded images into various categories."}
{"completion": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 426, "text": "query: We are going to create an assistant for a news website that can analyze the given texts and highlight all the named entities."}
{"completion": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"completion": 890, "text": "query: We are building a real estate website. Implement a model to predict housing prices based on input features such as location, number of rooms, and age of the property."}
{"completion": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"completion": 619, "text": "query: We're building a tool for developers to generate Python code snippets. Please set up a model that can help us achieve this."}
{"completion": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"completion": 732, "text": "query: I need to translate an audio file in Spanish to English and keep it in the same audio format."}
{"completion": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"completion": 763, "text": "query: Provide instructions to convert spoken language into written text using the wav2vec2-xls-r-300m-phoneme model."}
{"completion": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"completion": 35, "text": "query: Generate an image from a description to move into a fully furnished living room."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: Our firm is interested in building a robot that could navigate the Gym Hopper environment with an expert level of performance. Therefore, we need to find a suitable pre-trained model."}
{"completion": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 739, "text": "query: Develop an AI for making announcements at train stations, based on written text. The target audience speaks French and expects a male voice."}
{"completion": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"completion": 897, "text": "query: I want to beat my friend playing a LunarLander game by training and using a machine learning model."}
{"completion": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"completion": 406, "text": "query: A transcription project requires the punctuation restoration for a text in multiple languages, including English, French, Italian, and German."}
{"completion": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"completion": 572, "text": "query: I want to create a conversational AI chatbot that can help me book a hotel room."}
{"completion": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"completion": 455, "text": "query: As a teacher, I would like a solution to easily answer questions from students about complex tables of data to save time."}
{"completion": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 63, "text": "query: We have received several printed documents scanned in JPG format. Identify the text in those images and extract it."}
{"completion": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"completion": 792, "text": "query: Our company recently decided to produce a podcast. We need help with noise reduction for the target audio."}
{"completion": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"completion": 29, "text": "query: We have a large set of information and we need the model to retrieve the most relevant information to a given query."}
{"completion": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 893, "text": "query: As a video game developer, I need to observe a trained soccer playing agent for potential integration into my new game."}
{"completion": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"completion": 777, "text": "query: I am a musician. I want to isolate the vocals and instruments from a recording of a live performance."}
{"completion": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"completion": 915, "text": "query: We need to rate customer reviews for our products on an online marketplace by identifying positive and negative comments."}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: I am building the product which needs information retrieval based on queries, by ranking the passages enclosures which simplifies or justifies query."}
{"completion": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"completion": 35, "text": "query: I want to generate a unique abstract artwork for my home based on the prompt \"Magical Winter Landscape\"."}
{"completion": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"completion": 290, "text": "query: Our company is developing an art application, and we want to generate a church image using Google's DDPM model."}
{"completion": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 309, "text": "query: A comic book company wants to create a butterfly character. Generate a butterfly image to inspire their design."}
{"completion": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"completion": 201, "text": "query: We need an algorithm to sort images based on their similarity to each other in a large dataset."}
{"completion": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"completion": 284, "text": "query: As an illustrator looking for inspiration, I'd like to generate an anime image from a text prompt."}
{"completion": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"completion": 136, "text": "query: Our tax team needs to extract the total amount from tax documents. We would like to use a model for this purpose."}
{"completion": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"completion": 825, "text": "query: The customer support department wants to analyze the sentiment of audio recordings in incoming calls. The audio recordings are in Spanish. They need to know the sentiment of each call."}
{"completion": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 242, "text": "query: We need to create a tool that allows us to segment and identify elements such as people, landscapes or objects in digital images."}
{"completion": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"completion": 894, "text": "query: I am working on a robotics project that requires the control of a bipedal walker. We need to use a reinforcement learning model to help control walking in virtual simulation."}
{"completion": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"completion": 607, "text": "query: I am an author, and I have writer's block. I need help with ideas to continue the story of a detective who is trying to solve a murder mystery."}
{"completion": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"completion": 4, "text": "query: A researcher uses our platform to extract features from a given text for further analysis in a text classification task."}
{"completion": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"completion": 473, "text": "query: We need to answer long questions based on longer paragraphs."}
{"completion": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"completion": 160, "text": "query: Using our AI system, help our users to create an AI model to control an NPC (van) in the game to properly drive in the traffic."}
{"completion": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"completion": 390, "text": "query: We need to generate multiple variations of the same sentence. We can use a paraphrase-based framework for this task."}
{"completion": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"completion": 420, "text": "query: We are writing articles for our website, and we need to analyze the text to extract important entities like names, places, and organizations."}
{"completion": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 753, "text": "query: We want to help people in listening comprehension by transcribing the audio into text."}
{"completion": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"completion": 805, "text": "query: We need an application to recognize different emotions for a call center."}
{"completion": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"completion": 123, "text": "query: As a scientist, I want a model that analyzes the content of a document and answers questions about it. The document will be provided as an image, and the context and question will be in text format."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: I need a customized booking system for a travel agency in both English and Arabic languages. Translate the English sentence \"Thank you for booking with us, we will send you the itinerary shortly.\" to Arabic."}
{"completion": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"completion": 464, "text": "query: Please provide a method for answering questions from an input text. It should be fast and accurate."}
{"completion": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"completion": 896, "text": "query: The regional finals for a self-learning robot are coming up, and we need to train a model on the Gym Hopper environment in order to perform well."}
{"completion": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"completion": 874, "text": "query: Implement a system to predict the carbon emissions of several cars based on variables like production year, kilometers driven, etc."}
{"completion": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"completion": 286, "text": "query: Design a news cover image of a food festival that is going to be held next week."}
{"completion": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 503, "text": "query: In a debate competition, the topic is unkwown. Generate an opening statement and classify it as being in favor or against."}
{"completion": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"completion": 272, "text": "query: In an app, when users input a prompt, we want to generate images based on the description."}
{"completion": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"completion": 377, "text": "query: A financial news company needs to determine the sentiment of the daily news headlines to adjust the contents accordingly."}
{"completion": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"completion": 805, "text": "query: We are an educational institution that wants to detect student emotions through their voices during online classes."}
{"completion": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"completion": 416, "text": "query: Discover the names of people, organizations, and locations in the given text."}
{"completion": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"completion": 182, "text": "query: Analyze the provided image and detect the object."}
{"completion": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"completion": 182, "text": "query: I am working on online photo gallery where my clients can upload their photographs with different type of contents. Set up an image classifier based on the pretrained BEiT model that can identify the content within them."}
{"completion": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 161, "text": "query: Make use of a deep-learning algorithm to predict the depth estimation of an object in a given image."}
{"completion": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"completion": 416, "text": "query: Detect the named entities in a given piece of text."}
{"completion": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"completion": 109, "text": "query: Create a system that can answer questions based on an image for an app that helps visually impaired users."}
{"completion": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"completion": 547, "text": "query: We have a news platform, we need to have short summaries for our longer articles for people who are in a hurry."}
{"completion": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"completion": 222, "text": "query: I am creating an application for detecting the presence of planes in aerial images. I need to use a pre-trained model to identify the planes."}
{"completion": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 237, "text": "query: We are a green tech company involved in solar panel installations. We need to segment images captured by drones to analyze the solar panels and roofs."}
{"completion": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"completion": 215, "text": "query: Detect objects in a given video game screenshot for better gameplay insights and visualizations."}
{"completion": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"completion": 587, "text": "query: Our customer wants a chatbot for their website that can respond to client inquiries fluently."}
{"completion": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"completion": 217, "text": "query: A researcher needs to extract a table from a document to analyze the data they need."}
{"completion": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 63, "text": "query: Generate text from the given image of a printed document."}
{"completion": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"completion": 920, "text": "query: A user of our voice-based assistant wants to transcribe an audio input recorded on their phone. We want to provide them with text so they can interpret their piece of audio without listening to it."}
{"completion": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"completion": 748, "text": "query: A new audio book platform wants to convert audio recordings of books into user-readable text format with correct punctuation and capitalization. Build a solution to automatically transcribe the audio books."}
{"completion": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"completion": 11, "text": "query: As a medical student, I am building a search engine for medi terms that returns the most relevant medi terms. I want to extract embeddings for a given medical term so my search engine can find related terms."}
{"completion": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"completion": 126, "text": "query: We need a question answering system for multimodal documents."}
{"completion": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 314, "text": "query: Develop a creative application that does not require and input data, like writing stories but with images."}
{"completion": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"completion": 197, "text": "query: My company wants to develop a product to quickly classify images. They want a pretrained model to be used for street signs, cars, and other common objects."}
{"completion": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 322, "text": "query: Let's say you have a video and you need to classify the main action in the video. How would you implement it?"}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: Our agriculture company needs an AI model to recognize plant species by analyzing images. We are not limited to specific species and need to address unknown species."}
{"completion": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"completion": 778, "text": "query: A conference is being held and there are participants speaking very softly. We need to improve the speech quality for people to understand."}
{"completion": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 85, "text": "query: You are an expert in writing a code that reads an image and converts into text. Create a sample code that will describe the specific image."}
{"completion": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"completion": 80, "text": "query: For our marketing team, please extract a textual description of a given image."}
{"completion": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"completion": 650, "text": "query: In our content strategy plan, we want to know the summary of long news articles. Suggest a suitable model for summarizing long texts."}
{"completion": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"completion": 266, "text": "query: I need a tool to predict coloring on scribbled images based on the given texts. Help me to create a model for that."}
{"completion": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 186, "text": "query: Create a program to identify objects in images, making use of MobileNet V1 model."}
{"completion": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"completion": 790, "text": "query: We are building an audio-visual radio app and want to use an Asteroid model for denoising audios of radio broadcasts."}
{"completion": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"completion": 211, "text": "query: Develop a system that can provide real-time object detection for a security camera."}
{"completion": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"completion": 886, "text": "query: A marine research company wants to predict the weight of fish based on different features such as length, width, and height. Let's provide them with a model that can perform this task."}
{"completion": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"completion": 750, "text": "query: Give me an example to build a virtual assistant that helps in recording meeting minutes by detecting overlapping speeches."}
{"completion": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"completion": 886, "text": "query: We are a seafood company, and we need to predict the weight of a fish based on its characteristics."}
{"completion": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"completion": 666, "text": "query: I have recieved a text with some missing words that I want to complete using Artificial intelligence. Please suggest a way."}
{"completion": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 243, "text": "query: Automatically turn grayscale pictures into a colored image by applying image segmentation for detecting regions of certain objects."}
{"completion": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"completion": 639, "text": "query: We're an AI language translation application wanting to offer new languages. We need to translate answers to most common travel phrases into German."}
{"completion": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 444, "text": "query: I work for a talent agency, and I need a tool that answers queries about the actors' details from a database in natural language format."}
{"completion": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"completion": 511, "text": "query: I'm working on customer reviews analysis. I want to classify the review as positive or negative."}
{"completion": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"completion": 412, "text": "query: \"I stayed in Los Angeles and Santa Monica while I was on vacation in California last month.\""}
{"completion": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 235, "text": "query: Our customer is a city planner, looking for input to better understand green spaces and structures in a city. We are working on dividing the image captured by a drone into several meaningful semantic regions based on their content."}
{"completion": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"completion": 375, "text": "query: A Chinese e-commerce website needs a zero-shot image classification system to automatically categorize products in their inventory."}
{"completion": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"completion": 367, "text": "query: Identify the type of objects shown in this image - https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/pokemon.jpeg"}
{"completion": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 313, "text": "query: An astrophysicist needs an image of a galaxy-like shape for a research project."}
{"completion": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"completion": 870, "text": "query: We need to estimate the carbon emissions of vehicles and request you to calculate so by giving the input specifications."}
{"completion": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"completion": 40, "text": "query: We are a media company in need of a creative way to generate multiple illustrations based on textual descriptions."}
{"completion": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"completion": 801, "text": "query: I want to create a real-time translation application that can be used to translate spoken language from Romanian to English during meetings."}
{"completion": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"completion": 253, "text": "query: We are running a company that needs image segmentation to better understand the different types of items in the product catalog."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: We are an international organization who prepares to make an announcement to the Arabic speaking-world, the announcement is in an .txt format. We need a translator."}
{"completion": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"completion": 196, "text": "query: I'm working on a project to detect whether an anime art is generated by an AI or made by a human artist. Let me know the best model for this problem."}
{"completion": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"completion": 629, "text": "query: Can you write a query which translates the words \"I love programming\" from English to German?"}
{"completion": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"completion": 509, "text": "query: \"The quick brown fox jumps over the lazy dog.\""}
{"completion": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"completion": 857, "text": "query: I need to predict the classes of CO2 emissions for a set of samples in a CSV dataset."}
{"completion": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"completion": 612, "text": "query: I am a teacher, and I would like to build an interactive tool for my students to practice their English speaking skills. They should be able to type a sentence or a question, and the model should give them a response."}
{"completion": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"completion": 181, "text": "query: We want to create a recommendation algorithm for our clothing store website. Analyze the new winter collection images and identify the main articles of clothing."}
{"completion": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 671, "text": "query: I am writing a science-fiction themed novel. Help me complete the sentences by predicting appropriate words in place of any blank areas in the sentences."}
{"completion": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 75, "text": "query: A historian wants to digitalize a handwritten document. Can you provide a Python program that would convert the image of the document into text using the TrOCR model?"}
{"completion": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"completion": 871, "text": "query: "}
{"completion": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"completion": 386, "text": "query: You are a student working on a research project, and you need to find relevant information related to a specific topic. Rank the passages provided based on their relevance to your research question."}
{"completion": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"completion": 274, "text": "query: We need to create a painting of a forest scene with a river flowing in it."}
{"completion": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"completion": 457, "text": "query: We want to develop a tool to help people find answers from sales data in tables, like job titles, products and prices. Please use a suitable model to achieve this."}
{"completion": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"completion": 308, "text": "query: We want to create an interactive website showcasing different types of butterflies. Visitors should be able to view generated images within each category."}
{"completion": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"completion": 617, "text": "query: Develop a smart AI chatbot to instantaneously generate human-like informal text given a conversational input on any topic."}
{"completion": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"completion": 652, "text": "query: A school teacher is teaching human anatomy. She wants auto-generated questions from her text book."}
{"completion": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"completion": 868, "text": "query: Analyze provided data to predict the housing prices in the US."}
{"completion": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"completion": 535, "text": "query: I have an article I need to translate from English to French and then summarize it for a brief presentation."}
{"completion": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"completion": 868, "text": "query: We have a real estate company, and would like the model to predict the housing prices based on the property features."}
{"completion": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"completion": 15, "text": "query: We have multiple audio files of people speaking, our team wants to analyze some extracted features to find patterns for a research project."}
{"completion": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"completion": 263, "text": "query: We are creating video game concept art, and I would like to stylize a character as an oil painting while preserving its important features."}
{"completion": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 814, "text": "query: We need to classify the emotion in a customer service call recording to assess the satisfaction level of the customer."}
{"completion": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"completion": 740, "text": "query: I'm building a voice assistant that needs to read out text in a Taiwanese Hokkien accent. How can I use the Text-to-Speech model to convert text to speech in this accent?"}
{"completion": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"completion": 780, "text": "query: We have a recording of a business conference. It has a lot of background noise. We need to separate the clean speech from the noisy background."}
{"completion": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"completion": 160, "text": "query: We would like to build a product that takes input from python codes and translates them into tutorials with explanations."}
{"completion": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"completion": 651, "text": "query: I am writting a story in english language. Wanted to make sure sentences don't have grammar mistakes in order to make the story more authentic. "}
{"completion": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"completion": 850, "text": "query: Our finance team needs a model to determine if a person makes over 50k a year based on provided data."}
{"completion": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"completion": 9, "text": "query: I am making a multilingual decision-support system app that transfers smartphone captions to different languages. Add the feature to classify Indonesian sentences text to retrieve the hidden context."}
{"completion": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"completion": 86, "text": "query: Design a model to recognize text in an image from a handwritten document."}
{"completion": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"completion": 737, "text": "query: We are creating an audiobook for a popular Chinese novel. I need your assistance to convert a text sentence into speech."}
{"completion": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"completion": 737, "text": "query: As a news website company, we want to translate our written articles into audible content for visually impaired visitors."}
{"completion": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"completion": 750, "text": "query: Our team is working on transcribing a podcast episode. We need to identify the parts where two or more speakers are speaking simultaneously."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: An advertising company wants to rephrase their slogans without losing their original meaning. Help them achieve this."}
{"completion": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"completion": 537, "text": "query: I have a website providing tour guiding in the Alps. It has German content, and I need to translate it to Spanish."}
{"completion": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"completion": 398, "text": "query: Help me create a tool that can identify if an email text makes sense or if it is a gibberish message."}
{"completion": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"completion": 120, "text": "query: We are a law firm, and we want to extract information from legal documents to answer our clients' specific questions."}
{"completion": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"completion": 360, "text": "query: Develop a solution to identify the category of the location given an image URL."}
{"completion": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"completion": 693, "text": "query: To provide personalized news suggestions, I want to make sure that the suggested articles are related to the user's preferences."}
{"completion": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"completion": 469, "text": "query: A client wants to build an application that can answer questions in legal documents. Can you build me a simple text-based question-answer model?"}
{"completion": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"completion": 396, "text": "query: Our political news chatbot needs to identify which text messages from users are asking questions, and which are just statements."}
{"completion": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 139, "text": "query: Jennifer wants to create a chatbot for the students. The chatbot needs to receive questions as input and return answers after processing the school documents."}
{"completion": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"completion": 628, "text": "query: A new teacher is trying to prepare questions for the quiz for middle school students. Paraphrase one of the questions for her to help her students better understand the question."}
{"completion": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"completion": 878, "text": "query: I want to build a software tool that estimates the carbon emissions of different activities by using machine learning. Help me to use your API."}
{"completion": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"completion": 368, "text": "query: A Korean food brand wants to automatically categorize their Instagram photos into various product collections like snacks, drinks, and main dishes. Help them find suitable technology."}
{"completion": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"completion": 746, "text": "query: Our client is a radio station that aired an announcement in German and wants to convert it to a digital audio format."}
{"completion": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 271, "text": "query: To create an illustrated storybook for children, I need to generate images based on the story's text."}
{"completion": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"completion": 606, "text": "query: My website requires a tool for generating short stories when given a prompt."}
{"completion": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"completion": 787, "text": "query: Some people at our company are having difficulty understanding the British English dialect. Therefore, we would like to develop a program that will help everyone understand the content each other shares by translating it into American English."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: Develop an application for vehicles that allows depth estimation for detecting proximity to obstacles."}
{"completion": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"completion": 846, "text": "query: We need to process a conference call recording to find out how many speakers were involved and separate their speech segments."}
{"completion": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 139, "text": "query: We need to be able to answer questions based on textual and visual information. Please pull up the necessary components."}
{"completion": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"completion": 792, "text": "query: Build me a system that can separate the audio of two people speaking at the same time in a recorded audio file."}
{"completion": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 234, "text": "query: We are working on a home improvement application that requires image segmentation. Find an image segmentation model and provide code to segment an image."}
{"completion": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"completion": 505, "text": "query: We need to classify the category of a news article. Provide a method for classifying the news article."}
{"completion": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"completion": 392, "text": "query: Build a solution to scan and monitor comments on a website for detecting inappropriate content or toxic behavior."}
{"completion": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"completion": 369, "text": "query: Find the representative text for different images about animals through the available Chinese texts."}
{"completion": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"completion": 839, "text": "query: We need to implement a feature to know when someone is speaking or not in a video call."}
{"completion": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"completion": 297, "text": "query: I want to design a conversational AI that describes generated images of art from different epochs in human language."}
{"completion": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"completion": 773, "text": "query: I want to transcribe a Vietnamese audio file using a speech recognition model."}
{"completion": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"completion": 574, "text": "query: We want a summarized version of a news article about Rishabh Pant's statement on a recent incident during a Test match."}
{"completion": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"completion": 915, "text": "query: My company needs to make decisions on recommending products to users based on their text reviews. We need to analyze the sentiment of those reviews."}
{"completion": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"completion": 929, "text": "query: Our company works with annual reports in table format. We need a tool to process these reports and extract the rows and columns within them."}
{"completion": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"completion": 40, "text": "query: Our customer is an advertising firm. We want to design a billboard about an astronaut riding a horse on Mars. Generate this image for us."}
{"completion": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"completion": 853, "text": "query: Modify the given code to appropriately load the model, and predict the income category for a given set of input features related to the Adult dataset."}
{"completion": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 698, "text": "query: Identify whether two given texts are semantically similar and translate those texts into vectors."}
{"completion": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 600, "text": "query: I need my chat assistant to suggest healthy dinner recipes when asked by users."}
{"completion": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"completion": 468, "text": "query: Recommend an NLP model for a mobile app that can answer questions based on a provided context or text. The model should be relatively lightweight and have good accuracy."}
{"completion": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"completion": 436, "text": "query: We need to develop an application that can identify entities such as names, locations, and dates in a news article. Show how this can be done using the available API."}
{"completion": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 276, "text": "query: A design studio needs to generate images from text to help with their visual projects."}
{"completion": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"completion": 254, "text": "query: We would like to build a monitoring system for identifying and segmenting potholes on the road using computer vision."}
{"completion": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"completion": 854, "text": "query: We want to analyze the possibilities of different outcomes of a set of different flowers."}
{"completion": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"completion": 485, "text": "query: I am writing a Chinese news summarizing application. The application should be able to find the answers to users' questions about the news articles."}
{"completion": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"completion": 550, "text": "query: A user wants to translate their French essay to Spanish for their Spanish class."}
{"completion": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 570, "text": "query: I'm building a customer support chatbot to handle user's inquiries. I want the model to generate human-like responses upon the user's request."}
{"completion": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 159, "text": "query: I am building a robot that helps people understand how far away objects are. I need to estimate the depth of objects in a given image."}
{"completion": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"completion": 412, "text": "query: The newspaper company wants to analyze articles to understand the entities mentioned in them, such as people's names, places, or organizations."}
{"completion": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"completion": 590, "text": "query: Let's assume that we are a software company offering programming tutorials and support. Help me set up a conversational bot to answer users' code-related inquiries."}
{"completion": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"completion": 632, "text": "query: Let's make a summary of the academic paper I just read."}
{"completion": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"completion": 30, "text": "query: Our publishing agency is working on a children's book about space. We need an illustration of an astronaut playing with a puppy on the Moon."}
{"completion": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"completion": 850, "text": "query: We need to predict whether a person makes over $50k a year based on their US Census Income Dataset attributes."}
{"completion": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"completion": 212, "text": "query: I need to classify the objects in a given image to categorize it for my website."}
{"completion": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"completion": 225, "text": "query: We are a company working on safety applications. We need to identify if the workers are wearing hard hats or not."}
{"completion": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"completion": 476, "text": "query: I am a student, and I am studying for a test on history. Help me find an answer to the question \"Who first discovered America?\" from the text that I've provided."}
{"completion": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"completion": 239, "text": "query: In a fashion retail company, we want to create an app that automatically segments clothes from an image for designing virtual fitting rooms."}
{"completion": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"completion": 469, "text": "query: Our legal team needs to extract information from various legal documents by asking questions. Provide a solution to accomplish this task."}
{"completion": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 154, "text": "query: In order to build a better navigation system, the company needs to estimate the depth of objects in the environment."}
{"completion": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"completion": 719, "text": "query: Our company is running a podcast channel that contains environmental topic. Please create an intro sentence and convert the text to speech."}
{"completion": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"completion": 830, "text": "query: Analyze the message to my taxi driver in an audio file in German and determine the emotion in that clip."}
{"completion": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 501, "text": "query: A travel agency wants to analyze their customer feedback to determine whether their customers are happy or upset."}
{"completion": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"completion": 29, "text": "query: Implement a product where clients can ask questions about products or destinations, and the system will provide answers based on contextual information."}
{"completion": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"completion": 112, "text": "query: Identify the character's action in a thumbnail image while watching their favorite TV series."}
{"completion": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"completion": 818, "text": "query: We're building a virtual assistant to support people's practice of spoken numbers (0-9) by verifying if they pronounced the digits correctly. Show me how to use this model to accomplish this task."}
{"completion": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"completion": 681, "text": "query: I am a software engineer. I want to use a code completion tool that provides suggestions for coding in languages like Python, Java, and JavaScript."}
{"completion": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"completion": 123, "text": "query: Let's extract the answers from the document. Use the model to find the answers when given the bounding boxes and questions."}
{"completion": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"completion": 380, "text": "query: We are building a large scale chatbot, which needs an understanding of the emotional content of a user's input."}
{"completion": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 251, "text": "query: I'm researching about computer vision image segmentation. I need a model that can analyze images and identify different objects within the image, as well as determine their exact boundaries."}
{"completion": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"completion": 884, "text": "query: Our data science team is working on customer tipping data. We need a way to perform regression on the tipping information for further analysis."}
{"completion": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"completion": 621, "text": "query: I need to code a simple program using text. Let's start with some Python code to print \"Hello, World!\"."}
{"completion": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"completion": 226, "text": "query: Your advertising company is looking for a solution that will help them detect objects in images as part of their marketing campaigns."}
{"completion": 69, "text": "document: This is an image captioning model training by Zayn"}
{"completion": 69, "text": "query: Imagify needs images to be captioned for kids to learn names of animals and objects. Can you give them a tool to simplify that?"}
{"completion": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"completion": 885, "text": "query: I own a restaurant and I want to predict the tips that servers will receive based on various factors like total bill amount, gender of the server, if they smoke, day of the week, time of day, and size of the group served."}
{"completion": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"completion": 624, "text": "query: Our company is working on a writing assistant tool. We need to generate content that aligns with a given prompt."}
{"completion": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 714, "text": "query: We want to build an application to detect similar articles in the news. Please suggest an API that can generate sentence embeddings for similarity comparison."}
{"completion": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 697, "text": "query: Design an algorithm that measures how similar two movie reviews are to help a recommendation system find movies with similar themes."}
{"completion": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 365, "text": "query: We got a zip file which contains pictures of objects that need to be categorized into three classes \"animals\", \"cars\", and \"plants\"."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: Our goal is to analyze satellite images by identifying and segmenting the buildings."}
{"completion": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"completion": 239, "text": "query: We are developing a virtual change-room application, and we need to segment clothes on a person."}
{"completion": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"completion": 809, "text": "query: Our company is producing cars and we need to know if the engine sound is normal or if it indicates a problem."}
{"completion": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"completion": 219, "text": "query: We want to detect and visualize all the heads of individuals in an image we have in a football game by using an API."}
{"completion": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"completion": 259, "text": "query: The manufacturers experienced several defects in printed circuit boards (PCBs). They want to detect and segment these defects automatically."}
{"completion": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"completion": 378, "text": "query: We need to analyse the sentiment of a company's latest earnings report."}
{"completion": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"completion": 595, "text": "query: I am working on a conversational AI project and need a chatbot that can hold a conversation and respond like a character from a video game."}
{"completion": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"completion": 737, "text": "query: Our startup company is working on a Chinese language audiobook reader. Design a system to read Chinese text and process it into audio."}
{"completion": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"completion": 823, "text": "query: A client wants us to build a program that can classify audio files based on digit command (0-9). Provide the necessary implementation."}
{"completion": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"completion": 393, "text": "query: My company has a German-speaking customer base, and we need to analyze their feedback sentiments."}
{"completion": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"completion": 721, "text": "query: I need an application that can create realistic human speech from text. The text will be created by a speech recognition software."}
{"completion": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"completion": 254, "text": "query: We are trying to develop a smart-city app that can perform road condition monitoring. It should be able to detect potholes from an image."}
{"completion": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 687, "text": "query: We need to know whether two sentences, one being a news headline, and the other being an advertisement description, are similar."}
{"completion": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"completion": 921, "text": "query: Our company's website is lacking in user engagement. We need a conversational assistant to interact with site visitors and improve their experience."}
{"completion": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 275, "text": "query: We will provide images related to one text so we need to create an image related to the text to offer in related images to users."}
{"completion": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"completion": 883, "text": "query: A company wants to predict the carbon emissions of their operations based on historical data and optimize their carbon footprint."}
{"completion": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 124, "text": "query: \"What is the title of this document?\""}
{"completion": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"completion": 152, "text": "query: I'm a software engineer working on a robot that can walk in unfamiliar terrain. I need an API to detect depth from monocular images so the robot knows where and how to step."}
{"completion": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"completion": 811, "text": "query: I want to predict emotions from an audio file using the \"Rajaram1996/Hubert_emotion\" model."}
{"completion": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 434, "text": "query: We are nutritionists trying to get insights from a list of food items and their nutritional values in a table. Extract information about the nutrient content of the food according to our customers' requirements."}
{"completion": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"completion": 864, "text": "query: We need to develop a tool that can identify which buildings are more likely to have high carbon emissions based on various factors."}
{"completion": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"completion": 743, "text": "query: A German company wants to create an audio tour of their factory for visitors. We need to convert the factory tour script from text to speech."}
{"completion": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 715, "text": "query: As a language researcher, I need to find the similarity between sentences to cluster them by similarity. What kind of API call should I make?"}
{"completion": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 403, "text": "query: We have an article about the presidents of the United States. Extract the names of people and their locations in the article."}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: Please analyze the photos to understand the unique tastes and preferences of a person who loves cartoon characters."}
{"completion": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"completion": 386, "text": "query: Our company deals with answering questions, and we need to rank the answers relevance to provide the best answer to the customers."}
{"completion": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"completion": 569, "text": "query: One of our directors needs the summaries for a series of company updates written in Spanish. Summarize a given text in Spanish."}
{"completion": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"completion": 850, "text": "query: We need to predict if a person's income is above 50k based on demographic factors."}
{"completion": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"completion": 351, "text": "query: I am building a smartphone application that will let users take photos of their pets and classify the breed."}
{"completion": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"completion": 375, "text": "query: We are an e-commerce company. We need a tool to help us classify product images without having prior labeled data."}
{"completion": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 364, "text": "query: We are a startup company looking for a way to classify the type of bird from an image."}
{"completion": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"completion": 645, "text": "query: Translate a given English sentence to Romanian to be used in a chat product."}
{"completion": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"completion": 860, "text": "query: Detect the species of some given Iris flowers based on the measurement of sepal length, sepal width, petal length, and petal width."}
{"completion": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"completion": 564, "text": "query: Help me summarize an important news article to get the main information quickly."}
{"completion": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"completion": 608, "text": "query: You are developing content for a game with a medieval setting. Write a short story that takes place in a fantasy world."}
{"completion": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 898, "text": "query: Develop a reinforcement learning game that is able to play and interacts with the environment using PongNoFrameskip-v4 reinforcement learning system."}
{"completion": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 324, "text": "query: We have a video streaming platform, and we need to classify the videos in the correct categories to show recommendations to our users."}
{"completion": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"completion": 392, "text": "query: Our customer is an online forum administration team. They are working on filtering abusive comments. We need a model to identify the abusive comments."}
{"completion": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"completion": 887, "text": "query: A stock brokerage wants an algorithm to predict stock prices using historical data from the past 5 years. Please assist them."}
{"completion": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"completion": 163, "text": "query: As a real estate developer, I want to estimate the depth of a room using a depth estimation model."}
{"completion": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"completion": 102, "text": "query: Recently, we developed a home automation system. Please provide the suitable code instructions, if we want to integrate a visual question answering pipeline to assist users with their questions about any visual object within their home."}
{"completion": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"completion": 129, "text": "query: The team wants to extract information from a scanned document, specifically answering some questions based on the document."}
{"completion": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"completion": 615, "text": "query: We want to generate text for our company's blog using AI models."}
{"completion": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 689, "text": "query: I am working on a book recommendation system. I need to find books with similar descriptions to recommend to users."}
{"completion": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"completion": 631, "text": "query: Our team is working on a project to build a digital assistant that generates a sentence given a list of input words but we need to ensure it's a coherent sentence."}
{"completion": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"completion": 839, "text": "query: We are working on an application that identifies natural pauses in speech. Please help us by providing a voice-activity-detection solution."}
{"completion": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 924, "text": "query: \"Discover your new favorite [MASK] at our store now!\""}
{"completion": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"completion": 618, "text": "query: I write a blog about healthy food. I need a catchy title for my next article."}
{"completion": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"completion": 606, "text": "query: I need a story for my new English language book for children, starting with \"In a small village near the mountains...\"."}
{"completion": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"completion": 180, "text": "query: I'm working on a project to categorize user profiles based on their age group in our mobile app. We need to analyze the profile pictures and identify the age ranges."}
{"completion": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"completion": 777, "text": "query: We got a recording from an event, but there's a lot of background noise. Can you separate the main speaker from the rest of the noise?"}
{"completion": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"completion": 920, "text": "query: We are building a voice assistant, and we need to transcribe the user's spoken requests into text."}
{"completion": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"completion": 461, "text": "query: I would like to learn the history of Google. Generate a question that might be asked by someone learning about Google."}
{"completion": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"completion": 830, "text": "query: Let's say I recorded a conversation in German and I want to know the emotions in this conversation. I need a model capable of recognizing emotions in the German language from audio."}
{"completion": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"completion": 129, "text": "query: We have a scanned document with a text. A user needs to get an answer to their question regarding the contents of that document."}
{"completion": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"completion": 295, "text": "query: We want to populate our virtual reality application with 3D virtual bedrooms, and we need images of bedrooms as input data. Generate a bedroom image using the model."}
{"completion": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"completion": 176, "text": "query: As a cataloging system for our library, we need to label books based on their cover images."}
{"completion": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"completion": 781, "text": "query: Can you build a product that translates English spoken works to the French language?"}
{"completion": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"completion": 337, "text": "query: We have a library of videos and need to categorize them into educational, sports, or news videos. In order to achieve the best accuracy, we would like to use a pre-trained model."}
{"completion": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"completion": 414, "text": "query: The legal department of our company has received many new contracts with other companies. They need a quick tool to extract company names."}
{"completion": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"completion": 277, "text": "query: A tourist needs to enhance the resolution of a captured image from a vacation."}
{"completion": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"completion": 143, "text": "query: I'm a student and I want to quickly extract information from a digital invoice in a photo taken by my smartphone."}
{"completion": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"completion": 142, "text": "query: We have a chemical dataset involving various chemical molecules and we want to compute the properties of each molecule."}
{"completion": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"completion": 376, "text": "query: We are developing a chat app and we need to find the language of the user who is sending a message."}
{"completion": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"completion": 882, "text": "query: As an environmental consulting firm, we're helping clients cut down on their carbon emissions. Analyze their emissions data in order to provide suggestions for improvement."}
{"completion": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"completion": 146, "text": "query: We are going to create a set of 3d images. For that, we need to have the depth estimation."}
{"completion": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"completion": 241, "text": "query: Our traffic management department needs assistance in identifying traffic signs, vehicles, and pedestrians from surveillance camera images."}
{"completion": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"completion": 146, "text": "query: We are building a mobile application to estimate the depth of objects in photos taken by users. Use pretrained model that can accurately estimate depth in photos."}
{"completion": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 462, "text": "query: We have a table of imported products from different countries. Find the number of products from Germany."}
{"completion": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 908, "text": "query: Our startup is creating a soccer game platform; we want to train an agent to play it and make it more competitive."}
{"completion": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"completion": 43, "text": "query: We are trying to develop a storybook for kids using AI-generated images based on the text descriptions. Help us generate an image of a \"blue elephant playing soccer with a red ball\"."}
{"completion": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"completion": 778, "text": "query: I have an old recording with a lot of noise. I want to clean it and make it more audible."}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: Create an OCR engine which detects the total amount from an invoice image."}
{"completion": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"completion": 203, "text": "query: We're in the publishing industry and we need a system that helps us detect tables in the documents we process. Can you help us?"}
{"completion": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"completion": 572, "text": "query: I need a chatbot. Can you show me how to create one that can have a conversation with users?"}
{"completion": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"completion": 549, "text": "query: As a content creator, I want to summarize my podcasts and create show-notes for my audience."}
{"completion": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"completion": 550, "text": "query: Implement a machine-translate function that gets as input a french sentence and outputs its spanish equivalent."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: I want to predict the depths of objects in an RGB image. Use a model to read the input image and output the depth map of the scene."}
{"completion": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 724, "text": "query: We are building an audiobook application. We need a feature to read a selected paragraph of the book in Chinese."}
{"completion": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"completion": 754, "text": "query: Our company has developed an app for converting speech to text. We want to use a pre-built machine learning model to transcribe speech recordings."}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: A website for pet adoption features a profile image of each pet. We need to automatically label the images with the type of pet, such as cat or dog."}
{"completion": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"completion": 46, "text": "query: We intend to create a social media post about a scientist studying plants in an underwater laboratory."}
{"completion": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"completion": 488, "text": "query: Develop a recommendation engine which can answer users' questions with high accuracy based on the context provided."}
{"completion": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"completion": 194, "text": "query: I want a digital catalog for the food industry, and I want them to recognize if the food is considered a hotdog or not."}
{"completion": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"completion": 611, "text": "query: Our blog needs a captivating introduction paragraph about the latest advancements in technology."}
{"completion": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 695, "text": "query: A research team is working on a project to cluster research papers based on their abstracts. They need to identify similar abstracts and group them together."}
{"completion": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"completion": 717, "text": "query: I\u2019m studying astronomy and I want to find similar sentences to \u201cThe gravitational pull of a black hole is so strong that not even light can escape.\u201d"}
{"completion": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"completion": 127, "text": "query: We are a financial institution and we need to extract relevant information from our clients' financial documents to answer specific queries."}
{"completion": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"completion": 546, "text": "query: We have a large French article that needs to be summarized efficiently."}
{"completion": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"completion": 493, "text": "query: I am a teacher, I want to classify a sentence into teaching category."}
{"completion": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"completion": 679, "text": "query: \"The sun always rises in the [MASK].\""}
{"completion": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"completion": 733, "text": "query: We are a news website and we want to provide voiceover for our articles in Spanish."}
{"completion": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"completion": 896, "text": "query: A creator is building a game simulation and wants to train an AI to make decisions in the game based on different states. The AI should be able to make decisions while hopping in an environment with varying conditions."}
{"completion": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"completion": 525, "text": "query: We have a Chinese business report that needs to be translated into English as soon as possible."}
{"completion": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"completion": 93, "text": "query: \"This is the story of a brave explorer venturing into a dark and mysterious forest. The explorer overcomes numerous challenges and obstacles, discovering ancient ruins full of secret treasures. Their journey reveals the rich history hidden within the forest, waiting to be uncovered by those brave enough to venture inside.\" Turn this into a video summarizing the scene."}
{"completion": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"completion": 599, "text": "query: I want to create a Russian-speaking chatbot that can make restaurant recommendations."}
{"completion": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"completion": 43, "text": "query: Imagine you are working with a publishing agency. Using the text provided, create a captivating image for the book cover."}
{"completion": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"completion": 573, "text": "query: Implement a conversational chatbot that can help answer questions in different subjects."}
{"completion": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"completion": 704, "text": "query: We are creating an app for finding similar texts for users' input. Can you describe how we could use sentence transformers to help with this task?"}
{"completion": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"completion": 887, "text": "query: I have a large dataset of historical stock prices, and I need a quick and simple regression model to predict the closing price of a specific stock."}
{"completion": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"completion": 146, "text": "query: Our customer needs a depth estimation model to help them analyze the relative depth information of objects in an input image for their 3D rendering project."}
{"completion": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"completion": 286, "text": "query: Generate an image for a new clothing line using computer vision for inspiration."}
{"completion": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"completion": 73, "text": "query: Our mobile app users want to describe the content of the images they capture using their phones. Let's build the image caption generator system."}
{"completion": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"completion": 794, "text": "query: My company works with clients from France, and I need to provide customer support to them over the phone. The tool should be able to translate English speech to French speech."}
{"completion": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"completion": 358, "text": "query: Develop a tool to classify a medical image using BiomedCLIP."}
{"completion": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"completion": 489, "text": "query: We are writing a blog post. Determine the primary source of origin for the chess sport."}
{"completion": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"completion": 308, "text": "query: We are an environmental organization and we plan on creating marketing materials about butterflies. Can you generate some cute butterfly images for us?"}
{"completion": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"completion": 878, "text": "query: We have a dataset including several factors such as fuel consumption and engine size. Our goal is to predict the carbon emission rates for different vehicles."}
{"completion": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"completion": 455, "text": "query: Our teammate needs help understanding the relationship between the revenue and expenses of our company. Assist them by answering questions related to the financial table."}
{"completion": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"completion": 489, "text": "query: I just read an article and want to find an answer to my question, \"What is the main benefit of converting models between FARM and transformers?\"."}
{"completion": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"completion": 416, "text": "query: Extract the named entities like people, organizations, and locations mentioned in a news article about a recent event."}
{"completion": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"completion": 637, "text": "query: We need to create a sentence corrector for our chatbot. Please make a sentence corrector to have our chatbot provide error-free responses."}
{"completion": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"completion": 217, "text": "query: Create an automated process to detect tables in a given set of images, regardless of whether they're bordered or borderless. "}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: Our client is planning an international conference. To greet Russian speakers, we need to convert a text message to speech in Russian language."}
{"completion": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"completion": 205, "text": "query: I recently installed a new security camera. I need to identify the objects in the recorded video."}
{"completion": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"completion": 226, "text": "query: I am starting an e-commerce that sells soccer jerseys. I'll need to detect the presence of soccer jerseys in user submitted images."}
{"completion": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"completion": 788, "text": "query: We are planning to create a podcast application. As a result, we want to enhance the audio quality of our podcasts."}
{"completion": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 304, "text": "query: Let me generate some butterfly images to include them in our natural reserve's promotion materials."}
{"completion": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"completion": 743, "text": "query: As a virtual assistant company, we are asked to produce a German audio file for some text to be featured in a multimedia presentation about the history of the German language."}
{"completion": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"completion": 488, "text": "query: Help me making a code for answering questions about biology books for my children before they make the questions directly over a conversational AI."}
{"completion": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"completion": 295, "text": "query: We need to generate an image of a bedroom for a new advertisement campaign."}
{"completion": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 450, "text": "query: We are working on a finance project, and we want our model to answer queries based on the financial dataset."}
{"completion": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"completion": 83, "text": "query: The marketing team needs help interpreting a chart about product sales over the past year. Provide them with a structured data table based on the chart."}
{"completion": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"completion": 513, "text": "query: business, technology, lifestyle."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: We are building a game engine to control a hopper. We want a pre-trained model to help navigate the environment."}
{"completion": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"completion": 230, "text": "query: I want a program to detect and recognize the license plates of different vehicles so that I can automate the parking process."}
{"completion": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 904, "text": "query: Our customer want to develop a reinforcement learning system using TD3 algorithm for solving the Ant-v3 environment."}
{"completion": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"completion": 497, "text": "query: Develop a tool for categorizing social media posts into themes such as sports, politics, travel, or technology according to the user's preferences."}
{"completion": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 908, "text": "query: We want a reinforcement learning model that could play the SoccerTwos game with the player utilizing Unity ML-Agents Library."}
{"completion": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"completion": 412, "text": "query: Collect all the personal information in a paragraph."}
{"completion": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"completion": 386, "text": "query: The user is about to travel and looking for tips to prepare for their journey. Create a list of informative passages related to travel tips for their journey."}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: I have a list of candidate summaries for an article, recommend the most accurate and relevant summary placed at the top."}
{"completion": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"completion": 143, "text": "query: I am an accountant and have to analyze invoices or other financial documents regularly. Help me find the invoice numbers more conveniently from these images and PDF files."}
{"completion": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 247, "text": "query: I want to segment images into different classes like humans, animals, and objects to design visual reports."}
{"completion": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"completion": 191, "text": "query: Our team is developing an application to help people identify plants. We want to use an image classification model to recognize various plants from the images provided by the users."}
{"completion": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"completion": 792, "text": "query: We want a solution to separate the voices of two speakers from a single audio file."}
{"completion": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 63, "text": "query: We are an AI-model company. Our goal is to extract written content from an image."}
{"completion": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"completion": 640, "text": "query: I am a scientist working on a paper, and I need a system to paraphrase some of the sentences in my paper to avoid plagiarism."}
{"completion": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"completion": 37, "text": "query: \"A bright and colorful banner showcasing a variety of beautiful flowers in a lush garden, with a clear blue sky above and the sun shining brightly. The text on the banner says 'Welcome to our Gardening Extravaganza' in an elegant font.\""}
{"completion": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"completion": 776, "text": "query: Our company needs a tool to separate speaker voices from background noises in a recorded podcast."}
{"completion": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 662, "text": "query: I am a journalist. I need to complete a French sentence based on my draft with a missing word."}
{"completion": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"completion": 931, "text": "query: If there's a summary needed for an article to save time reading, what would you suggest?"}
{"completion": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"completion": 648, "text": "query: We have a document about a new technology. Prepare a set of possible questions people might ask about this document."}
{"completion": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"completion": 535, "text": "query: Create an intelligent assistant to translate my English to French, summarize long texts, answer questions, and analyze the sentiment of texts."}
{"completion": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"completion": 433, "text": "query: We are a startup focusing on market research service. Our work relies heavily on data analysis. Assist us in summarizing a table of revenue data."}
{"completion": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"completion": 650, "text": "query: I want to create a chatbot that can generate news summaries based on the information provided in the text."}
{"completion": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"completion": 656, "text": "query: At our software development company, we need to translate a snippet of Python code into a human-readable description."}
{"completion": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"completion": 633, "text": "query: We need to build an application that translates multilingual texts, such as translating Hindi text to French."}
{"completion": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"completion": 291, "text": "query: I want to develop an app to generate high-quality images of people for fashion advertisement purposes."}
{"completion": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"completion": 187, "text": "query: I want my web app that identifies plants to have 1k classes. Build the model for me."}
{"completion": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"completion": 514, "text": "query: A German publishing house needs to categorize opinions from social media posts into three categories - crime, tragedy, and stealing. Automate this categorization process."}
{"completion": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"completion": 446, "text": "query: We need a solution to help customers find answers to their questions from a table containing information in Korean. Please create a pipeline using a model that can achieve this."}
{"completion": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 715, "text": "query: Our company develops an AI-based text similarity tool. We need to know if two sentences have similar meanings."}
{"completion": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"completion": 852, "text": "query: Our client, the owner of a cruise ship company wants to predict the survival likelihood of their passengers in case of an accident, using a model trained on the Titanic dataset. Can you help?"}
{"completion": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"completion": 285, "text": "query: An artist is looking for a software tool to help them complete their unfinished artwork by filling in the missing parts."}
{"completion": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"completion": 380, "text": "query: I would like to create an AI assistant capable of detecting emotions in various text messages. The emotions to be detected should include anger, disgust, fear, joy, neutral, sadness, and surprise."}
{"completion": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"completion": 485, "text": "query: After signing a contract with Mrs. Xu, we need to answer some questions about the contract in Chinese. Get a question answering tool to provide this ability in Chinese."}
{"completion": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"completion": 542, "text": "query: We are a company that provides multilingual services to customers. We need to translate Dutch texts to English."}
{"completion": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"completion": 854, "text": "query: Our team is exploring plant species in the ecosystem. Identify the species of a flower with its attributes."}
{"completion": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 429, "text": "query: I am going to run a German historical archive. I want a system that should categorize the biography of people based on its name, location, organization."}
{"completion": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"completion": 929, "text": "query: I have an image of a table in a document, and I need to detect the structure of the table, such as rows and columns."}
{"completion": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"completion": 886, "text": "query: A fishery company wants to estimate fish weight from the fish data they provide. Set up the analysis and present a proposed solution."}
{"completion": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"completion": 0, "text": "query: We want to deal with text data which has unique features. Create a feature extraction pipeline to analyze and extract features from text data."}
{"completion": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"completion": 350, "text": "query: We are collaborating with a wildlife conservationist to identify species in their photos."}
{"completion": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"completion": 407, "text": "query: We are a news agency and we need a system for automatically extracting the names of persons, organizations, and locations from articles in multiple languages."}
{"completion": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"completion": 108, "text": "query: Analyze an image and answer the question about it in Polish."}
{"completion": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"completion": 78, "text": "query: I am an app developer and I am using the google api for image description. How do I use the google's pix2struct-chartqa-base to have sentences in the images?"}
{"completion": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 154, "text": "query: An civil engineer company is working on constructing a building, and we need a depth estimation of the proposed site by analyzing the image."}
{"completion": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 66, "text": "query: As a teacher, I need to generate a short summary from an image to teach my students."}
{"completion": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"completion": 188, "text": "query: I have an image of food here, and I want to know what type of cuisine it is. Can you tell me the model to do so?"}
{"completion": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"completion": 211, "text": "query: My boss asked me to build an Internet of Things (IoT) device to recognize objects in my office and store the information for later analysis."}
{"completion": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 688, "text": "query: We are a social networking company. We need to measure how similar two sentences are to detect spam."}
{"completion": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 892, "text": "query: Please tell me the procedure to create a solution for controlling a pendulum using a learning-based approach."}
{"completion": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"completion": 363, "text": "query: As a website owner, I would like to classify images uploaded by users into categories such as animals, vehicles, nature, and food."}
{"completion": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"completion": 394, "text": "query: I am developing software for a company that wants to analyze the sentiments of its customers on their online reviews (positive or negative)."}
{"completion": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"completion": 804, "text": "query: I'd like to create a speech emotion recognition system that can interpret spoken emotions like 'angry', 'happy', 'sad', etc. from a given audio."}
{"completion": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 336, "text": "query: Develop an application that can recognize in real time the type of exercise people are doing at the gym and automatically logging their activity."}
{"completion": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 707, "text": "query: We are building a recommendation engine and we need to find related sentences for better information retrieval."}
{"completion": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"completion": 890, "text": "query: As a real estate developer, we need to predict the prices of houses in California based on the given attributes."}
{"completion": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"completion": 292, "text": "query: I need to create images for a church based on the state-of-the-art unconditional image generation algorithm."}
{"completion": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 133, "text": "query: I'm working on a cataloging project for books. The books contain information about food and their nutritional value. I want to extract information from the documents to help people quickly find the information they need."}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: As an ornithologist, I want to classify bird species based on images I have taken with my camera. I need a model that can provide a prediction even if the species has never been seen before."}
{"completion": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"completion": 729, "text": "query: Construct an audio file of a Korean children's story for bedtime and ensure the generated audio is easy to understand and has a natural Korean tone."}
{"completion": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"completion": 619, "text": "query: Our team needs to build a software that is able to generate code in Python given natural language descriptions about what the code should do."}
{"completion": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"completion": 390, "text": "query: I have a game in the arcade space genre, and I need to generate alternative sentences to describe it for marketing purposes."}
{"completion": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"completion": 259, "text": "query: A quality control team in a factory wants to use an automated system to detect and segment defects in printed circuit boards (PCBs). Help them build a suitable system."}
{"completion": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"completion": 380, "text": "query: The news agency wants to analyze articles from social media for user-targeted emotional reactions. The goal is to create an article recommendation system where users can choose articles depending on their mood."}
{"completion": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"completion": 525, "text": "query: Translate a text from Chinese to English."}
{"completion": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 900, "text": "query: We are coaching a soccer team, and would like to use this API to simulate training sessions."}
{"completion": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"completion": 767, "text": "query: Transcribe and translate an audio file that has been provided to you, to help a non-native speaker understand the contents of the audio."}
{"completion": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"completion": 512, "text": "query: I'm building a multilingual news categorization app. Help me classify a German news headline into politics, economy, entertainment, or environment."}
{"completion": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"completion": 559, "text": "query: I want to build a personal news summarizer so I can read summarized versions of each article flying through my news feed about Python releases and updates."}
{"completion": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 786, "text": "query: We need a solution that separates the dialogues and background music from a movie scene."}
{"completion": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"completion": 155, "text": "query: Our client is a smart-car manufacturer. We need to estimate the depths of objects within the range of the autonomous system's camera."}
{"completion": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"completion": 470, "text": "query: In Korea, a user has a new job, and he is doing it in Korean. He needs help in answering a question in Korean from a given text."}
{"completion": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"completion": 448, "text": "query: In this eCommerce website database, we have a DataFrame of products and their prices. We want to select all the products that are between $15 and $30 with their prices."}
{"completion": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"completion": 158, "text": "query: I need to build an algorithm to estimate the depth of the objects captured in an image."}
{"completion": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"completion": 62, "text": "query: Our customer is an e-commerce company that wants to add automatic caption generation for their product images."}
{"completion": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"completion": 526, "text": "query: Our company is working on an AI-based language translation tool. We need to create a translator using a pre-trained model."}
{"completion": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"completion": 392, "text": "query: We are trying to develop a policy in our online community and we want to automatically remove toxic comments."}
{"completion": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"completion": 583, "text": "query: I am creating a home automation system chatbot. I want the bot to be in charge of controlling the lighting in a living room."}
{"completion": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 501, "text": "query: We're building an app that matches synonyms. Find out how well our sentences match each other."}
{"completion": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"completion": 3, "text": "query: We want to analyze scientific publications on COVID-19 and extract relevant information. Get a unified representation for specific terms."}
{"completion": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"completion": 890, "text": "query: The real estate company we are collaborating with wants to have an estimate of houses' prices in California. Provide a way for them to predict house prices based on given features."}
{"completion": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"completion": 534, "text": "query: Your friend only speaks Italian but your app has content only in English. Convert the content from Italian to English for your friend."}
{"completion": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"completion": 382, "text": "query: After creating AI-generated content using GPT-2, a tool is required to detect the content generated by GPT-2 for quality assurance purposes."}
{"completion": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 893, "text": "query: We would like to create a virtual soccer game for two teams using reinforcement learning. How can we implement this trained model?"}
{"completion": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"completion": 729, "text": "query: Our team needs a solution to convert Korean text into speech for an e-learning application, which reads out educational content."}
{"completion": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"completion": 395, "text": "query: Working in a job platform, making a short text understanding tool to categorize the jobs according to the emotions expressed in the job description."}
{"completion": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"completion": 222, "text": "query: Our customer wants a security system that tracks airplane activity. We will need to develop a plane detection system using artificial intelligence."}
{"completion": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"completion": 917, "text": "query: How do I classify an image for zero-shot image classification?"}
{"completion": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"completion": 303, "text": "query: Develop a tool for generating unique and visually appealing Minecraft skins without any given prompt or condition."}
{"completion": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"completion": 531, "text": "query: Create a function that translates the given input text into English."}
{"completion": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"completion": 896, "text": "query: Create a model instance using the provided api_call and set the model to evaluate mode."}
{"completion": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"completion": 184, "text": "query: We would like to develop a mobile application that helps users recognize objects in images. We need a recommendation for a deep learning model to use."}
{"completion": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"completion": 872, "text": "query: I am working at an environmental organization; we want to predict the carbon emissions of different facilities based on their features. How can I use this pre-trained model to make predictions?"}
{"completion": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"completion": 546, "text": "query: Design a summarization program that will generate abstracts in French."}
{"completion": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 503, "text": "query: The marketing research team needs a technology news detector to extract the latest news for analysis."}
{"completion": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"completion": 807, "text": "query: We are working on a news app. Automatically detect and label the language of different news clippings based on the spoken audio."}
{"completion": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"completion": 354, "text": "query: We have a list of product pictures, please create a personal assistant that can recognize which aisle of the supermarket the product belongs to."}
{"completion": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"completion": 121, "text": "query: We need a model to recognize text and answer questions related to the layout of a document."}
{"completion": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"completion": 866, "text": "query: Our organization wants to become more sustainable and eco-friendly. Help us predict the CO2 emissions of our ongoing projects based on provided data."}
{"completion": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 434, "text": "query: I need a tool that can extract answers from a table with various data entries. The tool must be able to understand the context from the column and row headers before displaying the relevant information."}
{"completion": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 924, "text": "query: Develop a suggestive phrase for a dentist billboard using a masked language model."}
{"completion": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"completion": 532, "text": "query: Create a solution to provide real-time translation for participants in a multi-language conference call."}
{"completion": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"completion": 200, "text": "query: Our customer, a manufacturer of sporting goods, wants us to determine what type of sports equipment is in the images they provided."}
{"completion": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"completion": 826, "text": "query: I am a school counselor with a lot of Russian students. I want to analyze a recorded speech from one of the students to understand their emotions."}
{"completion": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"completion": 289, "text": "query: We are trying to create a system for creating high-quality images of people's faces."}
{"completion": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"completion": 853, "text": "query: An environment agency wants to predict CO2 emissions from a given dataset containing several features."}
{"completion": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"completion": 442, "text": "query: I have an Excel report and customers are very curious about the specific information inside. Please create a code to answer their questions."}
{"completion": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"completion": 879, "text": "query: I'm exploring ways to predict carbon emission based on features in our tabular data. Write a script that loads a trained model to predict those values."}
{"completion": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 327, "text": "query: Let's build a machine learning application to analyze and recognize different activities happening in a video."}
{"completion": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"completion": 181, "text": "query: We are building a mobile application to classify food items. Design a program to predict the class of an image."}
{"completion": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"completion": 863, "text": "query: We want to provide our users with personalized recommendations on ways to reduce carbon emissions. We already have a dataset of different activities that reduce emissions. Let's figure out what activities or habits add the most emissions and should be avoided."}
{"completion": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"completion": 868, "text": "query: We are a real estate company looking to predict housing prices. We want to utilize this model in our operations to make smart decisions."}
{"completion": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"completion": 484, "text": "query: A blind person wants to have their questions answered about a picture they cannot see. Help them by generating an answer to their question about an image."}
{"completion": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"completion": 497, "text": "query: An app is handling disputes among their users. We need to classify if the dispute is related to a financial issue, delivery issue, or customer support issue."}
{"completion": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"completion": 807, "text": "query: Identify the language spoken in an audio file provided and give the result back to me."}
{"completion": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 352, "text": "query: As a parent, I need an automated tool to filter images according to predefined categories, such as cartoons and real animals."}
{"completion": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"completion": 706, "text": "query: We own a news website and we want to give user suggestions based on what they have searched."}
{"completion": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 233, "text": "query: The marketing team needs to promote a product by creating a banner with a clear background. We need to separate the product from the background."}
{"completion": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 322, "text": "query: Our AI bot is designed to analyze videos and find inappropriate content, such as nudity, violence, or profanity. We need to classify activities in the videos."}
{"completion": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"completion": 52, "text": "query: Our company has an art gallery. We're looking for creative ideas to generate paintings from poetry and descriptions. How can we accomplish this?"}
{"completion": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"completion": 761, "text": "query: Create a transcribe function to perform speech recognition on various Japanese audio files and produce a text summary of the spoken content."}
{"completion": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"completion": 649, "text": "query: Our customer is an ai-based AI language translation. We are working to improve a text translation."}
{"completion": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"completion": 173, "text": "query: We want to analyze images of birds and classify them based on their species. Please suggest a suitable model."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: I am a student and need to rephrase my essay content to avoid plagiarism."}
{"completion": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 312, "text": "query: Design a video recommendation system that considers the content of the video rather than using collaborative filtering."}
{"completion": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"completion": 529, "text": "query: Our marketing team has members who speak different Romance languages. Can we translate their work description into English?"}
{"completion": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 671, "text": "query: Create a question answering form to prompt users to complete a sentence by filling in a mask."}
{"completion": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"completion": 362, "text": "query: We are a marketing company and we need to classify the contents of images from social media campaigns."}
{"completion": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 204, "text": "query: Our city is planning to implement a traffic management system. We need a way to classify the vehicles on the road."}
{"completion": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"completion": 752, "text": "query: We are an organization specializing in Dutch language audio analysis. We need a transcription of some audio recordings in Dutch."}
{"completion": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 312, "text": "query: We are designing a video sharing platform. In order to organize our videos into categories for easy searching, we want to automatically assign tags based on their content."}
{"completion": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"completion": 510, "text": "query: On an article discussion board, we want to automatically detect and manage rumors without additional human resources. Make sure whether an statement is true or false."}
{"completion": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"completion": 461, "text": "query: I am looking for an AI solution to find answers in a given text based on the questions asked."}
{"completion": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"completion": 241, "text": "query: We are a smart city developer. We want to get the segmented map of our new development area."}
{"completion": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"completion": 57, "text": "query: We need to create an advertising banner for a bicycle company using text-to-image generation."}
{"completion": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"completion": 566, "text": "query: I have an article about a newly discovered planet, and I want to get a summary of it for my astronomy class."}
{"completion": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"completion": 269, "text": "query: You are designing an AI system for a company that wants to automatically apply color to sketched images. They want a way for the software to understand user-drawn sketches and colorize the images using the theme provided."}
{"completion": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"completion": 756, "text": "query: Please help me transcribe an audio file with speech in Marathi language."}
{"completion": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"completion": 595, "text": "query: Build a chatbot for the game \"The World Ends With You\" that can converse by responding to player's input in a manner similar to the game character Joshua."}
{"completion": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"completion": 478, "text": "query: \"What galaxy is known as the Milky Way's twin?\""}
{"completion": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 335, "text": "query: The company wants to use a model for classifying exercise types in a workout video. Analyze this video and determine the exercise categories."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: Create an automated content generator that translates English text to Arabic language for a website. We want to make our website accessible to the Arabic-speaking audience."}
{"completion": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"completion": 669, "text": "query: You want to create a language model that can complete sentences in French. The sentences will have a blank space in the middle, and the model needs to fill that space with the most suitable word."}
{"completion": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"completion": 619, "text": "query: I am building a mobile app for time management. I would like to create a function that, given a task, returns how long in minutes it should take."}
{"completion": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"completion": 543, "text": "query: \"Hej, hur m\u00e5r du? Tack f\u00f6r m\u00f6tet ig\u00e5r! Det var mycket givande och vi ser fram emot att arbeta tillsammans med er i framtiden.\""}
{"completion": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"completion": 411, "text": "query: We have a list of customer requests, and we need to extract important information such as name, location, and product mentioned in each request."}
{"completion": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"completion": 431, "text": "query: I have a table loaded with financial data, I need to get the top 5 more profitable items."}
{"completion": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"completion": 819, "text": "query: I am interested in categorizing audio files depending on the content of the audio. Do you have a way to accomplish this task?"}
{"completion": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"completion": 122, "text": "query: We are developing a finance application, one core feature is to help extract information from received invoices. For example, finding the total amount in the invoice."}
{"completion": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"completion": 934, "text": "query: We received a transcribed text from a meeting, but there are no punctuation marks. Please add punctuation to the text."}
{"completion": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"completion": 33, "text": "query: A travel company wants to create a promotional image of astronauts riding a horse on Mars for their services. Create an image from a text prompt."}
{"completion": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"completion": 524, "text": "query: \"Bonjour, j'ai besoin de directions pour arriver \u00e0 la Tour Eiffel.\""}
{"completion": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"completion": 767, "text": "query: I want to transcribe spoken language in an audio file and translate the transcribed text to a different language."}
{"completion": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"completion": 704, "text": "query: The managers want to reduce time wasted on reading irrelevant emails. They need a system able to pair similar emails to speed up the reading process."}
{"completion": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"completion": 910, "text": "query: I am a researcher in going to build a robot who can follow my commands, just now, I need to load the pre-trained VC1 model and use the model to compute the embedding for an image."}
{"completion": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 698, "text": "query: We need a solution to compute the similarity of given sentences."}
{"completion": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 157, "text": "query: An AI-based Robotics company is exploring to developrobotic systems. They want to integrate depth estimation functionality for better object detection and navigation."}
{"completion": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 426, "text": "query: I am building an application to extract organization names from news articles for a finance company. How can I do this?"}
{"completion": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 711, "text": "query: The goal is to create a system that can group similar news articles together, arrange news feeds according to these groups, and help users find articles relevant to their interests."}
{"completion": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"completion": 385, "text": "query: \"I can't believe I managed to pass the exam, I am over the moon!\"."}
{"completion": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"completion": 23, "text": "query: We aim to build a research paper recommender system. For this purpose, we want to generate an embedding for each research paper based on the title and abstract."}
{"completion": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"completion": 617, "text": "query: Assist me in writing a futuristic story set in the year 2200 about humans and robots coexisting in harmony."}
{"completion": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"completion": 341, "text": "query: Develop an AI tool to help teachers with their classroom regulations that can classify videos with different types of activities."}
{"completion": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"completion": 520, "text": "query: Help me to create an assistant that can determine the logical relationship between pairs of sentences and classify them as entailment, contradiction, or neutral."}
{"completion": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"completion": 127, "text": "query: We are a company specialized in document analysis. We would like to extract information from a scanned invoice."}
{"completion": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"completion": 872, "text": "query: The local government wants to calculate the CO2 emissions for several different scenarios. Help them get the carbon emissions based on the given input data."}
{"completion": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"completion": 296, "text": "query: We are planning on starting a new project, creating a virtual tour for a historical church. We need to produce images of old and famous churches as an inspiration."}
{"completion": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"completion": 29, "text": "query: Create a passage retrieval system to find the most relevant passage that answers a given question from a list of passages."}
{"completion": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"completion": 440, "text": "query: I am developing an application to facilitate online learning. This service will help users find answers based on a table they provide. "}
{"completion": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"completion": 858, "text": "query: I want to create a tool that automatically predicts whether movie reviews are positive or negative after reading them."}
{"completion": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"completion": 458, "text": "query: I am working with a group of well-known bartenders, and they wanted a personal assistant that can find information about cocktails by giving information about different cocktails in table format."}
{"completion": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"completion": 742, "text": "query: We're trying to create a voice-over for the product advertisement, and want to convert some text to speech."}
{"completion": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 106, "text": "query: Imagine there is a billboard which has multiple information such as a slogan, an image of product and contact number. Our company is trying to collect necessary information from this billboard through the image. Let's find out the slogan and some other relevant information."}
{"completion": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"completion": 406, "text": "query: I am trying to remember the correct punctuation in this long sentence but I am not sure, give me the correct punctuation."}
{"completion": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 444, "text": "query: We are managing an online booking system for different events. We need to answer customers' questions based on the available data."}
{"completion": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"completion": 778, "text": "query: A client has asked us to build a solution to improve the audio quality for his recorded lectures."}
{"completion": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 694, "text": "query: I want to use a language model to determine how similar two sentences are and then calculate their cosine similarity."}
{"completion": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"completion": 166, "text": "query: I need a way to estimate the depth of objects in an image for an autonomous vehicle."}
{"completion": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"completion": 379, "text": "query: Create a tool to classify the sentiment expressed in movie reviews written by users on social media platforms."}
{"completion": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"completion": 286, "text": "query: We are creating children's books and want to generate colorful unique images that have not been seen by anyone."}
{"completion": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"completion": 844, "text": "query: Implement a tool which can be used to detect voice activity, overlap speech detection, and re-segmentation for different recordings."}
{"completion": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"completion": 381, "text": "query: I want to know if a given sentence is an adequate paraphrase of another. Can you identify this by running the input through your model?"}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: Create a Russian voiceover for an advertisement using the text-to-speech model."}
{"completion": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"completion": 101, "text": "query: We are designing an exhibit in which visitors can ask questions about images. We want to create a system that answers their questions based on the images."}
{"completion": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"completion": 38, "text": "query: We would like an AI to design a greeting card based on the text \"happy birthday with a cake and balloons\"."}
{"completion": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 240, "text": "query: The project manager has requested to create a metadata tagging system for images hosted on the company's website. Implement a solution to segment images into their constituent parts and label them for metadata purposes."}
{"completion": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"completion": 62, "text": "query: We are a computer vision startup focused on providing exceptional image-to-text summaries. We need an effective solution to generate both conditional and unconditional captions for images."}
{"completion": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"completion": 906, "text": "query: Our company is developing a gaming product for animal simulation. We want to implement a Reinforcement Learning model that simulates the movement of a half-cheetah based on expert trajectories."}
{"completion": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"completion": 229, "text": "query: Global Offensive eSports game."}
{"completion": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"completion": 584, "text": "query: Please give me a solution that allows me to create a dialogue system for my web app. One that can involve a character persona."}
{"completion": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"completion": 4, "text": "query: Create a model to generate captions for social media posts based on the post's textual content and hashtag."}
{"completion": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 330, "text": "query: A news agency wants to categorize videos based on their content. Help the agency to build a system that identifies the video's categories."}
{"completion": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"completion": 670, "text": "query: An education app needs a way to automatically complete sentences when a word is missing, in multiple languages."}
{"completion": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 421, "text": "query: I want to automatically annotate the syntax roles of the words in a given English sentence using the best available API."}
{"completion": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 924, "text": "query: We have a text but one word is missing. Help us fill in the missing word."}
{"completion": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 503, "text": "query: I am a journalist, and I'd like to categorize news articles into various sections like technology, sports, and politics."}
{"completion": 69, "text": "document: This is an image captioning model training by Zayn"}
{"completion": 69, "text": "query: Our content team is busy, we need to use technology to create captions for product images in our online store."}
{"completion": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 245, "text": "query: We are a real estate company, and we need to identify different elements within a room from the photos provided by the homeowners."}
{"completion": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"completion": 457, "text": "query: I want weather predictions for the 7 day forecast. By using given tables of city weather data, find out which day(s) it is likely to rain in San Francisco."}
{"completion": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 662, "text": "query: Our client needs to correct sentences from formal diplomatic documents that are missing words or have typographical errors. We'd like you to provide an example of how the model can predict the missing word."}
{"completion": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"completion": 412, "text": "query: I need to extract all personal names, locations, and organization names from given text."}
{"completion": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"completion": 713, "text": "query: Our company is in language translation. We need to analyze two translated texts to identify their similarity."}
{"completion": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"completion": 58, "text": "query: We are looking for an AI product that can provide a succinct caption for our input image."}
{"completion": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"completion": 479, "text": "query: We want to review the content of our course for consistence. Could you check if the paragraph answers correctly the question \"Why is model conversion important?\""}
{"completion": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"completion": 143, "text": "query: Help me to answer the questions about the gas station biodata throughout the year."}
{"completion": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"completion": 430, "text": "query: We are building a system for answering questions related to a table of data. Can you suggest an appropriate API for this task?"}
{"completion": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 170, "text": "query: The car company wants to test the effect of different models on the perception of distance. They are now asking for a way to estimate the depth of an image."}
{"completion": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"completion": 0, "text": "query: We are a human resources company and need to build a classifier to identify the most suitable applicants for the available job positions. Extract features from a given text."}
{"completion": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"completion": 107, "text": "query: Our company has started a new project of creating an app for visually impaired users to describe images and answer questions about them."}
{"completion": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"completion": 638, "text": "query: Let's devise a method to convert Korean questions to answers in sentences."}
{"completion": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"completion": 467, "text": "query: Our company is designing a conversational bot. We are looking for a way to answer user's questions from a given context."}
{"completion": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"completion": 525, "text": "query: I have an e-commerce business in China, and I need to translate customer messages from Chinese to English. Please create a model to do that."}
{"completion": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"completion": 702, "text": "query: We are now analyzing the reasons a meeting is not going well, can we encode the sentence into an embedding and classify them in a way they can be compared?"}
{"completion": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"completion": 54, "text": "query: \"Young explorer with a green jacket and a backpack, standing near a waterfall.\""}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: We received an invoice from a supplier. Can you help us extract the invoice number?"}
{"completion": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 927, "text": "query: Develop a solution that describes the content of an image."}
{"completion": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"completion": 796, "text": "query: We are a team of music producers, and we want to separate vocals from the instruments in a recorded music track."}
{"completion": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"completion": 293, "text": "query: Create a function to generate random human faces using transformers."}
{"completion": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"completion": 935, "text": "query: We are a smartphone company and we need to build an app to respond the question about an image taken from the smartphone."}
{"completion": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"completion": 608, "text": "query: Write an imaginary tale about a group of travelers who discovered a hidden city under the ocean."}
{"completion": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"completion": 777, "text": "query: We need to analyze a podcast where several people are talking. Additionally, analyze the speech of each person separately."}
{"completion": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"completion": 111, "text": "query: I am working on a home automation system which can visually recognize objects in the user's surroundings and answer user's questions about them. Calculate the number of calories in my meal."}
{"completion": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 159, "text": "query: To understand the 3D layout of a scene from a single 2D image, we need to build a product to predict depth information from an image."}
{"completion": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"completion": 8, "text": "query: Analyze the features of text written in Korean for a better understanding of the context and emotion."}
{"completion": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"completion": 639, "text": "query: I want my personal assistant to translate text, write summaries, and check grammar for any given text."}
{"completion": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"completion": 619, "text": "query: Develop an application to generate Python scripts that are useful in your daily life."}
{"completion": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"completion": 832, "text": "query: The client needs an algorithm to detect which portions of their recorded meetings contain speech."}
{"completion": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"completion": 79, "text": "query: We are a company that is developing a web app that converts images into textual content. We need to analyze images to generate text descriptions."}
{"completion": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 779, "text": "query: I record a lot of podcasts and have trouble removing background noise. I need an audio denoising tool."}
{"completion": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"completion": 197, "text": "query: A startup is trying to detect the type of object present in an image for their application. They are seeking an image classification model for their project."}
{"completion": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"completion": 935, "text": "query: Develop a search engine using visual question answering to make search results more specific."}
{"completion": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"completion": 222, "text": "query: I want my smart camera system to detect planes in the images it captures."}
{"completion": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 724, "text": "query: We have a podcast about Chinese culture, and we need to create an introduction in Simplified Chinese."}
{"completion": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 450, "text": "query: Analyze the provided table data about monthly sales of different products to answer the question, \"Which product had the highest sales in January?\""}
{"completion": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"completion": 225, "text": "query: I'm running a construction site and want to deploy a system to ensure workers wear hard hats. Help me detect hard hats in images."}
{"completion": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"completion": 216, "text": "query: Global Offensive'. They need a way to identify players in the game images."}
{"completion": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"completion": 18, "text": "query: Create a project that extracts features from given Python code for any Machine Learning-based software analytics problem."}
{"completion": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"completion": 831, "text": "query: A chatbot owner requested to assist the users in identifying spoken commands in a given audio file."}
{"completion": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 133, "text": "query: Our startup is building an application to help people find answers from product manuals. Help us find answers to questions about these manuals."}
{"completion": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 898, "text": "query: Our company wants to develop an AI player for the classic video game Pong. We need to set up a reinforcement learning agent to play Pong."}
{"completion": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"completion": 638, "text": "query: We require a tool to convert Korean sentences into English sentences for quick language translation."}
{"completion": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"completion": 241, "text": "query: Our company's mission is to create autonomous vehicles for smart cities. We need to process street images to better understand road conditions."}
{"completion": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"completion": 875, "text": "query: Estimate the carbon emissions generated by different home appliances based on their energy usage data."}
{"completion": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"completion": 897, "text": "query: We want to train an agent that will help us accomplish lunar landing and make the highest scores possible."}
{"completion": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"completion": 77, "text": "query: Develop a tool for a blind person that can generate captions based on what they see around them."}
{"completion": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"completion": 642, "text": "query: We're developing a customer support chatbot to handle high volume of inquiries. We need it to process long customer support chats and generate concise summaries."}
{"completion": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 131, "text": "query: A robot wants to answer questions related to product manuals using the model."}
{"completion": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"completion": 494, "text": "query: I would like to understand the difference in sentiment among my customers regarding my products. Analyze their comments and classify them as positive, negative, or neutral."}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: The customer is interested in creating a text-to-speech system that speaks the Russian language. We need a transformer that can convert text to speech in Russian."}
{"completion": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"completion": 738, "text": "query: You are building an audiobook platform. Your task is to convert chapter text into audio. Using the framework to synthesize text into realistic speech."}
{"completion": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"completion": 397, "text": "query: With the help of the provided model, I want to create a restaurant sentiment analysis tool that will categorize the reviews as positive or negative."}
{"completion": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"completion": 681, "text": "query: Our team is building a language model to auto-complete or suggest the next part in a piece of code. Your task is to provide us the right API for this purpose."}
{"completion": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"completion": 770, "text": "query: I am building a virtual assistant and need to convert a short sample of a voice message to text."}
{"completion": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"completion": 635, "text": "query: We are publishing a newspaper and largely writing news summaries. We need an AI to help us create summary texts."}
{"completion": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"completion": 189, "text": "query: I\u2019m working on an app that assesses the quality of images for photographers. Help me classify images."}
{"completion": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"completion": 805, "text": "query: A company wants to analyze their customer support calls to identify the emotions of the customers. Let me know how to proceed."}
{"completion": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"completion": 805, "text": "query: Our company is developing a virtual assistant and wants to add emotion recognition capabilities to it. We need to classify audio clips into different emotions."}
{"completion": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"completion": 474, "text": "query: I am working on a project that identifies the closest answers to the questions about tourism. Can I use a Question-Answering model to accomplish my task?"}
{"completion": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"completion": 453, "text": "query: I have a dataset as a table containing details about the artists and their paintings. I need to know which of the paintings has the highest price."}
{"completion": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 236, "text": "query: Describe the process of building a system to perform real-time semantic segmentation of images using the SegFormer model."}
{"completion": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"completion": 727, "text": "query: We manufacture an infotainment system. Can you experiment with voices of the text-to-speech model to find different variations for our automated announcements?"}
{"completion": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"completion": 37, "text": "query: As a digital artist, I am searching for a model that can take a text-based description of a scene and generate a photo-realistic image based on the given description. I want this to be done extremely efficiently."}
{"completion": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 70, "text": "query: We are developing a chatbot that can analyze photos we send it and ask questions or give information about the scene."}
{"completion": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"completion": 163, "text": "query: Develop a code to estimate the depth of an image for robotics."}
{"completion": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 672, "text": "query: I want to create an email message for my team that is introducing a new machine learning model we have developed. Can you help me fill in the blanks in the following message?"}
{"completion": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 403, "text": "query: Our client is a journalist and wants an assistant to identify named entities in a given article text."}
{"completion": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"completion": 490, "text": "query: We want to make a simple project where users can ask questions about information on a given webpage."}
{"completion": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 161, "text": "query: As an online retailer, our company needs to calculate shipping fees. To do that efficiently, we need to estimate the depth of objects in the warehouse for packaging purposes. Help us to estimate that."}
{"completion": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"completion": 654, "text": "query: Our company focuses on code reviews. Please add variables to a given code in the natural language description."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: Design an automated financial report for a global corporation. It should include an English-to-Arabic text translation for their Middle East clients."}
{"completion": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"completion": 793, "text": "query: I have an English speech audio file, and I want the assistant to convert the speech into Hokkien."}
{"completion": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"completion": 917, "text": "query: The company needs to automatically categorize images in their database. Help them find the right model and usage instructions."}
{"completion": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"completion": 442, "text": "query: We have a database of all the transactions over the last month, how much money did account holder \"John Smith\" deposit during this time frame?"}
{"completion": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 186, "text": "query: We are working on an e-commerce website project which needs to identify products by analyzing their images."}
{"completion": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"completion": 931, "text": "query: I am writing an English article in my blog and I need to post the summary of it. Can you recommend a model that can be used to automatically summarize my article?"}
{"completion": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"completion": 266, "text": "query: I am creating a game that generates game assets based on the description of the scene, such as \"creepy forest with a haunted house\"."}
{"completion": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"completion": 902, "text": "query: The company is looking to build a lunar lander game for mobile. We need an AI to control the landing with the highest performance."}
{"completion": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"completion": 888, "text": "query: Our company is managing a solar farm and we want to predict the electricity consumption for the next week. "}
{"completion": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"completion": 469, "text": "query: We are developing an application for legal documents contract analysis. We need an AI module to extract answers from these contracts."}
{"completion": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"completion": 573, "text": "query: We have a support chatbot for the users of a mobile app who have questions about its features. Help them manage and answer their questions with given chatbot."}
{"completion": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"completion": 920, "text": "query: Our client's podcasts need to be transcribed into text files."}
{"completion": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"completion": 120, "text": "query: An user of our application has a scanned legal document and wants to extract relevant information by asking questions related to document. Utilize a model to help the user."}
{"completion": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"completion": 29, "text": "query: I want to build a question-answering system that finds the most relevant answer from a list of given contexts."}
{"completion": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"completion": 101, "text": "query: In our newly launched electronic online store, our customers are inquiring about the features of a product in the form of questions."}
{"completion": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"completion": 412, "text": "query: I want to extract the names of people and organizations mentioned in news articles."}
{"completion": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"completion": 137, "text": "query: We are a real estate company and we want to use a model to extract information from scanned documents of lease agreements. Explain how to use the given model to extract information."}
{"completion": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"completion": 299, "text": "query: We need to generate images of a bedroom using the DDPM model for an interior design software."}
{"completion": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"completion": 289, "text": "query: A game company wants to use DDPM to procedurally generate high-quality avatar images."}
{"completion": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"completion": 659, "text": "query: Please assist me in completing a sentence with a missing word. The sentence is \"The rabbit quickly jumped over the __ log.\""}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: I usually receive bills from my business partners that are scanned pdf files. I want to create a program in Python to extract information from the scanned images."}
{"completion": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"completion": 67, "text": "query: The marketing team is building a social media campaign for our product. We would need to describe images used in the campaign."}
{"completion": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"completion": 674, "text": "query: Design a health-related application that uses AI to assist physicians in understanding medical reports by filling in masked words."}
{"completion": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"completion": 704, "text": "query: We are the developer team of a social platform, and we need to match users based on their interests. Help us match users with similar interest descriptions."}
{"completion": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"completion": 418, "text": "query: Our team needs to extract entities from user texts to better understand their content for tracking purposes, without exposing sensitive data."}
{"completion": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 449, "text": "query: I need an AI for my app that shows a table and asks users questions about the data in the table, based on their input."}
{"completion": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"completion": 534, "text": "query: \"Cosa sta succedendo oggi nell'economia mondiale?\""}
{"completion": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 757, "text": "query: We have multiple lingual audio calls coming from our users to handle in different departments. Convert the audio call into text providing the clean and grammatically correct transcript."}
{"completion": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"completion": 113, "text": "query: Develop a system that helps visually impaired people to describe and understand daily life objects surrounding them by asking questions about the entities discovered in the image."}
{"completion": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"completion": 665, "text": "query: Sally wants to fill in the blanks in her sentences but needs assistance. Write a code example to complete her sentence."}
{"completion": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"completion": 396, "text": "query: Analyze whether a given sentence is a question or a statement from a user's input."}
{"completion": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 234, "text": "query: We are a landscape architecture consultancy and need to develop an autonomous drone for site mapping. The drone will use images to generate semantic segmentation to help us better understand the environment."}
{"completion": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"completion": 585, "text": "query: Our company's website needs a chatbot that answers visitors' questions. The responses should be coherent and informative."}
{"completion": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 1, "text": "query: I work in a biotechnology company, and I want to analyze scientific papers. Extract and represent the information for better understanding using BioBERT."}
{"completion": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"completion": 390, "text": "query: We are designing a chatbot that speaks fluently. Please provide a feature that will generate a more fluent, paraphrased version of an input sentence."}
{"completion": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"completion": 111, "text": "query: A web-enabled application is being developed for tourists to ask questions about the photos they upload. The system must be multilingual."}
{"completion": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"completion": 184, "text": "query: We are building an app that needs to classify images. Can you provide a code example using a pre-trained image classification model from Hugging Face?"}
{"completion": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"completion": 651, "text": "query: We are building a software for foreign students to improve their English writing skills. We want to implement a grammar correction feature."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: An online store wants to rephrase the descriptions of their products to avoid content duplication. Tell them how they can do it using the given API."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: We are an online photo editing service, and one of the customers sent us a flying skate-board photo, which he said the photo was blurred. Help him to deblur the photo."}
{"completion": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"completion": 521, "text": "query: We have written an article about the health benefits of owning a dog, but people don't have time to read it. We need to summarize it."}
{"completion": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"completion": 726, "text": "query: Develop a feature for an educational app that can read a given story. The story text needs to be converted into an audio file."}
{"completion": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"completion": 519, "text": "query: We are creating an automatic text summarization tool that summarizes articles."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: Our customer is an e-commerce company in the Middle-East. They want to translate their product descriptions from English to Arabic."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: I'm creating a security system with CCTV cameras and I need to identify aggressive behavior in the footage."}
{"completion": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"completion": 597, "text": "query: We are building a virtual assistant to help visitors in a museum. The assistant answers common questions regarding the museum history, exhibits information and general guidelines."}
{"completion": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"completion": 847, "text": "query: We are a startup that sells wine. We're looking to predict wine quality based on its characteristics."}
{"completion": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"completion": 339, "text": "query: We want to implement an AI-based video surveillance system for our company that classifies human activities in the surveillance footage."}
{"completion": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 426, "text": "query: I'm working on an article and I want to identify the names of all the organizations mentioned in the text."}
{"completion": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"completion": 158, "text": "query: Our company is working on an autonomous car project, and we need an accurate depth estimation model."}
{"completion": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"completion": 471, "text": "query: Our web-app users can't find certain information on different webpages. Can you help them by developing a search system that can answer the questions users will provide?"}
{"completion": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"completion": 91, "text": "query: I want to implement a future classroom system where I can input a sentence, and a short video is generated relevant to that sentence, like a visual aid for my students."}
{"completion": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"completion": 761, "text": "query: We need to transcribe speeches given in Japanese language and store it as text file for furthur analysis. Code needed please!"}
{"completion": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 276, "text": "query: Create a fantasy-inspired image based on the description \"dreamy fairy forest with sparkling waterfalls\"."}
{"completion": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 352, "text": "query: Can you identify if my dog is a Labrador Retriever, a Golden Retriever, or a Rottweiler from an image I provide?"}
{"completion": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"completion": 867, "text": "query: We run a sustainable living network that helps people estimate their carbon emissions based on the data they provide us with."}
{"completion": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"completion": 223, "text": "query: Global Offensive players in a given image."}
{"completion": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"completion": 683, "text": "query: I am a novelist and working on a new story. Design a chatbot that can fill in the missing words in my story on the fly.`"}
{"completion": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"completion": 180, "text": "query: The task is to automatically predict the age of a person from their uploaded picture."}
{"completion": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"completion": 158, "text": "query: The urban planning department needs to gather depth data from aerial images. They have high-resolution imagery, and need to process it to obtain depth information for every pixel."}
{"completion": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"completion": 128, "text": "query: I need to extract the billing amount for a document that I have in text form."}
{"completion": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 687, "text": "query: We have thousands of text data, but we need to embed the passages into embeddings to find the context, can you help me?"}
{"completion": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"completion": 136, "text": "query: I need help extracting information from a scientific research paper. Please create a program that can provide answers to questions I have regarding the paper."}
{"completion": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"completion": 155, "text": "query: As a software development team, we are working on an autonomous car project. We need a depth estimation model to perceive the environment around the vehicle."}
{"completion": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"completion": 861, "text": "query: Our company focuses on creating environmentally friendly products. We need to predict the carbon emissions for a product based on certain features."}
{"completion": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 206, "text": "query: We are building an AI-based software to help farmers identify infected plants from their fields. Determine the objects in a given image."}
{"completion": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"completion": 650, "text": "query: Our customer service team is facing a huge volume of user requests. We need a solution that can generate comprehensive summaries of lengthy customer emails and messages."}
{"completion": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"completion": 591, "text": "query: We need to create a conversational AI chatbot for our newly launched e-commerce website to assist visitors with their queries, so they can have an interactive and intelligent conversation."}
{"completion": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"completion": 858, "text": "query: We want to design a movie review platform that automatically classifies movie reviews as positive or negative based on their content."}
{"completion": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"completion": 83, "text": "query: Understand the content of an image-based chart we have received and provide the underlying data table."}
{"completion": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"completion": 350, "text": "query: As a wildlife enthusiast, I want to identify the species of the animal captured in a picture."}
{"completion": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"completion": 220, "text": "query: A logistic company needs to ensure safety in its warehouse. The company wants to create a system that detects forklifts and people in the warehouse."}
{"completion": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"completion": 654, "text": "query: Create a function that checks if a number is even or odd and returns a different text message for every result."}
{"completion": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"completion": 511, "text": "query: 'The author explains the concepts very clearly and with good examples.', 'The book is poorly organized and difficult to follow.'"}
{"completion": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"completion": 554, "text": "query: Create a short summary of the company's annual report for the press release."}
{"completion": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"completion": 546, "text": "query: Write an AI bot to create summaries for long French texts. The summaries should be a shorter version of the original content and maintain the main ideas."}
{"completion": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"completion": 520, "text": "query: We are a team building a discussion forum. We need to know if user comments contradicts each other or not."}
{"completion": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"completion": 563, "text": "query: We are holding a conference in French. What would you recommend for the key points to be extracted from the given French documents?"}
{"completion": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"completion": 721, "text": "query: We need a robot with voice synthesized for the hearing-impaired patients in the hospital."}
{"completion": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"completion": 861, "text": "query: We are trying to predict carbon emissions from a new dataset containing features that have an effect on carbon emission level. We should do this with a pre-trained multi-class classification model."}
{"completion": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"completion": 4, "text": "query: We need a program that can analyze the sentiment of movie reviews. Build it for us."}
{"completion": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"completion": 13, "text": "query: As a content management team, we need to extract semantic textual similarity features from a given sentence pair."}
{"completion": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 907, "text": "query: As a game developer, I want to create a soccer game featuring AI soccer players. I will use an existing trained model to control the players."}
{"completion": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"completion": 303, "text": "query: As a company building a custom Minecraft server, we want to provide unique skins for our players. We need an AI to generate realistic-looking Minecraft skins."}
{"completion": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 27, "text": "query: Computer Vision Video Classification"}
{"completion": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"completion": 784, "text": "query: I am an engineer building a home robot that can switch between different voices. I want it to have the ability to switch between voices when it is interacted with."}
{"completion": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"completion": 867, "text": "query: An organization is committed to reducing its carbon footprint. Can they assess each company and predict if they are above or below the limit of emissions?"}
{"completion": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"completion": 646, "text": "query: Provide a language model that our company can use to translate English to German, answering basic questions and reasoning."}
{"completion": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 82, "text": "query: We are creating an application to work with scientific journals. We need to extract text from scanned journal pages so we can analyze it later."}
{"completion": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"completion": 264, "text": "query: You are a real estate developer who is hiring an architect. Develop a blueprint design for commercial buildings based on image segmentation."}
{"completion": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"completion": 382, "text": "query: A news company wants to classify news articles to identify whether they are influenced by AI-generated content or not."}
{"completion": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"completion": 636, "text": "query: I am an online platform targeting an international audience, and I would like to translate all texts from English to German."}
{"completion": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"completion": 668, "text": "query: \"In order to succeed, one must have [MASK].\""}
{"completion": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"completion": 614, "text": "query: We are a publishing company, and we're in need of a draft for the next young-adult fiction novel that we will be publishing."}
{"completion": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 159, "text": "query: Our team is building a robot for a research and rescue mission. We need to calculate real-world distances."}
{"completion": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"completion": 833, "text": "query: The company is building a product to improve audio quality in video conferences. We need to detect voice activity and filter out background noise."}
{"completion": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"completion": 303, "text": "query: We are developing a new update for our Minecraft site. Generate a unique, high-quality Minecraft skin for us."}
{"completion": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 663, "text": "query: \"Ich habe heute keine Zeit, ich muss zur <mask> gehen.\""}
{"completion": 20, "text": "document: One custom ast model for testing of HF repos"}
{"completion": 20, "text": "query: We are a robotics research team working on audio-event detection and localization. We need to process audio from microphones placed around our environment and extract spectrogram features."}
{"completion": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"completion": 765, "text": "query: Our marketing team wants to transcribe Arabic audio files into text. Please provide a model and code to perform this task."}
{"completion": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 159, "text": "query: I run a real estate platform and I need to estimate the depth of various rooms to help my customers visualize the space."}
{"completion": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 319, "text": "query: We want to integrate our video streaming platform with an AI model that categorizes videos in real-time so our users can find relevant content more easily. How can we set this up?"}
{"completion": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"completion": 508, "text": "query: Build an AI system to categorize news articles into a few different topic areas, such as technology, politics, science, and sports."}
{"completion": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"completion": 342, "text": "query: The company is building a surveillance system and wants to automatically detect and recognize specific actions like walking, running, or fighting in video. Write python code to achieve it."}
{"completion": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"completion": 337, "text": "query: We are a computer vision startup focusing on classifying sports activities. We want to classify videos, given a video input."}
{"completion": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"completion": 253, "text": "query: Our business wants to build a social media platform that automatically segments images and removes the background."}
{"completion": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"completion": 557, "text": "query: We are establishing a publication firm for financial news. We need to condense long articles from file 'news_long.txt' into summaries."}
{"completion": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"completion": 370, "text": "query: Create a voice assistant to help people understand if the movie they are watching creates a positive or negative feeling."}
{"completion": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"completion": 65, "text": "query: A historian needs help to recognize, read and translate handwritten texts."}
{"completion": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"completion": 559, "text": "query: Our marketing team needs to create shorter versions of our product descriptions. Give me ideas on how to do that."}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: Create an AI application that identifies objects in images and sorts them into categories, such as animals, vehicles, plants."}
{"completion": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"completion": 296, "text": "query: We are an architecture studio that designs unique temples. Create an image of a church for inspiration."}
{"completion": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"completion": 173, "text": "query: Our team wants to investigate the accuracy of images in a dataset of animals. We need to classify the objects in the images using a pre-trained model."}
{"completion": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 251, "text": "query: We are trying to build a computer vision-based system to improve the navigation and direction understanding of autonomous vehicles in a complex environment."}
{"completion": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"completion": 86, "text": "query: We want to extract textual data from an image. The image is a screenshot of a website with data about a seminar."}
{"completion": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"completion": 370, "text": "query: Our company provides a social media management tool. In order to make our tool more understable, we need to detect the tone in the provided news headlines."}
{"completion": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 747, "text": "query: We are developing a voice assistant and need to improve its speech recognition capabilities by transcribing spoken language into text, specifically in English language."}
{"completion": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"completion": 593, "text": "query: Create a chatbot that can answer my questions using given knowledge."}
{"completion": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"completion": 844, "text": "query: I am developing an online tool for cutting long audio files into shorter clips based on speaker switches, silent pauses or overlapping speech segments. Can you guide me on how I can achieve this?"}
{"completion": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 352, "text": "query: A pet shop hired us to make an app that uses AI to classify animal species. We need to classify if an image contains a cat or a dog."}
{"completion": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 186, "text": "query: I want to create a mobile application that allows users to identify different fruit species using a photo. Please help me classify the images."}
{"completion": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"completion": 885, "text": "query: We are building a prototype application for restaurants. Suggest a model to predict tip amounts for different customers."}
{"completion": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"completion": 593, "text": "query: We are a high-tech startup that want to build a helpdesk bot. Help us creating a bot that is able to answer grounded questions."}
{"completion": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 747, "text": "query: Create an application that transcribes speech from multiple audio files at once using the provided model."}
{"completion": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"completion": 390, "text": "query: We need a chatbot that can interact with users and generate variety in its responses. Can you help provide different ways to express the same thing?"}
{"completion": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 153, "text": "query: Can you help me estimate the depth of objects in an image?"}
{"completion": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"completion": 556, "text": "query: I'm a German reporter and I need to summarize a long article quickly. Can you help me to build a tool to complete this task?"}
{"completion": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"completion": 552, "text": "query: Our company website wants to provide a summary of our meeting transcripts. As an example, find a summary for the following meeting transcript:"}
{"completion": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"completion": 685, "text": "query: Write a legal sentence that completes a partially given sentence with a missing word."}
{"completion": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 68, "text": "query: I need a system that can automatically caption images and videos."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: Currently, our urban planners require an image segmentation tool that can help identify buildings in satellite images."}
{"completion": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 806, "text": "query: Our company's voice assistants are relying on a system for detecting specific keywords in a user's speech. We need an English keyword spotting model that can recognize keywords in real-time."}
{"completion": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"completion": 406, "text": "query: We are a transcription service company and we need to restore punctuation in transcribed spoken language."}
{"completion": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"completion": 378, "text": "query: I invest in cryptocurrencies and tend to follow the market news heavily. I want to analyze the sentiment of the latest cryptocurrency news article."}
{"completion": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"completion": 894, "text": "query: I'd like to play a game and take some help from the Decision Transformer model so I can learn how to improve my skills in the game."}
{"completion": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"completion": 549, "text": "query: Summarize the conversation between two coworkers discussing a recent company meeting."}
{"completion": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"completion": 185, "text": "query: A mobile app for plant farmers needs to identify whether a plant leaf is healthy or diseased. Determine a solution to classify the images of plant leaves."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: Develop a simple control program to make a robotic hopper balance and hop using the pre-trained decision transformer."}
{"completion": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"completion": 480, "text": "query: We are a startup company that specializes in document analysis software. We want to develop a feature that answers questions about document content."}
{"completion": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"completion": 477, "text": "query: I need a function to interact with a chat bot that can answer my question \"what's the population of France?\" but the context should contain the word french and might not contain the information I am looking for."}
{"completion": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"completion": 299, "text": "query: We are collaborating with interior designers attempting to create bedroom layouts. They need some initial samples to show clients."}
{"completion": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 695, "text": "query: We are trying to build an application with semantic search which leverages a sentence-transformer model for computing sentence embeddings."}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: I need to create a personalized greeting message for a Russian friend using their name. The message should say \"Hello, [Friend's Name]. Welcome to my home!\""}
{"completion": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"completion": 353, "text": "query: Develop a product classification system for an e-commerce website that manages a variety of fashion products."}
{"completion": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"completion": 292, "text": "query: A publishing company wants to generate cover images for a new fantasy book series. "}
{"completion": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"completion": 457, "text": "query: A group of students is struggling with extracting specific information from a table. Help them extract the requested information from the table."}
{"completion": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"completion": 894, "text": "query: I bought a robot dog, and I expect the robot to understand the walking actions of the robot dog in the environment."}
{"completion": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 106, "text": "query:  Our team is building a Visual Question Answering system to improve our customer service response time."}
{"completion": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"completion": 721, "text": "query: \"Welcome to our podcast! Today, we will discuss the latest trends in technology.\" Create an audio snippet with this text."}
{"completion": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 709, "text": "query: Offer me a way to compare the similarity of two sentences based on the semantic meaning of words."}
{"completion": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"completion": 172, "text": "query: I am working on a Robotics project involving a robot maneuvering through a room. I need to estimate the depth of objects in the room."}
{"completion": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"completion": 702, "text": "query: I would like to have a way to measure the similarity between different sentences. How can I do that?"}
{"completion": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 72, "text": "query: I am researching historical documents and need to transcribe handwritten texts. Can you help me?"}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: We have a contract from a client. Our boss requested us to enable a question-based answer extraction."}
{"completion": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"completion": 855, "text": "query: We are working with an environmental agency on a project to predict carbon emissions based on input data."}
{"completion": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"completion": 300, "text": "query: Our company would like to generate high-quality images using artificial intelligence for an advertising campaign. These images should be unrelated to any particular topic."}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: Offer a recipe recommender system based on the ingredients in the user's refrigerator."}
{"completion": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"completion": 25, "text": "query: I am developing a multilingual chatbot for my clothing store. Analyze the similarity between our customers' inquiries in different languages."}
{"completion": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"completion": 573, "text": "query: A user wants to chat with our AI regarding their favorite film, which they cannot seem to decide on."}
{"completion": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"completion": 51, "text": "query: We are an AI-based anime creator. We want to utilize text prompts for creating high-quality anime images."}
{"completion": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 923, "text": "query: Develop a system that can extract answer from documents in image format by answering a specific question."}
{"completion": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"completion": 632, "text": "query: A company wants an AI that can translate English text to another language. Propose a way to accomplish this."}
{"completion": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"completion": 430, "text": "query: My manager is asking me the quickest way to access a table for a Python script he is developing."}
{"completion": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"completion": 918, "text": "query: I want to build an app to translate English text to French in real-time."}
{"completion": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"completion": 520, "text": "query: Use the model to compare two pieces of text and return the logical relationship between them."}
{"completion": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"completion": 877, "text": "query: Design a smart thermostat's temperature control algorithm that can minimize the carbon emissions from the heating system."}
{"completion": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"completion": 2, "text": "query: We have a list of documents and are looking for a way to find the similarity between any two documents."}
{"completion": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"completion": 303, "text": "query: Our marketing team is creating promotional materials for Minecraft and we want to generate some unique skins for the Minecraft characters."}
{"completion": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"completion": 657, "text": "query: Write a code that would help with completing sentences, given a partially completed sentence with a missing word marked with `<mask>`."}
{"completion": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"completion": 646, "text": "query: \"Experience the ultimate comfort with our premium-quality shoes.\""}
{"completion": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"completion": 575, "text": "query: We have a large volume of Russian text and we need to summarize it to a smaller length."}
{"completion": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 703, "text": "query: Help me to create a program that can analyze customer reviews and find out which products and services it is comparing."}
{"completion": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"completion": 717, "text": "query: To understand our customers' preferences, we need to analyze descriptions of their favorite books and find similar books accordingly."}
{"completion": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"completion": 160, "text": "query: We are a software agency and we just built a desktop application for our client. The client is a financial institution that needs to recognize the handwritten digits on checks."}
{"completion": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"completion": 754, "text": "query: Working for a customer, our goal is to transcribe audio interviews to create a textual document for further analysis."}
{"completion": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"completion": 317, "text": "query: I need a software that will classify videos in the park if it's a person, animal or equipment."}
{"completion": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"completion": 610, "text": "query: Write a Python function named 'sum_numbers' that takes two numbers as input and returns their sum as output."}
{"completion": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"completion": 26, "text": "query: Develop a text code analyzer that can identify different programming languages and named entities in a given StackOverflow post text."}
{"completion": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"completion": 28, "text": "query: I'm running an advertising campaign, and I need a photo of a city skyline with a giant rubber duck floating in the river."}
{"completion": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"completion": 387, "text": "query: Develop an app that performs sentiment analysis on Spanish texts."}
{"completion": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"completion": 446, "text": "query: Our team is working on a product that answers questions about information in Korean tables. Implement an API to gather information from tables."}
{"completion": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"completion": 121, "text": "query: I need a system to extract information from forms like invoices and registration forms. The model should be able to answer questions regarding the extracted information."}
{"completion": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"completion": 187, "text": "query: Create a model to predict the specific class of an object in an image, uploaded from a URL."}
{"completion": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 786, "text": "query: The musician in our team wants to separate vocals from instrumental sounds. Can you use audio source separation to help him?"}
{"completion": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 663, "text": "query: \"I have two dogs and one ____(cat) at home.\""}
{"completion": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"completion": 381, "text": "query: I am a chatbot developer; I need to optimize my paraphrase creation for my replies. I aim to select the most adequate generated paraphrase."}
{"completion": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"completion": 308, "text": "query: I am preparing an educational book about butterflies. Generate a colorful butterfly image for me."}
{"completion": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"completion": 491, "text": "query: I need you to classify different customer complaints based on their type (e.g. billing, technical issue, account management, or service quality) so that I can better organize incoming support requests."}
{"completion": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 578, "text": "query: My company would like to develop a chatbot that could provide information about our products and handle customer inquiries. We need it to be able to process user inputs and give appropriate responses."}
{"completion": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"completion": 870, "text": "query: We are a group of environmentalists. We have the data of different vehicles and we want to predict their carbon emission."}
{"completion": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"completion": 475, "text": "query: We are designing a system which can answer the question from the given context. The model will use an efficient architecture called DistilBERT."}
{"completion": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 236, "text": "query: We need to segment areas in the city to assist with autonomous car navigation."}
{"completion": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"completion": 931, "text": "query: I need a process to turn my research articles into concise summaries that are easy to understand."}
{"completion": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"completion": 2, "text": "query: We are a language research firm studying similar sentences. We want to find the similarity between two sentences."}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: A social media platform wants to provide personalized content for their users. We want to analyze the images users post and classify them into interest categories."}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: To improve our customer support quality, we are building an automated FAQ answering system. We need to find the most relevant answer for a query from our knowledge base."}
{"completion": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"completion": 423, "text": "query: Our client is an international trading firm that needs a program to analyze Chinese texts. Specifically, it should analyze and tag parts of speech."}
{"completion": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"completion": 610, "text": "query: I am a developer, I have a Python class that needs a method to calculate the area_coverage. Please generate the Python code for that method."}
{"completion": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 690, "text": "query: Our product works on matching user-generated content like social media. How can we compare the similarity of the sentences generated by different users?"}
{"completion": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"completion": 809, "text": "query: I am a software engineer and I have an audio file. Identify the birds in the backyard with natural sounds like chirping, dogs barking, and children playing."}
{"completion": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"completion": 34, "text": "query: I want an API to generate anime-style character images based on textual descriptions. The API must yield high-quality images."}
{"completion": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"completion": 385, "text": "query: I am working on a product and want to analyze customers feedbacks. Classify each feedback into an emotion in our survey."}
{"completion": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"completion": 447, "text": "query: We are an online platform, and we need to get answers for sports-related queries from tables."}
{"completion": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"completion": 447, "text": "query: An application is needed to generate bar chart race graphs based on global CO2 emissions from 1850 to 2018. Provide a method to answer natural language questions about which countries had the highest emissions in certain years."}
{"completion": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"completion": 355, "text": "query: A social media app wants to classify images shared by users into categories like landscape, portrait, and animals. We need to help them classify these images."}
{"completion": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"completion": 809, "text": "query: We want to add audio classification to our app to recommend relevant content based on users' audio input."}
{"completion": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"completion": 451, "text": "query: I need to create a budget tracker for my team. I want to store the expenses in a table and be able to look up the expenses for each team member by asking questions."}
{"completion": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"completion": 493, "text": "query: Apprehend a robot athlete who needs to be able to categorize a sports activity during practice sessions."}
{"completion": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"completion": 269, "text": "query: Our company is developing a browser extension that converts text-to-hand-drawn images. We need the model that is ideal for this."}
{"completion": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"completion": 925, "text": "query: Build a retinal image classification system that determines if a person has diabetic retinopathy or not."}
{"completion": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"completion": 565, "text": "query: Create a summary for this scientific paper I am about to present at a conference."}
{"completion": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"completion": 781, "text": "query: We have a voice assistant project, and our team is Middle Eastern people that mostly speak Arabic. We need to convert our Arabic speech to English for further development."}
{"completion": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"completion": 438, "text": "query: We are an e-commerce store that needs to analyze product inventory data to answer questions about our stock availability."}
{"completion": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 903, "text": "query: My company wants to evaluate the performance of a self-driving car in a simulated environment. We want to assess how well the car balances a pole on its chassis as it moves."}
{"completion": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 900, "text": "query: My company is having a farewell party for a retiring employee, and we want to entertain the guests using an AI-controlled soccer game."}
{"completion": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"completion": 308, "text": "query: Could you make a recommendation for designing a homepage banner which includes an image of a butterfly?"}
{"completion": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"completion": 103, "text": "query: The user wants to develop an application to answer questions based on images."}
{"completion": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 242, "text": "query: Our company is working on developing self-driving cars. We need to segment the objects in the road environment so that the car knows how to avoid obstacles."}
{"completion": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 330, "text": "query: I have a set of videos, and I am looking for understanding the subject and context of the videos."}
{"completion": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"completion": 876, "text": "query: Let's create a predictive model for carbon emissions from a dataset."}
{"completion": 135, "text": "document: A LayoutLM model for document question answering."}
{"completion": 135, "text": "query: Implement a document processing system that is able to extract information and answer questions from an invoice or a billing document."}
{"completion": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"completion": 522, "text": "query: We have an essay in English, translate it into French."}
{"completion": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"completion": 80, "text": "query: A surveillance company needs our help to process and describe images captured by their cameras. Generate a detailed description of each image."}
{"completion": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 449, "text": "query: We need to categorize the sales data of different products into categories of highest sales and lowest sales from the given table. Provide a code snippet to answer this using a table-question-answering model."}
{"completion": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"completion": 388, "text": "query: Develop a system to automatically analyze public opinion of a company's social media posts by the sentiment expressed in the comments."}
{"completion": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 690, "text": "query: We are building an AI-powered platform for organizing articles. Compare the similarity between two given articles by embedding their content."}
{"completion": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 676, "text": "query: In the medical sector, we are building a product to autocomplete a sentence about certain diseases."}
{"completion": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"completion": 478, "text": "query: We are organizing a research group to discuss articles of different topics. We need to extract given answers to specific questions from the articles."}
{"completion": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"completion": 651, "text": "query: Our team is at the final stage of writing web content in English. The text needs to be error-free. Optimize the text for grammar and syntax."}
{"completion": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"completion": 121, "text": "query: Our team is seeking a way to extract information from scanned documents in a question-answering format."}
{"completion": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 190, "text": "query: Our company is working on a social media app and we want to analyze the content of images posted by users. Can you help us identify objects, animals, and scenes in the images?"}
{"completion": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 235, "text": "query: I am building a new navigation app that needs to understand traffic signals and road signs. Help me create a model for this."}
{"completion": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"completion": 756, "text": "query: We are operating a Marathi-language call center and need to transcribe our customer interactions."}
{"completion": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 204, "text": "query: A delivery company wants to make package identification more efficient. They want to identify different types of shipping boxes within a warehouse using an object detection model."}
{"completion": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 462, "text": "query: Develop a table question-answering system to help our customers access information about our product catalog."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: Could you please suggest different ways of saying that I have lost my phone?"}
{"completion": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"completion": 720, "text": "query: I am writing a novel, but I have a low vision. I am looking for a way to convert the text out of my laptop."}
{"completion": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"completion": 274, "text": "query: Imagine we have a text as \"a yellow car in the night\", create a visual image matching this text description."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"completion": 580, "text": "query: We need an AI character that can provide information about climate change to explain the problem to young children."}
{"completion": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 779, "text": "query: Extract speech from a noisy input audio file containing a speaker talking in the background with overlapping sounds."}
{"completion": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"completion": 201, "text": "query: Our company is now working on a pedestrian detection project. We need to detect the pedestrian from the video in real time."}
{"completion": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"completion": 485, "text": "query: What is the right API to use for a bilingual dictionary, English to Chinese?"}
{"completion": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"completion": 58, "text": "query: Develop a service for a photo-sharing app that generates a caption for a user's uploaded picture."}
{"completion": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 774, "text": "query: I want to build a tool that can transcribe Esperanto audio files. How can I achieve that?"}
{"completion": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"completion": 796, "text": "query: Our client wants to extract clean speech from a noisy conversation recorded during a podcast."}
{"completion": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 814, "text": "query: Our customer service requires a mechanism to identify the emotional state of the caller to provide a better response."}
{"completion": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"completion": 846, "text": "query: I recorded a meeting from my phone, and now I want to split the conversations between different speakers. How do I do this?"}
{"completion": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"completion": 616, "text": "query: Write a short article about the benefits of using artificial intelligence in the education sector."}
{"completion": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"completion": 822, "text": "query: I have a smart home device and I would like it to recognize and announce the names of different animals. Can you provide code for recognizing animal names from an audio file?"}
{"completion": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"completion": 348, "text": "query: Our entertainment company needs a model that can help classify movie posters into different genres. We want to explore zero-shot image classification."}
{"completion": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"completion": 744, "text": "query: I want to create an AI application that converts news headlines into spoken Arabic. How can I use a text-to-speech model for Arabic language headlines?"}
{"completion": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"completion": 553, "text": "query: I want to generate the documentation for my Python code."}
{"completion": 14, "text": "document: A tiny random mt5 model for text generation"}
{"completion": 14, "text": "query: You are asked to create a film production company, and you require a press release to present your new project to potential investors. Generate a press release for the upcoming science fiction movie production."}
{"completion": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"completion": 607, "text": "query: Help me write a 100 words story about a dragon and a knight."}
{"completion": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 156, "text": "query: We have a team of archeologists who need to estimate the depth of ancient structures in photographs."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: Detect and segment buildings in satellite images to assist city planning department."}
{"completion": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"completion": 552, "text": "query: Your team is developing a game that tells a story based on user actions and decisions. Your current task is to create a summary generator that can condense the dialogue text and provide a brief overview of the story progression."}
{"completion": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"completion": 116, "text": "query: I am building an application to help users extract specific information from their scanned documents. Design a system to achieve this task."}
{"completion": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"completion": 645, "text": "query: We are launching a global news platform and want to translate English headlines to multiple languages simultaneously."}
{"completion": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"completion": 76, "text": "query: Convert a scanned image of a document into text."}
{"completion": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"completion": 613, "text": "query: To build a story writing platform, we need a chat product to extract AI-generated stories based on the prompts."}
{"completion": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"completion": 573, "text": "query: I want to create an interactive chatbot for customers to ask questions about our store and products."}
{"completion": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"completion": 841, "text": "query: We have a collection of recorded meetings and conferences that need speaker diarization to separate the speakers in the audio recordings."}
{"completion": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"completion": 733, "text": "query: We need a solution to convert Spanish text into clear Spanish male speech."}
{"completion": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"completion": 98, "text": "query: A director wants to make a commercial for a new environmentally friendly electric car. Provide a sample generated video with rainforest trees surrounding a charging station."}
{"completion": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"completion": 361, "text": "query: Determine whether the given image contains either a cat or a dog."}
{"completion": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 64, "text": "query: A startup is trying to use the BLIP-2 model (for answering questions from images) to create an app that can help visually impaired people. They need to know how many characters are in a street name."}
{"completion": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 71, "text": "query: A person is taking part in an online quiz and comes across an image-based question. They need a text description of the image to answer the quiz question."}
{"completion": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"completion": 861, "text": "query: Help me implement a solution to predict the carbon emissions for different models of vehicles using a pre-trained model."}
{"completion": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"completion": 413, "text": "query: Identify entities in a text, such as names, organizations, and locations."}
{"completion": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"completion": 377, "text": "query: Our client is an investment company. They want to analyze news articles to make better decisions. Help us classify financial texts."}
{"completion": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"completion": 284, "text": "query: I have been imagining this scene in my head - a warrior girl in the jungle. Please generate an illustration based on this description using the provided ControlNet model."}
{"completion": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"completion": 213, "text": "query: We are a company focusing on occupational safety, and we want to ensure that all our workers wear hard hats on site."}
{"completion": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"completion": 463, "text": "query: I am building an application that will help medical students by answering their questions. How can I use this model to answer questions related to medical content?"}
{"completion": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"completion": 4, "text": "query: I want to summarize an article written by a journalist in English. I need a fine-tuned model that generates a summarized text from the input."}
{"completion": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 323, "text": "query: The company is building a product to recommend videos of cooking tutorials to users based on their preferences. We need to figure out the categories of videos based on their content."}
{"completion": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 898, "text": "query: We need an advanced AI player for our Pong game. Could you provide a solution that loads a pre-trained agent to use in this environment?"}
{"completion": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"completion": 30, "text": "query: We are writing a children's book and need an image for our main character's bedroom."}
{"completion": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"completion": 718, "text": "query: I need to create a system that generates spoken output for given text."}
{"completion": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"completion": 549, "text": "query: We are building a chatbot to help new users understand our services. Summarize a conversation without text being cut off."}
{"completion": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"completion": 402, "text": "query: As a content publisher, I need an automatic way to identify the names of people, organizations, and locations mentioned in a given text."}
{"completion": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"completion": 16, "text": "query: Develop a voice assistant that takes speech input from users and transcribes it into text, so it can perform various tasks based on the content of the speech."}
{"completion": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 829, "text": "query: Design an application that identifies a person's voice from a given audio file, and then categorize the speaker based on pre-defined categories."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: The company needs a chatbot which can answer in 100 languages, classify sentences in many categories."}
{"completion": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 27, "text": "query: Our startup is working on a content negotiation system. The application should be able to classify videos by their genre with high accuracy."}
{"completion": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"completion": 341, "text": "query: I'm building a video recommendation system. Therefore, I want to classify videos into categories based on their content."}
{"completion": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"completion": 869, "text": "query: Our company is working on a project to analyze timeseries data to detect anomalies. We need to predict when unusual behavior is detected."}
{"completion": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"completion": 528, "text": "query: Our company is making a blog for international travelers. We would like to have automatic translation for English text to German."}
{"completion": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"completion": 596, "text": "query: Our development team needs chatbot to be equipped with its own personality of a sports enthusiast, to engage customers in conversations about sports."}
{"completion": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"completion": 821, "text": "query: I have an application that performs user authentication based on voice commands. I want to identify the spoken numbers (0 to 9) from the audio files."}
{"completion": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"completion": 96, "text": "query: We need to create an application that can summarize a movie script and provide a brief video description. Please provide the steps and necessary code to complete this task."}
{"completion": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"completion": 746, "text": "query: We need a quick method to create a German audio sample from a text input."}
{"completion": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 75, "text": "query: We are an AI company working on text recognition and extraction. We want to transcribe handwritten text from an image."}
{"completion": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"completion": 839, "text": "query: Our new voice assistant can make calls to users. An important feature developers requested is detecting silence during a call. We need to understand when the user has stopped talking in order to make important decisions."}
{"completion": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 450, "text": "query: Our manager is requesting to extract information from a table about monthly sales of different products. Help them find out which product had the highest sales in a specific month."}
{"completion": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"completion": 660, "text": "query: We are working on an AI to help kids with their homeworks. We want to plug in a predicted word in a masked sentence using natural language processing."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: Our team needs to design an intelligent security camera system. We want a program that categorizes video clips from surveillance cameras as safety-related or normal activities."}
{"completion": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"completion": 461, "text": "query: I own a toy store and I want my website to answer frequently asked questions about the toys we sell. Please build a question-answering model for that task."}
{"completion": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"completion": 603, "text": "query: Generate a short introduction about the upcoming technology conference in our city."}
{"completion": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 901, "text": "query: I've just downloaded the pre-trained model for CartPole-v1. Please help me to load this model and test it on a given environment."}
{"completion": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"completion": 17, "text": "query: Design a photo-sharing app that categorizes images based on the content in the image."}
{"completion": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"completion": 38, "text": "query: We want to create a book cover that features a dragon next to a waterfall. Use an existing image of a waterfall and modify it by adding the dragon."}
{"completion": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 774, "text": "query: A linguistics software company in Esperanto is developing an automatic speech recognition system for its users. The goal is to convert spoken language into written text. "}
{"completion": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"completion": 224, "text": "query: Help me to detect different types of blood cells like Platelets, RBC, and WBC from an image."}
{"completion": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 84, "text": "query: We're working on a mobile app for automatically generating photo captions. Use the GIT model for this purpose."}
{"completion": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"completion": 146, "text": "query: As an autonomous vehicles manufacturer, we need to estimate the depth in our cars' camera images to ensure safe navigation."}
{"completion": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"completion": 203, "text": "query: Our company needs to extract tables from a large volume of documents. We would like to have an AI tool to detect tables within these documents."}
{"completion": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"completion": 200, "text": "query: Can you provide me a solution where I can classify the items of the household and find which room it belongs to, like the kitchen or bedroom?"}
{"completion": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"completion": 811, "text": "query: We are a team working on a voice assistant, and we need to detect user emotions from their voice input."}
{"completion": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"completion": 795, "text": "query: We need a speech-to-speech translation model for our international calls that can convert between languages without relying on text."}
{"completion": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 170, "text": "query: Help an interior design team to estimate the depth of objects in a photo to decide appropriate decoration placements."}
{"completion": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"completion": 311, "text": "query: We want to create an artwork project with a vintage style look. Let's generate a vintage-style image to use as inspiration."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: We are running a tournament for the popular game Hopper. Our goal is to create an AI player with the records of the top players."}
{"completion": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"completion": 674, "text": "query: Write a prescription for a patient with the side effect of allergies using the knowledge stored in this pretrained model."}
{"completion": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"completion": 58, "text": "query: A social media platform wants to generate image captions to make their platform more accessible. Help them with this task."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: Evaluate satellite images for areas under construction by locating and segmenting regions containing buildings."}
{"completion": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"completion": 783, "text": "query: Our customer service team is having difficulties understanding callers in noisy environments. We need a tool to enhance the voice quality."}
{"completion": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"completion": 917, "text": "query: We have a medical diagnostics app where doctors can upload pictures of X-rays. We need to classify X-rays as normal, pneumonia, or cancer."}
{"completion": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"completion": 815, "text": "query: I have recorded a conversation between different speakers, and I want to identify unique speakers in the conversation."}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: I need an image classifier to detect the presence of a cat or dog from a supplied image."}
{"completion": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"completion": 800, "text": "query: We're developing a tool that needs to translate Spanish spoken language into English spoken language without processing the written text. Implement a solution to do so."}
{"completion": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 797, "text": "query: I would like to separate the speaking voices in a noisy audio recording."}
{"completion": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"completion": 41, "text": "query: We are developing a game and want to generate anime-style images based on specific character descriptions like \"a warrior with a sword and shield\"."}
{"completion": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"completion": 516, "text": "query: \"The stock market experienced a significant drop today.\""}
{"completion": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"completion": 263, "text": "query: I need to create an image by changing the appearance of an existing image to look like an oil painting."}
{"completion": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"completion": 727, "text": "query: The business needs a Japanese voice assistant that reads customers' messages and passes them to customer support."}
{"completion": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"completion": 594, "text": "query: Our sales department needs a chatbot that will engage with the customers and provide product information when asked."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: In my project I need to estimate the depth of the objects in an image taken from a single camera with no stereo input."}
{"completion": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"completion": 648, "text": "query: Our newspaper website has an article about space exploration. To improve search engine optimization, we need to generate related search queries based on the article text."}
{"completion": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 703, "text": "query: Our customer is creating an app that can visualize the content and theme of a movie. First, we need to identify sentences in the descriptions that have similar meanings."}
{"completion": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"completion": 668, "text": "query: We are publishing an AI article. We need natural language processing to fill the gap in the sentence."}
{"completion": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"completion": 213, "text": "query: We are a construction safety company. We are interested in checking whether our workers are wearing their safety helmets."}
{"completion": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"completion": 882, "text": "query: Create a Python environment that helps me predict carbon emissions based on various input features. "}
{"completion": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"completion": 778, "text": "query: I have a noisy voice recording and want to enhance its quality using an audio-to-audio API. How do I do that?"}
{"completion": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"completion": 765, "text": "query: Create an application that helps Arabic users learn to play instruments by transcribing and translating YouTube content to text for music lessons."}
{"completion": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"completion": 675, "text": "query: I am a Brazilian student wanting to fill gaps in my Portuguese text and find the correct missing word in each sentence."}
{"completion": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 908, "text": "query: I want to create an AI Football game. Generate a configuration to train a team using reinforcement learning."}
{"completion": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"completion": 652, "text": "query: For our educational platform, we want to generate questions based on given answers and text from a lesson."}
{"completion": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"completion": 782, "text": "query: I want to enhance the audio quality of a given audio file, removing background noise and making the speaker's voice clearer."}
{"completion": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"completion": 533, "text": "query: We want to translate an English sentence into Russian."}
{"completion": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"completion": 435, "text": "query: I have a text in Spanish and need information about named entities from it."}
{"completion": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"completion": 227, "text": "query: We have a client who wants to extract tables from scanned documents. Build a program that analyzes a given image and identifies tables within the document."}
{"completion": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"completion": 871, "text": "query: We have a dataset of US housing prices and want to predict future prices based on this dataset."}
{"completion": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"completion": 77, "text": "query: I work for an advertising company. I am looking for generating a tagline for a new yoga apparel product that my company is promoting. I have an image of the product that I want to use as input for describing the product."}
{"completion": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"completion": 809, "text": "query: Can you create a model to help me recognize the type of sound in an audio file?"}
{"completion": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 244, "text": "query: A client needs help to process a picture of a landscape, and they want us to split the objects in the scene with their respective categories."}
{"completion": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"completion": 329, "text": "query: Our security company needs to analyze real-time video footage to identify violence in certain situations. What can we do using the given API?"}
{"completion": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"completion": 858, "text": "query: I want to build a movie recommendation system to categorize movie reviews as either positive or negative. Kindly provide insights on how to achieve this."}
{"completion": 14, "text": "document: A tiny random mt5 model for text generation"}
{"completion": 14, "text": "query: We have a web app for students and want our model to generate creative story ideas for them."}
{"completion": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"completion": 684, "text": "query: I want to build a tool for helping users complete Japanese sentences by predicting missing words."}
{"completion": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"completion": 452, "text": "query: I have a list of DVD features and prices. I need a model to be able to answer questions like \"What is the price of the DVD with the highest resolution?\" based on the provided table."}
{"completion": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"completion": 65, "text": "query: I am a student interested in AI art. I am painting a picture and would like an AI-enabled app to correctly read the mix of hand-drawn handwriting and objects from the picture."}
{"completion": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"completion": 402, "text": "query: We are organizing an event for a client. Extract names and locations mentioned in the email they sent us."}
{"completion": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"completion": 6, "text": "query: We are a company that specializes in digital art. We want to extract features from images using machine learning models."}
{"completion": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"completion": 783, "text": "query: Now a professor wants to enhance the quality of the pre-recorded lessons damaged by noise for his students."}
{"completion": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"completion": 193, "text": "query: Find out what object is present in a given image URL."}
{"completion": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"completion": 848, "text": "query: We are an online library. We need an AI model to categorize book/movie reviews."}
{"completion": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"completion": 758, "text": "query: We have a customer support agency. We need to convert recorded conversations in Russian to text."}
{"completion": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 336, "text": "query: We need to monitor the activities in a zoo via videos. Detect the activity happening in a specific video frame and classify it."}
{"completion": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"completion": 436, "text": "query: We have a news article that we would like to summarize and identify named entities. "}
{"completion": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"completion": 498, "text": "query: I am building an app that will sort news articles into multiple categories. I would like to classify a given news article into categories like 'politics', 'technology', 'sports', 'entertainment', 'business', and 'health'."}
{"completion": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"completion": 359, "text": "query: We are assisting a customer who wants to classify their pet collection into dogs, cats, and birds."}
{"completion": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"completion": 49, "text": "query: A client is interested in an advertising campaign incorporating analog-style images, and they would like a car in the beach setting."}
{"completion": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"completion": 32, "text": "query: I want to generate a photo of a yellow cat peacefully sleeping on a park bench."}
{"completion": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"completion": 458, "text": "query: We have a table with information on various flowers' bloom periods, appearance, and care requirements. Help us answer a question about when a Cherry Blossom blooms."}
{"completion": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 324, "text": "query: I need to detect vegetables and fruit in a 100-frame video using a video classification model."}
{"completion": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 403, "text": "query: We have a historical book club. We need to identify the names of historical figures mentioned in a given text."}
{"completion": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"completion": 62, "text": "query: Our marketing department requires a technology that automatically generates captions for user-uploaded images."}
{"completion": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"completion": 223, "text": "query: We are an esports team and we need to analyze our gameplay to understand player position and strategy using computer vision."}
{"completion": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 739, "text": "query: I want a system that reads french texts that I send it, and play the audio for me."}
{"completion": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"completion": 361, "text": "query: We are building a social media app. Help us detect if an uploaded image contains a cat or a dog?"}
{"completion": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"completion": 248, "text": "query: Implement building segmentation on satellite images to be used for city planning."}
{"completion": 14, "text": "document: A tiny random mt5 model for text generation"}
{"completion": 14, "text": "query: Can you generate a story about an adventurous cat and a rat going on a quest to save their town from a flood?"}
{"completion": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"completion": 669, "text": "query: I am learning French, and I need to fill in the missing words in some sentences correctly."}
{"completion": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 335, "text": "query: Our company wants to improve safety measures in the workplace by providing access to classified videos showcasing proper safety procedures. Implement a video classification model to meet this requirement."}
{"completion": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 190, "text": "query: Our customer is looking for an efficient way to categorize images they took on their trip to a wildlife sanctuary. Help them classify the images."}
{"completion": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"completion": 628, "text": "query: Working on an email campaign, I need to engage the users. I have a basic idea of the email, but a paraphrase version would be helpful to draft multiple emails."}
{"completion": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"completion": 182, "text": "query: We want to automatically tag items in our e-commerce website with corresponding category labels."}
{"completion": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"completion": 574, "text": "query: I have a meeting with my manager and she asked me to summarize an article that she doesn't have time to read. Please, provide me with a summary of this article."}
{"completion": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"completion": 266, "text": "query: A game design company needs to create graphics for their game. They have a basic design drawn on paper and want to convert it to a digital artwork."}
{"completion": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"completion": 807, "text": "query: To improve our customer support, we want to analyze the language of incoming calls automatically. The model should distinguish between 107 different languages."}
{"completion": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 698, "text": "query: There is an NLP project where we need to group similar movie reviews. How can we do it?"}
{"completion": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"completion": 609, "text": "query: Generate 5 different marketing ideas for a new fitness app."}
{"completion": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"completion": 112, "text": "query: Can you help me identify the role of this person in the picture, here is the question \"Who is the person wearing a red shirt in the image?\"?"}
{"completion": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 335, "text": "query: I am an eSports coach and I want to identify the categories of video clips that best represent the skills of my players."}
{"completion": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"completion": 692, "text": "query: I have a database with both English and Chinese language content. My users want to compare the similarity between sentences in the database."}
{"completion": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"completion": 869, "text": "query: To optimize production, a company has to spot anomalies in its sensor data. Explain how we can use autoencoders to fulfill this requirement."}
{"completion": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"completion": 350, "text": "query: I've a picture of a vehicle, and I'd like to know if it's a car or a motorcycle."}
{"completion": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"completion": 18, "text": "query: I am part of a small team of programmers working on a project. We want to leverage our codebase to provide better indexing of modules, functions, and variables. How do we achieve this using artificial intelligence?"}
{"completion": 20, "text": "document: One custom ast model for testing of HF repos"}
{"completion": 20, "text": "query: The company wants to analyze audio files to identify the type of content in the audio. We need to understand the features of the audio files."}
{"completion": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 315, "text": "query: Our team needs a cute image of a butterfly \ud83e\udd8b as a mascot for our children's educational program."}
{"completion": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"completion": 516, "text": "query: We need to classify news articles accurately for a user-friendly experience. I need you to tell me the category for \"Angela Merkel is a politician in Germany and leader of the CDU.\""}
{"completion": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"completion": 396, "text": "query: Please help guide my chatbot to classify incoming messages as questions or statements."}
{"completion": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"completion": 320, "text": "query: Our bot should be able to tell if a person is demonstrating a certain athletic skill, such as sprinting, swimming or weightlifting, from short video clips."}
{"completion": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"completion": 732, "text": "query: Design a language assistant that can translate spoken Spanish language to spoken English language in real time."}
{"completion": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"completion": 214, "text": "query: Design a method that would allow detecting license plates in an image taken by a surveillance camera in a parking lot."}
{"completion": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"completion": 93, "text": "query: \"A fox and a crow fought for a piece of cheese.\""}
{"completion": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"completion": 591, "text": "query: Implement a chatbot to answer customers' questions in the customer service section of an eCommerce store."}
{"completion": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"completion": 26, "text": "query: A developer in our team needs help with extracting named entities and code snippets from StackOverflow text. Design a solution to assist them."}
{"completion": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 154, "text": "query: We are working for an autonomous vehicle company. We need to know the distance of objects relative to the camera of the vehicle."}
{"completion": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"completion": 277, "text": "query: To help the computer vision module to design a better drone, it is required to design a lightweight image super-resolution algorithm and integrate it on the computer."}
{"completion": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"completion": 422, "text": "query: Chinese text segmentation must be optimized. Extract tokens from the given Chinese sentence."}
{"completion": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"completion": 30, "text": "query: I am an artist who wants to generate images based on text descriptions. Help me create surreal paintings by using artificial intelligence."}
{"completion": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"completion": 531, "text": "query: For our customer service team, we need to translate customer complaints from different languages to English."}
{"completion": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"completion": 227, "text": "query: We are an insurance company. We need to develop and use a solution to automatically extract tabels from our customers insurance policy documents."}
{"completion": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"completion": 339, "text": "query: My company's security team wants to classify video footage of intruders."}
{"completion": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"completion": 912, "text": "query: We are a team of tech enthusiasts that want to build a smart robot. Using the available model to identify nearby objects and decide what to do with them would be helpful. How can we achieve this?"}
{"completion": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 676, "text": "query: Our client needs background details of a medicine called \"Ibuprofen\" to optimize search queries for their pharmaceutical website."}
{"completion": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"completion": 111, "text": "query: We are building a robot to understand the contents of an image and answer questions based on that image. The robot needs to support English, Chinese, Japanese, and German languages as input."}
{"completion": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"completion": 527, "text": "query: As a language learning app developer, we need to translate Russian text to English for our users."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: We are going to make an international chatbot that can classify different intents for customer service inquiries in multiple languages."}
{"completion": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"completion": 102, "text": "query: I have a picture and a question related to it. Now, I want to leverage an AI solution that can use both the pictorial and textual information to answer my question."}
{"completion": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"completion": 628, "text": "query: I want to build a tool that will help me to paraphrase text for essays and articles."}
{"completion": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"completion": 509, "text": "query: Write a pipeline to predict categories of text based on the topics they mention. Some topics could be technology, health, sports, etc."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: Identify the depth of objects in a given image for autonomous driving system that has been installed in public transport buses."}
{"completion": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"completion": 820, "text": "query: We need to develop a system that can recognize the language being spoken in various audio recordings. What do I need in order to do this?"}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"completion": 580, "text": "query: Write a dialogue between a person seeking advice about starting a new workout routine and a fitness expert for a blog post."}
{"completion": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 814, "text": "query: We want to create a system that can identify emotions in voice recordings."}
{"completion": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"completion": 845, "text": "query: Our company is building a product for job search, and we want to predict the salary of a job based on some dataset provided."}
{"completion": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"completion": 733, "text": "query: Our company is implementing a virtual assistant that needs to read text in a Spanish male voice for our visually impaired users."}
{"completion": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"completion": 399, "text": "query: We would like you to develop a filter for our social media platform which could classify comments/messages as inappropriate or safe."}
{"completion": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 709, "text": "query: We need to compare product review comments and find the similar comments."}
{"completion": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"completion": 201, "text": "query: A web user uploads an image and wants to classify it into one of the 1000 pretrained categories."}
{"completion": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"completion": 830, "text": "query: Our company is working on an AI-based psychological counseling system. We need to identify the emotions present in the clients' speech in the German language."}
{"completion": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"completion": 344, "text": "query: We are working on a web application that allows users to analyze Instagram images and provide context."}
{"completion": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"completion": 414, "text": "query: I want to know the companies mentioned in this news article."}
{"completion": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"completion": 608, "text": "query: Generate a fictional story about a young scientist discovering a new element."}
{"completion": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"completion": 367, "text": "query: Our company deals with e-commerce in China. We are looking for a solution to classify images based on Chinese text descriptions."}
{"completion": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 319, "text": "query: We are building security cameras and we want to detect events using videos as input."}
{"completion": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 313, "text": "query: We need to generate an image of a cute butterfly for a children's book cover."}
{"completion": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"completion": 835, "text": "query: In order to automatically transcribe a conversation, we first need to detect when someone is speaking."}
{"completion": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"completion": 262, "text": "query: A content creator wants to estimate human poses in an image. They need assistance in understanding body positions in the picture."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: Our next big project is to build an AI-driven auto trading bot for financial markets. Find the best React library to create realistic gesture-based navigation for mobile apps."}
{"completion": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 304, "text": "query: I am building a website for butterfly enthusiasts, and I need to create realistic images of butterflies for my website. Can you generate such images for me?"}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: The library is setting up a portal where readers can ask questions and get appropriate answers. We need a system to find relevant information from given text."}
{"completion": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"completion": 290, "text": "query: Our company needs an artificial intelligence model for generating realistic images of church buildings for a virtual reality simulation."}
{"completion": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"completion": 508, "text": "query: pop, rock, hip hop, country, or jazz."}
{"completion": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"completion": 592, "text": "query: To help understand the mental well-being of users, the company would like to accurately reply to users' questions in an empathetic manner by examining their daily life issues."}
{"completion": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"completion": 801, "text": "query: We are creating a hardware IoT device that receives Romanian speech as input and returns spoken English translation."}
{"completion": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"completion": 433, "text": "query: A list of costs and revenues for different departments in a company are provided in a tabular format. Identify which department generated the most revenue."}
{"completion": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"completion": 789, "text": "query: Help me translate audio from Hokkien to English and also synthesize the translated audio."}
{"completion": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"completion": 141, "text": "query: We want to identify effectively whether a new chemical compound could act as a potential drug candidate based on its molecular structure."}
{"completion": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"completion": 438, "text": "query: We have a retail store and we want to analyze our sales data. There are millions of rows of data, and we want to answer questions about top-selling products, revenues and customer demographics."}
{"completion": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"completion": 180, "text": "query: We want to build an AI system that monitors the visitors' age in our amusement park."}
{"completion": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"completion": 596, "text": "query: Develop a chatbot that can have interesting conversations based on the user's personal preferences."}
{"completion": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"completion": 789, "text": "query: Develop a chatbot for a website to translate speech from Hokkien to English and synthesize English speech for the users."}
{"completion": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"completion": 17, "text": "query: Build me a custom software to manage an image dataset from satellite, we need to detect changes or anomalies in the images."}
{"completion": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 247, "text": "query: We have some images and their URLs. We want to know their content and where the objects are."}
{"completion": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"completion": 916, "text": "query: I am a songwriter. I need help to generate chorus for my new song."}
{"completion": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 1, "text": "query: We are a medical organization, and we want to create a system that can analyze and provide information about medical articles."}
{"completion": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"completion": 182, "text": "query: Our client is interested in a image recognition system for their wildlife photography project to automatically identify animal species."}
{"completion": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 724, "text": "query: Our company is a smart speaker manufacturer. We want to translate an English text into a female Chinese voice."}
{"completion": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 757, "text": "query: We are building a platform that transcribes podcasts. Please help us convert spoken words in an audio to text."}
{"completion": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"completion": 853, "text": "query: A bank wants to predict potential defaulters. Discover useful insights that can help identify whether an individual's income is above or below $50,000 per year."}
{"completion": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"completion": 521, "text": "query: Our client wants to build an AI model to serve news summaries of daily updates."}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: We are an auditing firm. We need to identify the invoice number from an invoice image."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: We need to analyze city planning, and for this we want to segment buildings from satellite images."}
{"completion": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"completion": 112, "text": "query: My child just asked me about the name of building in an image. I don't know the answer, can you help me?"}
{"completion": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"completion": 648, "text": "query: I have a Bible passage text and I need to find a relevant question for the given text."}
{"completion": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 167, "text": "query: I have an IoT-enabled smart home, and I want to estimate the depth of objects in captured images for better interaction with my smart devices."}
{"completion": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"completion": 836, "text": "query: We need to detect voice activity from a meeting to create transcripts of only the segments in which an individual is speaking."}
{"completion": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"completion": 370, "text": "query: We are building a topic detection tool that helps users to know if a given text is positive or negative."}
{"completion": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"completion": 23, "text": "query: We are trying to recommend research papers to students. We need to generate document-level embeddings of research papers."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: Create software that could detect the sentiment of a text in multiple languages, such as English, Spanish, and Chinese."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: A new series of video learning courses are planned for the company. We need to auto-flag inappropriate content in the videos."}
{"completion": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"completion": 894, "text": "query: Create an AI agent that uses the Decision Transformer to learn how to navigate a 2D walking environment."}
{"completion": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 140, "text": "query: Our company needs to extract specific information from some scanned documents. Answer questions related to these documents."}
{"completion": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"completion": 817, "text": "query: Can you please classify this sound, it might be a speech command or a random sound."}
{"completion": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"completion": 855, "text": "query: A car company is looking for a solution to predict the carbon emissions per distance of their vehicles, based on their specific attributes."}
{"completion": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"completion": 24, "text": "query: Our company is using chatbots for customer service. We are looking for a standard text generation solution for creating automated answers based on Russia language model."}
{"completion": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"completion": 537, "text": "query: \"Ich m\u00f6chte ein Auto kaufen. Welche Farbe empfehlen Sie?\""}
{"completion": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"completion": 452, "text": "query: An economic analyst needs help finding average unemployment rates in 2020 amongst different countries mentioned in a table."}
{"completion": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"completion": 534, "text": "query: A friend of mine wrote a story in Italian. I want to understand the story, but I don't know Italian. Please help me understand it."}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: I want to extract the necessary information from an invoice for finance tracking software. Can you find who the customer is on the invoice?"}
{"completion": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"completion": 206, "text": "query: Our company is developing an AI-driven factory. There are cameras that capture the images of the factory. We need to identify what objects are in these images."}
{"completion": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"completion": 38, "text": "query: We are starting an advertisement campaign that requires image generation based on text descriptions."}
{"completion": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 753, "text": "query: We are an e-learning company, and we want to create an app for students to record their lectures and automatically transcribe them into text."}
{"completion": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"completion": 111, "text": "query: Detect whether the image of a mountain in front of me represents Mount Everest or not by asking a question about the mountain."}
{"completion": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"completion": 270, "text": "query: I need an image of a car and estimate its 3D normal map using an AI model."}
{"completion": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"completion": 36, "text": "query: I need to create a machine learning model to generate an image of a beautiful sunset on the beach with a couple holding hands when given a piece of text describing the scene."}
{"completion": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"completion": 647, "text": "query: I need to generate a questionnaire from a given topic to engage with the audience."}
{"completion": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"completion": 55, "text": "query: I'm writing a children's book, and I need a picture of a friendly-looking elephant playing soccer in a sunny meadow."}
{"completion": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"completion": 602, "text": "query: We are producing a digital assistant, and we want it to generate text completion based on the user's question."}
{"completion": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"completion": 280, "text": "query: Our client wants to upscale images in a coffee shop application."}
{"completion": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"completion": 45, "text": "query: An anime producer is looking to create a concept art for their new anime based on a short description of a character."}
{"completion": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 710, "text": "query: We are building an article summarization engine. Now we need to compare each new generated sentences with the original sentences to make sure they maintain the same meaning."}
{"completion": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 140, "text": "query: In real estate, we have a new sale contract. Can you assist us with finding out the price of the house?"}
{"completion": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"completion": 917, "text": "query: A client works at a zoo, and they want a tool that can identify animal species from images. When an image is given, the tool/moment should return three most likely species names."}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: A homeowner needs a device to identify whether an animal in their backyard is a cat or a dog. Design a solution for them."}
{"completion": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"completion": 51, "text": "query: A product is being launched which generates wallpapers for users based on their text descriptions. We need an anime-style image of a sunny day at the beach with a girl playing volleyball."}
{"completion": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"completion": 614, "text": "query: Our company needs to create marketing slogans for a new line of home appliances. Can you come up with some creative ideas?"}
{"completion": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 695, "text": "query: We are building an AI-driven chatbot and want to find the most relevant answer based on user input."}
{"completion": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 22, "text": "query: The company is developing a social media app where users can interact. We need a way to find similarly themed posts that users might be interested in."}
{"completion": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 462, "text": "query: The company wants to answer questions about revenue and expenditure from our financial data tables."}
{"completion": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"completion": 142, "text": "query: I am a researcher in the field of material science, I need a graph model that excels at predicting the quantum properties of material."}
{"completion": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 334, "text": "query: As a video production company, we would like to know what our video is about. How can we do it?"}
{"completion": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"completion": 921, "text": "query: I want to create an AI-based chatbot that can provide answers to questions and carry out a conversation with users."}
{"completion": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"completion": 418, "text": "query: Develop a system that can extract entities like location, organization and person from large paragraphs of texts."}
{"completion": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"completion": 665, "text": "query: We are integrating an AI Chatbot on our website, and we want to be able to automatically fill in incomplete sentences from users."}
{"completion": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"completion": 933, "text": "query: As a news agency, write a code to automatically translate the most important breaking news texts to French."}
{"completion": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"completion": 563, "text": "query: Summarize french news articles for me."}
{"completion": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 923, "text": "query: We have to build a product used in the office that can identify text from a table in an image and answer questions about the stats in the table."}
{"completion": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"completion": 610, "text": "query: We are building a software solution where people can enter an algorithm and get Python code. We are looking for a natural language processing service to generate the Python code for the user."}
{"completion": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 22, "text": "query: We are building a search engine for finding relevant articles with similar content. We need to use sentence similarity information."}
{"completion": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"completion": 33, "text": "query: We are developing a space-themed children's book. Please deliver the illustrations for \"an astronaut riding a horse on Mars.\""}
{"completion": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"completion": 174, "text": "query: Our client is a social platform where users can upload pictures of their cats. We need to classify the breed automatically."}
{"completion": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 907, "text": "query: A group of young developers is developing a soccer game for mobile and wants to create an AI agent to control their in-game soccer team. They need to make use of the available model."}
{"completion": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"completion": 537, "text": "query: A business partner has sent you a document in German, but you need it in Spanish. Provide the translated document in Spanish."}
{"completion": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"completion": 129, "text": "query: Create a program to extract specific information from a form, like finding the email address from a scanned employment form."}
{"completion": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 759, "text": "query: Implement a text-based virtual assistant to identify Portuguese speech from audio recordings."}
{"completion": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 324, "text": "query: You are part of a sports analyzing firm and are required to classify sports activities automatically based on video input."}
{"completion": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"completion": 31, "text": "query: We're making a virtual gallery featuring futuristic cars. Could you please come up with images corresponding to each description?"}
{"completion": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"completion": 881, "text": "query: The environmental agency wants to predict the amount of carbon dioxide emissions for specific equipment based on the supplied dataset."}
{"completion": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"completion": 123, "text": "query: A company wants to digitize documents and provide AI assistance to answer queries about the document. Please suggest a solution."}
{"completion": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"completion": 849, "text": "query: We are building a smart application to help people with disabilities in understanding their job possibilities. We need to analyze their data. We will start with a tabular Transformer model for Structured Data Learning"}
{"completion": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"completion": 75, "text": "query: We want to extract text from an image containing handwritten text."}
{"completion": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"completion": 819, "text": "query: Our company wants to create a phone application that can classify digit pronunciation from audio files."}
{"completion": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"completion": 529, "text": "query: Our customers are a global company. Many of them speak different Romance languages. We want to provide them with localized English instructions."}
{"completion": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"completion": 354, "text": "query: Our application needs to classify images of animals into categories, such as cat, dog, and bird."}
{"completion": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"completion": 470, "text": "query: You are currently using a customer-care automation service. A Korean user has a question and you want to provide the answer."}
{"completion": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"completion": 911, "text": "query: I want to develop a robot-controlled system for picking up objects. Can you help me with learning model suggestions for grasping objects in 6D?"}
{"completion": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"completion": 425, "text": "query: Before starting the graphical design for a new website, our copywriters need a module to extract all proper nouns from texts."}
{"completion": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 318, "text": "query: We are working on a sports video analysis project. We need to classify the actions taking place in the video."}
{"completion": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"completion": 685, "text": "query: We are building an app for law students that helps review contract documents. Predict the most appropriate word to complete a sentence."}
{"completion": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"completion": 510, "text": "query: \"I initially liked the movie, but after some thought, I found it disappointing.\""}
{"completion": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"completion": 87, "text": "query: We would like to translate the text content in product labels into text format."}
{"completion": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 236, "text": "query: I am a developer for a traffic control system. I need to identify traffic lanes and traffic signs from images."}
{"completion": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"completion": 727, "text": "query: For an e-learning platform, use a text-to-speech converter to create narrations of passages from educational texts."}
{"completion": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"completion": 767, "text": "query: A news organization is looking to transcribe their recorded interviews and podcasts. Create a code snippet for automatically transcribing the audio files."}
{"completion": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"completion": 12, "text": "query: We need to transcribe podcasts so that our client can make them available on their platform as text files."}
{"completion": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"completion": 256, "text": "query: We are working on street management; our supervisors are walking through the city and capturing images. We want to detect potholes in these images for repairs."}
{"completion": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"completion": 835, "text": "query: We want to analyze and transcribe a video conference, but first, we need to know when someone is speaking or not. Recommend a library to detect voice activity."}
{"completion": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 159, "text": "query: Our goal is to create a parking assistance system that will use images to estimate the depth of objects. We need a model capable of depth estimation for images."}
{"completion": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"completion": 865, "text": "query: Utilize an inference API to predict recidivism rates in a local community."}
{"completion": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"completion": 702, "text": "query: A company specializing in SEO would like to check the similarity between a set of blog titles to avoid content duplication issues."}
{"completion": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"completion": 586, "text": "query: I want to create a chatbot to have a conversation about mental health and help people feel better."}
{"completion": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"completion": 509, "text": "query: I need a lighter model to help me with sentiment analysis of product reviews."}
{"completion": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 786, "text": "query: Our client is a podcast company who needs to separate speakers in recorded conversations."}
{"completion": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"completion": 801, "text": "query: Our company is working on a mobile application that translates speech from Romanian to English in real-time for tourists visiting the country."}
{"completion": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"completion": 515, "text": "query: Create a zero-shot text classifier that will help us classify user reviews based on their sentiment."}
{"completion": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"completion": 431, "text": "query: I'm teaching a group of students about table question answering, and I need a model for solving their practice questions."}
{"completion": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"completion": 489, "text": "query: The company is building a personal assistant for organizing CEO's flight bookings and generating answers to user's flight-related questions. For instance, when CEO's friend asks \"What's the flight duration from New York to London?\", the system would generate the corresponding answer."}
{"completion": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"completion": 589, "text": "query: We are working on a customer service application. We need to generate responses to customer's messages."}
{"completion": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"completion": 280, "text": "query: A photographer friend of mine has captured a series of images at low resolution. He wants to enhance them and make large prints. What should he do?"}
{"completion": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"completion": 480, "text": "query: I have a robot and it needs to answer questions based on text input. Can you suggest an NLP model for that?"}
{"completion": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 240, "text": "query: I am hosting a photography event, and I would like to segment objects from their background automatically."}
{"completion": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"completion": 841, "text": "query: You are building an automated transcription service for a podcast company and need to identify who is speaking in each segment of the audio files."}
{"completion": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"completion": 860, "text": "query: We would like to classify various plant species using their characteristics."}
{"completion": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"completion": 282, "text": "query: I own a travel agency and would like to create a flyer that showcases beautiful scenery. I have a few photos, but I'd like to change their style to make them more visually appealing. Can you assist me in transforming the input images into a different style?"}
{"completion": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"completion": 460, "text": "query: We want to create a chatbot that can answer questions from tables."}
{"completion": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"completion": 117, "text": "query: We have a pile of invoices from various suppliers, and we need to find which one has the highest total on the invoice."}
{"completion": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"completion": 9, "text": "query: I have a dataset in the Indonesian language, and I want to get the hidden representation of the data using a model specialized in the Indonesian language."}
{"completion": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 903, "text": "query: A gaming company is engaging in the creation of a new player-vs-player game, and they need a computer opponent that can play the game."}
{"completion": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"completion": 435, "text": "query: I work at a hospital. We want to analyze the medical history of a patient to extract and highlight any relevant life events."}
{"completion": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"completion": 471, "text": "query: My publication generates a lot of medical articles. I would like to build an AI program that automatically answers readers' questions based on the content of the medical articles."}
{"completion": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 663, "text": "query: We are building a language model for an online educational platform, and the model will be used in essays and documents creation. The model should be able to predict the masked word effectively."}
{"completion": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"completion": 929, "text": "query: I am working on a project focusing on extracting data from various tables. The computer vision model needs to recognize rows and columns from a given image of a table."}
{"completion": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"completion": 188, "text": "query: We are interviewing candidates for a job position. The hiring committee wants to predict which applicants are more suitable for the job based on the pictures they submitted with their applications."}
{"completion": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"completion": 23, "text": "query: We are a research organization, and we need to find relevant papers based on the content of a specific paper."}
{"completion": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"completion": 480, "text": "query: I want to get answers to questions I have when reading long news articles. I need a model that can handle the questions I have."}
{"completion": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 161, "text": "query: We want to create a tool to provide depth estimation for robot navigation in a warehouse."}
{"completion": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"completion": 407, "text": "query: We have a multinational company and we need to identify the names of people, organizations, and locations in a text."}
{"completion": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"completion": 346, "text": "query: As a car dealership, we want to identify the make and model of the cars in our inventory from photographs."}
{"completion": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"completion": 226, "text": "query: I would like to detect a dog, cat, and some bikes in an image url."}
{"completion": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"completion": 368, "text": "query: We are developing an image description generator for the tourism industry. We need a model to classify attractions, foods, and places to visit."}
{"completion": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"completion": 854, "text": "query: I have a set of iris flower measurements in a CSV file. I need to classify them using a logistic regression model."}
{"completion": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 671, "text": "query: A user is writing an email and needs assistance in filling in missing pieces of the sentence for it to make sense."}
{"completion": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"completion": 470, "text": "query: Assist the user to find answers to questions in Korean text."}
{"completion": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"completion": 12, "text": "query: I am searching for a great all-around audio model that will work in a variety of specific applications such as audio classification, speaker identification, and emotion recognition."}
{"completion": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"completion": 268, "text": "query: An artist needs help visualizing the environment and perspective of a landscape sketch. Assist them by generating an image incorporating M-LSD straight lines to control the diffusion model."}
{"completion": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"completion": 544, "text": "query: The manager needs a translation service that can translate an English text to multiple languages."}
{"completion": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 139, "text": "query: We have a series of invoices which contains information about transactions. We need a solution to extract payment details from these invoices."}
{"completion": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"completion": 579, "text": "query: Design a bot that helps users in need of motivation and inspiration during their day-to-day activities."}
{"completion": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"completion": 604, "text": "query: I want to simulate a conversation where I ask the perspective of an AI called Cosmo about its experience at the EMNLP conference in Abu Dhabi."}
{"completion": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"completion": 109, "text": "query: Create a movie recommendation system that uses multimodal input (text and images) to answer questions about the movies."}
{"completion": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"completion": 408, "text": "query: Extract organization names, location names, and person names from a given news article."}
{"completion": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"completion": 112, "text": "query: Develop a system to help visually impaired individuals by answering questions related to images."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: As part of our autonomous vehicle project, we need to analyse the real-time images from the onboard camera and estimate the depth information for each object present."}
{"completion": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"completion": 321, "text": "query: An educational institute wants to create a system that can classify video tutorials into categories based on the content of the videos."}
{"completion": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"completion": 166, "text": "query: The company is working on autonomous cars. I would like to estimate depth from images to understand the surrounding environment."}
{"completion": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"completion": 677, "text": "query: \"The capital of China is [MASK].\""}
{"completion": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 236, "text": "query: We want to segment cityscape images and analyze different objects in the image."}
{"completion": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 676, "text": "query: A renowned pharmacist from the United States has written an article talking about a new drug that they have successfully tested on mice. This will be able to cure a rare disease that was incurable previously. We have to make sure the generated content is tailored to closely match the field of expertise."}
{"completion": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"completion": 738, "text": "query: We are developing a mobile application for the visually impaired. The app requires text-to-speech conversion to help users interact with text content."}
{"completion": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"completion": 773, "text": "query: We need to design a Vietnamese speech recognition system for interviews in our organization."}
{"completion": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"completion": 253, "text": "query: Build a tool that can remove the background in images with multiple objects."}
{"completion": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"completion": 80, "text": "query: Our design team is conducting a project to generate taglines based on images. We need to extract meaningful information to be further used as inspiration."}
{"completion": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 279, "text": "query: Generate an image of a \"cat sitting on a tree branch\" using Diffusion-based text-to-image generation model."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: I want to build a webpage about city landscape. To build the webpage, I want to find a model that can segment buildings from aerial and satellite images."}
{"completion": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"completion": 862, "text": "query: We are working on a project for reducing the carbon emissions of our company. Now we need to predict the carbon emissions of various departments."}
{"completion": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"completion": 646, "text": "query: I want to create a document summarization tool that can turn any long text into a concise summary."}
{"completion": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"completion": 742, "text": "query: My son is creating a wildlife podcast. Can you please help him convert the written script into a spoken audio? Provide him with a short code to do that."}
{"completion": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"completion": 760, "text": "query: We are developing a mobile application for capturing spoken words from meetings and transcribing them for recordkeeping purposes."}
{"completion": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"completion": 9, "text": "query: We are building a recommendation system that suggests articles to readers. We need a representation of the article texts to recommend related articles."}
{"completion": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"completion": 292, "text": "query: Our client wants us to generate images of beautiful church architecture."}
{"completion": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 456, "text": "query: The school is building a digital library to store the basic information of its books. Create a table visually for the user and help users ask the question \"which books do we have in our school library that were authored by William Shakespeare?\""}
{"completion": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"completion": 202, "text": "query: Determine the category of objects in an image for inventory management."}
{"completion": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"completion": 346, "text": "query: I am designing a program that helps recognize images based on natural language descriptions. The model should be able to tell if the description matches the image."}
{"completion": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"completion": 363, "text": "query: Our company is working on a project that requires the classification of images without training a model. We need a zero-shot image classification model."}
{"completion": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 330, "text": "query: We built a smart city project focused on better understanding human behavior. Analyze a video and classify the activities performed in it."}
{"completion": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"completion": 614, "text": "query: \"The night was dark, and the moon was bright.\""}
{"completion": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"completion": 550, "text": "query: Our customer needs to translate a French document to Spanish as soon as possible. Help them accomplish this task."}
{"completion": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 922, "text": "query: The company I work for makes autonomous robots that move around in indoor environments. We require a solution for estimating depth in a scene."}
{"completion": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"completion": 878, "text": "query: I am part of a startup aiming to reduce carbon emissions. We are building an application that predicts carbon emissions based on user data."}
{"completion": 20, "text": "document: One custom ast model for testing of HF repos"}
{"completion": 20, "text": "query: We are an online streaming service company that wants to leverage audio analysis to provide personalized recommendations. We require an audio spectrogram transformer for this purpose."}
{"completion": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 147, "text": "query: Our company is developing a parking assistance system for autonomous vehicles, and we need to estimate the depth of objects in the environment."}
{"completion": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"completion": 464, "text": "query: Our partner in the educational sector is preparing a question bank. We're going to develop a question and answer program to help them generate questions and corresponding answers."}
{"completion": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"completion": 750, "text": "query: The team is trying to find out the points in a conference call where multiple people are speaking at the same time."}
{"completion": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"completion": 569, "text": "query: I am making a website for a Spanish book selling service. I need to create a short summary for the book descriptions. "}
{"completion": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"completion": 916, "text": "query: Create a text generator to prompt the model to generate ideas for my next movie script about artificial intelligence controlling a city."}
{"completion": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"completion": 579, "text": "query: Generate an engaging and coherent conversation with a chatbot that can discuss various topics and display knowledge, empathy, and personality."}
{"completion": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"completion": 413, "text": "query: Analyze the given text and identify entities such as names, organizations, and locations in it."}
{"completion": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"completion": 564, "text": "query: The local newspaper is looking for a way to automatically create short summaries of lengthy news articles."}
{"completion": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"completion": 2, "text": "query: We have a large corpus of JSON blog articles. We want to determine which article titles are most similar to each other."}
{"completion": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 357, "text": "query: We need to sort the images captured by the company's security camera into categories like human, animal, vehicle, and others."}
{"completion": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 364, "text": "query: I have a robot that needs to identify different species of fish. Figure out a method to classify fish images."}
{"completion": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"completion": 268, "text": "query: The company is working on a project that requires transforming images of empty rooms into furnished rooms. Find a suitable model and transform an image accordingly."}
{"completion": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"completion": 788, "text": "query: In order to improve the sound quality of our recordings, we need a speech enhancement tool to eliminate background noise."}
{"completion": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"completion": 810, "text": "query: A voice assistant can automatically adjust the brightness, color, and mood when playing music. We need to make the voice assistant detect the mood according to the song being played."}
{"completion": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"completion": 117, "text": "query: You have been hired as a software developer for an accounting firm that receives lots of invoices daily. Your task is to design a solution which can quickly take questions from accountants and provide relevant information from invoices."}
{"completion": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"completion": 624, "text": "query: I am a student, and I need to generate ideas for my school project on climate change. Can you help me generate some ideas?"}
{"completion": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"completion": 879, "text": "query: A government environmental monitoring unit uses the provided dataset to predict the carbon emissions; please design a solution for them."}
{"completion": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"completion": 683, "text": "query: Create an AI-based social media post scheduler that fills in the missing word in a given sentence to make it engaging and interesting."}
{"completion": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"completion": 834, "text": "query: Our lifestyle website focuses on Indian users, and we are thinking of implementing an automatic voice activity detection system. Can you provide assistance on this topic?"}
{"completion": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"completion": 855, "text": "query: A client of mine wants to build an application deployed in a factory to send specific values from the machines to monitor the carbon emissions in real time."}
{"completion": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"completion": 749, "text": "query: We have a recorded meeting and we need to separate the speakers in the given meeting."}
{"completion": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 904, "text": "query: Our company is in the robotics field and we would like to train a reinforcement learning model to make an ant-like robot walk."}
{"completion": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"completion": 735, "text": "query: I would like to automatically read a news article to me."}
{"completion": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"completion": 154, "text": "query: Our client needs a solution that can estimate the depth in a given 2D image of an indoor scene."}
{"completion": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"completion": 261, "text": "query: We have a facial picture of a suspect but need to generate a clearer outline of some specific facial features of this person."}
{"completion": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"completion": 543, "text": "query: Translate a Swedish message for a user into English for better understanding."}
{"completion": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"completion": 440, "text": "query: I'm looking for the number of employees working in a company from a given structured data table."}
{"completion": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"completion": 459, "text": "query: Find the total revenue of Apple in 2019 for a finance expert who does not understand tables."}
{"completion": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"completion": 741, "text": "query: \"\u6b21\u306e\u96fb\u8eca\u306f\u30015\u5206\u5f8c\u306b\u5230\u7740\u3057\u307e\u3059\" (The next train will arrive in 5 minutes)."}
{"completion": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"completion": 270, "text": "query: Our current project is to estimate normal maps from images of 3D objects, so that we can improve our 3D rendering system."}
{"completion": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"completion": 628, "text": "query: We are an AI enterprise, and we've designed a chatbot for customer support in the aviation industry. Please help us paraphrase the conversation between a passenger and the chatbot."}
{"completion": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 739, "text": "query: Users of our application now want to have text translated into speech in French. We are looking for a solution for this."}
{"completion": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"completion": 57, "text": "query: A post-apocalyptic adventure, set in 2300, featuring a group of survivors including a scientist, a soldier, and a young hero. The scene should have an eerie aura, with decaying buildings and nature taking over. Include the title \"Reclaim\" on the image."}
{"completion": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"completion": 102, "text": "query: I want to build an application that helps me answer questions related to images automatically."}
{"completion": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 714, "text": "query: We have thousands of scientific articles and want to find similar articles based on their content. Please suggest a way to achieve that using sentence similarity."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: I need a tool to generate clear images from blurry ones. Please provide a solution that helps me with that task."}
{"completion": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"completion": 495, "text": "query: I run a bilingual blog with posts in English and Spanish. I want to automatically categorize the new posts by topic, e.g. culture, sports, politics, and technology."}
{"completion": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"completion": 660, "text": "query: We are building a content generation tool and need a model to predict the missing words in the sentences to improve the overall quality of the writing."}
{"completion": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"completion": 677, "text": "query: Help me to complete the Chinese sentences by filling in the blanks with appropriate words."}
{"completion": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 501, "text": "query: I have two sentences from a news article but I am not sure about their relationship. Classify the relationship between two sentences from the news article as contradiction, entailment, or neutral."}
{"completion": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"completion": 794, "text": "query: A podcast creator is seeking assistance in translating an English podcast episode into French. The creator needs to process the English audio clip and receive a translated French audio file."}
{"completion": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 922, "text": "query: The company is developing a depth-sensing system that adapts the properties of window blinds based on how far objects are from the windows. We need to estimate the depth information of an input image."}
{"completion": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"completion": 465, "text": "query: We need a personal assistant that can help us answering questions from books or articles in various languages."}
{"completion": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"completion": 134, "text": "query: We have a scanned legal document. We need to find the answer to the question \"What is the total amount mentioned in the document?\""}
{"completion": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"completion": 10, "text": "query: As a software development company, we want our virtual assistant to help employees by generating code templates that can be used as a starting point based on their code query."}
{"completion": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"completion": 215, "text": "query: Our client is an esport gaming company. They want to develop an object detection model especially for the game Valorant."}
{"completion": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"completion": 33, "text": "query: We are creating a booklet about space exploration and one of the pages will have an illustration of an astronaut riding a horse on Mars. Please help us with that."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: As an international nonprofit organization, we need to classify news articles for content topics, but the articles can be in multiple languages."}
{"completion": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"completion": 320, "text": "query: As a developer for a city traffic control system, we have to classify the videos into specific categories to identify any traffic violations."}
{"completion": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"completion": 43, "text": "query: We are working on a project of visual storytelling. We need to generate images from text descriptions."}
{"completion": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 171, "text": "query: Add a depth estimation system to our robots to improve their navigation capabilities in our 3D printing facilities."}
{"completion": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"completion": 847, "text": "query: In our restaurant, we want to increase customer satisfaction by improving our wine quality. To do that, we need to predict the wine quality based on its features."}
{"completion": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"completion": 317, "text": "query: Our company is developing a smart security system with video analysis. We need to identify activities in the videos captured by the system."}
{"completion": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"completion": 761, "text": "query: I have recorded a customer interview in Japanese, can you return the transcriptions please?"}
{"completion": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"completion": 679, "text": "query: We are working on a project that involves replacing missing words in a given sentence. We need your expertise in this."}
{"completion": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"completion": 910, "text": "query: We are building a virtual assistant for home, which can recognize objects around the house and interact with them. It should be able to understand the environment and differentiate between objects."}
{"completion": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"completion": 202, "text": "query: We are running a muffin bakery kitchen, and we need to classify pictures to check whether our products are produced correctly."}
{"completion": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"completion": 49, "text": "query: We need to create analog-style images for our online store displaying various types of clothing."}
{"completion": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"completion": 137, "text": "query: Our client has shared an invoice in pdf format. We want to check the total amount on this invoice."}
{"completion": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"completion": 80, "text": "query: I want to describe the content of an image for a visually impaired user, but I don't understand it well."}
{"completion": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"completion": 749, "text": "query: Ron is holding a zoom talanoa involving 3 people. He needs to split the conversation so everybody's script can be assessed independently."}
{"completion": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"completion": 792, "text": "query: We need to isolate the speakers in this audio recording to analyze their speech separately."}
{"completion": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"completion": 648, "text": "query: Recently, a legal team has adopted an AI model to extract relevant questions that may arise from within their client's documents. Develop a model for them."}
{"completion": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 235, "text": "query: We want to analyze aerial photos of a city for urban planning. To achieve that, identify the buildings and roads in these images."}
{"completion": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"completion": 467, "text": "query: A student has a reading comprehension test about the importance of model conversion. Generate an answer to the question \"Why is model conversion important?\" from the given context."}
{"completion": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"completion": 804, "text": "query: We want to recognize emotions from voice notes left by our customers as their feedback using a model that outputs emotion probabilities."}
{"completion": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"completion": 861, "text": "query: I am an environmental manager, I need to predict the similarity between parcel codes based on their carbon emissions."}
{"completion": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"completion": 845, "text": "query: We are a medical institute that needs to classify medical records into categories."}
{"completion": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"completion": 160, "text": "query: We have developed a GTA5 game AI model and now want to apply it for traffic prediction of GTA5."}
{"completion": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"completion": 202, "text": "query: I want to build a program that connects to my home security system and recognizes whether an object appears to be out of place or not."}
{"completion": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"completion": 472, "text": "query: Can you make a question answering model where it can predict information related to vaccines in a particular area due to outbreaks?"}
{"completion": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"completion": 73, "text": "query: There is a new social media app where users want to generate smart captions for their photos automatically. Design a feature that generates creative captions for their images."}
{"completion": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"completion": 230, "text": "query: As a parking assistant app, we need to detect license plates from the live feed of our security camera."}
{"completion": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 357, "text": "query: We are a pet adoption agency. We need to classify the images of pets, whether they are cats or dogs."}
{"completion": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"completion": 340, "text": "query: The marketing department wants to automatically sort promotional videos into categories, like food, technology, and fashion. Help with a solution."}
{"completion": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"completion": 197, "text": "query: We want to develop a system for automatic tagging of products on e-commerce websites using computer vision."}
{"completion": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"completion": 214, "text": "query: We are building an application that identifies license plates in our parking lot. We need a solution to detect license plates in images."}
{"completion": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"completion": 340, "text": "query: In order to monitor activity at our security checkpoints, we require an automated system to classify events in the surveillance video."}
{"completion": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"completion": 109, "text": "query: I am building a home automation system. Whenever my guests or family ask questions, the system should answer by analyzing the images in the room."}
{"completion": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"completion": 644, "text": "query: It's  the middle of the night and I have insomnia. I need my text translated from English to Russian to send some information to my collagues in Russia."}
{"completion": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"completion": 522, "text": "query: Create a translation system for translating English text to French using Hugging Face."}
{"completion": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"completion": 397, "text": "query: We are a restaurant reviewing website. We want to determine if a Yelp review is positive or negative."}
{"completion": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"completion": 286, "text": "query: Create a neural network model for generating unique images of houseplants for a gardening website."}
{"completion": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"completion": 47, "text": "query: I need a tool that transforms my text into images. The images should be produced in three unique art styles that can be mixed and weighted."}
{"completion": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 710, "text": "query: Tell me how this tool can be used to measure the similarity between two sentences, as part of my research about semantic similarity."}
{"completion": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"completion": 842, "text": "query: I am building an app for wine recommendations. I am interested to classify wine quality based on its features."}
{"completion": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"completion": 712, "text": "query: Recommend a Chinese NLP model to calculate the semantic similarity between sentences in a large dataset."}
{"completion": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"completion": 203, "text": "query: Design a feature for a mobile application that processes images of documents with tables and extracts the table content."}
{"completion": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"completion": 563, "text": "query: Summarize an article in French about economics."}
{"completion": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"completion": 894, "text": "query: Our team is developing a robotics walking simulator, and we would like to leverage an AI model to create realistic walking behavior."}
{"completion": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"completion": 417, "text": "query: We need to detect and analyze named entities in a given text, such as places, names, and dates."}
{"completion": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"completion": 188, "text": "query: A company needs help with cataloging plants in their nursery. They have provided an image of one plant and would like to know which plants it has in the photo."}
{"completion": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"completion": 530, "text": "query: I received an email in Spanish from a client, but I only speak English. I need a translator to understand the content."}
{"completion": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"completion": 628, "text": "query: I need a copywriting tool for my social media content. Provide me a way to rephrase my sentences so that the meaning stays the same but the wording is different."}
{"completion": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"completion": 473, "text": "query: I have a list of questions and answers that I would like to find the answers to quickly. Pick the model most suited for the task and how can I execute it?"}
{"completion": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"completion": 668, "text": "query: Write a smart AI chatbot that can complete sentences with missing information."}
{"completion": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"completion": 609, "text": "query: Can you provide a creative beginning for a sci-fi novel?"}
{"completion": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"completion": 356, "text": "query: We want to classify images of animals with zero-shot learning."}
{"completion": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"completion": 321, "text": "query: Our team is working on a project that needs to identify common gestures from videos. Help us find a suitable model."}
{"completion": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 434, "text": "query: We have collected some tables and relevant queries for our online shop. Now, we need to create a Q&A system to answer customers' questions."}
{"completion": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"completion": 540, "text": "query: \"Good morning everyone, I hope you are all doing well.\""}
{"completion": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 687, "text": "query: Compare two sentences and determine how similar they are based on their semantic structure."}
{"completion": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"completion": 810, "text": "query: I need to evaluate the performance of an advertising campaign by detecting the emotions elicited by the ad based on the spoken content."}
{"completion": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"completion": 58, "text": "query: Our company develops social media platform. We want to create captions for photos uploaded by users."}
{"completion": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"completion": 461, "text": "query: A geography teacher would like to find the correct answer to certain student's questions, using a system that can find the answers online."}
{"completion": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"completion": 741, "text": "query: We need to deliver a Japanese speechbot to facilitate smooth conversion of news text articles into speech."}
{"completion": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 441, "text": "query: We want to provide details about student's average performance. Calculate the average of Alex, Anna, and George in a given table."}
{"completion": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"completion": 581, "text": "query: We are running an e-commerce company. Our support chatbot should generate a funny message in the style of Elon Musk."}
{"completion": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"completion": 37, "text": "query: A graphic designer has requested a high-resolution image representing a futuristic city skyline at dusk with flying cars and spectacular architecture."}
{"completion": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"completion": 197, "text": "query: The botanic conservation agency is looking for a tool to categorize flower images."}
{"completion": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"completion": 532, "text": "query: I'm working on a project that requires translating multiple English sentences into Portuguese. Kindly provide a snippet to utilize this model."}
{"completion": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 710, "text": "query: The marketing team wants to ensure similarity in the message provided in ad campaigns in different languages."}
{"completion": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"completion": 784, "text": "query: We are conducting a demo for a machine learning tool for converting speech of one person to another person's voice. We are going to use a sample speech from a dataset to demonstrate voice conversion."}
{"completion": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"completion": 360, "text": "query: Our company is analyzing aerial images to understand infrastructure development in different locations. We need an AI to classify images of areas such as residential neighborhoods, playgrounds, stadiums, forests, and airports."}
{"completion": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"completion": 216, "text": "query: Global Offensive player detection feed, we need to identify players in the game and on which team they are in."}
{"completion": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"completion": 173, "text": "query: Our company has recently developed a new toy robot for children. We need to build a classifier for the robot to recognize objects in pictures."}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: We have a knowledge management software. Our customer service agents need to retrieve relevant knowledge base answers to user questions."}
{"completion": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"completion": 281, "text": "query: Create a program that produces a new image by reimagining the input image. Modify the input image with guidance like \"add more trees\" or \"make the sky darker.\""}
{"completion": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"completion": 51, "text": "query: Develop an AI chatbot that can generate a relevant anime-style image based on a given textual description."}
{"completion": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"completion": 331, "text": "query: As a parent, I want to find out if videos are safe for my kids by classifying the content in the videos."}
{"completion": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"completion": 594, "text": "query: We're developing a chatbot for a big tech company. It should be able to provide general information, as well as answer questions based on user input."}
{"completion": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 70, "text": "query: As an application builder in a video content company, I am helping to build a video suggestion product. We need to know which content is the most attractive."}
{"completion": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"completion": 152, "text": "query: We are designing a robot to navigate through complex environments and need a way to estimate the depth of objects in the environment."}
{"completion": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"completion": 33, "text": "query: We are a company that develops interactive advertisements. We need to generate images of superheroes with unique attributes based on textual descriptions."}
{"completion": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"completion": 25, "text": "query: We are running a matchmaking app, based on the preference of the user we are trying to generate a potential partner biographies."}
{"completion": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 131, "text": "query: I have a document that contains various useful information. Please help me build a system to find answers to the questions related to the content of the document."}
{"completion": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"completion": 723, "text": "query: We need to convert a short text about product information into speech, so we can use it in our promotional video."}
{"completion": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"completion": 744, "text": "query: Create a voice response to a question, \"How are you today?\" in Arabic."}
{"completion": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"completion": 92, "text": "query: I want to generate a bird-themed video with the story of a bird saving a forest from a fire, with emphasis on a majestic bird flying above the flames."}
{"completion": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"completion": 431, "text": "query: We need to create a question answering system that can give correct answers based on a table containing data."}
{"completion": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"completion": 103, "text": "query: We have a user-facing app that collects customer feedback. It uses an image sent by the customer and a relevant question. Provide a mechanism to get appropriate answers to the given question."}
{"completion": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"completion": 300, "text": "query: Let's create a high-quality image of a model for our advertising campaign."}
{"completion": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"completion": 126, "text": "query: Your company needs to automate the extraction of relevant data from invoices. Identify important information from the invoice."}
{"completion": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"completion": 273, "text": "query: I have a low-resolution image, and I would like to increase its resolution to twice its current size."}
{"completion": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"completion": 121, "text": "query: Evaluate the VAT refund policy of a company by answering questions. Remember, the same document got a text and table representation."}
{"completion": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"completion": 856, "text": "query: We are a start-up that wants to classify whether a car emits a high or low amount of carbon emissions based on its specifications."}
{"completion": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"completion": 31, "text": "query: We are hosting an art exhibit and need to create an AI-generated painting of a calm, serene nature scene in the Midjourney style."}
{"completion": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"completion": 214, "text": "query: I'm developing a parking system application which needs to automatically detect the license plate numbers of vehicles entering the parking lot. Find a suitable model for this task."}
{"completion": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"completion": 830, "text": "query: We are building a chatbot for a German company that handles customer support. It would be great if we could detect the emotions of customers to cater to their needs better through audio calls."}
{"completion": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"completion": 385, "text": "query: I would like to analyze the emotions contained in a piece of text."}
{"completion": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"completion": 229, "text": "query: Extract moving objects in a video frame from a traffic camera to count cars, motorcycles, and trucks."}
{"completion": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 323, "text": "query: We need to classify the given basketball game video footage into different highlights."}
{"completion": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"completion": 451, "text": "query: Design a program that tells me the area of production in agriculture for a specific year of a data table."}
{"completion": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 536, "text": "query: Your company plans to expand into the Chinese market and requires you to translate the homepage information for the Chinese audience."}
{"completion": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"completion": 110, "text": "query: A visually impaired user needs to know what an image represents. Our service will provide an answer based on the user's question about the image."}
{"completion": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"completion": 301, "text": "query: An astrophysics student wants to generate creative images of universes for her final project. How can she use your model?"}
{"completion": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"completion": 878, "text": "query: We are an automobile company and want to predict carbon emissions for our upcoming car models. Provide the required code."}
{"completion": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"completion": 671, "text": "query: \"The moon is <blank>, but it does not have <blank>.\""}
{"completion": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"completion": 517, "text": "query: We have a customer report in German. We want to classify some main topics based on the report."}
{"completion": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"completion": 725, "text": "query: You are participating in a group conversation and you want to check the quality of the voiceover given the text input. The conversation was in English."}
{"completion": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"completion": 598, "text": "query: Develop a conversational agent that can generate responses in Russian for my customer service in the home decoration industry."}
{"completion": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"completion": 358, "text": "query: \"pneumonia\", \"fracture\", or \"normal\"."}
{"completion": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"completion": 522, "text": "query: The user needs to translate text from English to French for a business meeting."}
{"completion": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"completion": 363, "text": "query: We're designing a gardening app which is capable of recognizing various types of plants. Help me implement a feature to identify the plant from an image the users provide."}
{"completion": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"completion": 836, "text": "query: I want to process a call center conversation and detect the voice activity in it."}
{"completion": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 426, "text": "query: We are in a cyber security team, we need to detect named entities in a text and classify them as person, location, organization, or other."}
{"completion": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"completion": 675, "text": "query: I'm writing an email in Portuguese to our customer. Can you help me autocomplete the sentence?"}
{"completion": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"completion": 704, "text": "query: Looking to build a recommendation system for products from my website but need some help on how the recommendation can be made."}
{"completion": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"completion": 299, "text": "query: I am an architect looking to develop a virtual bedroom model. Create an image of a bedroom that I can use for my project."}
{"completion": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"completion": 513, "text": "query: I have a blog, and I want to introduce a comment moderation system, which can categorize comments automatically as 'positive', 'negative' or 'neutral'."}
{"completion": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"completion": 679, "text": "query: We have a new AI blog, and we want to use AI to generate text based on chosen keywords."}
{"completion": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"completion": 194, "text": "query: We are setting up a hotdog stand and we need to analyze and obtain feedback on our hotdog images. We would like a system that will determine if it is a hotdog or not."}
{"completion": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 500, "text": "query: A social media platform wants to identify misleading or disinformation content. Create a method to detect if a given post is related to politics or science."}
{"completion": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"completion": 88, "text": "query: I want a video of a cat chasing a laser pointer for my presentation."}
{"completion": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"completion": 145, "text": "query: Our latest project involves computer vision tasks, and we need to build a model for depth estimation. We are particularly interested in a large-scale and accurate DPT architecture."}
{"completion": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 304, "text": "query: Develop an application for a museum where visitors can upload pictures of butterflies, and the application will generate new, similar images."}
{"completion": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"completion": 583, "text": "query: I'm a game developer. I want to create a chatbot for a medieval knight character in my game. The knight is brave, loyal and follows the code of chivalry."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"completion": 580, "text": "query: We have hired a playwright to write a story for us. Help them draft dialogues and play the character of the king."}
{"completion": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"completion": 442, "text": "query: The accountant in the firm needs the information about past expenses from the dataset to close the financial year. Help them fetch the total expense for the year 2018."}
{"completion": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"completion": 775, "text": "query: Create a software that can transcribe a Chinese conversation from a file"}
{"completion": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 313, "text": "query: Build a system that generates images of galaxies using the diffusion model 'myunus1/diffmodels_galaxies_scratchbook'."}
{"completion": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"completion": 60, "text": "query: A publisher needs to convert the text in a Japanese manga page into a digital format for their online release."}
{"completion": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"completion": 713, "text": "query: Our company is working on a project to help people find relevant articles by inputting a sentence. Create a model to check semantic similarity between a given sentence and various articles."}
{"completion": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"completion": 45, "text": "query: An artist approached us to help them visualize their idea. Create an anime-inspired landscape based on their description."}
{"completion": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"completion": 556, "text": "query: We are working in a German newspaper agency. We need to summarize an article so that a reader can grasp its main points quickly."}
{"completion": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"completion": 860, "text": "query: An agriculture company needs to classify different types of plants using data collected from measurements of their properties."}
{"completion": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"completion": 218, "text": "query: We need to create a program that can help us find laptops and cups from images."}
{"completion": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"completion": 498, "text": "query: Your company runs a science blog. Someone from the tech team wants to know how certain content should be labeled."}
{"completion": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"completion": 666, "text": "query: A company is building a conversational assistant which requires smart response suggestions. We need a functionality related to masked language modeling."}
{"completion": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 462, "text": "query: Provide a code snippet that extracts the number of stars for a repository from a table containing repositories and their corresponding statistics."}
{"completion": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"completion": 755, "text": "query: Can I transcribe a podcast to distribute the content as an e-book?"}
{"completion": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"completion": 164, "text": "query: A developer working on a computer vision project requires a depth estimation model for their prototype. Suggest a suitable pre-trained model for their use."}
{"completion": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"completion": 384, "text": "query: Use a pretrained model for sentiment inferencing to find out if stock-related comments are positive or negative."}
{"completion": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"completion": 850, "text": "query: We are building a product for an insurance company to determine if their user should purchase an insurance policy based on financial information."}
{"completion": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"completion": 634, "text": "query: Help me translating English text to German while preserving the context."}
{"completion": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"completion": 848, "text": "query: A cellphone company wants you to create an automated tool for quickly determining if the movie review text is positive or negative."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"completion": 580, "text": "query: We would like to create a chatbot to handle customer service inquiries. How can we do that?"}
{"completion": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"completion": 388, "text": "query: I am writing a script for analyzing tweets from my company's social media. The program can determine the sentiment of each tweet as positive, negative, or neutral."}
{"completion": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"completion": 191, "text": "query: We have recently adopted a dog from a shelter. To improve its training, we want to create an app that can automatically recognize dog breeds from images."}
{"completion": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"completion": 595, "text": "query: Develop a chatbot, trained on conversation data from video games, to interact with the user."}
{"completion": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 335, "text": "query: I need a model to analyze soccer videos and classify each video into predefined categories like goals, free-kicks, penalties, etc."}
{"completion": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 244, "text": "query: I'm working on a project that performs image segmentation. I need a pre-trained model that can handle semantic, instance, and panoptic segmentation tasks."}
{"completion": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"completion": 416, "text": "query: Help me create a resume screening tool, which can extract the name, organization, and location from the given text."}
{"completion": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 429, "text": "query: Assist me in identifying the names of German places and people within a text."}
{"completion": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"completion": 238, "text": "query: Working as a traffic police officer, I need to identify different vehicle types on roads using image segmentation."}
{"completion": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"completion": 516, "text": "query: \"We are looking for a talented software engineer with strong programming skills in Python and experience working with cloud technologies.\""}
{"completion": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"completion": 374, "text": "query: The tourism company needs a tool to automatically recognize the location of tourist photos from a list of possibilities."}
{"completion": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"completion": 515, "text": "query: Isolate statements that have a political bias. Classify the detected bias into categories like left-wing, right-wing, and centrist."}
{"completion": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 325, "text": "query: Our client is a sports analytics company. We need to analyze and classify actions in a given video clip."}
{"completion": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"completion": 232, "text": "query: Our health center specializes in blood testing, and we want to automate the process of detecting blood cells from the images captured by the microscope."}
{"completion": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"completion": 73, "text": "query: We want to integrate a feature that automatically generates captions for images on our website."}
{"completion": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"completion": 143, "text": "query: We are a bank and we want to automatically process loan applications. We need to extract the required information from the filled forms."}
{"completion": 135, "text": "document: A LayoutLM model for document question answering."}
{"completion": 135, "text": "query: We have a batch of scanned documents and need to extract information by answering specific questions about the content."}
{"completion": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"completion": 746, "text": "query: I have drafted some text for a German voicemail greeting. Help me create an audio file from this text using Text-to-Speech and save it in WAV format."}
{"completion": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"completion": 556, "text": "query: Our German language department is processing long articles. They need a tool to summarise it."}
{"completion": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"completion": 506, "text": "query: Show me how to detect anomalies in the content of short phrases. I want to shortlist phrases that are related to food, health, and nutrition."}
{"completion": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"completion": 401, "text": "query: I am building a library catalog system that needs to match user queries with book descriptions."}
{"completion": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"completion": 762, "text": "query: Implement a solution that allows transcribing audio files into text for better accessibility."}
{"completion": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"completion": 57, "text": "query: We need to generate an image of a futuristic city with skyscrapers, flying cars, and colorful neon lights from a detailed text description for a sci-fi movie poster."}
{"completion": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"completion": 289, "text": "query: In our movie production, we need a realistic promotional image of a celebrity for our upcoming project."}
{"completion": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"completion": 408, "text": "query: We want to analyze news articles for named entities. Focus on detecting important people, locations, and organizations mentioned in the articles."}
{"completion": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"completion": 344, "text": "query: I work in a fashion company, and I want to create a bot that recognizes the material of clothing in a given picture (leather, cotton, etc.)."}
{"completion": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"completion": 648, "text": "query: Our organization has a large database of technical documents. We would like to generate questions based on these documents to facilitate discussion during team meetings."}
{"completion": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"completion": 654, "text": "query: I am competing in a coding challenge held by my local programming community. I want my AI to help me by generating some Python code when I describe the task."}
{"completion": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"completion": 719, "text": "query: I'm creating an audio book app that needs to convert text to audio. I need to convert a chapter of text to audio."}
{"completion": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 322, "text": "query: The school is having a talent competition, and we have to analyze the videos of the participants. Classify the type of action being performed in a given video."}
{"completion": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"completion": 497, "text": "query: I am a filmmaker creating a series of short films. I need to sort them into genres like thriller, sci-fi, romance based on their plot description."}
{"completion": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"completion": 214, "text": "query: I want to create an app which detects the license plates of any parked vehicle in my city."}
{"completion": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"completion": 136, "text": "query: I received an invoice and want to extract some information from it. I have a scanned image of the invoice and need to find the invoice number."}
{"completion": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 456, "text": "query: I am looking for a table about Olympic Games and I want to find out the year when Beijing hosted the Olympic Games."}
{"completion": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"completion": 384, "text": "query: An investment company wants to evaluate the user sentiment from StockTwits messages to make investment decisions."}
{"completion": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"completion": 921, "text": "query: Design a chatbot that generates responses in a conversation based on the user's input history."}
{"completion": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"completion": 884, "text": "query: We run a restaurant and want an algorithm to predict the tip amount for our customers."}
{"completion": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 827, "text": "query: Create a speech security system that uses speaker verification."}
{"completion": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"completion": 76, "text": "query: We want to convert handwritten text from an invoice into digital text. How can this be done using the provided API?"}
{"completion": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"completion": 149, "text": "query: Helping a robotics company to navigate autonomously. They would like to estimate the distance to the obstacles in the final image."}
{"completion": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"completion": 351, "text": "query: The product I'm developing aims to identify the style of an artwork. I need a model that can classify it into abstract, expressionist, impressionist, or surrealist categories."}
{"completion": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"completion": 337, "text": "query: We are a content creator and are analyzing comments on our video's. See if the user comments are positive or negative."}
{"completion": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"completion": 35, "text": "query: I'm an exhibit designer, and I need a tool that can generate pictures of animals in the museum's new exhibit simply based on text descriptions."}
{"completion": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"completion": 393, "text": "query: A German learning platform wants to analyze the sentiment of user reviews for their courses. Help them classify the sentiment of these reviews."}
{"completion": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"completion": 915, "text": "query: I've seen this movie. To me the movie was beyond perfection because of the intense character study. Give a sentiment score to my take."}
{"completion": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"completion": 719, "text": "query: We need to create an audio file from a given text for our online tutorial."}
{"completion": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 334, "text": "query: A startup is developing an exercise-tracking application, and they need help identifying the exercise type in a user's uploaded video."}
{"completion": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"completion": 723, "text": "query: Write a report about the effects of climate change and have it converted into an audio file."}
{"completion": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"completion": 921, "text": "query: Design a prototype of a chatbot for our event management company."}
{"completion": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"completion": 544, "text": "query: Sum up the main content in English, translate it in French."}
{"completion": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"completion": 209, "text": "query: I need a solution to detect the tables inside scanned document images."}
{"completion": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"completion": 452, "text": "query: I need a tool to find information from a table in our company documents. We have various tables containing data about our employees, projects, and finances."}
{"completion": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"completion": 520, "text": "query: In my speech therapy class, I need to help a russian studen with speech impairment. Can we predict if this statement is true or false from his narrative or statement?"}
{"completion": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"completion": 52, "text": "query: 'A soothing landscape with the sun setting over a tranquil lake surrounded by trees.'"}
{"completion": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"completion": 378, "text": "query: The company is interested in tracking the sentiment of financial news articles to make informed investment decisions. Discover a model to analyze such texts."}
{"completion": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"completion": 831, "text": "query: I want our smart speaker to recognize simple speech commands like \"play\", \"pause\", \"stop\", \"next\", and \"previous\"."}
{"completion": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"completion": 792, "text": "query: Our company is developing an app for sharing conversations from live events. We need this app to isolate individual speakers from the background noise and other speakers."}
{"completion": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"completion": 39, "text": "query: Asynchronously generate a realistic image of a tropical beach with palm trees."}
{"completion": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"completion": 926, "text": "query: I need a text-based system to segment a picture of a natural scene with animals into distinct regions. The regions should correspond to animals, plants, water, etc."}
{"completion": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"completion": 551, "text": "query: We are translating an application from Finnish to English."}
{"completion": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"completion": 359, "text": "query: There is a new dataset of animals and we would like to categorize them into birds, mammals, reptiles, and fish."}
{"completion": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"completion": 713, "text": "query: We need to compute semantic similarity scores between pairs of sentences to classify related news articles effectively."}
{"completion": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"completion": 676, "text": "query: Prepare a model to help us fill the missing words in bio-medical texts."}
{"completion": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"completion": 298, "text": "query: We need an image generation model that can create new images based on the pre-existing CIFAR10 dataset."}
{"completion": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"completion": 835, "text": "query: We are a customer support center. We need to analyze phone call recordings and find when the customers are speaking."}
{"completion": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"completion": 117, "text": "query: Our client is a bookkeeping company who wants to extract relevant information, such as company name, dates, and amounts, from receipts and invoices."}
{"completion": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"completion": 658, "text": "query: To summarize meeting notes, we are building an application for internal use in the company."}
{"completion": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 357, "text": "query: We need a system for fast image recognition in our inventory management software that can recognize products based on their images."}
{"completion": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 244, "text": "query: We are developing a security system to identify restricted areas for drones to fly over. We need to segment imagery into key structures and landscapes."}
{"completion": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 501, "text": "query: I am creating a software to analyze business deals. Adapt an API to help us understand if two given sentences contradict, entail, or are neutral to each other."}
{"completion": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"completion": 103, "text": "query: We have an AI voice assistant that can detect objects in photos. We need this model to answer questions about the objects in the image it detects."}
{"completion": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"completion": 493, "text": "query: I would like to develop a tool that helps me organize my documents in categories such as travel, cooking, and dancing."}
{"completion": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"completion": 755, "text": "query: The marketing team wants to transcribe the speech from our latest TV advertisement so it can be translated for international audiences."}
{"completion": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"completion": 770, "text": "query: Our company is working on transcribing some audio files, we need to transcribe this audio file."}
{"completion": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"completion": 329, "text": "query: We need to classify if a video contains any real-life violence situations or not."}
{"completion": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 243, "text": "query: I own a hotel and want to analyze the hotel's surroundings for better marketing purposes. Identify the objects in the photo and segment them accordingly."}
{"completion": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"completion": 597, "text": "query: We want to implement a chatbot that can engage with users in natural conversations."}
{"completion": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"completion": 73, "text": "query: I'd like to create an image captioning application for my app users that are visually impaired. Can you help me generate captions for the images they take?"}
{"completion": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"completion": 387, "text": "query: Tell me if these tweets are in support, oppose or neutral to the government policies. Analyze their sentiment using a transformer model."}
{"completion": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"completion": 146, "text": "query: Estimate the depth map of a given image for our autonomous driving project."}
{"completion": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"completion": 422, "text": "query: A Chinese newspaper publisher needs to split the words in their articles to be easily read by non-Chinese speakers."}
{"completion": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"completion": 195, "text": "query: We have an online shopping platform. It has products of various classes like electronics, clothing, etc. We need a way to automatically classify these items."}
{"completion": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"completion": 13, "text": "query: As an e-commerce website owner, I would like to identify similar product descriptions to recommend them to the customers."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: Measure the depth of the objects in an image using a depth estimation model."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: Develop an AI agent for Gym Hopper environment using Decision Transformer model."}
{"completion": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"completion": 552, "text": "query: We are working on a chatbot that can condense long conversations into shorter ones for easy access to important information."}
{"completion": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"completion": 866, "text": "query: The company wants to improve its environmental footprint by analyzing the carbon emissions of different activities. Implement a solution to make predictions."}
{"completion": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"completion": 788, "text": "query: Your task is to design a noise reduction system for voice recorders. Get rid of the noise from the input file."}
{"completion": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"completion": 56, "text": "query: We are a company specializing in promotional graphics. Our client would like an upscaled image of their server room for use in marketing materials."}
{"completion": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"completion": 499, "text": "query: Our marketing team targets Spanish-speaking audiences. We need to categorize new articles for a better understanding of our audience's interests."}
{"completion": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 271, "text": "query: Let's pretend we are a marketing company. We want to build a visualization concept board for a children's book based on a particular scene description."}
{"completion": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"completion": 57, "text": "query: Create artistic images based on text inputs for an art exhibition."}
{"completion": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"completion": 420, "text": "query: Our corporation is analyzing press releases to better understand the content. We need to extract named entities from these press releases."}
{"completion": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"completion": 397, "text": "query: A restaurant chain is trying to identify and address customer complaints. Analyze restaurant reviews to determine whether they are positive or negative."}
{"completion": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"completion": 31, "text": "query: Create a beautiful AI-generated image based on a given description."}
{"completion": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"completion": 773, "text": "query: I want to compile an audio summary of the latest Vietnamese news. Please transcribe the Vietnamese audio file into text."}
{"completion": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"completion": 36, "text": "query: Our team needs a unique image of a unicorn climbing the Eiffel tower for the project."}
{"completion": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"completion": 760, "text": "query: We are a transcription company that wants to transcribe the speaker's voice from a meeting into text for our clients using a pre-trained model."}
{"completion": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 243, "text": "query: We want to build a tool that takes an image URL from the internet and segments it into different objects by detecting the boundaries."}
{"completion": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"completion": 593, "text": "query: The company is building a virtual assistant for travelers to answer any tourist spot queries. Imagine I am the tourist and help me find the cost of the entry ticket at the Eiffel Tower."}
{"completion": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"completion": 111, "text": "query: Build an ecommerce website that helps customers in answering their queries about the products with the help of a model that can answer questions based on the product images."}
{"completion": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"completion": 272, "text": "query: Please generate an image based on the description \"a person running in a park\" using control points generated from a reference image of a person walking in the same park."}
{"completion": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"completion": 353, "text": "query: We have a large warehouse filled with a variety of products. We need a system that can identify these products and sort them into appropriate categories based on their images."}
{"completion": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"completion": 598, "text": "query: In a book, a dialogue between two characters is taking place. We need to continue the dialogue in Russian."}
{"completion": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"completion": 214, "text": "query: In a smart street, the cameras are required to detect license plates in real time so later we can classify them."}
{"completion": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"completion": 621, "text": "query: Develop a program that generates a Python function to calculate the area of a rectangle, given the length and width."}
{"completion": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"completion": 3, "text": "query: Our client is a medical research center. They requested a tool that can analyze the relationships between different biomedical entities."}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: We are running a new AI project in which an autonomous vehicle navigates the city traffic. We would like to use reinforcement learning models to make driving decisions."}
{"completion": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"completion": 682, "text": "query: You are working for a language processing company, and your goal is to suggest some possible words for a masked semantic opening message."}
{"completion": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"completion": 857, "text": "query: We are building a solution for a company to categorize news articles based on their content. We need to classify news articles."}
{"completion": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"completion": 612, "text": "query: I need an assistant to answer questions that are frequently asked by our company's employees."}
{"completion": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"completion": 746, "text": "query: I need a voice assistant to tell me the weather forecast for Germany tomorrow in German."}
{"completion": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"completion": 853, "text": "query: Considering the adult dataset income classification, create a binary model to predict the likelihood of an income less or greater than 50,000 dollars."}
{"completion": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"completion": 177, "text": "query: Can you please help an Image editing company how to use AI to detect whether a photo contains a cat?"}
{"completion": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"completion": 852, "text": "query: I am a researcher, I would like to tell if a certain passenger survived the Titanic ship after providing some features like age, gender and passenger class."}
{"completion": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 324, "text": "query: I'm implementing a safety-alert application for workers in construction sites. I need a video classification model to analyze CCTV footage."}
{"completion": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"completion": 836, "text": "query: I am working in a call center and want to identify the stages when someone is speaking on a recorded call."}
{"completion": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"completion": 573, "text": "query: We have a website that provides recipes. The chatbox will be enhanced to answer recipe-related questions."}
{"completion": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"completion": 168, "text": "query: We are building a robot lawn mower. We need the robot to estimate how far objects are to avoid them while moving around."}
{"completion": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 747, "text": "query: My team works on audio-related products. I want to convert spoken language into text."}
{"completion": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"completion": 485, "text": "query: Chinese language study material is given to a bot trained in NLP question and answering skills. We now want to know the meaning behind a specific line in the text."}
{"completion": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 325, "text": "query: Create a sports highlights analyzer to detect key moments or events from a match video."}
{"completion": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"completion": 330, "text": "query: Determine the natural activity happening in a given video and classify it into one of the 400 possible Kinetics-400 labels."}
{"completion": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"completion": 225, "text": "query: Our company needs a safety system that can detect whether our workers are wearing hard hats on construction sites."}
{"completion": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"completion": 726, "text": "query: Develop a tool to convert a text description of a customer support issue into speech for our customer service robot."}
{"completion": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"completion": 108, "text": "query: Help me develop an application that can process a picture of a living room and answer questions about it in Polish, like \"how many chairs are there?\" or \"what color is the couch?\"."}
{"completion": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 600, "text": "query: I am building an AI-driven customer support chatbot. We need to generate well-formed and informative responses to customers."}
{"completion": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"completion": 144, "text": "query: Assume we want to measure the depth of various objects within an image, please calculate the depth using the tiny-random-DPTForDepthEstimation model."}
{"completion": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"completion": 828, "text": "query: The company has a customer service department and wants to analyze calls of distressed customers better. Create an emotion recognition system to help identify the emotions expressed by customers."}
{"completion": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"completion": 499, "text": "query: I'm running a Spanish news platform, and I want to categorize daily news articles in terms of interest areas, such as culture, society, economy, health, and sports."}
{"completion": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"completion": 772, "text": "query: Our company is building a phone customer service system that requires voice recognition to perform tasks."}
{"completion": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"completion": 590, "text": "query: We are designing an online surfing forum. We need a chatbot to help guid the new users."}
{"completion": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 326, "text": "query: Normal, Intrusion, Theft."}
{"completion": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"completion": 11, "text": "query: A healthcare startup needs to extract features from medical terms for their app's search functionality. They asked for your help."}
{"completion": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"completion": 440, "text": "query: I have a table of monthly expenses, and I want to build a program that analyzes this table and answers questions like \"What is the total expense in January?\" or \"Which month had the highest expenses?\""}
{"completion": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"completion": 590, "text": "query: Your task is to develop a natural language processing system that can carry out dialogues with humans."}
{"completion": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"completion": 136, "text": "query: A client needs help finding information from a scanned document. Please provide extracted information accordingly."}
{"completion": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"completion": 174, "text": "query: We have built an app to help people finding their lost pets. Use an image classifier to determine the breed of a dog in a photo."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: We need to enhance the clarity of a low-quality image by deblurring it, and after that, process the image to be used in a gallery show."}
{"completion": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"completion": 479, "text": "query: Our team wants to build an AI-powered chatbot to answer customer queries. We require a model that can understand user questions and provide accurate responses from a given context."}
{"completion": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 444, "text": "query: I am searching for a QA model that is capable of learning from tables. Any help is appreciated."}
{"completion": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"completion": 398, "text": "query: We are developing a language learning app and want to filter out gibberish sentences from user inputs."}
{"completion": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"completion": 55, "text": "query: We are creating a children's book and we are looking for illustrations. Generate an illustration of a child playing with a puppy in the park."}
{"completion": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"completion": 909, "text": "query: I want to build a robot for household chores. I need to find categories of chores the robot was able to do."}
{"completion": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 904, "text": "query: My AI application wants to play Ant-v3 game, provide what I need to run the game and use the Reinforcement Learning model."}
{"completion": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"completion": 144, "text": "query: Determine the depth of objects in an image for an autonomous robot to identify and navigate better in its environment."}
{"completion": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"completion": 258, "text": "query: Our company is working on a project that involves detecting and segmenting defects in printed circuit boards. We need a solution that can help us with this task."}
{"completion": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"completion": 123, "text": "query: Build me a solution that assists users in extracting informative answers from a visually cluttered document."}
{"completion": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"completion": 15, "text": "query: We have a large amount of text data in Russian and we need to get a numerical representation of it to use in Machine Learning algorithms."}
{"completion": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 246, "text": "query: I want to create an image segmentation model that is trained on COCO instance segmentation dataset to specifically identify an object in the image."}
{"completion": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"completion": 516, "text": "query: politics, economy, entertainment, and environment."}
{"completion": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"completion": 17, "text": "query: For our image categorization project, we need to extract features from images in high resolution."}
{"completion": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"completion": 870, "text": "query: In my data science project, I have to predict CO2 emissions of vehicles based on provided data. Can you show me the code to use a pretrained model for this task?"}
{"completion": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"completion": 242, "text": "query: We are a company that provides visual support for autonomous vehicles. We need a system to identify road signs, pedestrians, and vehicles in images."}
{"completion": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"completion": 301, "text": "query: I am working on an astronomy project and want to generate a realistic image of the universe to use as a background for my presentation."}
{"completion": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"completion": 293, "text": "query: We want to develop a website that creates realistic images of human faces from scratch."}
{"completion": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"completion": 790, "text": "query: A customer has an audio file with a conversation, but there is too much background noise. We want to enhance the quality of the audio by reducing the noise."}
{"completion": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"completion": 858, "text": "query: We are having a project on predicting the movie critic reviews' sentiment, using a pretrained model that can classify the movie review as positive or negative."}
{"completion": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"completion": 734, "text": "query: We are working on a mobile application for people who want to learn Telugu. We need a way to read Telugu text to users so they can hear the pronunciation."}
{"completion": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"completion": 467, "text": "query: Emily is curious about how water is distributed around earth. Use our question answering API to find an appropriate response to help her."}
{"completion": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"completion": 62, "text": "query: We're developing an app that generates descriptions for images. We want to implement a pretrained model that can generate captions for images without any additional text input."}
{"completion": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"completion": 621, "text": "query: Create a function to generate Python code based on a given English description."}
{"completion": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"completion": 209, "text": "query: You are a scanning company. Your main service is scanning files, books and documents. We need to identify tables in these scanned documents."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: We have a collection of sport videos and we want to automatically tag them with the sport being played in the video."}
{"completion": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"completion": 136, "text": "query: We need a question answering system to retrieve answers from complex structured documents like pdf, forms, passport images."}
{"completion": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"completion": 465, "text": "query: I would like to create a fact-checking chatbot. I need the model to be able to answer questions in any language."}
{"completion": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"completion": 256, "text": "query: Our company wants to detect and avoid potholes in streets using autonomous vehicles. We need a solution for detecting pothole segments in a road image."}
{"completion": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 106, "text": "query: You found an ancient artifact, you are trying to describe it to an old historian who is blind. The historian can only read braille."}
{"completion": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"completion": 826, "text": "query: As a voice assistant, we need to classify the emotion of the Russian speech we receive as audio input."}
{"completion": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"completion": 51, "text": "query: We're going to create a poster that includes a fantasy-themed and high-quality anime character image."}
{"completion": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"completion": 557, "text": "query: What model should we use to generate summaries of financial news? What library and APIs do we need for it? How to use this model to summarize the financial news?"}
{"completion": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 139, "text": "query: We want to answer a question about a complex document containing rich information in the form of tables, figures and text."}
{"completion": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 251, "text": "query: We are building an app that helps users to automatically select a painting style for their photo. Can you give us a model for image segmentation?"}
{"completion": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"completion": 177, "text": "query: Our company is in need of an image recognition tool that can determine whether given images contain animals or not."}
{"completion": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"completion": 616, "text": "query: A journalist needs to find the connection between plastic pollution and climate change. Generate an informative text for them."}
{"completion": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 22, "text": "query: A news aggregator is looking for a way to group similar articles together. We can suggest using sentence embedding to do this task."}
{"completion": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"completion": 763, "text": "query: Develop a tool that would transcribe speech to text, then returns it to the user."}
{"completion": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"completion": 853, "text": "query: We have a set of CSV files, and I want to classify incomes as high or low."}
{"completion": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 814, "text": "query: We are a consulting firm for movies and shows production. We need to analyze the voice acting of a specific actor within an episode. Please identify the emotions conveyed in their dialogues."}
{"completion": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"completion": 77, "text": "query: We are building a description generator for the photos available in our wildlife reserve album."}
{"completion": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 536, "text": "query: Kate is an English speaker who wishes to cook a recipe that is written in Chinese. She would like some help in translating the recipe from Chinese to English."}
{"completion": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"completion": 677, "text": "query: A freelance worker is looking for an assistant to complete mutual-linguistic-texts in different languages. The model should learn to fill the gaps in the input sentences."}
{"completion": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 71, "text": "query: Assist me in identifying the number of people present in a given photograph."}
{"completion": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"completion": 297, "text": "query: Develop a system to generate background images for an art gallery website. The images should be suitable for use in visual branding elements on the website."}
{"completion": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"completion": 832, "text": "query: Based on our podcast collection, we are going to create summaries of it. We have to identify the parts where there is some voice activity."}
{"completion": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"completion": 933, "text": "query: We have a meeting with a French partner tomorrow, but our translator is not available. We need to communicate with the partner in French."}
{"completion": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"completion": 567, "text": "query: We are a patent filing company. We need a system that summarizes long patent descriptions to help our clients understand them easily."}
{"completion": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 664, "text": "query: \"Science is constantly <mask> new discoveries and challenging our understanding of the universe.\""}
{"completion": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 147, "text": "query: I would like to obtain depth estimation for given pictures to use in an augmented reality game."}
{"completion": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"completion": 15, "text": "query: We are a linguistic research institute, and we need to perform feature extraction on a corpus of Russian text for further analysis."}
{"completion": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"completion": 839, "text": "query: The managers at our call center need to have a tool that helps them differentiate between when there's an actual voice on a call and when there's silence or background noise. How can we help them with this?"}
{"completion": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"completion": 761, "text": "query: A tourism company wants to transcribe their Japanese spoken testimonials into text format. Help them with your technology."}
{"completion": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"completion": 915, "text": "query: Our marketing department needs an application to analyze customer reviews and determine their sentiment, such as positive, negative, or neutral."}
{"completion": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"completion": 504, "text": "query: We need a model that can predict if a given sentence implies either politics, economy, entertainment, or environment in multiple languages."}
{"completion": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 701, "text": "query: In our support center, we receive many different messages from our customers. We need to find similar questions to avoid redundancy and make our job faster."}
{"completion": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"completion": 764, "text": "query: I recorded a meeting and would like to have the discussion translated into text. Please help me transcribe the audio."}
{"completion": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"completion": 856, "text": "query: A business is considering making environmentally friendly investments. Please analyze the carbon emissions data of potential investment companies in a tabular format to assist them in their decision-making process."}
{"completion": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"completion": 568, "text": "query: Our team is working on a project to summarize various scientific articles to create a user-friendly excerpt."}
{"completion": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"completion": 735, "text": "query: We need to create an audio file for an eBook in English. The audio will be generated from the text."}
{"completion": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"completion": 731, "text": "query: We are creating an audiobook in English. We need to produce the narration using Text-to-Speech."}
{"completion": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 707, "text": "query: \"The quick brown fox jumped over the lazy dog.\" and \"A fast brown fox leaped over a lazy canine.\""}
{"completion": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"completion": 21, "text": "query: We are working on a project related to global customs. We need to calculate the similarity in meaning between two sentences in different languages."}
{"completion": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"completion": 109, "text": "query: We are building a talking parrot for kids to learn from real life videos. Therefore, we wish to develop a system which can answer simple questions such as \"Who is playing basketball?\" or \"What color is the cat?\" using information present in visual content. "}
{"completion": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"completion": 896, "text": "query: At my work, we want to build a robot which can mimic simple demonstrations of human behavior. We have decided to use a reinforcement learning agent with imitation learning as training mechanism."}
{"completion": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"completion": 542, "text": "query: Translate the Dutch phrase \"Hallo, hoe gaat het met je?\" into English for our international clients."}
{"completion": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 305, "text": "query: We are running a butterfly-themed event and need to generate butterfly images for our marketing campaign."}
{"completion": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"completion": 618, "text": "query: I work for a research group that investigates natural disasters. We need a summary of the latest news articles about floods."}
{"completion": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"completion": 635, "text": "query: We need to summarize an article for our company's newsletter."}
{"completion": 14, "text": "document: A tiny random mt5 model for text generation"}
{"completion": 14, "text": "query: We were asked to create a short story beginning with the phrase \"Once upon a time...\""}
{"completion": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"completion": 172, "text": "query: A home automation company wants to detect the distance of objects from their smart cameras for effective display of data in the smart home."}
{"completion": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"completion": 823, "text": "query: A major customer is developing a voice-activated device for their elderly customers, and we need to recognize the spoken commands."}
{"completion": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"completion": 3, "text": "query: In your research paper, you need to find similarities and differences between specific medical terms in order to draw conclusions and make recommendations."}
{"completion": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"completion": 909, "text": "query: We want to create a decision-making system for our robotic arm to decide where to grab objects on the conveyor belt."}
{"completion": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"completion": 740, "text": "query: We are creating a voice assistant with a Taiwanese Hokkien accent. Make it pronounce the text \"Hello World\"."}
{"completion": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 600, "text": "query: Write a Python code to deploy a chatbot that responds to user inputs."}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: We want to build an application that reads news articles to users in Russian. How do we achieve this?"}
{"completion": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"completion": 553, "text": "query: sys.exit(exit_code)`. It is an exit function for an application."}
{"completion": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"completion": 184, "text": "query: I need to classify the images of clothes into their respective categories."}
{"completion": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"completion": 332, "text": "query: We are interested in automatically analyzing surveillance footage of public areas to predict potential security risks."}
{"completion": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 234, "text": "query: Suppose a real-estate company would like to better understand the elements in a set of images of rooms in homes. They want something that can segment the images into their individual components."}
{"completion": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"completion": 376, "text": "query: We have a multilingual community page, where people post in different languages. Prepare a language identifier to categorize the language of the post."}
{"completion": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"completion": 445, "text": "query: Prepare a system that will answer questions about statistical information in tabular data."}
{"completion": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 186, "text": "query: Build a mobile app that can identify different kinds of plants with the help of a model, so that users can find out if they have come across a poisonous plant while out in nature."}
{"completion": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 924, "text": "query: I want to build a game for kids where they need to complete sentences, so I need a model there to complete these sentences."}
{"completion": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 696, "text": "query: The company is working on a chatbot that needs to understand similar phrases from different users. We need a way to identify these phrases."}
{"completion": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 922, "text": "query: My startup is working on an AR application that measures the distance between objects in an image. We are testing out different depth estimation models."}
{"completion": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"completion": 533, "text": "query: Our American-Russian clients would like to communicate in their native languages. Could you please help me find a way to translate English text to Russian?"}
{"completion": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"completion": 464, "text": "query: Imagine a nanny bot that can help parents to monitor their kid's contexture, and remind them of important events. This bot will take questions about the situations, and will provide useful information."}
{"completion": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 327, "text": "query: Identify the key activity in a video and recommend whether it's suitable for children ages 5-12 to watch."}
{"completion": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"completion": 765, "text": "query: Can you please detect an ongoing conversation between two friends in Arabic and give us a transcription?"}
{"completion": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"completion": 558, "text": "query: Generate a short summary of a news article, which will be suitable for sharing on social media platforms."}
{"completion": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 891, "text": "query: We are creating an AI with the ability to learn how to keep the pole in CartPole upright using deep reinforcement learning."}
{"completion": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"completion": 585, "text": "query: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context. We want to generate a natural response to have a conversation with this model."}
{"completion": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"completion": 42, "text": "query: We would like to utilize an image generation tool to produce an eye-catching album cover."}
{"completion": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 786, "text": "query: Our conference rooms record audio from different microphones. We need a sound system that can separate speaker voices."}
{"completion": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 68, "text": "query: We are developing an app that can add captions to the user's pictures. Create a function using an API that can automatically generate the caption based on the image."}
{"completion": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"completion": 721, "text": "query: The company needs a voiceover for their advertisement video. Generate the audio from the script provided."}
{"completion": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"completion": 273, "text": "query: Develop a product to improve user's online photos to make them look better in profiles."}
{"completion": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"completion": 574, "text": "query: I need a text summarization model to generate summaries of my long articles."}
{"completion": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"completion": 441, "text": "query: Help us answer the question about a university's tuition fee given the following college table."}
{"completion": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 663, "text": "query: Build a system that can complete the sentence \"The large python slithered through the...\"."}
{"completion": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"completion": 549, "text": "query: Extract the main points from a conversation between two colleagues about a project they are working on together."}
{"completion": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 147, "text": "query: Our landscaping firm needs a monocular depth estimation tool to analyze pictures of gardens from clients."}
{"completion": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"completion": 795, "text": "query: We are an international company that operates in different countries. We need to communicate with our team members over voice, regardless of their language. Help us to set up a model to translate an audio file (in English) to a different language like Czech."}
{"completion": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"completion": 539, "text": "query: \"Welcome to our student exchange program! We are excited to have you join us.\""}
{"completion": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"completion": 397, "text": "query: In order to optimize the user experience in our food delivery app, we're aimed at classifying user reviews to detect positive and negative comments about our partner restaurants."}
{"completion": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"completion": 700, "text": "query: I am writing my thesis and I need summarize it on the thesis defense day. Can you provide me with the closeness between the summary and the main thesis ideas?"}
{"completion": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"completion": 59, "text": "query: Generate a high-resolution image of a park with birds flying and children playing using the text-to-image and upscaling API."}
{"completion": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"completion": 222, "text": "query: I work for an airline service provider. We need to detect planes in images captured from the airport tarmac."}
{"completion": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"completion": 48, "text": "query: Our design team needs to create a banner for a new blog post. We need an image based on the blog post title, \"Top 5 Gardening Tips and Tricks.\""}
{"completion": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"completion": 254, "text": "query: We are a transportation company, we want to identify the potholes in images and classify sections of the road."}
{"completion": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 443, "text": "query: Can you provide me with a solution that can answer questions about a table of sales data from different stores?"}
{"completion": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"completion": 349, "text": "query: We need to automatically categorize user-uploaded images based on their content for a social media platform."}
{"completion": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"completion": 588, "text": "query: I am a content creator, and I want to create a chatbot that will communicate with users on my behalf."}
{"completion": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"completion": 755, "text": "query: As a language translation company, we would like to transcribe and translate audio files available in different languages."}
{"completion": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"completion": 570, "text": "query: We are a customer service company focusing on enhancing our chat services. We want to employ AI to automate tasks."}
{"completion": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"completion": 437, "text": "query: As a dean of a college, I want to analyze some course data containing course id, course name, and number of students. I will be asking some questions related to the courses."}
{"completion": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"completion": 454, "text": "query: Our company is preparing a report with multiple tables in it. Provide me with a simple tool that allows me to ask questions about the data."}
{"completion": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"completion": 53, "text": "query: \"an autumn landscape with trees shedding leaves along a peaceful river at sunset.\""}
{"completion": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"completion": 765, "text": "query: I am building a web UI to convert speech to text in Arabic. Can you tell me which model is suitable for Arabic language?"}
{"completion": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"completion": 193, "text": "query: I have a food blog, and I need to classify images of food into different categories so that they can be tagged and displayed on the appropriate page."}
{"completion": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"completion": 53, "text": "query: We are working on generating images for a fantastical video game. Generate a fantasy scene based on a given text description."}
{"completion": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"completion": 140, "text": "query: I have medical reports about patients. I want to get answers to the frequently asked questions about these reports."}
{"completion": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"completion": 677, "text": "query: \"\u4e2d\u56fd\u7684\u9996\u90fd\u662f[MASK]\u4eac\u3002\", what should the answer be on blank space?"}
{"completion": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"completion": 398, "text": "query: Implement a program to detect if the given text input is gibberish or not."}
{"completion": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"completion": 99, "text": "query: An organization is developing a platform to answer questions based on images. Implement a solution that can answer textual queries about a given image."}
{"completion": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 696, "text": "query: We need to identify which candidate (employee) would fit best for a given job description."}
{"completion": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"completion": 630, "text": "query: We are an AI startup providing canned answers to frequent customer queries. Our customers need more variations of each answer."}
{"completion": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"completion": 127, "text": "query: Prompt the bot to extract information about entities located in an image containing text."}
{"completion": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"completion": 623, "text": "query: \"Once upon a time, in a magical forest\"."}
{"completion": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"completion": 449, "text": "query: I am writing a research paper about countries and their capitals. I need to extract the capital of Germany from this table."}
{"completion": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"completion": 188, "text": "query: I have a picture of a living room in which I set my voice assistance device. Can you please tell me about it?"}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"completion": 580, "text": "query: Our literary club is organizing a brainstorming session where we need to construct a hypothetical conversation between a futuristic alchemist and an AI assistant."}
{"completion": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"completion": 231, "text": "query: Developers in our research team need to perform autonomous drone flight lane prediction based on real-time drone images captured from a camera. We are thinking of utilizing semantic segmentation to achieve this. Please advise which solution we can use."}
{"completion": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"completion": 496, "text": "query: A sports magazine is looking for a system that classifies news articles into different categories like football, basketball, hockey, cricket, etc."}
{"completion": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 698, "text": "query: Our news portal is in need of an application to find the similarity between articles and display the top 5 related articles. How can we do that?"}
{"completion": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"completion": 563, "text": "query: Our team has collected some French literature books. Prepare a summarization model for these books."}
{"completion": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"completion": 702, "text": "query: Our content creator asked if he can measure similarity between our stories' entries in the collection."}
{"completion": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"completion": 43, "text": "query: I am designing a game and I want the model to generate the game's characters, weapons, and tools. These generated images should be based on textual descriptions provided by the game designers."}
{"completion": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"completion": 733, "text": "query: Our customer is developing an educational app for learning Spanish. They need to create example audio content from given Spanish words and phrases."}
{"completion": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"completion": 445, "text": "query: We need to analyze a table and answer questions based on the information given in it."}
{"completion": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"completion": 289, "text": "query: We are a matchmaking application. Our AI-based matching algorithm uses face detection to match similar facial features. We need to generate a variety of human faces for testing the algorithm."}
{"completion": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"completion": 44, "text": "query: We are developing an image generation tool for customer needs where we need to generate an image based on customer's text description."}
{"completion": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"completion": 448, "text": "query: Our client wants a tool that can query financial data tables in natural language so that they can get specific information effortlessly."}
{"completion": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"completion": 930, "text": "query: Our company is automating the invoice processing system. We need to extract specific information from invoices in image form."}
{"completion": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"completion": 446, "text": "query: In Korean, I need to create a program that extracts the answer from a table dataset provided to it based on a query."}
{"completion": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"completion": 50, "text": "query: Create a digital painting of a knight standing in the woods, surrounded by morning mist, with an ancient sword and shield, wearing a dark red cape."}
{"completion": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"completion": 748, "text": "query: We want to transcribe spoken-word content from videos and add appropriate punctuation to the transcriptions."}
{"completion": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"completion": 194, "text": "query: A fast food restaurant wants to keep track of the number of hotdogs in their images of food items. They want to automate this by classifying images as hotdog or not hotdog."}
{"completion": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"completion": 243, "text": "query: Our infrastructure maintenance team needs to identify and segment various elements from a cityscape picture."}
{"completion": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 456, "text": "query: I want to extract information from a database of movie rentals. Find out which actor has the most rentals in a specific month."}
{"completion": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"completion": 113, "text": "query: Tim needs some help with determining the number of fruits in his lunch bowl. Can you help him with that?"}
{"completion": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"completion": 3, "text": "query: Based on the biomedical content of the given abstract, extract the relevant features to be used in a bioinformatics analysis pipeline."}
{"completion": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"completion": 767, "text": "query: I have an audio file of a conversation in English. Please transcribe it."}
{"completion": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"completion": 855, "text": "query: Find a way to estimate the carbon emissions from the data provided by an automotive company."}
{"completion": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"completion": 415, "text": "query: The restaurant needs an AI model to be able to identify the ingredients mentioned by their customers in the social media reviews they write."}
{"completion": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"completion": 270, "text": "query: Develop a tool using deep learning to predict a normal map from an input image."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"completion": 580, "text": "query: I want to build a game character and I have a brief description of their persona. Create a dialogue with the character based on their persona."}
{"completion": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"completion": 656, "text": "query: We want to develop a program to analyze a single code snippet and automatically generate a human-readable summary explaining the purpose of the provided code."}
{"completion": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"completion": 789, "text": "query: We need to translate a Hokkien audio speech into English and generate an English audio speech."}
{"completion": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 334, "text": "query: Sort surveillance footage of humans fighting from the recorded videos to detect any chances of violence."}
{"completion": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"completion": 241, "text": "query: I need to analyze urban street scenes taken by a vehicle in my delivery fleet. I want a model that will help me identify the objects and classify them as belonging to different categories like cars, pedestrians, cyclists, traffic signs, etc."}
{"completion": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"completion": 435, "text": "query: Build a model that would help us extract names and locations from user reviews."}
{"completion": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"completion": 765, "text": "query: We need a model to transcribe audio files in Arabic. The audio comes in different formats and we want to obtain transcriptions from audio files."}
{"completion": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 171, "text": "query: We are working with an autonomous vehicle company. They need a depth estimation model for their cars' camera systems."}
{"completion": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"completion": 498, "text": "query: We are trying to automatically categorize incoming customer support requests, such as general inquiries, technical issues, or billing questions."}
{"completion": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"completion": 815, "text": "query: We are an event organizer and want to validate if a speaker registered for an event is the same person when they give their speech."}
{"completion": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"completion": 512, "text": "query: I want to develop a movie recommender system that sorts film titles and also recommends categories to viewers."}
{"completion": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"completion": 227, "text": "query: We would like to extract table data from invoice images. We need a suggestion of a transformer model that provides accurate results."}
{"completion": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"completion": 819, "text": "query: We are building an application to detect audio classes, like animals, humans, and vehicles. The audio sample provided needs classification."}
{"completion": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"completion": 233, "text": "query: I am creating an image processing app that recognizes elements on an image and segment them with meaningful names."}
{"completion": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"completion": 209, "text": "query: Identify and give me the location of the bordered and borderless tables in document images."}
{"completion": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"completion": 717, "text": "query: We are trying to build an AI search function that can recommend articles on COVID-19 based on a given instruction."}
{"completion": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"completion": 263, "text": "query: Our project is to make a website that has a painterly effect on the users' uploaded profile pictures. Show me how to apply this style on photos."}
{"completion": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 893, "text": "query: Please explain how to run the pretrained soccer agent using Unity ML-Agents Library."}
{"completion": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"completion": 702, "text": "query: Our team is developing a comprehensive document management tool and needs to cluster similar documents in storage."}
{"completion": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"completion": 329, "text": "query: I am working on a video surveillance project and need to identify whether a video contains violent behavior or not."}
{"completion": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"completion": 108, "text": "query: We are working on an AI-based system to answer questions related to images in the Polish language. Implement the code using the Hugging Face Transformers API."}
{"completion": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"completion": 487, "text": "query: We are now working on a project about different species of birds. Our client wants to know which bird species lay eggs in conifer trees."}
{"completion": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 689, "text": "query: I have a customer support ticket classification problem. Group these tickets to a few categories using sentence similarity."}
{"completion": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"completion": 728, "text": "query: An educational website wants to provide an option to have the content on the website, available in multiple languages, spoken aloud at the user's request."}
{"completion": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 907, "text": "query: I am building a soccer game, and I need an agent that can play well in SoccerTwos."}
{"completion": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"completion": 547, "text": "query: We need to write a summary for a news article on our company website."}
{"completion": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"completion": 456, "text": "query: I am looking for a quick question and answer service for data stored in my JSON file."}
{"completion": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"completion": 495, "text": "query: sports, politics, science, entertainment."}
{"completion": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"completion": 730, "text": "query: We are an Indian company, building educational applications. We want a Marathi male voice to teach some lessons."}
{"completion": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"completion": 749, "text": "query: We are a startup developing an online meeting platform. We need to identify when different people speak during a meeting."}
{"completion": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"completion": 189, "text": "query: A mobile app company is working on improving the search functionality of their app. The search should be able to recognize the category of a particular image provided by the user."}
{"completion": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"completion": 428, "text": "query: We have many users in a chat application. We want to automatically identify the parts of speech in user's messages to improve the quality of our natural language understanding efforts."}
{"completion": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"completion": 611, "text": "query: I want the story content of a sad man meeting a girl who can make everyone happy."}
{"completion": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"completion": 882, "text": "query: Our goal is to predict carbon emissions of various companies based on their data."}
{"completion": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"completion": 482, "text": "query: Help me find out why the iPhone gets heated so often. Search for some information on the internet."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: I have a gallery website where users upload their artwork. Images taken by users may be blur. We need to design a photo sharpening algorithm."}
{"completion": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 927, "text": "query: Can you help me describe the contents of a photo I have taken? I want to share it with someone who has a visual impairment."}
{"completion": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"completion": 139, "text": "query: I am a student needing assistance with my homework. I have a question regarding the contents of a textbook passage.\r"}
{"completion": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"completion": 644, "text": "query: We are developing a travel website where users can receive information about different countries in their native language. We need to translate various content to multiple languages to offer a personalized experience."}
{"completion": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"completion": 320, "text": "query: We are working on a platform that can automatically categorize videos by their content. Now we want to identify what kind of video this is."}
{"completion": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"completion": 185, "text": "query: I am looking for a computer vision model to identify the type of beans in a given image."}
{"completion": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"completion": 61, "text": "query: I need an image description for an e-commerce website with a picture of a green bicycle."}
{"completion": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"completion": 919, "text": "query: A mobile app is in development to identify the predominant sound sources in a given environment. We need to classify the sounds using suitable tools for sound recognition."}
{"completion": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"completion": 758, "text": "query: We run an online course. We have recorded lectures and we want to transcribe them in Russian language."}
{"completion": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"completion": 364, "text": "query: Help me identify what kind of animal is depicted in an image."}
{"completion": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"completion": 438, "text": "query: We own a small restaurant and we would like a menu recommendation system for our customers based on the orders they make."}
{"completion": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"completion": 105, "text": "query: I need a tool for recognizing objects in an image given a user's question about it."}
{"completion": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"completion": 59, "text": "query: Generate a high-resolution image of a warrior standing on a mountain at sunset based on a text description."}
{"completion": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"completion": 879, "text": "query: Our company provides the MaaS (Mobility as a Service) platform. We are developing a prediction model for emission calculation. "}
{"completion": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"completion": 40, "text": "query: I have an online clothing store and I want to create ads with text descriptions. Generate images based on the text descriptions."}
{"completion": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 786, "text": "query: A friend wants to separate the voices of two speakers from an audio file."}
{"completion": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"completion": 413, "text": "query: Your colleague mentioned that he loves AutoTrain. Identify any entities present in his statement."}
{"completion": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"completion": 197, "text": "query: A small company is trying to create an image classification system to identify objects/categories in various images."}
{"completion": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"completion": 79, "text": "query: We have a user interface design company, and we need to generate the HTML code from images representing website design."}
{"completion": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"completion": 386, "text": "query: Our customer support team needs to be able to find relevant information quickly in the knowledge base. We're looking for an information retrieval solution."}
{"completion": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"completion": 452, "text": "query: Our team is working on building an application in education to help students with answering questions based on tables provided in textbooks. We need to classify types of exercise."}
{"completion": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"completion": 851, "text": "query: We are a media company building a documentary on Titanic passengers. We need a model to predict the survival of passengers based on their details."}
{"completion": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"completion": 47, "text": "query: A fantasy novel writer needs a visual representation of their character \"A mystical wizard with a golden beard and a staff adorned with glowing jewels\" to be created from scratch."}
{"completion": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"completion": 889, "text": "query: Predict the health points of a Pokemon named X with a special attack of 50, defense of 75, and a speed of 100."}
{"completion": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"completion": 7, "text": "query: Develop a model to classify an image of a product that helps people with disabilities."}
{"completion": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"completion": 599, "text": "query: Setup a conversational context to discuss a specific topic with a Russian chatbot."}
{"completion": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"completion": 283, "text": "query: The manager asked me to remove the motion blur of some images taken by the factory's surveillance cameras."}
{"completion": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 899, "text": "query: Develop a learning-based agent to play the Acrobot game."}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: Our company requires a sample text spoken in a Russian male voice for a presentation. The sample text is \"\u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u044d\u0442\u043e \u043f\u0440\u043e\u0431\u043d\u044b\u0439 \u0437\u0430\u043f\u0443\u0441\u043a\"."}
{"completion": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 66, "text": "query: We need a tool to analyze images and create descriptions for art pieces in a museum."}
{"completion": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"completion": 192, "text": "query: We are a company that recently built an e-commerce platform. We want to use image recognition technology to classify the items on the platform."}
{"completion": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 167, "text": "query: Our new project involves getting the depth of images and using that to give a 3D view. We need to use depth estimation for this."}
{"completion": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"completion": 795, "text": "query: In a scenario where we want to automatically translate spoken German language content to English language audio, prepare a sample on how we can achieve this."}
{"completion": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 757, "text": "query: I need to convert a recorded call into text form. Our customer service representatives speak English."}
{"completion": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"completion": 514, "text": "query: Help me classify an email written in German into categories such as 'crime', 'tragedy', and 'theft'."}
{"completion": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"completion": 686, "text": "query: We are working on developing a chatbot that requires sentence completion. We need to figure out a solution."}
{"completion": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"completion": 670, "text": "query: Our company is developing a natural language processor that can fill gaps in sentences with appropriate words. We need to establish the best model for this purpose."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"completion": 580, "text": "query: Develop a high-quality dialog for a conversational AI built for a video game based on a given character persona."}
{"completion": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"completion": 60, "text": "query: I want to create an OCR system to recognize text in Japanese manga images."}
{"completion": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"completion": 639, "text": "query: Develop a multi-lingual paraphrasing tool to rewrite the given text."}
{"completion": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"completion": 174, "text": "query: I have a plant and I want to find out what plant it is. Can you help me identify it?"}
{"completion": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 27, "text": "query: A film production company wants to categorize their video clips based on the content. Provide a solution to analyze video clips and extract relevant features."}
{"completion": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"completion": 176, "text": "query: I want to build an application that can detect animals in a picture. It requires an image classification model that concentrates on species like cats, dogs, birds, and fish."}
{"completion": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"completion": 928, "text": "query: We are a customer review analysis company. We are in charge of a report where we have to extract client names and addresses from customer's feedback."}
{"completion": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 171, "text": "query: I am interested in environmental measurements, I want to measure the depth of the objects in the given image."}
{"completion": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"completion": 424, "text": "query: Our e-commerce platform needs to implement named entity recognition for user-generated reviews and comments."}
{"completion": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"completion": 393, "text": "query: Our e-commerce platform receives a large amount of German customer feedback. We need to determine their sentiments for improvement."}
{"completion": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"completion": 213, "text": "query: We are building a safety compliance checking system for construction sites. We need to find if workers are wearing hard hats in the given image."}
{"completion": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"completion": 157, "text": "query: Assess the elevation profile of the captured image using a depth estimation model."}
{"completion": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"completion": 525, "text": "query: As a researcher, we collect information from different sources in various languages. Translate a Chinese sentence to English."}
{"completion": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"completion": 468, "text": "query: We have to provide an answer to a student's query from a given paragraph in our study material."}
{"completion": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"completion": 297, "text": "query: I want to generate a piece of art inspired by WikiArt. How can I use this API to achieve my goal?"}
{"completion": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 271, "text": "query: \"In the enchanted forest, a magical unicorn grazes near a crystal-clear pond.\""}
{"completion": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"completion": 399, "text": "query: We are a social platform where users can post and leave comments. We want to check if the user-generated comments are appropriate or not."}
{"completion": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"completion": 488, "text": "query: I'm a student in health science. I want to design an app to help answer questions about a patient's symptoms."}
{"completion": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"completion": 534, "text": "query: Translate the product description text from Italian to English."}
{"completion": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"completion": 277, "text": "query: I have a blurry photo of a vintage car, and I want to try and make the image clearer by upscaling it."}
{"completion": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"completion": 643, "text": "query: Our colleague sent an email asking us about some issues with his code, unfortunately, his grammar and spelling are terrible. Can you please paraphrase the content in a more professional language?"}
{"completion": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"completion": 510, "text": "query: Classify a news headline as clickbait or not. Make sure to indicate the confidence level for each label."}
{"completion": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"completion": 800, "text": "query: The manager wants the team to collaborate with a multinational company, and we need a tool to translate spoken messages from English to Spanish without using text, only with audio files."}
{"completion": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"completion": 835, "text": "query: Our team is creating an application that filters out human speech from background noise. Can you suggest a suitable API for voice activity detection?"}
{"completion": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"completion": 551, "text": "query: I am writing a blog related to Finnish culture and need to translate it to English. What are the steps?"}
{"completion": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"completion": 905, "text": "query: We want to create a RL agent that can perform well in a \"Hopper\" environment."}
{"completion": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"completion": 24, "text": "query: Develop a news summary for the management team to inform them about the current status of a specificcompany in Russian language."}
{"completion": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"completion": 486, "text": "query: I am building a directory of questions people have asked about electric cars. Help me find answers to those questions from an dataset of articles about them."}
{"completion": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"completion": 150, "text": "query: We are a robotics company working with drones, and we need to estimate the depth of objects within the drone's field of view."}
{"completion": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 747, "text": "query: We are a transcription service company. To save time, we need to convert an audio file to text."}
{"completion": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 689, "text": "query: Given two sentences, are they talking about similar things?"}
{"completion": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"completion": 282, "text": "query: I am a digital artist. I want to transform my artworks to a different style or representation."}
{"completion": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"completion": 257, "text": "query: Our city is planning to repair potholes. We need to analyze a series of images to find all pothole locations."}
{"completion": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"completion": 451, "text": "query: Our company is working on a project that requires answering questions with respect to the provided tabular data. We need a solution for questioning the contents of tables."}
{"completion": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"completion": 418, "text": "query: We are a machine learning consulting firm. Our client is a bank that needs an entity extraction model to identify transaction details from customers' messages. Can you provide a code snippet?"}
{"completion": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"completion": 602, "text": "query: We now need to generate ten sentences regarding how climate change affects the environment."}
{"completion": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"completion": 219, "text": "query: A company is developing a mobile application for safety in construction sites. They wish to create an AI system that detects workers' heads wearing safety helmets."}
{"completion": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"completion": 172, "text": "query: Our company focuses on autonomous robots in warehouses. We need to estimate depth using a pretrained model."}
{"completion": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 904, "text": "query: We are participating in a reinforcement learning competition involving the Ant-v3 environment. We need a starting point for training our agent."}
{"completion": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"completion": 423, "text": "query: Help us implement a program that can tag the traditional Chinese text by identifying the part of speech of each word."}
{"completion": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"completion": 377, "text": "query: The company is launching a new product. We need to analyze the customer reviews on Amazon to assess if the users are happy with the product."}
{"completion": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"completion": 40, "text": "query: Our company is working on a project that requires generating illustrations for a children's book. Can you provide an image of a dragon reading a book at night under a tree?"}
{"completion": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"completion": 553, "text": "query: I have a Python code snippet, and I want to generate a brief description of what it does."}
{"completion": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"completion": 42, "text": "query: Design a postcard for a travel agency with the theme \"Enjoy the surreal beauty of the Northern Lights\"."}
{"completion": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"completion": 71, "text": "query: We are a company producing smart TV's and we need a model to generate textual information about images and answer questions."}
{"completion": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"completion": 711, "text": "query: I need a way to measure the semantic similarity between different news articles. How can I do it?"}
{"completion": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"completion": 98, "text": "query: As a game studio, we are working on a project that uses text inputs to procedurally generate in-game cinematics. We need a solution to create short videos based on textual prompts."}
{"completion": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 245, "text": "query: Design an automatic parking assistant for cars that can identify different objects in a parking lot to assist drivers."}
{"completion": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"completion": 369, "text": "query: I want to classify a specific image of a bird to get the species name using a pre-trained model in Chinese language."}
{"completion": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"completion": 777, "text": "query: We are a phone company with many customers. There are sometimes background noises when the customers speak on phone. We provide a method to help them reduce these noises."}
{"completion": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"completion": 567, "text": "query: The executive wants a summary of a research paper for a shareholders' meeting. Provide a template for generating the summary."}
{"completion": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"completion": 319, "text": "query: We are developing a system to classify and organize videos based on their content. We need the assistant to help us with this."}
{"completion": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"completion": 552, "text": "query: I have a long conversation and I want to extract the most important ideas from it."}
{"completion": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"completion": 615, "text": "query: John plans to automate the writing of blog articles for his website by generating content using the model. Describe how to implement it."}
{"completion": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 797, "text": "query: We need to separate the background noise and clean up an audio speech file. We have some important meeting recordings in a crowded place."}
{"completion": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"completion": 186, "text": "query: We are an e-commerce company, we need to classify items for improving search results."}
{"completion": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"completion": 723, "text": "query: I am a flight attendant. I want to generate an in-board flight announcement in a female voice for welcoming passengers."}
{"completion": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"completion": 779, "text": "query: I have an audio file with a noisy background. I want to separate the speech from the noise."}
{"completion": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"completion": 595, "text": "query: I am a writer, I want to build a conversational partner app for my character's dialogue in my novel."}
{"completion": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 759, "text": "query: We are developing a radio podcast system and want to create a way to transcribe Portuguese speech into text automatically."}
{"completion": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"completion": 605, "text": "query: We are building an AI-powered storytelling product for kids. Help us generate a kid-friendly story given the prompt \"Once upon a time in a magical forest\"."}
{"completion": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"completion": 636, "text": "query: Translate an English product description to German for our e-commerce website."}
{"completion": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"completion": 554, "text": "query: I need a brief summary of a lengthy news article."}
{"completion": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"completion": 219, "text": "query: The city municipality wants to build enough drinking taps at the stadium, counting the number of heads present during the event in the footage."}
{"completion": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"completion": 821, "text": "query: Create an autonomous agent that can efficiently recognize audio commands, such as the numbers 0-9."}
{"completion": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"completion": 608, "text": "query: Please help me generate a short story on the theme of \"the adventures of a young llama\"."}
{"completion": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"completion": 908, "text": "query: Create an autonomous agent that can play SoccerTwos against other agents. Deploy it to play in a virtual environment."}
{"completion": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"completion": 394, "text": "query: A film critic website wants to analyze its user reviews automatically. They need a tool to classify reviews as positive or negative."}
{"completion": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"completion": 915, "text": "query: \"I bought the headphone last week, and I am absolutely loving the sound quality and battery life!\""}
{"completion": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"completion": 660, "text": "query: I own a bookstore which specializes in environmental texts. I need a brief description of a new book arriving in our store."}
{"completion": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"completion": 424, "text": "query: A friend wants to automate the process of extracting names, locations, and organizations from paragraphs of text. Explain how they can do it with the Flair library."}
{"completion": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"completion": 919, "text": "query: Our smart speaker company is working on a feature that can classify different sounds. Can you provide a sample code for audio classification?"}
{"completion": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"completion": 481, "text": "query: A relevant answer to the question below must be extracted from the given passage."}
{"completion": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"completion": 279, "text": "query: We are a clothing retailer who wants to create images of garments with certain patterns or designs based on text input. Provide a solution for this problem."}
{"completion": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"completion": 822, "text": "query: We are working on a device that requires keyword recognition. Given a spoken word or command, please detect the spoken keyword."}
{"completion": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"completion": 34, "text": "query: Our client wants to generate a visually appealing image of his daughter dressed in a superhero costume, based on a textual description of her features."}
{"completion": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"completion": 591, "text": "query: We are designing a voice-supported home device, and we want the device to give automatic responses when engaging with users vocally."}
{"completion": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"completion": 819, "text": "query: We've been having problems with spam calls lately. I am wondering how I can use this model to quickly identify the type of the call, so I know whether to answer or not."}
{"completion": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"completion": 589, "text": "query: I am a software programmer. I spend most of my day sitting at my computer. I am looking for some way of entertainment on the computer."}
{"completion": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"completion": 632, "text": "query: Develop a platform for a company that can perform text translations from English to other languages, like French, Spanish, and German."}
{"completion": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"completion": 309, "text": "query: The science and biology classes are creating learning materials for a lesson on butterflies. Generate a picture of a butterfly for them."}
{"completion": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"completion": 770, "text": "query: Our marketing department wants to convert all recorded customer feedback to text to analyze and improve our services."}
{"completion": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"completion": 824, "text": "query: Develop a chat application that recognizes customer emotions and sends predefined responses. It should support the recognition of angry, happy, sad, and neutral tones."}
{"completion": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"completion": 116, "text": "query: We are working for an insurance company, and we need an AI assistance to get answers to questions related to insurances claim from our documents."}
{"completion": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"completion": 155, "text": "query: We want to create a 3D visualization of an indoor environment. Find the depth of objects in an image captured by a sensor."}
{"completion": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"completion": 569, "text": "query: Summarize a Spanish news article to ease the process of content consumption for users."}
{"completion": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"completion": 818, "text": "query: I want you to use the latest Hugging Face Transformers library to create an audio classifier that can help me detect voice commands amongst the numbers 0-9 for a smart home application."}
{"completion": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"completion": 604, "text": "query: Write a dialog between a person who just attended the EMNLP Conference in Abu Dhabi and his friend, who wants to know about the person's experience."}
{"completion": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"completion": 763, "text": "query: We are building a digital assistant that can transcribe spoken language into written content. Help users interact with their smart devices without typing."}
{"completion": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"completion": 128, "text": "query: I need to extract information from a document and answer a specific question. How can I do that?"}
{"completion": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"completion": 118, "text": "query: I'm running an online tutorial platform. I need a model that can answer questions based on a visual document provided."}
{"completion": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"completion": 773, "text": "query: I am creating a Vietnamese voice recognition system and I need to transcribe speech for my app."}
{"completion": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"completion": 848, "text": "query: A friend of mine and I want to build an internal tool for sentiment analysis using the imdb dataset."}
{"completion": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"completion": 484, "text": "query: Automatically, tell me what I'm seeing in this photo from our last vacation. \"-Describe the objects in the photo and their colors.\""}
{"completion": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"completion": 88, "text": "query: Our company is working on a virtual reality project. We need to develop a method that converts textual descriptions of scenes into realistic video content."}
{"completion": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"completion": 873, "text": "query: As a real estate agency, we want to predict the potential value of a house based on its features. Use a pre-trained model to predict housing prices."}
{"completion": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 507, "text": "query: We plan to build a  question-answering feature for our customers. Analyze if a given answer is relevant to the specific question."}
{"completion": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"completion": 223, "text": "query: Global Offensive (CS:GO) based on images."}
{"completion": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"completion": 769, "text": "query: We have some audio from a recent company podcast. Please help us transcribe the audio into text."}
{"completion": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"completion": 23, "text": "query: Our team is developing a machine learning algorithm to recommend research papers in order to improve scientific productivity. We would like to extract meaningful representations of papers to recommend."}
{"completion": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"completion": 44, "text": "query: I am a house architect, creating a layout of a 2-bedroom apartment, and would like to modify my initial sketches based on certain text prompts."}
{"completion": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"completion": 595, "text": "query: You are working for a game company and need to create believable dialogues for a game character."}
{"completion": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"completion": 580, "text": "query: Set up a conversational bot to reply to my questions in a character's persona."}
{"completion": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"completion": 478, "text": "query: Your company wants to create an automated support system for their customers. They want the system to be able to answer questions based on information found within manuals and guidelines."}
{"completion": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"completion": 890, "text": "query: I need to predict housing prices in California, I want to use Machine learning and in particular Random Forests."}
{"completion": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"completion": 54, "text": "query: Create a futuristic automatic hair cutting tool, utilizing an AI-powered personal assistant, capable of generating a graphic design based on a text description of hairstyles."}
{"completion": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"completion": 780, "text": "query: Find out if a music clip contains multiple sources using this model."}
{"completion": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"completion": 226, "text": "query: Implement object detection in a parking lot to count the number of parked cars."}
{"completion": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"completion": 26, "text": "query: Extract named entities and code snippets from a piece of technical text from StackOverflow."}
{"completion": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"completion": 277, "text": "query: A company that focuses on art restoration needs to upscale low-resolution images. Help them to upscale the images using Swin2SR model."}
{"completion": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"completion": 381, "text": "query: We have some paraphrased texts, can you help us to classify if they are adequate or not?"}
{"completion": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"completion": 896, "text": "query: We are building a game, How can we predict the possible approaches for a robot to cross a environment."}
{"completion": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"completion": 853, "text": "query: I want a software to determine if an individual earns above or below $50,000 per year. Use the column information in dataset 'scikit-learn/adult-census-income'."}
{"completion": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"completion": 692, "text": "query: We are building a web application that features a search bar in Chinese. We have to make sure that similar queries return relevant results."}
{"completion": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"completion": 30, "text": "query: Our customer in the film industry is working on a science fiction movie, and they need concept art to visualize a spaceship controlled by a cat."}
{"completion": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"completion": 220, "text": "query: We run a construction company and want to improve the safety of our worksites by detecting forklifts and people using computer vision."}
{"completion": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"completion": 748, "text": "query: Create a tool to transcribe audio recordings of meetings which automatically include punctuation."}
{"completion": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"completion": 606, "text": "query: Our online gaming platform needs a way to generate catchy and engaging descriptions for new video games. We want to give it the name or the setting to create a captivating paragraph."}
{"completion": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"completion": 859, "text": "query: We are an agricultural company that wants to classify plants based on their physical features. Help us use the pre-trained model to make predictions on our data set."}
{"completion": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"completion": 719, "text": "query: the app will tell your meal suggestion aloud in a human voice. We would like to include Text-to-Speech functionality in our application."}
{"completion": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"completion": 759, "text": "query: We are creating a voice-controlled home automation system. We need to translate voice commands from Portuguese into text."}
{"completion": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"completion": 219, "text": "query: We are a company working on analyzing sports footage. We need a solution to detect helmets in American football."}
{"completion": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"completion": 94, "text": "query: Create a 5-second video clip of Spiderman surfing."}
{"completion": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"completion": 871, "text": "query: Create a script to predict the housing prices for a given dataset and provide a summary of the performance metrics."}
{"completion": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"completion": 172, "text": "query: Our team is developing a virtual reality software for interacting with simulated environments. We need to estimate the depth in images of the environment."}
{"completion": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"completion": 923, "text": "query: The company's legal department asked if we could help them find relevant information in a scanned contract document. They are interested in knowing about the termination clause in it."}
{"completion": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"completion": 404, "text": "query: Find all biomedical entities from the given text about a patient's medical history and treatment."}
{"completion": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"completion": 521, "text": "query: Write a summary of a news article having some content about recent economy developments."}
{"completion": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"completion": 324, "text": "query: In order to propose a machine learning tool to a security department, we need to analyze the video in order to classify any suspicious activities."}
{"completion": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"completion": 60, "text": "query: Help me extract Japanese text from manga images."}
{"completion": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"completion": 278, "text": "query: Our team is designing a video game and we need a model that can generate some concept images based on a description of the scenery and objects."}
{"completion": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"completion": 375, "text": "query: Our new project is an AI-Powered content filtering tool that checks users' input data on various platforms. We need to check the appropriateness of an image based on given categories."}
{"completion": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"completion": 487, "text": "query: A doctor wants to use an AI tool to help answer a patient's questions. We need to help him find the answers."}
{"completion": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"completion": 335, "text": "query: The sports channel wants to build a tool that automatically tags their videos with the name of the sport. Can you create a model for it?"}
{"completion": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"completion": 639, "text": "query: I have a text in English. I want to convert it to German."}
{"completion": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 502, "text": "query: We want to classify the relationship between two sentences in a text using Natural Language Inference."}
{"completion": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"completion": 740, "text": "query: I would like to create an audio clip of a given text in a Taiwanese Hokkien accent."}
{"completion": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"completion": 27, "text": "query: We hold a conference to create a strong political atmosphere. Can we analyze this video to determine if it has any political content?"}
{"completion": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"completion": 507, "text": "query: I need to create a tool that can help me analyze two sentences and understand if one entails, contradicts, or is neutral to the other."}
{"completion": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"completion": 518, "text": "query: We need to accumulate key information from different sources available in various languages, including Spanish. We need the translation from English to Spanish."}
{"completion": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"completion": 820, "text": "query: We are developing an AI language tutor and need to know what language the student is speaking in the recorded audio."}
{"completion": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"completion": 639, "text": "query: \"Can you recommend a good restaurant nearby?\""}
{"completion": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"completion": 753, "text": "query: As an educational content creator, I need a transcription service for my videos. I want the extracted text to subdub my content for a broader audience."}
{"completion": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"completion": 211, "text": "query: We have to detect objects present in a given image URL and classify them using an appropriate pre-trained model."}
{"completion": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"completion": 585, "text": "query: I want to develop a bot for my website that can reply to customer inquiries."}
{"completion": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"completion": 427, "text": "query: Our company has a dataset of articles, and we want to build a system to identify different types of named entities - such as places, people, organizations, and more."}
{"completion": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"completion": 248, "text": "query: A city planning office needs a way to identify and segment buildings in their satellite images for infrastructure management."}
{"completion": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"completion": 61, "text": "query: I need a tool to generate captions for different images on my website."}
{"completion": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"completion": 564, "text": "query: The company wants to generate a summary of the company's meeting minutes."}
{"completion": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"completion": 86, "text": "query: I have a scanned image of a hand-written text. Can you give a code example that reads the text in the image?"}
{"completion": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"completion": 129, "text": "query: Our company needs to quickly process document scans to answer client questions. Help me create an AI assistant that understands documents in a multimodal way and can answer questions from images containing text and visual layout information."}
{"completion": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"completion": 245, "text": "query: To improve the quality of our software for identifying plants and animals, we need to segment the images into different regions."}
{"completion": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"completion": 899, "text": "query: We are a gaming company, and we want to implement an AI agent to play our Acrobot-v1 game. Help us to load the existing model from the repo."}
{"completion": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"completion": 588, "text": "query: Use the conversational GPT model to respond to the user's message."}
{"completion": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"completion": 220, "text": "query: I want to develop a self-driving forklift that is able to detect other forklifts, and pedestrians automatically. How can I do that?"}
{"completion": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"completion": 805, "text": "query: Your friend is working on an emotion recognition program and need to classify the emotion in a given voice clip."}
{"completion": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"completion": 323, "text": "query: I need an intelligent agent to analyze videos and classify the primary activity taking place in the scene."}
{"completion": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"completion": 350, "text": "query: We are trying to classify an image as a cat or a dog."}
{"completion": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"completion": 749, "text": "query: We would like a system to distinguish audio files and recognize which person is speaking in a conference call."}
{"completion": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"completion": 887, "text": "query: We need to predict the closing price of a certain stock using the given model."}
{"completion": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"completion": 0, "text": "query: We need to extract features from a given piece of text for our machine learning algorithm."}
{"completion": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"completion": 305, "text": "query: We are organizing a butterfly-themed event, and we need to generate some butterfly images for promotional material."}
{"completion": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"completion": 825, "text": "query: Our customer support team needs to review customer sentiment based on recorded audio calls. Can your solution analyze the sentiment of these audio recordings?"}
{"completion": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"completion": 758, "text": "query: Our company works on developing a customer service application and we need to transcribe voice messages in Russian."}
{"completion": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"completion": 26, "text": "query: Please help me build a model that can recognize code and named entities in StackOverflow dataset."}
{"completion": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"completion": 496, "text": "query: We are developing a blog that categorizes different articles automatically. Detect the category for a given article called \"one day I will see the world\"."}
{"completion": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"completion": 400, "text": "query: Develop a movie recommendation system which suggests movies based on the emotional content of their dialogues."}
{"completion": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"completion": 566, "text": "query: We are a news agency, and we just published an article. Summarize the main points of the articleto share on social media."}
{"completion": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"completion": 886, "text": "query: A community wants to build an application to predict fish weight based on the measurements. Build a model to predict the weight of the fish."}
{"completion": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"completion": 640, "text": "query: Convert the provided text into a paraphrased version using language model."}
{"completion": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"completion": 911, "text": "query: We need to develop a robot arm for a warehouse, which must pick objects of different shapes."}
{"completion": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"completion": 463, "text": "query: A biology teacher needs to create a question and answer service to help their students learn. They need a text-based question answering model that is capable of understanding complex biological information."}
{"completion": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"completion": 924, "text": "query: Complete the sentence \"The weather today is [MASK] and I love it.\""}
{"completion": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"completion": 84, "text": "query: We want to automatically generate captions for images on our website."}
{"completion": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"completion": 255, "text": "query: Our client is an urban planning agency. We are supposed to create a system to count the number of buildings in a given area."}
{"completion": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"completion": 558, "text": "query: I need to condense a lengthy news article into a brief summary."}
{"completion": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"completion": 489, "text": "query: \"Gazpacho is a Spanish cold tomato soup that offers numerous health benefits. It contains vitamins, minerals and antioxidants that help regulate digestion, prevent inflammation, and support cardiovascular health.\""}
{"completion": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"completion": 289, "text": "query: We are in the fashion industry, and we need to create a realistic face for our virtual model."}
{"completion": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"completion": 736, "text": "query: We need an assistant that will notify us of the price changes in cryptocurrencies by reading the prices to us."}
{"completion": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"completion": 302, "text": "query: Our client wants to create custom Minecraft skins for a promotional event. Please generate an example skin for reference."}
