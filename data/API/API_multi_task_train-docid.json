{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: To ensure the security of the building, the new system needs to recognize and classify different types of vehicles entering and leaving the campus."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: We need to analyze the population of different countries but the data is spread in a table format. How can we use AI to extract specific information from the table?"}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: We want to enrich the digital artwork for the virtual gallery by generating a vintage-themed image."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: We are a photography studio and we need to generate images that look like adorable animal photos."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: Can you transcribe the given audio file into text for a language processing task?"}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: A dragon with its wings spread."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: We are working with an environment-aware company. We want to predict the carbon emissions of something by providing the data in CSV format."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: Detect the type of action being performed in a video using a sequence of frames as input."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: A journalist received a review paper on electric vehicles. In order to include the relevant information in their article, the young journalist must condense the paper into a 2 to 3 sentence summary."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: Develop an AI that can engage in a multi-round conversation."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: We need a bot to find out if a given piece of text was generated by the GPT-2 language model."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: We would like to create a virtual soccer game for two teams using reinforcement learning. How can we implement this trained model?"}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: I heard of a new NLP technology that can answer questions using given context/input. Can you please tell me how I can use it?"}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: An astrophysicist needs an image of a galaxy-like shape for a research project."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: We have a biology themed game app. The players are required to identify images in the game. We want to run an analytics test for which we need to categorise the provided images. "}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: If there's a summary needed for an article to save time reading, what would you suggest?"}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: As an AI developer, I am working on a voice assistant application. I want to transcribe human speech from an audio file to text so that the application can understand and respond to the user's commands."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Generate a fictional story about a young scientist discovering a new element."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: I'm working on a project to categorize user profiles based on their age group in our mobile app. We need to analyze the profile pictures and identify the age ranges."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: Our team needs to develop a surveillance system capable of performing various segmentation tasks such as semantic, instance, and panoptic. We'd like to use one model for all these tasks."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: A client of mine wants to build an application deployed in a factory to send specific values from the machines to monitor the carbon emissions in real time."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: I have a dataset of reviews in plain text, and I need to find which ones are similar to \"The food is delicious.\"."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: I need to develop a model for summarizing Chinese news articles."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: In our company, we are regularly encountering documents with lots of text, and we want a tool that helps us find accurate answers to our questions."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: I am creating an Indonesian language analysis application. I need to generate contextual embeddings for text written in the Indonesian language."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Create a Python function to provide a list of descriptions for images in a folder."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: I am a teacher working to get soccer players to be able to play efficiently and make good decisions during the game, and want to use the SoccerTwos trained model."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: We need a German text-to-speech application that converts the given text to an audio file using Tacotron2 and HIFIGAN."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: Our company is running a podcast channel that contains environmental topic. Please create an intro sentence and convert the text to speech."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: Suppose we have an image containing people wearing hard hats. Implement a system to detect the presence of these safety helmets in the image."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: We need to create an automated system to group similar customer reviews together."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: We are a podcast production company. We need to clean up audio recordings with background noise and reverberation."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: I am working on a video surveillance project and need to identify whether a video contains violent behavior or not."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: I have medical reports about patients. I want to get answers to the frequently asked questions about these reports."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: We are a company that prints custom artwork on T-shirts. We need to use AI to generate an image of \"a green unicorn in a magical forest\" based on Canny edges."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: I am a teacher at a university for the Chinese language department. I would like you to help me analyze the parts of speech of a given Chinese sentence."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: We want to classify an image of our client's products in order to help them customize their advertisements."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: We need to mimic Elon Musk's speaking style to make our marketing campaign more engaging. Generate a response as if he is replying to a question."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: Please identify the food in the image and classify it according to the ImageNet-1k dataset."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: The marketing team needs assistance in analyzing customer feedback through phone calls. We need to identify only the parts of the audio where customers are speaking."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: We want to populate our virtual reality application with 3D virtual bedrooms, and we need images of bedrooms as input data. Generate a bedroom image using the model."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: food, movie, or music."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: I want an app that would analyze and classify my moods based on my social media text inputs."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I am a primary school teacher, and I am preparing a reading comprehension project for my students. I want to know the answer to a question from a given text."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: We are a smart agriculture company that repeatedly needs to segment the land into different regions based on vegetation and crop health. Provide instructions to use a model that can help us achieve this."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: A group of podcasters need a transcription of their latest episode to create show notes for their website."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: Our company is building a chatbot that helps people choose which movie to watch. The chatbot needs to analyze movie descriptions and suggest movie categories."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: I am working with a group of well-known bartenders, and they wanted a personal assistant that can find information about cocktails by giving information about different cocktails in table format."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: Create a chatbot that can provide users with business advice and resources on how to start a company."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: We are developing an application in which one feature allows users to translate a text from one language to another. We want to translate an English sentence into German."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: The company is building an autonomous driving car. We need a solution to estimate depth in order to perceive the surroundings of the car."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: Design a unique shoe for our upcoming fashion collection."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: I am working on a call center application and I want to greet my Spanish speaking customers with a generated audio which says \"Hola, bienvenido a nuestro centro de llamadas. \u00bfEn qu\u00e9 puedo ayudarte hoy?\""}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: Our customer support receives several inquiries. We want to be able to categorize them as technical issue, billing issue, or general inquiry."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: We are a financial institution and we need to extract relevant information from our clients' financial documents to answer specific queries."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: Help us implement a program that can tag the traditional Chinese text by identifying the part of speech of each word."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: As an online learning platform, we need to build a system that can answer questions automatically."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: We have a document with a few missing words, and we need to fill in the blanks using a language model."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: Help me create a computer generated graphic of a superhero character for my upcoming sci-fi story."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: Design a mechanism to identify a certain sound from an audio sample."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: We are working on a travel agency to advise visitors on information about the former host cities of the Olympic Games given the years they hosted them, so we want to extract the city hosting the games in 2012."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Assist me in searching images related to \"wonders of the world\" and describe them."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: After creating AI-generated content using GPT-2, a tool is required to detect the content generated by GPT-2 for quality assurance purposes."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: I want to predict how much tip I should give at a restaurant based on factors like total bill, time of day, and if I am a smoker or not."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: I am a house architect, creating a layout of a 2-bedroom apartment, and would like to modify my initial sketches based on certain text prompts."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: We are developing a meeting summarization solution. We want to estimate voice activity in the audio and provide a clean transcript of the meeting."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: I want to predict whether a person's income is higher or lower than $50,000 based on their demographic and socio-economic information."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: A multi-lingual digital news scanner for our multi-national company needs to extract the names of people, organizations, and locations mentioned in the news articles."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: We want to convert a political interview's audio file to a text transcript for our client's newsletter."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: Create a program that can answer questions about an image given in different languages like English, Chinese, Japanese, and German."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: A writer is struggling to translate his French text into the English language. Recommend a model to catch his mind and create the texts fluently."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: I have a meeting with my manager and she asked me to summarize an article that she doesn't have time to read. Please, provide me with a summary of this article."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: We were asked to create a short story beginning with the phrase \"Once upon a time...\""}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: The Physical Therapy Department needs a pose-estimated version of patients doing exercises to provide feedback on their form and postures. Develop a pipeline to process these images."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: A friend texted me in Spanish about their plans for the day, and I want to know if it includes activities related to sports, culture, or nature."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: We are building a chatbot for a company's customer support. We want to summarize conversation transcripts and send them as a report for managers."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: We want to add audio classification to our app to recommend relevant content based on users' audio input."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: Our company sells anime-style canvas prints. We want to generate new pictures based on specific prompts to expand our catalog. For example, generate an image of a sunset with a cherry blossom tree."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: We are developing a Pokemon game and need to predict a Pokemon's HP based on its other features."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: \"The stock is going to soar!\", \"Sell now or regret it!\", and \"Steady growth in the long term\"."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: We are running a new AI project in which an autonomous vehicle navigates the city traffic. We would like to use reinforcement learning models to make driving decisions."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: To optimize production, a company has to spot anomalies in its sensor data. Explain how we can use autoencoders to fulfill this requirement."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: We are the staff of a customer support center. We have collected different voice records to analyze customer's emotions."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: I want to develop a system that generates realistic images of churches for a 3D mapping project. The system should output high-quality images in 256x256 resolution."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We are an animal shelter and we need to classify images of cats and dogs. Help us with the right model and process."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: In our application, we need to calculate the similarity between different sentences entered by users."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: I have a robotic dog that monitors my yard for security. I want him to identify intruders with good reliability. Could you come up with a method using this API to identify the intruders?"}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: As a writer, I'm looking for a way to understand the similarity of sentences that I write to check for repetitiveness."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: Our client needs background details of a medicine called \"Ibuprofen\" to optimize search queries for their pharmaceutical website."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: In our new article, we want to help users that can't see images well by providing textual description of images' content. We need a model that can answer questions about the image."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: We need to develop an application that can identify entities such as names, locations, and dates in a news article. Show how this can be done using the available API."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: I want to analyze my tweets across 4 languages (English, Spanish, French, German) to show me the sentiment of these tweets."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: Our blog has many articles with poor grammar. Can you help to correct the grammar of an example sentence?"}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: I want to develop a bot for my website that can reply to customer inquiries."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: Let's show a user-generated text prompt as a photo-realistic image at a park."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: I am building a home personal assistant and want to classify images from the home environment. We would like to utilize a quick recognizer."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: We are working on generating images for a fantastical video game. Generate a fantasy scene based on a given text description."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Convert the provided image to a descriptive text."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: We want to classify the relationship between two sentences in a text using Natural Language Inference."}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: We are a company that builds a photo management application. We want to automatically sort photos into categories like landscape, animal, food, people, and architecture for easy browsing."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: We have a multinational company and we need to identify the names of people, organizations, and locations in a text."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: I have a table related to Olympics that consists of year and city columns. I need to know in which year Beijing hosted the Olympic Games."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: We want our smart home devices to recognize what is the object in the image they captured, so that we can provide an answer to the user."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: I am a 10th-grade student doing my annual school essay project on the \"Development of the human brain over the centuries and its impact on society\". Can you generate 50 words so I can develop my thoughts in a flow for my school essay?"}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: Our customer is an online forum administration team. They are working on filtering abusive comments. We need a model to identify the abusive comments."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: What is the sentiment of this restaurant review? \"The service was fantastic and the food was delicious. We will definitely come back again!\""}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: We need to classify images of cats of various breeds to create a search option based on breed."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: Our telegram bot needs to convert a dialogue into a concise summary. We want to use the Russian dialogues summarization model for this purpose."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: Our customer is creating an app that can visualize the content and theme of a movie. First, we need to identify sentences in the descriptions that have similar meanings."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: I want to use the morden game playing reinforcement learner for playing Acrobot."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: As a video production company, we would like to know what our video is about. How can we do it?"}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: We are running a website for helping people find recipes based on pictures. Find the recipe for the dish in the provided image."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: Our marketing team is preparing a promotional campaign. They need a video showing a dog playing with a frisbee."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: Our company is interested in the technology that can detect various speakers in a given conversation. We would like to build a product around it."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: I am working on a project where I need to generate a realistic dialogue based on a user prompt. How can I use DialoGPT-large to achieve this?"}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: My robotics team is building a dancing robot, we need to classify the dance moves from video inputs."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: We are trying to build an app that predicts the depth of an image from a self-driving robot. Assist us in the process."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: We are developing a chatbot that can analyze photos we send it and ask questions or give information about the scene."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: Help me conduct a binary classification task predicting whether a person's income is above or below $50,000 per year."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: The local town hall provided a document folder with tables containing data about the town, and the task is to ask the system to provide the answers without tedious exploration."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: Create a program that can understand the sentiment of spoken words in Spanish language."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: We are participating in a quiz about the solar system and need instant translations for the questions from English to German."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: I want to perform text generation for a summary on a very long article that I have just read."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: I want to create a series of vivid butterfly images for an art project. Show me how to generate these realistic-looking images automatically."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: Create a classifier to identify the language of a speech signal in 107 different spoken languages."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: We are launching a new photo gallery app and want to automatically classify each image for better organization."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: Our gaming company is creating an anime-style game. We need to generate various anime-style characters and landscapes for the game based on text descriptions."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: Develop an application to detect active voice in an audio to help with transcription tasks and improve the user experience."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: I am building a security product for detecting unauthorized objects in a restricted area. Can you detect objects in images and return their coordinates, scores, and categories?"}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: We need to build an application that translates multilingual texts, such as translating Hindi text to French."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: Our company deals with answering questions, and we need to rank the answers relevance to provide the best answer to the customers."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: We need an AI application that can help us to control a car climbing up a steep hill according to the surrounding environment."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: A gaming company is developing an AI program to detect and analyze players in a given game to make it easier for coaches and analysts."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: Analyze a financial news article and extract all the mentioned company names and their stock ticker codes."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: Create artistic images based on text inputs for an art exhibition."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: My son wants to pariticipate in a quiz competition. Can you help him in answering the question related to \"The discovery of medicine.\"? "}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: Implement a multi-turn conversation with an AI character that is a detective trying to solve a mysterious crime."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: \"Can hydrotherapy help with back pain relief?\""}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: We need to build an image processing application that can enhance the resolution of low-quality images."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: A task requires understanding the structure and information within a document. We need to get answers to specific questions based on the document content."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We are trying to recommend research papers to students. We need to generate document-level embeddings of research papers."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: Please provide a solution for extracting information from a scanned document based on user\u2019s questions."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: In order to develop an application for car parking management, we need to separate different objects in an image taken from a parking lot."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: Can you summarize this content to a shorter version?"}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive eSports game."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: You have been hired as a software developer for an accounting firm that receives lots of invoices daily. Your task is to design a solution which can quickly take questions from accountants and provide relevant information from invoices."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: We are a digital encyclopedia company and want to find the most relevant content from a list of passages to answer specific questions."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: Our company is interested in mapping the interiors of buildings. We need a tool to estimate distances within a 2D image."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: We have an e-commerce dataset with both numerical and categorical data, and we want to categorize users to help us improve our marketing strategy."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: I have developed a new blog and I want to compare the similarity metric between two sentences, one from the blog and the other from the audience feedback."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: In my piece of code for detecting beans diseases in crops I need to include an image classification model."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: We are designing a new banner for our website about pets. We want an image to be generated for our banner."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: Use the conversational GPT model to respond to the user's message."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: Can you generate a Python code snippet to implement iterator pattern for a simple list?"}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: I want to develop a language translation tool which can handle different languages like English, German, and Spanish."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: The company plans to develop an AI-based doorbell that detects and distinguishes between different voices in noisy environments. Implement a model for voice activity detection."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: A company is developing an app for enhancing the quality of low-resolution images. For this purpose, they need to upscale the input images by a factor of 4."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: We are an architecture firm working on creating smart cities. We need to analyze and classify video feeds from traffic cameras to understand traffic patterns."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: I have a huge database of sentences and I need to find the most similar ones to my target sentence. Can you please help me find them in the most efficient way?"}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: Our company is developing a parking assistance system for autonomous vehicles, and we need to estimate the depth of objects in the environment."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: Create a piece of writing with the beginning sentence \"It was a dark and stormy night...\", which is generated by the model."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: Our museum needs a new digital exhibit on butterflies. We want some generated images of them."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: Looking to build a recommendation system for products from my website but need some help on how the recommendation can be made."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: We are building a system for answering questions related to a table of data. Can you suggest an appropriate API for this task?"}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: Our client needs an image segmentation solution to process aerial images for crop analysis. They want to separate different elements in their aerial images automatically."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: Develop a voice assistant that takes speech input from users and transcribes it into text, so it can perform various tasks based on the content of the speech."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: "}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Imagine a user wants to know the color of a specific object in a photo. Prepare a tool that can answer their question."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: We are an automobile trading company and would like to predict the price of a car based on certain features like mileage, make, model, year, and installed options."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: We acquired a confidential business document containing important information. We need to locate any details about 'revenue.' Please guide me how to extract the revenue information using this model."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: In our database of customers, we need to know the number of customers who are between the age of 20 and 35 and living in New York."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: A company is launching a smart AI-based voice assistant that can be used for home automation systems. We would like to synthesize natural-sounding human speech from text."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: We are a healthtech organization, and we want to anonymize our records for compliance purposes."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: Provide the instructions for audio classification to determine the speaker identity"}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: I am working on a project about NLP that has a collection of sentences. I'd like to convert these sentences into numerical vectors to perform semantic search."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: Find a way to predict the electricity consumption by using the historical data of electricity demand."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: Using our AI system, help our users to create an AI model to control an NPC (van) in the game to properly drive in the traffic."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: Help me reduce background noise from a recorded customer support call."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: We are working on a property marketing app to predict the housing prices. Please assist us with the model."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: We want to enhance our image search engine by making it capable of understanding and classifying images to provide better results."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We are an insurance company that processes forms, but we need to speed up the process by extracting tables from forms. "}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: We are developing a new system for video surveillance that can detect and classify suspicious activities. Implement a model that can help us in identifying such incidents."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: I am working in a call center and want to identify the stages when someone is speaking on a recorded call."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: Right now I have a podcast in foreign language. I want to covert it to English."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: Sally wants to create a program that will listen to recordings of phone calls from her call center and transcribe them into readable text."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: A baby robot that flies around the room needs to know if it has landed on and walks on a surface or if it's hovering."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: The marketing department of our company needs an algorithm that can tag product images for use in ads."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: The company is developing a digital assistant for making announcements over a speaker system. We need to figure out how to convert text to audio."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: We have developed an app that shows memes. We want to add a feature that will answer questions related to the content of the meme for our users."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: A blind person wants to have their questions answered about a picture they cannot see. Help them by generating an answer to their question about an image."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: We need a robot with voice synthesized for the hearing-impaired patients in the hospital."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: I need to find out how similar two given sentences are."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: We are a medical organization, and we want to create a system that can analyze and provide information about medical articles."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: We have an application being marketed in the wildlife sector. We plan to create images that can identify animals by predicting their species."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: Compare two sentences and determine how similar they are based on their semantic structure."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: Create an advertisement image for a new car by placing it in an urban setting with cutting-edge design."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: I am an artist who wants to generate variations of my paintings using an AI method that can control the diffusion."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: A teacher wants a tool that can help answer questions related to a spreadsheet she's working on about her student's grades."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: We have an audiobook company and we need to deliver samples of different books. Automate the conversion of different book summaries to audios."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: A friend of mine wrote a story in Italian. I want to understand the story, but I don't know Italian. Please help me understand it."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: I have an online clothing store and I want to classify images sent by customers to automatically add them to the right categories of the clothing."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: Create a system that will analyze the sentiment of users movie reviews and decide if they liked or disliked the movie."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: I am building a Q&A system for my website. I would like to retrieve relevant answers based on user queries using neural search."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: We are operating a website on tourism in Europe. We have a paragraph written in English and need it translated to Italian."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: I'm running a construction site and want to deploy a system to ensure workers wear hard hats. Help me detect hard hats in images."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: Can you help me to enhance the quality of my advertisement's image using GPT API?"}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: A person just shared an audio clip of Spanish speech on our helpine. We need to determine if they have positive, negative, or neutral sentiments."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: The city department wants to predict carbon emissions using provided data."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: My company has received an investment offer from a French investor. They want to know an executive summary of our business. Kindly help."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: I need to create a tool that allows me to rephrase sentences to enhance my written communication."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: We are a showroom company, and our customer asked us to describe their products based on some provided images."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: I want to have a conversation with an AI chatbot when I am alone at home."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: Can you please create a story on how robots and humans co-exist in harmony?"}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: \"The night was dark, and the moon was bright.\""}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: We want a sports broadcasting company to detect video footage of sports-related activities."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: Create a system that can group similar sentences together."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: I found an old book from a flea market. I wonder if there is any significant events or persons in it. Can you help me?"}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: I am the teacher's assistant, and we want to rephrase a given sentence to avoid plagiarism in our materials, keeping the same meaning."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: I want to create a system capable of identifying people's voices. Prepare a model that can classify several speakers' voices."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: The marketing team analyzes users' reviews to improve their software. They need a review translated from French to English."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: I want to segment vehicles from an image of a street for our parking monitoring system."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: Develop a solution to answer questions related to a specific input context."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: Our company provides image analysis services for real estate images. We need to segment parts of images into categories such as walls, windows, and doors."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: We're trying to estimate carbon emissions based on various input data like fuel consumption, engine size, etc. Could you help us with that?"}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: You are now working as a virtual assistant for a businessman. He needs reminders and follow-ups to stay on top of his tasks. Generate a text to help him handle these reminders."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: I need to detect vegetables and fruit in a 100-frame video using a video classification model."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: Our team of researchers need a tool to summarize scientific articles for quick reading. Can you help them?"}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We are a robotics company. We are building an indoors patrolling robot that detects and recognizes objects."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: We need to improve the quality of a cartoon image by removing noise from it."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: We need a tool to classify news articles into categories like sports, politics, and technology."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: I want to build a system that can answer questions based on tables. How can I achieve this?"}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: They want to include Marathi voice over in their advertisments. Help them with the text-to-speech for the Marathi language."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: Create a code snippet that loads the VC-1 model from Hugging Face Transformers, processes an image, and gets its embedding for a robotics task."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: I'm working on an application to build daily plans for people, and I need to extract useful information from raw text."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: Build me a solution that assists users in extracting informative answers from a visually cluttered document."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: We are planning to open the zoo in town, to identify the probability of species can you suggest a process?"}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: Write a pipeline that can fill in the blanks in a given sentence using a pre-trained language model."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: Design an intelligent surveillance system to identify vehicles in a parking lot."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: I have a set of videos, and I am looking for understanding the subject and context of the videos."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: We would like to build an audiobook application for Korean novels. Transform a given text into an audio file."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: We have a Japanese language learning platform. Sometimes, users miss certain words, help them figure out the missing words."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: We are building a virtual assistant for home, which can recognize objects around the house and interact with them. It should be able to understand the environment and differentiate between objects."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: Your company is developing a voice assistant for smartphones. You need to implement a text-to-speech feature for the voice assistant to read out messages aloud."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: Our newspaper website has an article about space exploration. To improve search engine optimization, we need to generate related search queries based on the article text."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: We are in the fashion industry, and we need to create a realistic face for our virtual model."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: We need a speaker diarization tool for a meeting to identify different speakers and transcribe their speech."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: We want to classify a cell image in terms of whether it shows a healthy cell, an infected cell, or a dead cell."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: Build a carbon emissions calculator for vehicles based on factors such as engine type, size, weight and fuel consumption."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Our company needs to create an attention-grabbing poster. It should showcase a unicorn galloping on a snowy mountain."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: Help an interior design team to estimate the depth of objects in a photo to decide appropriate decoration placements."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: Our team specializes in document analysis, and we'd like to be able to answer questions about the content of scanned documents."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: We are hosting an art exhibit and need to create an AI-generated painting of a calm, serene nature scene in the Midjourney style."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: We want to create a natural-sounding voice to narrate our company's promotional video."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: residential area, playground, stadium, forest, or airport."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: The team needs to create an audio file of a text input for the company's new audiobook platform."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: A company is working on building a movie recommender. Ensure the suggested movies attract various age groups."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: We are working on traffic systems and the camera stream should be converted into categories like accident, closed road, heavy traffic, etc."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: I need to build a simple machine learning model to classify handwritten digits from image data."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: I am leading an initiative of environmental awareness. We have received a long document about climate change policy. Please help me to find out the key points of the policy and some potential actions."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: You have a 3D application where you want to understand the depth of objects. Compute the depth based on rgb input image conversion."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: Develop a way to evaluate spoken numbers of a user from 0 to 9."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: We have a website that requires unique profile pictures for each user. We need to generate profile pictures for the users."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: Build a model that would help us extract names and locations from user reviews."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: We need to increase the amount of training data for our natural language understanding model. Generate paraphrases of the given input text."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: As a language learning app developer, we need to translate Russian text to English for our users."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Can you help us segment our customer reviews into positive, negative, and neutral categories?"}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: Develop an application that reads the user's message and classifies their emotion."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: Build a video classifier to analyze cooking videos and determine which type of cuisine is being used."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: We are starting an advertisement campaign that requires image generation based on text descriptions."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: We need an image generation model that can create new images based on the pre-existing CIFAR10 dataset."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Generate a picture of a butterfly with background for an article about butterflies."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: Please prepare a utility for me to translate \"Life is beautiful\" to Italian."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: I want to analyze a table with housing statistics about different cities, find out which city has the highest average income."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: Create a solution to find the color of a specific object in a picture by asking the model a question about the color of the object."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: I got a document with some tables. I cannot find the relevant data for GDPR. I need some help to find the desired, relevant data in the document."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: We need a program to translate English to German so that users can understand when reading about foreign news in German."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: In the text classification program, I would like to identify whether the content is AI-generated or written by humans."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: Create a digital painting of a knight standing in the woods, surrounded by morning mist, with an ancient sword and shield, wearing a dark red cape."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: We need a quick recap of an article in French to put on our website."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: 'The Importance of Physical Exercise for Mental Health'."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: In our content strategy plan, we want to know the summary of long news articles. Suggest a suitable model for summarizing long texts."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: We have a law firm and we have multiple scans of legal documents. How can we extract information of a specific question related to these documents for our case?"}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: Create a visual question answering tool that receives an image and a question in the Polish language as input, and provide an answer to the question based on the image heuristics."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: We are developing a travel website where users can receive information about different countries in their native language. We need to translate various content to multiple languages to offer a personalized experience."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: Help us to extract image segments so we can further process the images better."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: Analyze similarities between the given documents and the search query."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: I am writing a script for analyzing tweets from my company's social media. The program can determine the sentiment of each tweet as positive, negative, or neutral."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: A Chinese professor has published an article in a popular journal and is conducting a discussion with the readers. Process the paragraph and provide the answer to reader's question."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: We are building a smart call center solution that needs to detect when a person is speaking or not speaking in a conversation. "}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: Our landscaping firm needs a monocular depth estimation tool to analyze pictures of gardens from clients."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: We are developing educational software and we need to automatically answer questions based on given documents."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: Design a suitable algorithm for a news aggregator app that classifies and sorts news articles from various sources into different categories."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: We are a digital agency and we would like to predict if the companies will buy our products. We have collected a dataset of companies with digital marketing and social media metrics."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: We need to create an AI-driven search engine, and we want to use the best performing model for searching and ranking the text from large databases."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: Work with language experts to detect semantic similarity in sentences that are multilingual- find out if translations provided are accurate."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: We are developing a language learning application. Our customer wants an Arabic text-to-speech feature."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: I am writing a game description and I'd like to translate it into multiple languages using a language model."}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: Recently, we have two proposals from two different departments. Please evaluate their similarity to help us decide which one to choose."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: Develop a chatbot system that can have natural conversations with users using ingen51/DialoGPT-medium-GPT4."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: I have a sentence and I want to check if the sentence is correct. Please correct it if necessary."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: We have a list of customer reviews, and we want to find similar reviews by grouping them based on their semantic similarity."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Your client is a city planner who needs information about the buildings in an area. Generate an image with highlighted buildings from a satellite image for them."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Our company is working on a platform to create digital assistant for the visually impaired. We'd like to build a feature that generates textual descriptions for images."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: We have a Chinese language website, and we want to complete the missing words in a paragraph. Can you give me an example for a given sentence?"}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: A customer is planning to implement sustainable manufacturing practices in their factory. They need help predicting the amount of carbon emissions based on given variables."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: I need to find the location of an image taken in a city, and I have a list of possible city options."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: A car manufacturer needs a solution that can estimate carbon emissions level for the cars they produced based on some given features. Propose a solution using the provided API."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: I am building a summarizer that can compare sentences. I want it to be able to recognize AMD related eNooks as well as normal sized books."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: Help a visually impaired person to comprehend the information in a product manual. Their query is related to a specific section."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: Create a function to generate random human faces using transformers."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: A student needs help with homework. They are given a paragraph about the history of their city, and they need information about the founding year of the city."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: Develop a program that generates high-quality images of cats using a denoising diffusion probabilistic model."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: We are working on a new mobile application which suggests fashionable clothing. We need to categorize different types of clothing."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: We need to generate images of a bedroom using the DDPM model for an interior design software."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: We are trying to develop a podcast application. The first step is to denoise the audio and enhance the content of the user's recordings."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: A new project is starting where fashion design will be created with the help of AI. We require the generation of random small images for inspiration."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: We have an anime website, and we want to generate image previews for each anime based on text description."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: I am an engineer building a home robot that can switch between different voices. I want it to have the ability to switch between voices when it is interacted with."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: We need to build a phone app to identify dog breeds."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: We're building an app that can find information in photos of documents, even if the text is formatted differently. I need the assistant to extract the answers."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: Our company has a German report and we need a summarized version to understand the key points."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: We need to summarize an article for our company's newsletter."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: A gaming company is developing an AI-powered cheat detection system that flags suspicious activity in the game screenshots. We need to detect different objects in those images."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I am a historian researcher. I need to find the number of casualties in each major battle documented in a large dataset."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: I am a professional doctor, and I need a recommendation for a recent study on COVID-19 vaccines for Pfizer."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: I am developing software for a company that wants to analyze the sentiments of its customers on their online reviews (positive or negative)."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: I want to implement image segmentation for a satellite imagery application."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: Architecting a software that manages a database of archived scanned documents, provide a solution to extract information from these archived scanned documents given a specific question."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: We have a document about a new technology. Prepare a set of possible questions people might ask about this document."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: Our current project is to estimate normal maps from images of 3D objects, so that we can improve our 3D rendering system."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: As a game designer, we want to create a chatbot to interact with the players and provide them with hints when they are stuck in the game."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: We have a collection of old newspapers that we need to digitize, and we want to find a solution for extracting their textual content."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: I'm building a voice assistant that needs to read out text in a Taiwanese Hokkien accent. How can I use the Text-to-Speech model to convert text to speech in this accent?"}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: Transform this text from a customer review without punctuation into a more readable format with punctuation marks."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: We are a podcast production company, and we need to improve the audio quality by separating the speakers from the mixed audio."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: We want to build a tool that takes an image URL from the internet and segments it into different objects by detecting the boundaries."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: I want to develop an application that will help me to recognize and classify images of animals."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: Tell me how can I create a robot for general chat by computing the distance between sentences and find the most similar sentence in a large corpus."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: A client is interested in an advertising campaign incorporating analog-style images, and they would like a car in the beach setting."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: We need to develop a real estate website and classify the images of properties based on their respective categories, like residential, commercial, or land."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: I am developing a 3D art project and need to access depth information from 2D images. What model can be used to approximate depth in images?"}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: I'm working on a project where I need to develop an AI model that can answer questions based on given images."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: We have a computer vision problem where multiple objects are recognized in an electronic circuit board. Please segment the defects found in a circuit board image."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: Develop a system that allows us to extract information from legal documents and create summaries of the information."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: I need to create an AI-powered sentence auto-completion tool that suggests the next word or phrase in a sentence for me."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: Locate forklifts and people in an image from a warehouse and provide their coordinates."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: I have a table with various Olympic events and their respective medal winners. I need an assistant to find the year when the event took place in Beijing."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: We have gathered data about customers of a bank regarding their occupation, salary, and age. Analyze this data and classify whether customers are in high, medium, or low credit risk categories."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: As an executive assistant in an international trading company, I often receive emails in English, and I need to translate them into Italian for my boss to read."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: Our news app needs to provide short summaries of articles for users with limited time. Develop a method to generate summaries for readability."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: Design a function to recognize the sentiment of movie reviews."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: Create a solution to provide real-time translation for participants in a multi-language conference call."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: We'd like to have the process of translating spoken Hokkien text to spoken English in an efficient manner such as through a speech-to-speech translator."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: The company creates a mobile app for cars. We need to classify different car types in the images captured by the app."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: A city planning office needs a way to identify and segment buildings in their satellite images for infrastructure management."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: Develop a program to answer questions from a scanned document containing both text and layout elements."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: A group of students is struggling with extracting specific information from a table. Help them extract the requested information from the table."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: Our company is in charge of organizing events. We would like to build an AI model that could detect if an email is about an event proposal, a client's feedback, or a request for an appointment."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: I need to create a platform to classify images uploaded by my clients. The model should be capable of classifying the images into different genres."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Take the image's URL input and provide the segmented image of the buildings."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: I need an assistant to answer questions that are frequently asked by our company's employees."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: Provide a solution to apply video classification on user-generated content to identify whether it is a personal, sports, or educational clip."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: We need to find a way to filter out nonsensical comments from the feedback section of our website."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: A smart device that has visual recognition capabilities is helping a visually impaired customer to answer questions about items in their home."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: We need to complete French sentences with missing words."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: I run a company that does predictive analytics for various businesses. I want to predict if a book will be liked by our audience."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: As a part of a project, we are developing an AI model, which will learn how to control a robot, making it hop like a Kangoroo."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: I have recorded a customer interview in Japanese, can you return the transcriptions please?"}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: The project requires generating a natural image of a yellow cat sitting on a park bench based on a textual prompt we provide."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: Read through the given text and complete any missing word(s) in it."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: We want to create a software that automatically completes a given piece of code."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: As a game studio, we are working on a project that uses text inputs to procedurally generate in-game cinematics. We need a solution to create short videos based on textual prompts."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: We have a variety of information on our website and need to translate our English content to Chinese to reach a wider audience."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: We have an architectural project and we are looking for a way to estimate the depth of an image."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: We want to automatically generate captions for images on our website."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: Create a vivid picture of a fantasy setting describing a peaceful waterfall surrounded by lush green trees with a wooden bridge connecting the banks."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: I'm creating an application that automatically identifies and categorizes animals in wildlife videos. I need to know the category of a specific animal in a video."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: Our company wants to provide support for multiple languages in our voice assistant. We need to be able to recognize the language spoken by the user."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: I am planning to detect whether two sentences are similar in my multi-language chat product."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: I am a journalist, and I want to know the category of my article which is in German language."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: We want to create an audiobook for a paragraph of text. Generate the audio for the given text."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: We want to convert handwritten text from an invoice into digital text. How can this be done using the provided API?"}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Our design department is looking for a tool to generate creative and unique illustrations from text descriptions. We want to incorporate this feature into our design workflow."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: Our client is a real estate agency, and they would like to predict the price of a house using a single column regression model."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: Implement a conversational chatbot that can help answer questions in different subjects."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: I am creating a Vietnamese voice recognition system and I need to transcribe speech for my app."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: We need a system to answer questions based on the given context. Build an API that can retrieve information from the given statements."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: I need a creative text generation model to write a short story about space exploration."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We've got a scanned document and we want to know if there's information about the total amount on the invoice."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: Create a high-resolution image of a tropical beach using text-to-image generation."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: Our urban planning department would like to understand the height of buildings in our city. Determine their height using depth estimation in a monocular image."}
{"text_id": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 64, "text": "query: Our client requests a description for an image from their website. The model needs also to answer questions about the objects from that photo."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: Design a system to extract main ingredients for food enthusiasts participating in a social network application marketing their recipes."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: How can the movie producer know audience's thoughts on their movie by analyzing movie reviews? What's the basic coding implementation for that?"}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive (CS:GO) match."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: You are an AI in family robot. We are on dinner table, chat with me and ask my opinions on topics."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: Can you generate a customer support bot that can provide assistance with queries related to a product?"}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: I am an environmental scientist, and I need a tool to automatically classify satellite images into categories like residential areas, playgrounds, stadiums, forests, and airports."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: Our company deals with e-commerce in China. We are looking for a solution to classify images based on Chinese text descriptions."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: Develop a system that can efficiently translate English text to French."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: To increase customer satisfaction, we want an automatic reply for our company email. A lead has asked a question about the pricing of our product."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: We are building a trivia app where users compete to see who can answer the most questions correctly. Help us to utilize an API to provide answers to the trivia questions."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: We are building an application to help tourists identify famous landmarks and find answers to their questions based on the image of the landmark. Using a multimodal model, we need to provide information about the provided image and the text question."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Our company is focusing on understanding the carbon emissions level for various products in the industry. We've got a dataset containing information about those products. Kindly predict carbon emissions levels for those."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: We are dealing with a large set of medical data that needs de-identification to maintain patient privacy. Help us with de-identifying the given text."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: We are building a social media app that will display the main ingredients and dishes of a cooking recipe posted by a user in formatted text."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: We have a dialogue paragraph in Russian, and we need a summarized and concise version of the dialogue."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: I'm working on a travel app to help English-speaking tourists navigate around different romance-speaking countries. Provide code to translate phrases from different romance languages to English."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: I need a solution to detect the tables inside scanned document images."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: I want a system for tagging my Instagram posts with meaningful tags so they attract the right audience."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: You are asked to create a film production company, and you require a press release to present your new project to potential investors. Generate a press release for the upcoming science fiction movie production."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: I am writing a proposal for a potential investor on our app, but some parts are missing. Can you help me to fill them in?"}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: Our company is working on a project that requires extracting answers to questions from design blueprints and technical documents. We need to process both text and spatial layout information in these documents."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: Assist me in transcribing a podcast episode by converting speech from an audio file to text."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: Assist me in filling the missing word in a Japanese sentence."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: We have a dataset including several factors such as fuel consumption and engine size. Our goal is to predict the carbon emission rates for different vehicles."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: Develop a program to convert sentences in Russian language into their respective sentence embeddings, using BERT large model."}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: I have a document that contains various useful information. Please help me build a system to find answers to the questions related to the content of the document."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: I need an AI tool that helps with classifying news articles into categories like \"sports\", \"entertainment\", \"politics\", and \"science\"."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: Develop an application that reads aloud a text written in Marathi using a male voice."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: We are developing an automated PCB inspection system. Segment the defects on the image provided."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: Develop a tool that can identify the number of computers in a given image and answer the question, \"How many computers are there in the image?\""}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: The teacher of a high school history class is looking for a tool that can help students find answers to questions about historical events based on the content of the class material."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: I would like to generate a motivational statement about becoming successful."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: Provide a code snippet that extracts the number of stars for a repository from a table containing repositories and their corresponding statistics."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We are working on an application that needs to automatically label workout videos to add them to the correct category."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: An application is needed to generate bar chart race graphs based on global CO2 emissions from 1850 to 2018. Provide a method to answer natural language questions about which countries had the highest emissions in certain years."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: As a game developer, I want to create a soccer game featuring AI soccer players. I will use an existing trained model to control the players."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: Develop a tool for a blind person that can generate captions based on what they see around them."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: Our company designs autonomous vehicles, and we need to compute depth estimates from camera images."}
{"text_id": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 64, "text": "query: A startup is trying to use the BLIP-2 model (for answering questions from images) to create an app that can help visually impaired people. They need to know how many characters are in a street name."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: We are building a recommendation system for a movie streaming platform to find films with similar plots."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: Create a system that transcribes Vietnamese speech to text in real-time for a user who is unable to read Vietnamese."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: We are developing an application for a fun food festival. It should be able to determine whether a food item is a hotdog or not. Build a way for us to detect this!"}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: Taking images from a gallery, the task is to generate captions describing the contents within the image."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: Our marketing team needs to create shorter versions of our product descriptions. Give me ideas on how to do that."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: I want to use this model to detect anomalies in a timeseries dataset of temperature recordings in a lab."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: A sports-focused website wants to have a feature to automatically classify sports type from video inputs. Let's build a video classifier for them."}
{"text_id": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 64, "text": "query: Create a system that can answer questions about images. For example, a user can input an image and the system will answer whether the image contains a cat."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: Create a system to answer questions based on given data tables."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: Create a simple chatbot using DialoGPT-large that listens to user input and returns a relevant response."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: We want to group product reviews by their similarity so that we can analyze common features and complaints."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: We are building a home security system that needs to identify potential threats in video footage recorded by the security cameras."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: Create a zero-shot text classifier that will help us classify user reviews based on their sentiment."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: An app needs to extract named entities, such as people, organizations, and locations, from sentences."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: We are working on a sports video streaming service where we need to classify which sport is being played in the live feed."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: My startup wants to provide an AI-driven automatic transcription service for podcasters."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: \"dog\", \"cat\", \"squirrel\", \"mongoose\", \"lion\". Help us with that!"}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: We need to classify pictures of cars taken in our garage."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: We need to create a product description for an energy drink without any input. The product should reflect the idea of providing a quick energy boost."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: We need to extract the total amount from an invoice received from the vendor."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: As a language enthusiast, I want to learn Hokkien, so I need to convert an English speech to Hokkien speech."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: A healthcare company wants to classify its patients. They have a dataset of patient features, and they want to train a model to predict which patients are likely to have certain conditions."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: As a content creator, I want to summarize my podcasts and create show-notes for my audience."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: I'm working on an app that will find objects in a picture. We need the model to detect objects in an image from a given URL."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: We want to create a chatbot that simulates conversation with Elon Musk."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: We need to create a tool that allows us to segment and identify elements such as people, landscapes or objects in digital images."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: Produce a caption for an image that accurately describes the content of the image for a photo sharing app."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: We are trying to build a chatbot, but first we need to import an NLP model to handle user queries."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: Our company is working on a chatbot. We need to predict a word with a chatbot program that completes the masked sentences with an appropriate word for users."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: Develop an application to estimate the depth of objects in an image for better navigation of drones in various outdoor environments."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Create a tool that can extract the text from an image of a document."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: The marketing team needs an image of a seaside town scene generated from a given text description."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: I have a meeting recording where three people were speaking at the same time, and I want to separate the conversation into individual audio tracks for each person."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: Our company has machines that record sensor data. We need to detect if there is any anomalous behavior in the sensor readings to avoid breakdowns."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: Write a python function that translates a given English text to German."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: Help me find the dense passage retrieval question embeddings for the given question."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: Calculate the depth of objects in an input image."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: I need to create a machine learning model to generate an image of a beautiful sunset on the beach with a couple holding hands when given a piece of text describing the scene."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: A stock brokerage wants an algorithm to predict stock prices using historical data from the past 5 years. Please assist them."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: We are an event organizer and want to validate if a speaker registered for an event is the same person when they give their speech."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: I want a multilingual model to help me predict the domain of some text without retraining it."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: I am developing a Mars simulation. I need to create random Mars-related events and descriptions."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Our real estate company needs to analyze images of houses and identify different regions such as walls, roofs, doors, and windows. "}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: We want to develop a system for automatic tagging of products on e-commerce websites using computer vision."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: I am building a security system for a football stadium. The system needs to automatically detect helmets in the frame from the CCTV camera footage."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: Can you help me? I am looking for a way to sort a list of comments by their similarity to a specific question."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: Develop an AI system that can recognize items in a photograph by leveraging a pretrained model such as the Vision Transformer."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: Let's create a predictive model for carbon emissions from a dataset."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: We are building a description generator for the photos available in our wildlife reserve album."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: Our company has developed a new game, and we need to create custom skins for in-game avatars."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: Our customers want to produce interesting event descriptions from a set of keywords."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: We have a human resources application that needs to extract names from unstructured text documents like CVs. We need a solution for extracting person names."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: I need an application which can answer any question related to a specific image provided."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: Detect potential leaks or wastage of resources in our facility using the CO2 footprints dataset. We need information to aid us in cutting our Carbon footprint."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: We are a production company that creates movies. We need to analyze movie scenes to understand their content."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: A travel blogger needs to translate her blog post about her trip from Stockholm to London, written in Swedish, to English to reach a wider audience."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: Our client needs a conversational agent that can assist with basic customer support enquiries."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: We're developing an app that generates descriptions for images. We want to implement a pretrained model that can generate captions for images without any additional text input."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: I am building a website about shoes, I want to make sure the logo image is shoes related."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: Users of our application now want to have text translated into speech in French. We are looking for a solution for this."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: In my business, I'll use the TAPAS model in a case where I have to correlate spreadsheet data with user input."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: Write a brief summary of the following text:"}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: I'd like to play a game and take some help from the Decision Transformer model so I can learn how to improve my skills in the game."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: We are an advertising agency and our clients want to launch their website. We should provide them with a clear set of images of certain products."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: We are working on developing a chatbot that requires sentence completion. We need to figure out a solution."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: A business needs to translate customer reviews from English to Russian to better understand their clientele."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: I am responsible for the safety of workers in a warehouse. I need to detect people and forklifts in images captured by the warehouse's security cameras."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: Determine the carbon emissions category of different vehicles based on the provided dataset."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: I am a digital artist. I want to transform my artworks to a different style or representation."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: We are a tutoring agency for primary school students. We have a table with their math test scores. We want to answer questions about the scores based on the provided table."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We are a library and need help reading historical handwritten manuscripts."}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: I need a document question answering system capable of handling text and layout information simultaneously to provide accurate responses."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: Compare the similarity of two sentences about weather and determine if they convey the same message."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: I need assistance to analyze image files of financial statements and to separate their columns and rows. The application should be able to figure out the structure of the tables in these documents."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: A virtual accountant needs to answer questions related to the invoice, such as the total amount and the name of the buyer."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: Transcribe and translate an audio file that has been provided to you, to help a non-native speaker understand the contents of the audio."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: We are a financial technology company investing in different companies. We want to classify news articles to determine whether there is a positive, negative, or neutral sentiment."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: Can you detect when someone is speaking in a conversation?"}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: The company needs to demonstrate a speech-to-speech translation system for English to Hokkien in a TED Talks presentation."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: A new series of video learning courses are planned for the company. We need to auto-flag inappropriate content in the videos."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: Create a news classifier which classifies the news into political, sports, entertainment, technology, business and health categories."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: We're a startup that focuses on automating customer support. We'd like to answer questions from customers about products from a table."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: \"During summer, the weather is usually very...\""}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: We are a Chinese voice assistant company, and we need to know how to transcribe conversations during a conference or meetings."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: We are building autonomous vehicles for urban transportation, we need to integrate depth estimation in our technology."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: A post-apocalyptic adventure, set in 2300, featuring a group of survivors including a scientist, a soldier, and a young hero. The scene should have an eerie aura, with decaying buildings and nature taking over. Include the title \"Reclaim\" on the image."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: The new feature requires our app to have a friendly conversational bot. Implement it in our system."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: I want to understand if two given sentences are similar and could be used for semantic search."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: You are currently using a customer-care automation service. A Korean user has a question and you want to provide the answer."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: Our company creates accounting software and we need to extract table structures from PDFs and images of financial documents."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: The marketing department is receiving news articles in Italian. We are now working on translating the articles into readable summaries."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: Investigate the relevance of a given document with a user query, I want to find the top relevant document."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: We are creating a children's book and we are looking for illustrations. Generate an illustration of a child playing with a puppy in the park."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: A researcher uses our platform to extract features from a given text for further analysis in a text classification task."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: We have recently started a project that requires depth estimation of drone pictures. Help us achieve this by predicting depth information. "}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: \"In the dark and stormy night, the castle stood as a shadow on the hill.\" Make sure each continuation is limited to 30 words."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: Our client needs to separate the speech and background noise from an audio recording."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: A medical technology company that develops software to automatically diagnose diseases from medical images requires us to build a system that can identify potential diseases within a given image."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: There is an Italian article in my company's dashboard, and I want you to provide me with a summary of the content."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: \"The first time I met a unicorn, I was strolling in the enchanted forest.\""}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: I got some photos from my trip to the zoo, but I can't remember what animals are there. Create captions for these images that describe the animals."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: I am preparing an app the generates photogaphs of nature sceneries, including forests, rivers and beaches."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: Develop a solution to caption images given their features."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: Provide me with a sample code on how to generate a 256x256 cat image using the 'google/ddpm-cat-256' model."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: We are a publishing company. Our user sent a long-description on their book. We need to create a summary of the provided book description."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Create a conversational bot that can empathically respond to given dialog contexts."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: Create a visual effect on art focused on the edges in the image to generate a new art piece."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: I am building a Chatbot mobile app for American users in which users can ask questions related to the images captured by the camera."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: I have a set of images of houses. Use ControlNet Model to predict a segmentation map for each of them."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: Develop a recommendation engine which can answer users' questions with high accuracy based on the context provided."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: We need a model to recognize text and answer questions related to the layout of a document."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: I own a bookstore which specializes in environmental texts. I need a brief description of a new book arriving in our store."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: My English teacher asked me to summarize a news article. Can you help me do that?"}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: I am a physician and tired to query information from research papers. How can I get the information directly on Covid through api?"}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: The company is working on a project that requires transforming images of empty rooms into furnished rooms. Find a suitable model and transform an image accordingly."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: As a software development company, we want our virtual assistant to help employees by generating code templates that can be used as a starting point based on their code query."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: We are a publishing company, and we're in need of a draft for the next young-adult fiction novel that we will be publishing."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: We are working on a startup that requires us to set up an avatar generation service. Can you help us generate avatars?"}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: I need a system to talk to users on a support page, where users ask questions about an e-commerce website they use."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: We have a large French article that needs to be summarized efficiently."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: Write me a code to answer a question based on the given context."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: \"Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions.\""}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: Our company is working on a project related to space and galaxies. We need a model to generate galaxy images."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: A researcher needs to extract a table from a document to analyze the data they need."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: We are interviewing candidates for a job position. The hiring committee wants to predict which applicants are more suitable for the job based on the pictures they submitted with their applications."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: We are a bank and we want to automatically process loan applications. We need to extract the required information from the filled forms."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: We have multiple audio files of people speaking, our team wants to analyze some extracted features to find patterns for a research project."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: We are fabricating an application to predict recidivism. Make use of the sklearn classifier pretrained model."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: Tell me how to assess the carbon footprint of a manufacturing process."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: Your task is to generate an audio file of a Russian sentence. \"\u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u044d\u0442\u043e \u043c\u043e\u044f \u043d\u043e\u0432\u0430\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u0443\u043c\u043d\u043e\u0433\u043e \u0434\u043e\u043c\u0430.\""}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: Our company needs to analyze surveillance camera footage to understand the types of activities happening in a specific area."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: We are a bookstore selling books of all categories. We would like to use your product to categorize books based on their cover images."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: We have a set of CSV files, and I want to classify incomes as high or low."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: An educational institute wants to create a system that can classify video tutorials into categories based on the content of the videos."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: Convert the following English phrase, \"happy birthday to you\", into Marathi using a Text-to-Speech model."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: \"In order to succeed, one must have [MASK].\""}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: We are creating an AI that evaluates construction site safety by analyzing photos of the construction workers. We need to know if they are wearing hard hats or not."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: We need a model that can evaluate paraphrases and determine if the generated paraphrase captures the meaning of the original sentence."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: I have many photos in my computer, but I want to know their content without openning them. Now I want a description of a photo which I found online."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: We are creating a football game application and want to develop an AI-based football player suitable for our new game."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: We want to create a product that estimates the distance of an object from a smartphone based on the objects image."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: We are running a matchmaking app, based on the preference of the user we are trying to generate a potential partner biographies."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: Automate the completion of an email in which the person who writes the email forgets a word."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: Detect whether the image of a mountain in front of me represents Mount Everest or not by asking a question about the mountain."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: We have a Chinese business report that needs to be translated into English as soon as possible."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: I need to create an AI model to classify images with Chinese texts and descriptions written in Chinese."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: We are developing a mobile application for the visually impaired. The app requires text-to-speech conversion to help users interact with text content."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: Create a notification system for a mobile application that plays an audible message when users receive new notifications."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: Our client is a healthcare company. They need a solution to detect and count different types of blood cells in medical images."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: Create a system that translates English articles about new technologies to Arabic. We need a technology article in English and its output in Arabic."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: As a parking assistant app, we need to detect license plates from the live feed of our security camera."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: Create a question-answer pipeline to help users find relevant information in a given text."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: A supermarket wants to advertise their products online. They need a short description of an image showing fruit and vegetable stands. Can you generate a suitable caption for the image?"}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: My city has a problem with potholes in the streets, and I want a solution to detect potholes in images."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: We are working on an AI application to classify the scenes in TV shows for extracting specific frames, which model do you suggest we use?"}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: We need an email template generated. Determine the grammar mistakes in the text."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: Create a code snippet to use an existing tiny random LayoutLM model for document question answering."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: We want to create an app that translates images and their text properties to help people with impaired vision."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: I want to analyze two sentences to identify the relationship between them as entailment, contradiction, or neutral."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: Utilize a text prompt to produce a fantastical image that represents a garden full of mythical creatures."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: For our German e-commerce website, we need a model to classify sentiment in user reviews."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: The city municipality wants to build enough drinking taps at the stadium, counting the number of heads present during the event in the footage."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: Our application needs a random image generator with high quality to feed its background."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Our company is developing an app for sharing conversations from live events. We need this app to isolate individual speakers from the background noise and other speakers."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: We recently launched a language learning app for children. We need to create a feature that answers questions about images that our young users may have."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: We have to build a product used in the office that can identify text from a table in an image and answer questions about the stats in the table."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: \"Which company has the highest percentage growth?\""}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: We need to predict the closing price of a certain stock using the given model."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: \"What time is it now?\""}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: The company I work for makes autonomous robots that move around in indoor environments. We require a solution for estimating depth in a scene."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: Your company is creating an AI-enabled document assistant. Implement a functionality to answer questions based on the content of business documents."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: I am building a robot to deliver mail to homes. The robot must navigate through dynamic environments filled with obstacles."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: As a real estate developer, I want to estimate the depth of a room using a depth estimation model."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: I want to find an article that is related to the one I was reading yesterday about AMD processors. Give me the similarity scores between the article I read yesterday and several articles I found today."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: A director wants to make a commercial for a new environmentally friendly electric car. Provide a sample generated video with rainforest trees surrounding a charging station."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: The teams are working to discover similar phrases in the article. We need to identify the phrases similar to \"How effective are vaccines?\""}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: Create a short video sequence featuring a panda playing the guitar."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: One of our clients is launching a new board game with a butterfly theme. They need images of multiple butterfly illustrations for the game cards."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: Our design team needs a quick sketch based on a given prompt. They have asked for a \"peaceful lakeside view.\""}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: I am developing a book cover for Alice in Wonderland, so I need an AI generated cover image based on the provided instructions."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: Our city is planning to implement a traffic management system. We need a way to classify the vehicles on the road."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: A headhunter wants to screen voice samples of applicants for their next job, color coding each applicant with too high nasality as yellow, too low as red, optimal as green, and unknown as white."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: Write a news headline that summarizes a reported incident in French."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: I work in a fashion company, and I want to create a bot that recognizes the material of clothing in a given picture (leather, cotton, etc.)."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: We are developing an App to classify photos. We need a suggestion on how a photo should be categorized."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: We are creating a content summarization tool that needs a model able to understand natural language texts and extract important features."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: We are a real estate agency, now creating virtual property images. Design a model to create images for virtual bedroom staging."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: A journalist needs to find the connection between plastic pollution and climate change. Generate an informative text for them."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: Our team wants to build a COVID-19 information bot. We need to answer questions related to the pandemic."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: Some people at our company are having difficulty understanding the British English dialect. Therefore, we would like to develop a program that will help everyone understand the content each other shares by translating it into American English."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: I need an image classifier to detect the presence of a cat or dog from a supplied image."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: I am looking for a natural language API solution to shorten a PubMed article into 1-2 sentences long summary."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: Our travel agency wants a tool to recognize the main attraction shown in a picture chosen as cover for a brochure. Design a tool for this purpose."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: Create an eye-catching piece of art for the cover of our new book. The image should depict a robot holding an umbrella during a thunderstorm."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: In my medical startup, I need to share patients' records between doctors but keep their data private. I would like to use an automatic tool that hides personal information."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: A Russian-speaking student has built a conversation bot to practice their oral Russian. Now they want a creative question to discuss with it."}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: I have an English speech audio file, and I want the assistant to convert the speech into Hokkien."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: My child just asked me about the name of building in an image. I don't know the answer, can you help me?"}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: Build a system that converts images into textual descriptions for visually impaired people."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: An architect wants to use AI to generate outlines of furniture in a room from a photo of the room."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: We need to implement a feature to know when someone is speaking or not in a video call."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: The urban planning department needs a tool to automatically generate rough drafts of buildings based on drawn line segments."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: Create a tool to identify whether an audio file is music or speech."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: We are trying to automatically categorize incoming customer support requests, such as general inquiries, technical issues, or billing questions."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: Our self-driving car project requires identifying the distance between objects in the scene. How can we estimate the depth of a scene using a pre-trained model?"}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: Find the forklifts and the people near them using an YOLOv8 computer vision algorithm."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: Our business is merging with another company, and we need to make a decision. Find out which documents on our servers are similar to the new partner company's documents."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: I want to create a product description about a leather backpack based on a low-resolution image. Upscale the image to a higher resolution for better visual representation."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: A news editor needs a solution to automatically recognize locations, organizations, and people in a given text for fact-checking purposes."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: Help a robotics company to find damaged PCB boards by detecting and highlighting the areas of the board that have defects."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: A new government regulation requires predicting the carbon emissions of electronic devices. Use the provided model to determine the emissions for each device data in a CSV file."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: In a scenario where you want to evaluate the performance of a gaming algorithm, predict the performance of the LunarLander-v2 algorithm."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: Provide a method for summarizing given English texts."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: \"The capital of Italy is [MASK].\""}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: I want to build a personal assistant to summarize the input text in Chinese."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: I want to estimate the depth of objects in an image. Please provide code to load the depth estimation model."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: We have a Spanish tourism company, we need to classify a Spanish text and determine if it is related to travel, cooking, or dancing."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: Generate text from the given image of a printed document."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: We need to develop a tool that can identify which buildings are more likely to have high carbon emissions based on various factors."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: We are running an animal adoption website and trying a machine learning approach to automatically classify images of pets as either cats or dogs."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: Write a service to extract names, dates, and organizations from the input news article or email."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: We are a pharmaceutical lab and want to extract important context from research papers to summarize findings."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: Lisa is having a hard time reading a technical document. Can you help her with a tool that understands document layout and answer her questions about the document?"}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: Create a digital art piece that features a serene landscape with mountains and a river in the style of a watercolor painting."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: I am a mathematician and have developed an AI driven learning system for teaching students. In order to match their questions to the correct answers from our database, I need to include an API which measures the similarity between the questions being asked and the answers we provide."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: Global Offensive (CS:GO). We need to identify the players and draw bounding boxes around them."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: We need a tool that can answer questions related to data in tables. Use Google's TAPAS algorithm to enable that capability."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: Recommend an NLP model for a mobile app that can answer questions based on a provided context or text. The model should be relatively lightweight and have good accuracy."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: We need to identify a type of action taking place in a video."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: Could you write a summary for a long news article?"}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Our goal is to analyze satellite images by identifying and segmenting the buildings."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: Our company has a huge repository of technical documentation. We want to create a tool to generate summaries to assist in quickly getting an overview of the documents."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: Our company creates birthday cards, we need to check if the card image contains a cake, balloons or birthday decorations in it."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: I am a Mathematics teacher. I'm preparing a text with missing words for my students to fill in. Could you help me with the fill-mask task for this text?"}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: Create an algorithm to classify a piece of artwork as either impressionism, surrealism, or cubism using a specific image as input."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: We are an organization specializing in Dutch language audio analysis. We need a transcription of some audio recordings in Dutch."}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: Create a classifier to understand the emotions from the dialogues of our new drama series."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: I want to create an interactive chatbot for customers to ask questions about our store and products."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Design a chatbot that can respond empathically to a user's questions by incorporating context from a given dialog."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: We are a robotics research team working on audio-event detection and localization. We need to process audio from microphones placed around our environment and extract spectrogram features."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: My company needs a tool for identifying similar support questions from customers."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: Our team is organizing a workshop, where participants were asked to answer a list of questions. I would like to summarize this data and answer questions based on the table that summarizes their responses."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: I authored a novel in Korean, and I want the story to be translated into an audiobook."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: Our company wants to build a video surveillance system with real-time detection of violent situations. We need a video classification model that can analyze the video feed and detect any incidents."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: We just created a new neural network architecture for image classification, and our first task is to classify an image from an URL."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: We need to group the users' interests in similar categories for personalized recommendations."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: We have to provide an answer to a student's query from a given paragraph in our study material."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: We are an Indian company, building educational applications. We want a Marathi male voice to teach some lessons."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: 'I love eating [MASK] for breakfast.'\""}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: I'm a student and I want to quickly extract information from a digital invoice in a photo taken by my smartphone."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: We need an AI service that can classify named entities in French text, such as people, organizations, and locations."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: Find out how similar two sentences are from an online review dataset. \"I love this product! It's exactly what I wanted.\" and \"The product is amazing and just what I was looking for.\""}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: A startup is trying to detect the type of object present in an image for their application. They are seeking an image classification model for their project."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: I want to process a call center conversation and detect the voice activity in it."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: Give a speech in political conference and needs to convey the message, \"Improving education is our prime responsibility.\""}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: I want to generate a commonsense sentence using a list of words."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: I have an audio recording of someone speaking in a foreign language. I need to transcribe it so that I can understand what they are saying."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: Our client has shared an invoice in pdf format. We want to check the total amount on this invoice."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: Our company is working on a smart traffic management project. We need to be able to segment and classify traffic scene images."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: We need to generate an image of a cute butterfly for a children's book cover."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: I am building an app that will sort news articles into multiple categories. I would like to classify a given news article into categories like 'politics', 'technology', 'sports', 'entertainment', 'business', and 'health'."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: This new model I have found claims to provide rich image-based descriptions and answer visual questions. Can you set it up and show me how it works?"}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: We are building an application that can separate background noises, voice, speech from an audio file or recording."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: A school teacher is organizing a competition where the students have to read a sentence with some missing words and the students need to predict those missing words. Our job is to design a system that can provide us with a predicted word for a given sentence with a missing word."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Imagine we are publishing a book about astronauts and want to create unique illustrations. Generate an image with the description \"a superhero astronaut flying in space above Earth\"."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: A film studio wishes to create a storyboard for a historical movie, but they want it in analog style. Create an image of ancient city."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: We are an art company. We need to identify what type of painting style is used in a given artwork."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: Let's say the customer expects our computer vision solution to detect and evaluate various visual styles of a photographed room. We need to provide them with an array of design classifications that our AI can distinguish automatically."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: We are a book club. We recently finished discussing Brave New World by Aldous Huxley? What's the name of the main protagonist?"}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: Our client is a simulation company. They want a neural network model that is trained on MNIST dataset with a specified data cap."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: An international company needs to translate user feedback from English to various target languages for the customer support team."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: We would like you to develop a filter for our social media platform which could classify comments/messages as inappropriate or safe."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: Assist an online video game streamer in detecting dropped spikes, enemies, planted spikes, and teammates in the game Valorant."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: Our client wants to create custom Minecraft skins for a promotional event. Please generate an example skin for reference."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: Our meeting recording software needs to identify overlapping speech portions in a given meeting recording. Can you suggest a solution for this task?"}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: Design a video advertisement for a new smartphone showcasing its features."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: Our team is building an AI-driven image generation product where a user can request a cat image generated using DDPM."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: We are building a chatbot that needs to understand the context of a conversation. Please find a way to compare our sentences with their response to determine the similarity."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: Summarize any random document to make sure it\u2019s concise and to the point."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: Create an API call to recognize the content of the speech and identify the speaker from an audio file."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: Our graphic design company wants to restore damaged images. We need to use an AI-based solution for it."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: We want to build a customer support voicebot that can direct customers to specific support agents based on the languages they speak in their voice messages."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: As a language school, we need a system to translate from German to English for incoming student applications."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: I'm analyzing historical data of Olympic Games and I want to know which year the Olympic Games took place in Beijing."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: I am a faculty member in a university research lab. I need to transcribe my Marathi podcast episodes to text format for our research."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: I want to extract the text from a document that is an image url from a certain webpage."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We need to develop a system that can recognize the language being spoken in various audio recordings. What do I need in order to do this?"}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: A company wants to estimate the carbon emissions of its products. How can we use the given model to help them with this task?"}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: I want a creative writing brainstorming tool to generate some ideas for my next story."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: I'm running a website that needs a system to recognize and classify different types of images uploaded by users."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: My company has a German-speaking customer base, and we need to analyze their feedback sentiments."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: We need a tool to create clusters of text which are semantically similar."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: We want to deal with text data which has unique features. Create a feature extraction pipeline to analyze and extract features from text data."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: \"I bought the headphone last week, and I am absolutely loving the sound quality and battery life!\""}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: Can you find whether an artwork of anime is created by a human artist or an AI?"}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: We want to create a book cover that features a dragon next to a waterfall. Use an existing image of a waterfall and modify it by adding the dragon."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: I need a language model capable of classifying texts into different categories in multiple languages."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: Create a program that translates Hindi text to Chinese."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: We are running a pet daycare business. We need a cute image of animals for our marketing campaign."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: I am a student of medicine, I want to build a personal assistant to answer my questions related to the subject of the materials I read every day."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: I'm building a multilingual news categorization app. Help me classify a German news headline into politics, economy, entertainment, or environment."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: Propose a solution for generating educational videos from user input."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: We are running a company that needs image segmentation to better understand the different types of items in the product catalog."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: We want to analyze scientific publications on COVID-19 and extract relevant information. Get a unified representation for specific terms."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: Our company is looking to conduct market research for new products and would like to extract information from images."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: We want to convert the speech in a conference recording to text. What model and library should we use?"}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: Suppose we want to generate creative advertising slogans for promoting an environmentally friendly product."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: Assume we want to measure the depth of various objects within an image, please calculate the depth using the tiny-random-DPTForDepthEstimation model."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: Create a model that will read random sentences and classify them as Gibberish or Legible."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: I am developing a machine learning-based chatbot solution for a large bank. I need to identify themes from customer support dialogs."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: As a market research analyst, I need to use the data we have from sales spreadsheets and tables to answer a specific question about the average sales of a certain product in Q1."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: You are a photography enthusiast and you need to figure out the best place to focus in the image. We need to figure out depth estimation for this."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: Planning to install an automated irrigation system that waters plants using computer vision. Determine the distance of plants from the sensor to optimize water usage."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: I received this long research paper, and I want to research a specific section about the effects of climate change in agriculture."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: We are working on a chatbot that needs to fill in the missing words using an AI model."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: We're making a mobile app for people to identify things in their surroundings. We need to be able to answer questions about images."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: The tourism office is now preparing a new video to introduce our city to Chinese people. Let's generate a simplified Chinese voiceover for it."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: I work in a company that builds global shopping products. I need to translate English product descriptions to German."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: Build an image generation tool that can create anime-style images based on text prompts."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: Can you please detect an ongoing conversation between two friends in Arabic and give us a transcription?"}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: Our customer is an advertising agency, and they need a tool to convert a sketch into a final image. They ask for a solution that incorportes suggestions for changes such as \"Add more color to the sky\" or \"Make the house look larger\"."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: ###Instruction:Our project manager needs to convert some Mandarin speech recordings into text format to create a written translation."}
{"text_id": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 797, "text": "query: I have a party at my place this evening, and we need to separate sources of music in our audio system. Can you suggest a way to do this?"}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: Working with a news company to develop an app with AI assistance to correct grammar mistakes."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: Our finance team needs a model to determine if a person makes over 50k a year based on provided data."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: I need to classify the objects in a given image to categorize it for my website."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: I am a teacher, and I would like to build an interactive tool for my students to practice their English speaking skills. They should be able to type a sentence or a question, and the model should give them a response."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: Please create a text-to-speech system for call centers, so the computer can speak with customers."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: I need an automatic summarization tool for our news website to provide short summaries of our articles."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: A student is working on a research project and needs help with a question-answering model to quickly find answers in their research materials. Can you guide them?"}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: Our company is a blog and we want to have an AI generate some potential opening sentences for a new blog post about technology trends."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: We need to detect and analyze named entities in a given text, such as places, names, and dates."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: The marketing team requires an automatic tool to caption their social media images."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: We are a robot manufacturing company, and our customer is asking about the historical context of when our company was founded. Please provide an answer to the question."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: I have a toy factory and need to build a robotic arm that assembles toys. I want to analyze and make decisions based on its vision."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: Our company creates a video platform for recommendations, we need to classify videos based on their content."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: Our team is working on a social listening tool. We need to determine user sentiment based on their comments."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Our client is a video game company, and they want us to create weapon concepts from text desctiptions."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: Our company needs a chatbot that can handle customer inquiries about our products and services."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: Our company collects data in tables and needs a function to easily answer questions from this data."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: Create a software to read a passage in an audiobook for visually impaired people."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: Identify the depth of objects in a given image for autonomous driving system that has been installed in public transport buses."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: \"\u4ed6\u662f\u4e00\u4e2a\u975e\u5e38 [MASK] \u7684\u4eba\". Let the AI predict the missing word."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: In a fashion retail company, we want to create an app that automatically segments clothes from an image for designing virtual fitting rooms."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: I am a software programmer. I spend most of my day sitting at my computer. I am looking for some way of entertainment on the computer."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: You are working on a project to help self-driving cars navigate better in complex urban environments. We need depth estimation for this task."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: The news agency wants to analyze articles from social media for user-targeted emotional reactions. The goal is to create an article recommendation system where users can choose articles depending on their mood."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: My company wants to predict electricity consumption based on historical data. I need an efficient random forest regression model."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We need an application to quickly classify whether a plant is damaged or healthy based on an image."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: Determine the budget allocation for Project X in the given financial document."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: Our customer is a real estate company. They want to be efficient in categorizing their building and land images. Let's help them classify their images."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: We are a company that sells home appliances, and we need to detect the category of the product based on the written description."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: A news organization is looking to transcribe their recorded interviews and podcasts. Create a code snippet for automatically transcribing the audio files."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: We're developing an interactive storytelling game for kids. I need to generate a character's dialogue based on its personality."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: I am a writer, and I need a tool that can suggest the next sentence in my story."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: We are a health organization who has a lot of documents like doctors online reports and their patient list. We need to de-identify these personal information."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: I want to create an AI-based chatbot to assist customers with their inquiries."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: Design a language translator software between English and Portuguese which could detect the format of the translation source text automatically."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: I am working in the real estate industry. I want to predict the housing prices for a given dataset."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: We are a publication house that needs content translated from Russian into English."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: Create a virtual pet with cute pictures. The pictures can be used for a new mobile app for kids."}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: We are implementing a smart traffic system. Kindly implement code to detect vehicles in an image."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: Our company is preparing a report with multiple tables in it. Provide me with a simple tool that allows me to ask questions about the data."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: Develop an AI chatbot that can generate a relevant anime-style image based on a given textual description."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: As analysts in an autority analyzing political debates on national TV, we need to detect when multiple people are speaking at the same time."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: We are planning to use Machine Learning to build a flower classification application. The application needs to be able to predict the label of flowers from their attributes."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: A gym is interested in developing a system where they can monitor the people doing exercises and identify the type of exercise they are doing."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: I own a restaurant and I want to predict the tips that servers will receive based on various factors like total bill amount, gender of the server, if they smoke, day of the week, time of day, and size of the group served."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: I have a travel blog that provides travel information in both Spanish and Catalan languages. Please help me to auto-translate my Spanish blog to Catalan."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: I am an AI developer. I am building an accessibility tool for visually impaired people, which uses a device to capture an image and a voice input to ask a question about the image. I want to know how to answer the question."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: We need to create an artwork for our newest novel, \"The Last Jungle.\" We want it to feature a blue paradise bird in the jungle."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: Create a solution that identifies an object in an image and answers questions regarding that object."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: I am an artist and I am exploring new ideas for a butterfly-themed painting series. Generate butterfly images for inspiration."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: I am building a tourist app, and I need to segment a cityscape image to help annotate buildings, roads, and surrounding areas."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: Our team needs a solution to detect voice activity in audio recordings from our conference meetings."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: Write a fictional story set three million years in the future, after mankind has left Earth. Start with \"Once upon a time, Earth was a bustling planet filled with life.\""}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: We want to build a chatbot that connects with website users to answer their questions. We want a chatbot that can ask and answer questions, and demonstrate knowledge, empathy, and personality."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: Summarize a news article about a cricket match between India and England."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: \"The book is in the ____.\" Help us complete this phrase."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: As a film producer, I need a tool that could create a short video sequence based on a given script to visualize a specific scene."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: I need to extract information from a document and answer a specific question. How can I do that?"}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: To analyze court proceedings, we need to find out who is speaking at any given moment."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: Our application needs to classify images of animals into categories, such as cat, dog, and bird."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: I'm creating an AI model to monitor the river near the bridge and classify whether the condition is \"normal\", \"overflowing\", or \"polluted\"."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: We are a photo editing company, and we need to deblur images using AI."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: Our company creates exam sheets for students. We want to use artificial intelligence to answer the questions."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: Someone shared an infographic about energy consumption with me, and I need help understanding the picture. Can you help me understand it by answering questions about it? "}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Can you help me extract tables from this document?"}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: We are creating an audiobook for a popular Chinese novel. I need your assistance to convert a text sentence into speech."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: We have an educational startup. We want a conversational agent that can answer questions to the text provided."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: Create an image classifier using a pretrained model for a marketing team that wants to classify images that show either city life or nature landscapes."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: Extract important information and named entities from a given text such as person names, organization names, and dates."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: I want to create a conversational agent that briefly describes their experience at a conference and answer my questions about it."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: Help our French news agency in summarizing an article to provide a quick overview of the topic in French."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: I am a doctor, and I need to detect lung sounds in patients' audio recordings. Could you help me analyze the audio data and extract relevant features?"}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: We need to generate an interesting story about robots for the children."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: I want to create a virtual exhibition of animals depicted in a certain traditional art style. Make sure to generate images of high quality."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: We need a personal assistant that can help us answering questions from books or articles in various languages."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: We're in the publishing industry and we need a system that helps us detect tables in the documents we process. Can you help us?"}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: Given this germam text \"Angela Merkel ist eine Politikerin in Deutschland und Vorsitzende der CDU\", implement a text classification model to classify whether it's related to politics, economy, entertainment or environment."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: To help my team answer the client's questions more efficiently, I need a question encoder model able to create an embedding for questions to better compare the answers stored in our database."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: I want to classify the spoken language in an audio file, \"audio_example.mp3\", and print the language with the highest probability."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: A travel company wants to create a promotional image of astronauts riding a horse on Mars for their services. Create an image from a text prompt."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: We are a language research firm studying similar sentences. We want to find the similarity between two sentences."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: We need artistic images by enhancing the existing collection. We want to create a new dataset with stylized images based on Canny edge detection."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: Our company focuses on code reviews. Please add variables to a given code in the natural language description."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: An architecture firm is working on a new project and would like you to create a concept image of a modern building based on their description."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: We are building an e-commerce website to sell products from Finland to international customers. We need to translate product descriptions from Finnish to English."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: What is the capital city of France? "}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: Recently, we need to analyze an article on health and extract verbs."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: We are working on a project that needs to extract table structures from images of pages containing tables. Make use of the table transformer model to detect the rows and columns."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: A manager at a tourism agency is responsible for curating travel suggestions for customers. The manager wants to quickly find relevant information in a document to answer specific customer questions."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: Our company needs a safety system that can detect whether our workers are wearing hard hats on construction sites."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: Develop a tool to estimate carbon emissions based on the input data from the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: The mobile app should include a feature that speaks out text descriptions in response to user queries."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: Build a system that can complete the sentence \"The large python slithered through the...\"."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Design an image for a company website with a catchphrase \"Green energy for a sustainable future.\""}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: Our team is creating an application that filters out human speech from background noise. Can you suggest a suitable API for voice activity detection?"}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: I have a robot and it needs to answer questions based on text input. Can you suggest an NLP model for that?"}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: My friend has a book with the first line, \"It was a dark and stormy night.\" I would like a personal assistant that would generate 5 different ideas for continuing with the story."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: Could you help me generate the continuation of the story \"Once upon a time there lived an old man and a young boy in a small village near the mountains...\"?"}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: I need a quick translation of a news article from English to Spanish for my foreign business partners."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: We're building a chatbot to help customers with computer related issues. Answer their queries using this Conversational AI model."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: Review multiple images of vehicle registration cards and answer a list of questions about the text present on these cards."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We need to find tables in the document and classify them as a bordered or borderless table."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: We are building an app that helps users to automatically select a painting style for their photo. Can you give us a model for image segmentation?"}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: As architects, we want to estimate depth in a room from a photograph to design our interior work."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: Asynchronously generate a realistic image of a tropical beach with palm trees."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: We are building a fitness app. It's crucial for us to classify workout types based on the video footage recorded from the users' devices."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: We want to use a model that can convert the voice of one speaker to the voice of another in real-time. We will use this technology for dubbing video content."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: We are a game design company. We need to estimate the normal map from depth map."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: I wish to create a fill-in-the-blank solution for our language learning app, which requires the generation of masked sentences."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: Our company is building a Japanese chatbot, and we need to predict possible words in a sentence containing a masked word."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: I work at a law firm and need to analyze scanned documents for specific information."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: We are working on a project to extract answers from scanned study materials. How can your AI help?"}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: Let's work together to create an algorithm for a basic arcade game called the Breakout no frame skip. I have always been fascinated by this game."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: Could you provide an Italian-to-English summary for the following Italian news article text?"}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: We want to create an email automation solution. Help us generate code snippets in Python to achieve this functionality."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We are working on an article that mentions the Olympic games. We need to know which city hosted the event in 2004."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: Our startup aims to predict the environmental impact of new construction projects. Determine a method to classify a project as high or low emission."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We need to classify sports in a video feed for a sports analytics company."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: Develop an automatic speech recognition software for a podcast app to transcribe human speech to text."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We are a software agency and we just built a desktop application for our client. The client is a financial institution that needs to recognize the handwritten digits on checks."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: Our client want to explore a new category of products. We need to help them classify the images of the items they have in their online store."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: We are a city council engineering office creating a program to detect and locate potholes in street images."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: I have a large dataset of historical stock prices, and I need a quick and simple regression model to predict the closing price of a specific stock."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: We are trying to develop an app for calculating carbon emission from a set of values from a csv file."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: You are asked to develop a system to answer questions about sales data provided in a table."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: We are a company creating webinars, and we want to convert our scripts into audio files. We need a text-to-speech model to make the conversion."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: As a communication tool company, we want to offer a feature that verifies speakers' identity based on the recorded audio files."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: I am a chemist. I would like a machine learning model to help me classify molecules based on their properties. Design a model to help me achieve this goal."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: I run a medical lab for blood sample analysis, I want to identify blood cells in the samples."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: A gaming company is engaging in the creation of a new player-vs-player game, and they need a computer opponent that can play the game."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: I am creating a picture book for children. We need to generate an image of a yellow cat sitting on a park bench, surrounded by colorful balloons."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: Our startup is building an application to help people find answers from product manuals. Help us find answers to questions about these manuals."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: We need a fill mask model that can automatically fill the spaces in sentences."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: Extract the text from an audio file which is in English language and create a short summary of the transcription."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: Extract transcription from an audio file with proper punctuation."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: I have developed an AI-driven character for a video game, and I need a visual sensing system to estimate the depth in the surrounding environment."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: \"Google's headquarters are located at Mountain View, California. Tim Cook is the CEO of Apple, located in Cupertino.\""}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: Chinese text segmentation must be optimized. Extract tokens from the given Chinese sentence."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: I am looking for recommendations for books to read, based on my favorite book title and description. I have an API that can provide books based on semantic similarity."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: We need a tool to answer specific questions about images of objects, people, and scenes."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Generate a futuristic story of a city's transformation into a smart city with AI-driven services and technology."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: Explain how to use this API to transcribe an audio recording of a podcast."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: I want to know if a given sentence is an adequate paraphrase of another. Can you identify this by running the input through your model?"}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: We are working on an application to track planes in images taken from the Earth's surface. We need a model to identify airplanes in the images."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: I have a long article and I want a personal assistant to help me answer questions about it."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: Please transcribe the text in an image of a handwritten document."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: We are working on an audiobook application and we need a text-to-speech model to read the books."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: Create a summary for this scientific paper I am about to present at a conference."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: We are receiving scanned handwritten documents and need to extract the text from them for further processing."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: My colleague is sending me a message, however, I am not sure what language they are using. Can you help me identify the language?"}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: A language teacher wants to build a tool to help students fill in the blanks for a given sentence. Use the appropriate model to perform this task."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: We have an online platform for selling clothes, and we need to categorize uploaded images by the users."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: Develop a smart AI chatbot to instantaneously generate human-like informal text given a conversational input on any topic."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: We want to create an artwork project with a vintage style look. Let's generate a vintage-style image to use as inspiration."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: I wrote a piece of text in German about treating the environment well. Translate it into English so that my international friends can read it."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: I am a data scientist studying the semantic similarity of two texts. I need to find the semantic distance between the two sentences."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: Build a program that reads a CSV file containing wine data and predicts the quality of the wine samples."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Our customers that use our OCR software are finding the applications helpful. Can we have a summary of the content of the picture without classifying the type of image?"}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: Help building a robot that can navigate autonomously through a room with obstacles. We need the robot to estimate depth from image input captured by its camera."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: We are building a support chatbot that can assist users with their technical issues. We want the chatbot to have the persona of a friendly and knowledgeable tech support agent."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: As a company operating in Germany, we need to identify important information, like organizations and locations, in the incoming German text messages."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: We are a pet adoption agency. We need to classify the images of pets, whether they are cats or dogs."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: Classify images of different food dishes and provide information if it's a pasta, pizza, burger, sushi or salad."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: We need a way to determine if two product descriptions on our e-commerce website are duplicates."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: Our customer is asking which language his client wrote an email with."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: We are developing an application that needs to perform part-of-speech tagging of traditional Chinese text."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: We need a tool to extract speech from a video conference recording, separate speakers, and create separate transcripts for each participant."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: Describe the process of building a system to perform real-time semantic segmentation of images using the SegFormer model."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: I am writing a short story about a knight named Sir Gallaghan. Write a dialogue involving Sir Gallaghan talking to another character."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: There is an NLP project where we need to group similar movie reviews. How can we do it?"}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: Create a Russian voiceover for an advertisement using the text-to-speech model."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: I am writing a scientific article on the evolution of fish weights, so I need a tool that can predict the weight of various fish species."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: Our company is working on a writing assistant tool. We need to generate content that aligns with a given prompt."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: We are working on a project to answer questions about tables. Implement an API to fetch answers from a given table and a natural language question."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: We are a content agency, in oder to quickly generate drafts, we need to use the AI model. Use a zero shot classifier to classify the article into 5 different topics(base on the content provided)."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: We need to analyze security camera footage to see if there are people entering a restricted area."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: One of our interns is working on coding an agent for the Pendulum simulation. Help them with suitable codes."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: Check if an image contains a specific object by classifying it using a pre-trained model."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: I want to identify the person with whom I'm talking to on the phone and sort the call into categories of friends, family, and work."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: I need a model that can answer questions based on a given context."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Our medical client wants us to create a tool to evaluate their patient's retinal images to determine if they have diabetic retinopathy. Can you create that?"}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: Classify an audio clip to see if it is a digit between 0 and 9."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: I need a code that trains a neural network on the MNIST dataset with a specific data cap, that can be further used for game applications like GTA5."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: We are building an audiobook app. We need to bring the book's text to life using text-to-speech technology."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: A music platform asked us to recommend songs of a similar genre based on the input of a specific song."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: \"I have always wanted to visit [MASK].\""}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: Can you assist me in synthesizing a Marathi male voice to say \"\u0906\u092a\u0923 \u0915\u0938\u0947 \u0906\u0939\u093e\u0924?\"?"}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: We are an astronomical institution and need a model capable of creating realistic images of outer space."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: Our new client is arranging a magic and anime convention and asked for a mascot. They described a cheerful fox-girl with long red hair, holding a staff, and wearing an attire complementing the magical theme."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: car, bike, bus, train, or plane."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: We would like our model to read two sentences and determine if they are semantically similar."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: Analyze the audio files collected from a call center to gather insights about customer preferences and trends."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: As a game enthusiast, I am developing an application that predicts Pokemon's HP. Please guide me on how to use the regression model."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: I'm looking for a model to help me summarize a long piece of text to a shorter version."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: We want to have a command-line tool to summarize very long scientific research papers."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: Our next big project is to build an AI-driven auto trading bot for financial markets. Find the best React library to create realistic gesture-based navigation for mobile apps."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: I want to estimate the mood of a song from lyrics, so I can recommend the song to users depending on their current feelings."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: Some clients are looking for a way to automatically detect the language used in mp3 files of spoken sentences. They would like to have an idea of how the performance of a model like that would be."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: Our company wants to offer an audiobook-making service, and we need to convert a given text into a voiced version."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: Your boss wants to find similar resumes in a large pile through an application. Help them design that application."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: I need to convert a recorded call into text form. Our customer service representatives speak English."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: I need to translate Mandarin phrases to English so that I can understand what my manager is saying."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: How do I classify an image for zero-shot image classification?"}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: The owner of a pet store needs a software to categorize uploaded pet images to their corresponding animal type."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: I need to identify whether the statement \"A dog is playing with a ball\" contradicts, entails, or is neutral to \"A pet is involved in an activity\"."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: Create an image of a black dog sitting on top of a car with high resolution."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: We are creating a coding help forum where users can input incomplete code, and an AI assistant can help them complete the code. Design a system that performs this task."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: Let's build a question answering system for a search engine. The system should generate questions to the given input document."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: A science fiction novelist needs an image classifier to write the story based on images he receives daily. He needs a simplified pipeline."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: Can you help me write a code to extract information from an invoice using a document question answering system?"}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: My grandma is having trouble reading emails in Telugu. Please create a module that can read the text and give us the audio output."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: We work for a gaming company, and our new project is a fantasy game that contains dungeons, castles, and various magical creatures. We need to generate a visual image of a commander's room inside the castle, based on a textual description."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: A company is building a conversational assistant which requires smart response suggestions. We need a functionality related to masked language modeling."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: I need to improve my robot's ability to understand natural language commands, please advise a solution"}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: I need a speech recognition engine to transcribe and convert some Marathi voice recordings into text."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: A university researcher is trying to measure the depth of an object from an image."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: Our company is an audio production house. We need to separate the vocals from an audio file and save them in two separate files."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: I am looking for a tool that can detect tables in given set of PDFs or images of documents. How can I accomplish this?"}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: I am an artist working on an anime theme who wants to generate a realistic image based on a character description provided as text input."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: \"I first thought that I liked the movie, but upon second thought it was actually disappointing.\""}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: People complaining about my replies being not clear and complete. I need help to make them professional ."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: I want to design a conversational AI that describes generated images of art from different epochs in human language."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: I am a novelist and working on a new story. Design a chatbot that can fill in the missing words in my story on the fly.`"}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: We are a oranization that needs to generate an image of a futuristic city landscape based on the text description."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: The gaming company you work for wants to incorporate an AI chatbot to respond to players when they request support. Help them create a chatbot."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: We want to build an AI-based chatbot that should able to classify user emotions based on the text inputs."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: There is a competition between chatbots. Can you provide a generative conversational agent that can participate in this competition?"}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: I am a music streaming platform owner. I want to know the emotional state of the user while listening to a particular song."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: Using this model, I'd like to generate a real-looking image from a simple sketch."}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: Can you help me build a software that recognizes images of animals and classifies them into various categories using 'google/vit-base-patch16-224'?"}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: I want to build a digital assistant that can answer questions about visually represented data. For example, if the user asks what color shirt someone is wearing in an image, the assistant can provide a response."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: A user is trying to find information on a specific topic from a set of documents. Help them retrieve the most relevant passage."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: I need to chat with an AI who's well-trained in real-life chat and implement a conversation with it."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: I am preparing a movie script in Russian. I want to embed each sentence in the script and analyze its contextual meaning."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: The ecologist team wants to develop a plant classification tool for different areas in the park. We need to schedule the maintenance and development in the park."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: Invent a plot for a science fiction novel set in space."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: Create an AI product for a television channel to help analyzing images and answering questions related to content on real-time during a broadcast."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: Create a script to predict the housing prices for a given dataset and provide a summary of the performance metrics."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: Set up a conversational bot to reply to my questions in a character's persona."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: The client requests a system that generates images with human figures based on textual description. Please draw an image with a chef in the kitchen."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: Our team is developing an edtech platform, where users can assess their English writing skills. We need a tool for automatic grammar correction."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: An online store wants to rephrase the descriptions of their products to avoid content duplication. Tell them how they can do it using the given API."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: Let us know if we can find an artist who knows how to draw architectural styles, and for practice they can simply draw an \"Italian villa in the hills surrounded by vineyards\"."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: We are building an AI customer service tool that can help companies analyze customers' sentiments from their tweets."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: Our company aims to build a product that generates videos from text descriptions. We need to create a video of \"Spiderman surfing.\""}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: I have a list of sales data with information about products, prices, and quantities sold. I need assistance to answer questions about this data."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: Create an AI-based system to identify if a clip belongs to a specific celebrity or an unknown speaker from an audio dataset."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: I have a restaurant in Spain. Please help me translate my menu from English to Spanish."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: The users want to get summaries of long articles they can post on their Twitter accounts."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: We received a transcribed text from a meeting, but there are no punctuation marks. Please add punctuation to the text."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: Create a function to generate a story. The story should begin with \"Once upon a time in a magical forest, there was a tiny creature.\""}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: Your boss is in charge of managing data for a Korean company. He needs your help to analyze a table with Korean descriptions to extract important information."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: A company wants to check quality control and detect the presence of defective items in manufacturing. We need to detect objects on an assembly line."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: I want weather predictions for the 7 day forecast. By using given tables of city weather data, find out which day(s) it is likely to rain in San Francisco."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I am building a new educational tool that answers questions based on a given context."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: I am a manager in a company and I would like to get a summary of a long report that I received so that I can focus on the main points."}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: I have an English article that needs to be translated to French. Can you help me find a solution?"}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: A Chinese newspaper publisher needs to split the words in their articles to be easily read by non-Chinese speakers."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: Our client is creating a language course for beginners and needs a software capable of converting text to speech in multiple languages, like English, Spanish, French, and Italian."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: Our company is developing security systems and we want to analyze the video footage to recognize any suspicious activities."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: We need to restore an old and damaged photo. The damage includes stains and scratches, so we need to refill the missing areas."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: I have a dataset of people's information (age, workclass, education, race, etc.) and I need to predict if they will have income greater than or less than $50,000 per year."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Propose an introduction for an article discussing the future of electric vehicles in the automotive industry."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: \"Who was the first person to walk on the moon?\""}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: I want to denoise this audio file and improve the intelligibility for listeners."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: A fictional story needs beautiful illustrations. Generate an image depicting \"a brave knight fighting a ferocious dragon in a dark forest\"."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: My company needs an AI system that can classify videos based on a pre-defined set of categories. Can you describe a model that could be used for this purpose?"}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: We have a large number of documents with tables. We need to extract the tables from these documents to get relevant information."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: We want to enhance our video game controls by improving rendering methods to generate highly-detailed scenery using a computer vision model."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: A company asked us to identify the entities from their monthly blog article and labels the person, location and organization."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: We are developing an internationalization platform for smartphone applications. We need to punctuate translation automatically."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: The company I work for wants to reduce its carbon footprint. To do this, they would like to estimate the carbon emissions produced by different processes within the company to identify where changes should be made."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: Develop an AI model to generate an image of an astronaut riding a horse on Mars."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: We are a startup working on building audio communication devices. Our goal is to provide users with high quality, noise-reduced speech audio with enhanced clarity."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: I have a picture of my pet and need a short caption generated to describe it."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: We are building an application that identifies license plates in our parking lot. We need a solution to detect license plates in images."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: We are a factory-focused environmental protection firm evaluating our factory's carbon emissions and seeking ways to minimize them."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: We are building an AI assistant that learns about art. We want to implement a text-to-speech feature. "}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: Help me understand if the provided text is a question or a statement, while processing user messages in a chatbot-like application."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: We need a tool that automatically completes Python code when given a prompt presented in an English sentence."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: I want to develop a program that can identify the entities in a given text string."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: I am writing a Chinese news summarizing application. The application should be able to find the answers to users' questions about the news articles."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: A marketer wants to generate paraphrased versions of a social media post to increase engagement. Find a way to get paraphrased versions of the text."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: Our online course curriculum includes multiple languages. We need to create audible transcripts of the course content for each language."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: The science and biology classes are creating learning materials for a lesson on butterflies. Generate a picture of a butterfly for them."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: Develop a Python script to generate vintage-looking images using a pre-trained model."}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: Build a solution to scan and monitor comments on a website for detecting inappropriate content or toxic behavior."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: In our restaurant, we want to increase customer satisfaction by improving our wine quality. To do that, we need to predict the wine quality based on its features."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: I am interested in investing in renewable energy companies. I have a long financial document to query for the dividends paid by a company named 'RenewX'."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: Our company is working on a project about reducing carbon emissions. We have gathered a dataset and need to choose an appropriate model."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: Suppose a real-estate company would like to better understand the elements in a set of images of rooms in homes. They want something that can segment the images into their individual components."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: A recipe text is provided. We want to create a video tutorial for this recipe."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: We are building an image transformation service that takes a text input and turns it into a stylized image. For example, if the input is \"chef in the kitchen\", it should generate a stylized image of a chef in the kitchen."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: I am traveling to Germany next month. I want to learn some German phrases to help me communicate with the locals."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: A photographer friend of mine has captured a series of images at low resolution. He wants to enhance them and make large prints. What should he do?"}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: Our company is on a mission to build a better AI-powered workplace safety system. We are now using AI technology to track whether employees wear their hard hats properly at the construction site."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: The manager wants the team to collaborate with a multinational company, and we need a tool to translate spoken messages from English to Spanish without using text, only with audio files."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: The marketing department wants to automatically sort promotional videos into categories, like food, technology, and fashion. Help with a solution."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: My team works on audio-related products. I want to convert spoken language into text."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: The manufacturers experienced several defects in printed circuit boards (PCBs). They want to detect and segment these defects automatically."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: Our developer has copy-pasted some code in a string with natural language descriptions. We need to identify and extract the code."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: Our educational software company creates a learning tool for schools and educational purposes. So please provide a solution to answer math questions based on given context."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: Implement a method to compare the similarity between a user's input query and a predefined list of sentences in a knowledge base."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: We are contacted by an animation company to help them generate realistic facial images as reference for their character designs."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: I'm making a virtual assistant for Mandarin-speaking users. It needs to convert text into audio to communicate with them."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: Please develop a program to help travelers remember city capital names. If the traveler asks you for the capital of a specific country, you should give the correct answer."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: Our lifestyle website focuses on Indian users, and we are thinking of implementing an automatic voice activity detection system. Can you provide assistance on this topic?"}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: I am a researcher in biology, looking for a assistant to answer questions related to my articles."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: My company would like to develop a chatbot that could provide information about our products and handle customer inquiries. We need it to be able to process user inputs and give appropriate responses."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: buildings, roads, vegetation, and water."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: A cellphone company wants you to create an automated tool for quickly determining if the movie review text is positive or negative."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: Can you devise a way to use text-generation model to write a continuation of this article? \"Autonomous vehicles have begun to revolutionize the transportation industry, particularly in urban areas where traffic is congested and public transit is often unreliable.\""}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: A restaurant owner wants to develop a wine recommendation system for their customers. They want to use wine quality classification to provide recommendations based on a dataset of wine features."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: We need to classify the category of a news article. Provide a method for classifying the news article."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: Our customer is a restaurant and wants an image of a delicious dish to be displayed in the window."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: We need to predict the annual income of individuals. We have the United States Census Income Dataset with various demographic features."}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: We are developing an office software and need to extract textual documents from a paper source."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Estimate the carbon emissions generated by different home appliances based on their energy usage data."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: I am building a project for an autonomous vehicle. I need a solution to estimate the depth in an image."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: I need to find similar questions from a set of frequently asked questions in my customer support section."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: Help me come up with a brief description of a meeting discussing the financial status of the company."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: Your colleague mentioned that he loves AutoTrain. Identify any entities present in his statement."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: I work for a car manufacturer and I would like to build a questionnaire for the client by using an artificial intelligence that recognizes depth. Design the necessary system."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: As a teacher, I need to generate a short summary from an image to teach my students."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: Create a movie recommendation system that uses multimodal input (text and images) to answer questions about the movies."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Our document management department wants to extract tables from scanned documents automatically. Please provide a solution."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: We have a scientific texts and we need to find the similar content with our article."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We want to analyze an image and produce a list of relevant keywords/tags to describe this image."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: \"The dog is playing fetch\" and \"The canine is retrieving the ball\"."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: We want to exploit depth estimation technique to get the depth information from a 2D image in order to recreate a 3D representation."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: I have a list of candidate summaries for an article, recommend the most accurate and relevant summary placed at the top."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: We are working on a mobile application for people who want to learn Telugu. We need a way to read Telugu text to users so they can hear the pronunciation."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Create a pipeline to process an image and generate a textual description, including extracted information."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: We are looking for an AI chatbot that can help users with their inquiries. It should provide a variety of creative responses."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: Count me a nice story with two lead characters. It should be extremely interesting."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: I want to use a deep reinforcement learning model to make MountainCar reach the top of the hill."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: We are building a game where the character balances a pole on a cart. Can you please assist us in finding a solution?"}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: I would like to learn the history of Google. Generate a question that might be asked by someone learning about Google."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: We want an assistant who can transcribe Marathi speeches and convert them into written formats."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: I'm composing poetry and want to generate sentences similar to the ones I input to get inspirations."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: Find out when a speaker is actively speking during a conversation."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: The company is investing in marketing strategies, and they need to extract information from several documents regarding their competitors. Analyze the documents and answer questions based on the documents."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: We are an insurance company that processes a lot of documents daily. Process the documents to respond to customer queries."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: Design a model that is able to generate meaningful responses in a chat-based environment."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: We need a new anime character sketch for our story. The character should be a warrior girl in the woods."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Organize a game event where the players are detected automatically for the proper operation without manual intervention."}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: Our company is working on a new feature to analyze emotions in text to better understand user comments. We're looking for a tool to classify emotions."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: We've collected a set of electronic devices containing information about their specifications. We want to compare them and find out which device has the highest battery capacity."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: A new teacher is trying to prepare questions for the quiz for middle school students. Paraphrase one of the questions for her to help her students better understand the question."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: I run an e-commerce brand, and sometimes we receive feedback from customers with grammar errors. Can we correct their sentences before responding to them?"}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: I want to build an app that describes images. The description should be a complete sentence in plain English."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: Design an AI assistant for a visually impaired person that recognizes objects and people and answers questions about images."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: We are a city planning company and we need to analyze images of urban areas to identify key elements like roads, buildings, and trees for our development projects."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: We are collaborating with a videogame company to make their videogames smarter using reinforcement learning. We want to make the AI of the game play the game to understand how to beat it."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: We are trying to build a chatbot focused on summarizing long conversations for future references."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: I want to create an automated voice assistant that converts my speech in one accent or voice to another accent or voice."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: Our marketing team has compiled a table of potential customers and their preferences. They require a way to pull out the most relevant records of customers who meet certain criteria."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: We have collected data on household appliances and now want to estimate their carbon emissions levels during usage."}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: We are managing a multi-lingual news website. Help us to generate summaries for the articles."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: As a medical student, I am building a search engine for medi terms that returns the most relevant medi terms. I want to extract embeddings for a given medical term so my search engine can find related terms."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: Create an AI that can analyze an image and provide a classification for the objects in it."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: Write a summary of a news article having some content about recent economy developments."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: I want to develop a language learning app to help users improve their pronunciation. We need to translate users' spoken words in Cantonese to English and then play back the translated text as spoken English."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: I work for a talent agency, and I need a tool that answers queries about the actors' details from a database in natural language format."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: We have a dataset of US housing prices and want to predict future prices based on this dataset."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We have a contract from a client. Our boss requested us to enable a question-based answer extraction."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: I work as a researcher in a multinational company, and I need to translate my English research paper to German."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: There is a new dataset of animals and we would like to categorize them into birds, mammals, reptiles, and fish."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: We are building a drone system to track and monitor the location of planes. Provide an API to detect planes in images taken from a drone."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: Our client is looking to build a conversational bot system. Implement the conversational model in their system."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We got the table of Olympic host cities and years. Help me find out which city hosted the Olympic Games in 2012."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: We are developing a mobile augmented reality app for exploring the city. We need to segment different objects in urban scenes."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: Our social media agency requires a solution to automate the process of classifying images with Chinese text captions."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: Design a system to help transcribe group meetings and differentiate between different speakers."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: A surveillance company needs our help to process and describe images captured by their cameras. Generate a detailed description of each image."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: I have audio recordings of my friends talking in Portuguese, and I need to understand what they're saying."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: Classify an image by detecting if it contains a dog, a cat, or a bicycle."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: We need an AI character that can provide information about climate change to explain the problem to young children."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: I have a website with a lot of textual information, and I need an AI model to answer website visitors' questions successfully."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: Help me generate a vintage-themed portrait using a fine-tuned pre-trained model."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: We are creating an application to automatically identify audio recordings of numbers. We need a solution to classify spoken numbers."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: Help me build a program to extract meaningful insights from the following paragraphs of two research papers to determine their relevance."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: Create an autonomous agent that can play SoccerTwos against other agents. Deploy it to play in a virtual environment."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: My team is creating a robot to balance a pole, similar to the CartPole problem. I would like to reuse an existing model to control the robot."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: A real estate company specializes in marketing church properties and requests for images to be generated to help them with their marketing efforts."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: My co-worker sent me an English text that needs to be translated into German. Please write me a function for translating English text into German using the mentioned model above."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: I am building a chatbot and as a first step it should be able to identify the language of the incoming messages."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: We need to convert a short text about product information into speech, so we can use it in our promotional video."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: I want to create a text-based AI assistant using a pre-trained model for text generation to make conversation natural."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: The company wants to create a simple demo app that reads out the weather forecasts using text-to-speech. Implement this feature.."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: We need to segment a given street image to distinguish pedestrians, vehicles, and other objects."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: We are building an app that needs to classify images. Can you provide a code example using a pre-trained image classification model from Hugging Face?"}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: A new concept phone is being launched, and we need to introduce it to our customers around the world in multiple languages. Translate a product description from English to German, French, and Japanese."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: Build me a custom software to manage an image dataset from satellite, we need to detect changes or anomalies in the images."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: As a researcher, we collect information from different sources in various languages. Translate a Chinese sentence to English."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: Develop a customer support system for our German clients. Translate the English response for our German customers."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: For the new multilingual AI project, we want to complete the given sentence by replacing the masked section."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: As a wildlife enthusiast, I want to identify the species of the animal captured in a picture."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: I have a photo, and I want to create variations of it for my art project."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: We need a solution that will recognize spoken Russian words in audio files. Please provide a pipeline to help us with that."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: Develop a tool that translates 5 languages to one Native Language."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: Can you help our language learning client transcribe Marathi audio files into text?"}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: We need your help to set up an automatic caption generator for our photo management system."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: Could you please suggest different ways of saying that I have lost my phone?"}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: I'm developing a parking system application which needs to automatically detect the license plate numbers of vehicles entering the parking lot. Find a suitable model for this task."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: Our data science team is working on customer tipping data. We need a way to perform regression on the tipping information for further analysis."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: Develop a language application to help users convert English text to German while messaging."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: The researchers need a model capable of categorizing videos. We want to group videos based on their content."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: I am working for a Smart Home Company. We need to classify audio commands from our smart home devices."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: I need a personal assistant to estimate the depth in a single image taken inside a room."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: Design a system that can be used to automatically learn foreign languages and dialects. It should take an input sentence and translate it to target dialect or foreign language."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: A gourmet wants to automatically identify the type of food in a description. Please help him generate an output."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: As a language teacher, I want to translate a sentence from English to German in the LIA project between languages."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: We want to predict CO2 emissions for the next month in our city and make our city more environment-friendly."}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: I am building a Chinese voice assistant that needs to generate synthetic speech based on the given text input. I want to use the kan-bayashi_csmsc_tts_train_tacotron2_raw_phn_pypinyin_g2p_phone_train.loss.best model."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: We need to provide a French NER capability to our language understanding software. We require the function to extract names, organizations, and locations in newspaper articles."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: A startup is developing an app for people with disabilities. The app needs to convert a given text to speech."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: I am designing a program that helps recognize images based on natural language descriptions. The model should be able to tell if the description matches the image."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: I need to extract all personal names, locations, and organization names from given text."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: Create an intelligent assistant to translate my English to French, summarize long texts, answer questions, and analyze the sentiment of texts."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: I need a multilingual personal assistant to find information within a large text."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: I need an unforgettable album cover for my next project inspired by a desert oasis with swaying palm trees and camels walking around."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: We are making a call center to analyze customers' emotions to help provide better services. Implement the emotion recognition model."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: I am an app developer. I need help recognizing the objects in a photo and generating a description for visually impaired users."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: Our client requested us to create a digital painting from a text description of a landscape with a lake and mountains in the background."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: Implement a solution that allows transcribing audio files into text for better accessibility."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: The challenge is to differentiate between the species of birds in the images provided by the participants of a bird-watching event."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: I am creating an art exhibit and would like to generate an original painting inspired by the WikiArt dataset."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: Please help me identify any defects in a printed circuit board (PCB) and the location of the defects based on an image."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: We are working to predict the amount of CO2 emissions from a given dataset and we want to load and use a pre-trained model."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: We are a company developing collision avoidance systems for drones. Implement a depth estimation model to help us predict distances inbetween objects."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: We are developing a surveillance system that identifies activities occurring in public spaces. Detect the activity shown in a video."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: As an online discussion forum, we want to employ machine learning techniques to help us detect whether a post has been generated by an AI or a human."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: I am trying to identify whether an image is of a cat or a dog."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: I'd like to create an image of a toy robot with a friendly appearance based on a rough scribble of the toy design idea. "}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: As a Russian speaker, I want to turn a long article into a brief summary."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: a short story writing helper."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: The local government wants to calculate the CO2 emissions for several different scenarios. Help them get the carbon emissions based on the given input data."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: We are organizing an event, and a marketing company sent us their proposal. Help me classify if it's good or bad."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: Helping a robotics company to navigate autonomously. They would like to estimate the distance to the obstacles in the final image."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: I need my chat assistant to suggest healthy dinner recipes when asked by users."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: I have a text paragraph, and I want to create multiple potential rephrasings to make it more diverse for content creation."}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: We are translating a product description from French to English for our international website."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: I work with designers, I need to turn some instructions into audio for their tools"}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: We need an API to measure the similarity between different customer reviews left on our website."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: I am now working on a multilingual chatbot. It should be able to answer any question, including translation, arithmetic problems and generative storytelling."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: Develop a drone that should identify humans and animals without colliding with any obstacles or harming the environment, and provide safety measures."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: We are a translation and transcription app company in India. We'd like to transcribe Marathi spoken audio into text."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: Create a system that can answer questions based on an image for an app that helps visually impaired users."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: At our economics department, we need to predict CO2 emissions for a given dataset, using XGBoost."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: Design a chatbot to mimic Elon Musk's approach to answering tweets."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: My friend is currently writing a Chinese essay and needs assistance in finding similar sentences in his essay to avoid repetition."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: Our customer wants a project that classifies audio files as speech, music or noise."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: We are going to create an assistant for a news website that can analyze the given texts and highlight all the named entities."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: Create a code snippet to identify the different parts of speech in a given text."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: We need to automatically segment vehicles in images from traffic cameras to analyze traffic patterns."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: I have an English text dataset and I want to assign syntactic roles to each token."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: Analyze the provided table data about monthly sales of different products to answer the question, \"Which product had the highest sales in January?\""}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: Develop a system that can upscale low-resolution images to improve their quality for a photography application."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: We would like to translate the text content in product labels into text format."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: Our company would like to generate high-quality images using artificial intelligence for an advertising campaign. These images should be unrelated to any particular topic."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: Create a voice activity detection model to confirm the presence of human speech in an audio recording from a sitcom."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: We are building a digital assistant that can transcribe spoken language into written content. Help users interact with their smart devices without typing."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: A company's e-commerce accountant needs to retrieve the total amount due from an invoice."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: I'd like to create a speech emotion recognition system that can interpret spoken emotions like 'angry', 'happy', 'sad', etc. from a given audio."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: I am a researcher, I would like to tell if a certain passenger survived the Titanic ship after providing some features like age, gender and passenger class."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: The enterprise has a knowledge base of its products. We need to look for relevant information about laptops."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: A digital artist has approached us to create images for a project by using text descriptions. Make an instruction for the artist."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: I am creating a program that generates random images of butterflies. I need to be able to generate different images each time the program runs."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: We are creating a video game and want to generate the artworks of our characters based on their lineart. Can you help us by providing some code that utilizes an API?"}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: I have a speech recording in Esperanto language. Convert this speech to text."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: We are building a topic detection tool that helps users to know if a given text is positive or negative."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: Create a recommendation system for a video game that matches game preferences with sample game clips and trained AI model."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: Our customer needs a depth estimation model to help them analyze the relative depth information of objects in an input image for their 3D rendering project."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: We need to develop an application that can differentiate between audio containing voice and audio without voice in Indian languages."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: I have an audio file with spoken language in it. Please help me transcribe the audio to text."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: We're developing an educational platform and need to generate some questions for students based on a given text."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: Help me build a question-answer system that can answer questions about a given text."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: We are real estate agents, determine the price of housing properties in California."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: We have a database of our company's employees with their ages, salaries, and roles. Sometimes we need to answer questions from their data."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: In a legal firm, they need assistance in quickly extracting relevant information from legal documents. Implement a question-answering system for getting specific information from legal documentation."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: I want to confirm whether the retrieved passage answers my question about a city's most notable art museum."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: For our investment club, we want to create a tool that analyzes the tone of financial statements from companies we might want to invest in."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: We have a knowledge management software. Our customer service agents need to retrieve relevant knowledge base answers to user questions."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Our team is now holding a photograph competition about Chinese cities. We need a tool to classify the submitted photographs."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: I want to create a short science fiction story. I need an AI to assist me in generating it."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: We run an online course. We have recorded lectures and we want to transcribe them in Russian language."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We are developing a robot navigation system for an elderly care facility. Design the navigation system for the robot using the VC-1 model."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: I have a printed circuit board (PCB) image; I need to identify and segment any defects, such as dry joints, incorrect installations, damages, or short circuits."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: We want to find a film poster that can be used as an inspiration for our upcoming fashion collection which has an 80s theme. Could you please describe the visual details and the emotion this film poster conveys?"}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: I am developing a large-scale question and answer site for developers. I want to extract named entities and code snippets from the corpus in order to build an organized database."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: As an AR developer, I want to develop an AR application using depth estimation. Please recommend a model for this task."}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: My company needs a machine learning model to upscale our clients' images with double resolutions for better quality."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: We are running an event in a stadium, and we need a system to transcribe the announcement in real-time."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: Our company collects customer feedback on its products. The goal is to analyze the customer feedback and understand the sentiment behind them."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: We are a real estate company, and we want to predict the selling price of a house based on its features."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: I want to generate a photo of a yellow cat peacefully sleeping on a park bench."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: Generate 5 different marketing ideas for a new fitness app."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: We are working on a device that requires keyword recognition. Given a spoken word or command, please detect the spoken keyword."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: We have gathered a table with company expense data for 2020. We need to know the expense per department. How can we get insights from this data?"}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: Our company's main product is a customer-facing app that detects objects in photos. Improve the app's capabilities by adding a feature that can segment the objects in the photos."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: I need a solution to transcribe spoken language in audio files (16kHz sampled) into text."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: Determine the predominant theme one can use for journal topics when they move to France."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: Build a solution for our customers who use newsletters. The solution should parse the text of the newsletter and answer any question about its content."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: I want to create a tool that generates answers to user questions about the history of famous people."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: We need to organize customer reviews for our company. We would like to find similar reviews and group them together to make it easier to analyze the data."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: We are building a chatbot for users to generate random cat images. We need to figure out which API to use to generate cat images."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: Help me translate English speech to Hokkien speech for a documentary video on Taiwanese culture."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: Our customer is a marketing agency. They want to generate catchy taglines for their business. We need to filter the taglines generated from the AI model with a high similarity to the existing tagline."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: Our client asked us to implement an automatic speech recognition system that would convert their customers' spoken words into text."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: A group of young developers is developing a soccer game for mobile and wants to create an AI agent to control their in-game soccer team. They need to make use of the available model."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: The company is interested in tracking the sentiment of financial news articles to make informed investment decisions. Discover a model to analyze such texts."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: Find a way to build a model which will help in the classification of carbon emissions."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: You're an AI personal assistant. The user has a long meeting recording and wants to detect voice segments for efficient note taking."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: As a chatbot creator, I need to help users test models in Russian using pre-built models."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: We are a company working on safety applications. We need to identify if the workers are wearing hard hats or not."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: I am building a mobile app for time management. I would like to create a function that, given a task, returns how long in minutes it should take."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: I have a business email that needs to be translated from Hindi to French. My client has a limited understanding of English."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: Our company is working on a new app that predicts the weight of a fish based on its given dimensions. We need help to estimate the weight of the fishes by using a trained regressor model."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: Create an application to alter images of landscapes based on user-guided instructions."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Implement a robotic arm system for grasping and motion optimization in a warehouse setting."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: Our client has a parking lot management system. They need to automatically detect license plates in the images taken by their parking lot cameras."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: Our team needs a dog image generated based on a specific text description."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: \"Albert met Samantha and George at the coffee shop near the museum.\""}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: Our client needs us to analyze his buildings and make sure they are safe. They sent us some images of these buildings."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: Create a smart app that, when the user speaks, identifies their emotional state."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: We are a company that provides visual support for autonomous vehicles. We need a system to identify road signs, pedestrians, and vehicles in images."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We aim to build a research paper recommender system. For this purpose, we want to generate an embedding for each research paper based on the title and abstract."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: We want to extract text from an image containing handwritten text."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: "}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: I receive many telephone calls in my office. Create a solution to detect when there are multiple people speaking at the same time in the conversation."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: I need to extract tables from invoices of different formats."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: A consultancy company wants to use machine learning algorithms to help understand different sources of energy and their effect on the environment. They asked if we could predict carbon emissions based on some given features contained in a CSV file."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: I am visiting Spain next week and I need to send a message in Spanish to my AirBnB host informing them about my arrival time. The message should be translated from French."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: Can you summarize what I'd need to do to use an AI model to chat with people in a text-based environment using this API?"}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: Your company wants to create an automated support system for their customers. They want the system to be able to answer questions based on information found within manuals and guidelines."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: Identify the language spoken in an audio file provided and give the result back to me."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: Design a calculator for carbon emissions based on tabular data."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: In the software troubleshooting process, we have to extract code snippets and named entities from StackOverflow posts. Please accomplish this."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: Our marketing team is working with a French campaign, and we need a solution that can help classify a given text into different categories like sports, politics, and science."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: I am running a restaurant management system, and I need a machine learning model to predict how much tip will be given by customers based on their bill and demographic characteristics."}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: We are building a software solution where people can enter an algorithm and get Python code. We are looking for a natural language processing service to generate the Python code for the user."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: We want to enhance our company's customer support service. Can you help build a conversational AI model?"}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: We are setting up a blog for our travel and art company. We need to generate an artistic image based on the text description provided."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: I manage a bank, and I need a model to predict whether a person will default on a loan application using their income history and other data."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: We are building an interactive game with an intelligent character. The character needs to respond to user inputs based on a game script dataset."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: I want to make an app that transcribes voice notes to text using Automatic Speech Recognition. Can you help me?"}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: In a multilingual conference, a speaker is presenting in Hokkien, and we need to translate the speech into English."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: We are building a prototype application for restaurants. Suggest a model to predict tip amounts for different customers."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: I would like to generate an image of a cat playing with a ball from a reference line art image using ControlNet."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: I am creating an AI-based tutoring app for kids, and I want to know if the kids are happy or sad during their tutoring sessions."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: We are working on a language training app. We want to generate more alternative sentences for a single input to expand our text corpus by generating paraphrases."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: We want a text-generation tool for auto-completion of our blog post's first few sentences."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: The urban planning department needs to gather depth data from aerial images. They have high-resolution imagery, and need to process it to obtain depth information for every pixel."}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: Write a code snippet to translate English speech into Hokkien speech without any text-based intermediaries."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: We are the car registration department. We need to detect license plates from images and identify them."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: Our job is to write blog content about Korean food. Generate a paragraph describing different types of Korean dishes."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: Our company needs a translation service for its employees working with French-speaking clients. They need to understand French speech in real-time."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: Our company wants you to develop an app that identifies people's age by analyzing their photos."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: Create a text generator to prompt the model to generate ideas for my next movie script about artificial intelligence controlling a city."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: We want to summarize a book that contains more than 300 pages."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: I want to analyze an image in our production line and automatically detect and classify objects."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: Let's say our company's audio recognition department needs software that will analyze audio recordings and detect distinct samples of human voice so they can build an intelligent voice assistant."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: We are designing an AI for a museum to answer questions from visually impaired visitors by identifying the objects in the exhibitions."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: Our company needs to extract tables from a large volume of documents. We would like to have an AI tool to detect tables within these documents."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: Can you help me leverage the capability of this legal text processing model to identify possible laws being referenced in a given piece of text?"}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: As a virtual assistant company, we are asked to produce a German audio file for some text to be featured in a multimedia presentation about the history of the German language."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Our customer is a data extraction company. We need to help them detect tables in documents and extract the data."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: A museum owner hired us to predict the theme and style of paintings without human knowledge."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: We are a telecommunication company dealing with call center customers. We want to identify the emotions of users from their audio."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: We want to transcribe spoken-word content from videos and add appropriate punctuation to the transcriptions."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: I want to build an analysis system to detect the color and shape of objects in a captured image when it is asked a question. The system will give text-based answers."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: In our newly launched electronic online store, our customers are inquiring about the features of a product in the form of questions."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: My boss wrote two customer reviews with a different tone. I would like to find the difference of sentiment expressed in two reviews that people written. How will I quantify that?"}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: We are an educational technology company creating a reinforcement learning agent for an educational game. Show us the steps to load a pre-trained agent for CartPole."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: Help me find out why the iPhone gets heated so often. Search for some information on the internet."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: Develop a language translation solution for a tourist application that needs to translate an English sentence to Czech."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: We are implementing a virtual assistant to provide recommendations for nightlife events in San Francisco. Generate a short paragraph describing a fun event that suits the context."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Help me develop a Portuguese audio transcription service."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: We are a team of music producers, and we want to separate vocals from the instruments in a recorded music track."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: We are designing a system which can answer the question from the given context. The model will use an efficient architecture called DistilBERT."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: Create a system that can extract important information from text like names, addresses, phone numbers, and dates."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: I run a coffee shop, and a new customer has just emailed me a table showing the many different coffee beans they import. They would like to know which coffee beans are from Guatemala. Please find this information for me."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: Create an AI chatbot using the neuralmind/bert-base-portuguese-cased model that can fill in the blanks for incomplete Portuguese sentences."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: We are developing an educational app, and need a model that can answer various questions from our users related to different topics."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: We are a quality control department in an electronics manufacturing company. We want to verify the possible defects in PCB boards."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: We are building an audio-guide app for Japanese tourists. We need a text-to-speech function for reading Japanese text in the app."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: A research team is working on a project to cluster research papers based on their abstracts. They need to identify similar abstracts and group them together."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: As a software engineer at an AI-powered photo sharing app, we need to classify user uploaded images into various categories."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: \"Visit Venice, a city built on 118 islands connected by 400 bridges. Explore its romantic canals, beautiful architecture, and exquisite Italian cuisine.\""}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: We require a tool to convert Korean sentences into English sentences for quick language translation."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: I work for a humanitarian organization, and we have been receiving a lot of emails from concerned citizens in Indonesia. Can you help me analyze the text and provide the overall sentiment?"}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: Our company deals with handwritten documents. Isolate the text from a handwritten document of our user and store it for future processing."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: Suppose we want to analyze social media reviews of our product, so we want to extract entities such as people, organizations, and locations from them."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: marketing, design, or engineering."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We need to improve the advertising of our new sports equipment. To do so, we would like to classify sports activities in short video clips."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: A nature protection organization's main focus is to identify endangered species for preservation campaigns. They need to know which species are endangered among the images submitted."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: We are assisting a movie studio that wants to create a photo-realistic poster for their upcoming film. "}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: There will be a meeting with our overseas partners, and our team members have different dietary preferences. I want to create a suggestion for food options from each country with our dietary preferences."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: I need help in making investment decisions based on the sentiment of financial news articles. Analyze the sentiment of the given text."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: Our company has collected information about its employees in tabular format. We want to easily answer questions about our employees' information, such as total count, average age, etc., based on the given tables."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: A retail store wants to apply computer vision in their system that can process images of their products to distinguish between different product categories."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: Create a task-oriented AI agent for users to translate \"Hello, how are you?\" from English to French."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: Can you classify a given image for me using the zero shot image classifier we just found and give me the probabilities for each image class?"}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: Create an application that helps people describe images pertaining to their favorite sports team."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: We are building a digital assistant and want to be able to distinguish between questions and statements made by users."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: Our design team needs to find inspiration for creating impressive illustrations of galaxies."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: A major customer is developing a voice-activated device for their elderly customers, and we need to recognize the spoken commands."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: A sign translation app needs to be built and we want to extract text strings from images of signboards."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: I am writing a report on long articles, and I need a summary to quickly understand the main points of an article."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: We hold a conference to create a strong political atmosphere. Can we analyze this video to determine if it has any political content?"}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: Create a summary of the following financial report containing 84 words or less."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Our team is dedicated to proposing solutions that reduce CO2 emissions. We need to predict carbon emissions from a given dataset."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: I need a description of a video for an English teaching video with the theme of \u201cgreetings and introductions\u201d for beginners."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: A German user needs a summary of a long article they just read."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: As a teacher, I want to use a visualization of a frog swimming in water in one of my lessons. I have a sentence to describe this scene, and I want a video based on my description."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: We are a company working on security cameras. It is important for us to detect violence and suspicious events in the videos."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: Detect if two text fragments are similar or not."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: Setup a conversational context to discuss a specific topic with a Russian chatbot."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: I am an AI Startup and working on a project which involves processing legal documents. I want to use an AI model for this purpose."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: Develop an algorithm to generate artistic images based on a text prompt alongside a line-art image."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: I want to create an app that estimates the depth of a scene from a single input image."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: Write a code to get a summary of IMDb movie plot that should not exceed 100 words."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: Recently, our company started working in the international market, and we now receive emails in different languages. We need a language model that can understand and complete sentences in multiple languages."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: I need a copywriting tool for my social media content. Provide me a way to rephrase my sentences so that the meaning stays the same but the wording is different."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We would like to sort the documents by similarity in Python to classify the research papers using document-level embeddings."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: I have a list of questions and answers that I would like to find the answers to quickly. Pick the model most suited for the task and how can I execute it?"}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: A scientist wants to know if the newly discovered animal is a species of dog or cat in a picture."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive (CS:GO) players in a given image."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: Our company records customer service calls in Chinese. We need to transcribe the calls to text to perform an analysis."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: I'm developing a smartwatch application that can determine the spoken numbers from the user's voice input."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: Our real estate company is now creating applications to embed this model to predict housing prices in the US."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: I am building a product to analyze the emotions of the users. Can you help me detect the emotion of a given text?"}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: We have just acquired a company in the energy sector. The new team believes there are anomalies in the energy consumption data. We need to detect those anomalies."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: Our team will record conversations with clients, and we need to identify the parts of speech of the spoken sentences."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: I am writting a story in english language. Wanted to make sure sentences don't have grammar mistakes in order to make the story more authentic. "}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: Create a system that enables users to find similar content by analyzing the textual content of the documents and organizing them into clusters based on similarity."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: A media house is looking to automate generating summaries for their news articles. Implement the text summarization feature."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: Our company wants to assess the damage to the streets in town. We need to identify potholes in road images."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: Our company wants to improve safety measures in the workplace by providing access to classified videos showcasing proper safety procedures. Implement a video classification model to meet this requirement."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: We need to generate various Minecraft skin designs for our upcoming video game. Let's use AI to generate some random designs."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: Our client wants to recreate their company\u2019s banner logo with the text \"Eco-Friendly Green Initiative\" prominently featured."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: I am a doctor focusing on rare diseases. I need help with answering questions about rare diseases."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: I am a student and need to rephrase my essay content to avoid plagiarism."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: I need to automatically find specific information from scanned receipts, such as the total amount due."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: My e-commerce company sells clothes, and I need help classifying a new dress image into a category."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: We want to build an application that reads news articles to users in Russian. How do we achieve this?"}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We want to classify the activities in a given video, and understand the genre of video content."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: \"In the enchanted forest, a magical unicorn grazes near a crystal-clear pond.\""}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: A film studio wants to create a trailer for their upcoming animated film \"The Enchanted Forest\". They need a scene where the main character, a brave squirrel, is running away from a fearsome dragon."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Can you give me a tool that could take the description of a scene and generate an image for me?"}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: I am a writer and I am currently suffering from writer's block. I need inspiration from a large pre-trained model to generate a paragraph about the future of automation."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: Could you translate an English text into French using optimum/t5-small pre-trained model?"}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: In a software documentation, I wish to automatically complete sentences to make them more fluent."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: We are working on a project to predict a vehicle's carbon emissions. We have a dataset in a CSV file and want to use an API to classify the samples as high or low emissions."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: Help me build an AI assistant for an online customer support system."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: I need to create a system to identify violent behavior in a school surveillance video."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: Translate a Chinese document to English."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: A company wants to predict and monitor carbon emissions based on their telemetry data. Help them setting up a model for that."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: The Human Resources department wants to extract the relevant information like name, email, and job title from a r\u00e9sum\u00e9 to improve the hiring process."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: Our team needs to create an automated assistant that can handle general inquiries from clients."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: Help us with a system that understands and processes human language to ease communication between humans and machines. We don't need a full virtual assistant but just something that can tokenize and classify parts of speech in English."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: Create a controller for an industrial robot arm using a reinforcement learning model that can play the Pendulum-v1 environment."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: We want to develop a tool to help people find answers from sales data in tables, like job titles, products and prices. Please use a suitable model to achieve this."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: We are working on a quiz game. Can you provide us the answer to this question?"}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: Our marketing team is working on a commercial project. We need to classify video clips for action categories to create a sports promo video."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: I want a personal finance management tool that can predict the annual income of the users based on their input information."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: We are developing a new game and we need to design a character based on a description from the game's writer."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: I need a system to analyze videos and classify them into general categories like sports, news, or entertainment."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: \"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", or \"go\"."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: I am writing an English article in my blog and I need to post the summary of it. Can you recommend a model that can be used to automatically summarize my article?"}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: An international business company wants to translate their French emails to English."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: Assess the elevation profile of the captured image using a depth estimation model."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: I have a collection of physical activities videos, and I need to identify the activity from each video."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: I am building an app for wine recommendations. I am interested to classify wine quality based on its features."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: Our company is working on a project involving the translation of a website from English to German. Please help us get a translated version of a given English text."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: How can I help my elderly mother read japanese books like manga on a Kindle without having to buy the electronic version?"}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: Our company has recently entered the global market, and it is essential to identify the languages spoken by the customers in the voice recordings for better customer service."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: We want to predict the housing prices of a neighborhood based on the input data of the houses."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: Implement object detection in a parking lot to count the number of parked cars."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: A restaurant owner provided us a list of receipts. How could we find out the total amount of sales in a day? "}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: We need to analyze a recording from a recent conference call with our Indian partners, could you extract the speech segments?"}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Create a web app that can detect diabetic retinopathy using images of the patient's eye."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We compete in the medical diagnosis domain, and we are building a knowledgebase of related research papers. Embed the content of a collection of medical research papers as document-level embeddings."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: \"Angela Merkel ist eine Politikerin in Deutschland und Vorsitzende der CDU\"."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: Our project's goal is to develop a system that can analyze a satellite image, identify different land cover types and classify them accordingly."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: I want to implement a future classroom system where I can input a sentence, and a short video is generated relevant to that sentence, like a visual aid for my students."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: Create a model to generate captions for social media posts based on the post's textual content and hashtag."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: Our clients are podcast hosts who want to separate out their voices from background noise in order to make their podcasts sound cleaner."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: We are a company that produces cars. Make a classification model that can predict whether our car will have a high or low carbon emission based on its characteristics."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: After signing a contract with Mrs. Xu, we need to answer some questions about the contract in Chinese. Get a question answering tool to provide this ability in Chinese."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: Our company is a tecnhical support laboratory. We need to detect and classify defects on electronic printed circuit boards (PCBs)."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: I am a Brazilian student wanting to fill gaps in my Portuguese text and find the correct missing word in each sentence."}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: Our teammate needs help understanding the relationship between the revenue and expenses of our company. Assist them by answering questions related to the financial table."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: We are an aviation monitoring organization. We need to detect airplanes in the sky in real-time."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: Our goal is to predict carbon emissions of various companies based on their data."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: Make use of a deep-learning algorithm to predict the depth estimation of an object in a given image."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: I want a model for a Q&A chatbot, capable of providing relevant answers based on context."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: The library is setting up a portal where readers can ask questions and get appropriate answers. We need a system to find relevant information from given text."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: Provide solutions to identify sound ranging from 0-9 from a set of collected sound recordings for a customer."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: Design a poster of a dolphin swimming in the ocean with a beautiful sunset in the background."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: what is the boy doing?"}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: A visually impaired user needs to know what an image represents. Our service will provide an answer based on the user's question about the image."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: The company develops an IDE. We need to analyze the source code written by developers and extract features for better code recommendations."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: I'm looking for a way to label different parts of images to improve my company's real estate marketing platform."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: Can you demonstrate how to embed an image for robotics using a pretrained model and then use it for object manipulation in a factory?"}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: I own a streaming platform, and I need a model that can classify a given movie dialogue line into one of your available classes (anger, disgust, fear, joy, neutrality, sadness, and surprise)."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: We are working on a project to enhance the architecture of a building. We need to process images of the building and identify straight lines."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: We are asked by a movie streaming company to analyse sentiments of viewers and categorize them as positive or negative for the latest blockbuster movie."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: I want to create an application where a user can type text and get an audio output of that text."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: Develop a tool that would transcribe speech to text, then returns it to the user."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: A toy manufacturing company is interested in implementing an image classification system that can also answer questions related to the toys. Our goal is to help them identify each toy and provide answers to specific questions regarding toys."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: Our client is a journalist and wants an assistant to identify named entities in a given article text."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: An online store wants to categorize images of products uploaded by users. Develop a system for image classification."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: We are building a talking parrot for kids to learn from real life videos. Therefore, we wish to develop a system which can answer simple questions such as \"Who is playing basketball?\" or \"What color is the cat?\" using information present in visual content. "}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: We are building a dashboard for an environmental organization to track greenhouse gas emissions, and predict future emissions based on their input data."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: We are building an online tutoring platform where students can answer quesitons based on data given in a table. Design a model that answers questions based on tables."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: I need a tool that can provide answers to questions based on a given context."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Our company is building an autonomous vehicle system. We want to understand an image's depth information with a neural network."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: As an environmental consulting firm, we're helping clients cut down on their carbon emissions. Analyze their emissions data in order to provide suggestions for improvement."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: Our company focuses on molecule modeling, and we want to use a pre-trained model to identify key features in our molecular data."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: We are a non-profit publishing news daily. We are looking for a shorter abstract in a blog on a technology topic, approximately 100 words long."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: I want to create a tool that automatically translates English sentences into French sentences for my language learning app."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: Your friend only speaks Italian but your app has content only in English. Convert the content from Italian to English for your friend."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: We are having a conversation with a person. She talked for a while. We need an abstract of her main points now."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: A chat support system wants to use AI to summarize the conversation between the support agent and the user."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: Our customer is a newspaper press, the translation department needs to translate English articles into French fastly and accurately."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Extract the main points from a conversation between two colleagues about a project they are working on together."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: We are trying to create a recommendation system for products based on customer reviews. Compare the similarity between different text inputs."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: Build a sentiment analysis model to add a rating system for the movies on the website. Positive and negative scores should be assigned based on the reviews."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: I would like to understand the difference in sentiment among my customers regarding my products. Analyze their comments and classify them as positive, negative, or neutral."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: Create an illustration for our web article, \"How the use of technology in agriculture can safeguard our tomorrow\"."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: I'm looking for a model that can extract the features of images in order to classify them into their categories."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: A geography teacher would like to find the correct answer to certain student's questions, using a system that can find the answers online."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: The customer needs help for a multilingual chat app to punctuate the content for better understanding."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: We are developing an AI bot that uses automated suggestions to complete sentences for users. We need a way to fill in the blanks."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: My friend sent me a Romanian speech recording, and I want to convert the speech into English so that I can understand it."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: I am building a soccer game, and I need an agent that can play well in SoccerTwos."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: We have just bought a car and we are trying to predict the CO2 emissions of it based on the car specification. "}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: Design a board game and create a simple guideline for the players."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: Our software needs to analyze videos of sport activities to detect and classify joggers, swimmers, and cyclists."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: We are looking to generate unique JPEG images of environments described in text for a futuristic film."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: Our company is building a team of autonomous robots to play SoccerTwos. We need a model to control their behaviour."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: In a smart home, we want to recognize the commands given by voices. Set up the code to identify the voice command. "}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: Imagine we want to make a system for document data extraction to retrieve specific information like company name or the invoice date. Construct this process."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: We are working on a news app. Automatically detect and label the language of different news clippings based on the spoken audio."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: We want to answer a question about a complex document containing rich information in the form of tables, figures and text."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: Generate depth estimates from an input image to visualize the 3D spaces in architecture."}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: The surveillance team is eager to monitor any suspicious activity in public places, detect objects in the surveillance feed and notify the team."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: I want to develop a system to synthesize speech from text using a female voice from the provided model."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: I'm learning the Dutch language and need help filling in the blanks in a sentence with the most suitable word."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: We want to create an application that can answer visual questions related to images. Design an API call for this application."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: We are currently working on a project in which our robots need to estimate the depth of objects for navigation. Can you help us with setting that up?"}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: Our goal is to create a tool to automate certain tasks in a warehouse. The tool should be able to perform actions like picking up an object, stacking, and sorting items."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: I was reading a long news article, and I want to get a brief summary of its key points."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: My application compares users' sentences and checks if they have similar meaning so that I can easily group them together."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: We need to analyse the emotions in the voice of a customer service representative speaking to one of our clients."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: We are building a drone that needs a solution to estimate the depth of surroundings for safety purposes. Find a way to estimate depth using a pretrained model."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: Our agriculture company needs an AI model to recognize plant species by analyzing images. We are not limited to specific species and need to address unknown species."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: I'm trying to find out how to say \"I love spending time with you\" in French."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: I need to know the answer to a question I have in connection witha paragraph."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: Create a platform to analyze Twitter content and determine the sentiment as positive, negative, or neutral for various topics."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: Create a media player application that can recognize the actions performed by people in the video, tag them, and display the results to the user."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: We want to help people in listening comprehension by transcribing the audio into text."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: We want to make easily filtered customer reviews from a French online store based on the categories of delivery, product durability, refund policy, and ease of use, using multilingual zero-shot classification."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: Our team wants to find out whether two sentences are similar or not in order to identify potential duplicate questions within our website."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: We are a startup and want to analyze a CSV file of products to identify which product has the highest price."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: One of our teammates is coming from a Python background and working on PHP code for our project. However, they forget to complete some PHP statements. Can we complete them by using language model?"}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: Create an AI chatbot that will reply to an input message."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Show me how cars, roads and buildings can be segmented in an urban environment."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: I found an old handwritten recipe, but I can't read it very well. I want to convert the recipe text into digital text."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: An advertising agency requested an AI solution to answer questions about the content of an image."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: I need to create an image by changing the appearance of an existing image to look like an oil painting."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: Our colleague sent an email asking us about some issues with his code, unfortunately, his grammar and spelling are terrible. Can you please paraphrase the content in a more professional language?"}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Summarize a conversation between Jeff and Philipp about training a Hugging Face Transformers model on Amazon SageMaker."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: We need a fine-tuned model for depth estimation in our self-driving car project."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: Please give me a solution that allows me to create a dialogue system for my web app. One that can involve a character persona."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We have some data from a manufacturing plant, and we want to predict the carbon emissions based on input features."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: Create a program that will give a summary of a given text in English."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: \"The hotel provides low-priced accommodations and an ordinary breakfast for guests.\""}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: I manage an online community discussion platform. I want an AI-based assistant that can provide supporting information for the ongoing discussions."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: The company wants to answer questions about revenue and expenditure from our financial data tables."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: My son wants to make a new Minecraft skin. Can you generate Minecraft skin images for my son?"}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: In order to evaluate whether it's safe to land a drone at a particular spot, we need to estimate the depth of the landing site."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: Help me to detect different types of blood cells like Platelets, RBC, and WBC from an image."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: Create a code to answer questions about a table, where the table contains information about employees, their roles, and their salaries."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We have an image with multiple paragraphs, and we want to answer questions based on the data in the image."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: I am from a company called Jooble. We have a job portal consisting of billions of opportunities. We need a system to filter out unsuitable items."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: I am working on a software product for language learning. Can you translate the following sentence to French? \"I love learning languages.\""}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: Our client is a Russian professional publisher and they want to analyze sentences for similarity with the articles they publish."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Create a method to generate a summary of a given Russian text with a adjusted compression ratio."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: We are creating a booklet about space exploration and one of the pages will have an illustration of an astronaut riding a horse on Mars. Please help us with that."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: The team wants to generate images of bedrooms to include in a housing advertisement. Help them by auto-generating high-quality, realistic images of bedrooms."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: A developer working on a computer vision project requires a depth estimation model for their prototype. Suggest a suitable pre-trained model for their use."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: I am building a website for butterfly enthusiasts, and I need to create realistic images of butterflies for my website. Can you generate such images for me?"}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: At our software development company, we need to translate a snippet of Python code into a human-readable description."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: Recently our company set up a project to provide accurate information concerning various tables. The system should handle a list of queries at once."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: The company is working on creating an application that translates spoken language in real-time. The app should support Spanish, English, French, and Italian. "}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: Our client wants a program to answer simple questions about a list of Olympic Games host cities and years. He would like to ask something like, \"In which year did Beijing host the Olympic Games?\""}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: Create an application which can extract information from a document such as a scanned invoice and answer basic questions like \"What is the total amount due?\"."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: Our client wants us to generate a custom realistic image of a human face for their upcoming marketing campaign. The image doesn't need to match any specific person or set of features."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: We want to estimate the carbon emissions of different manufacturing processes. Predict the carbon emissions for a given dataset."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: We are building a painting app and want to classify what our users are most likely to draw."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: We are a car photoshoot company, and sometimes we need to answer our customer\u2019s question about the car picture. So, we need an AI module to help answer the questions about an image."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: A company wants to predict the carbon emissions of their operations based on historical data and optimize their carbon footprint."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: For our customer service department, we need a tool that can automatically determine if a given customer question is related to shipping or technical issues."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: The task is to analyze source codes and identify patterns based on their code comments and Abstract Syntax Trees (AST) for our security systems."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: We have a scanned image of a document and need to extract particular information from it."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: I need a solution to help me answer questions about the population and the GDP of different countries from a table."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: I am developing a smart home system and want the system to help answer questions about the things in a room based on a picture."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: Design a bot that takes a noisy audio file as input and output the enhanced version of the same audio file after denoising and dereverberation."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: The game developer team wants to develop a soccer game with AI-controlled players. They need a model to be able to control their individual players."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: Unconditional photo-realistic image generation is the target for a new content delivery platform."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: I am the captain of Titanic. I have a list of all passengers. I need to predict if a passenger survived based on his details."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: The team wants to extract information from a scanned document, specifically answering some questions based on the document."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: Our Yoga class just expanded to a Russian speaking community, and we are translating our instructions to reach this new audience. Let's translate the instructions from Russian to English."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: A client is developing a virtual assistant with user identification feature based on voice input. We need to verify the user's voice."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: \"Who scored the most goals in the season?\""}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: Create a sports highlights analyzer to detect key moments or events from a match video."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: Our company is designing an audio guide system for smartphones. We need a way to recognize speakers' identities."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: Our client has an audio file of a panel discussion. We need to identify the speaker changes in this audio."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: For our educational platform, we want to generate questions based on given answers and text from a lesson."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: For an ongoing healthcare project, we need to get useful features from a given biomedical text data."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: We want a program that can analyze a picture of text and give us the written version of the text."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: Develop a solution to convert Japanese text into speech so that visually impaired people can get the information."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: We need a natural language processing model to have a multi-turn conversation with a user to help them solve their problems."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: Our company needs a system for analyzing financial news articles to assess the positive or negative market sentiment."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: Implement a solution that will generate a depth map for a given image."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: We are building a product to process historical recordings with background noise. We need to separate the speakers and reduce noise from these recordings."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: We will provide images related to one text so we need to create an image related to the text to offer in related images to users."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: I want to extract information from a database of movie rentals. Find out which actor has the most rentals in a specific month."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: We are building an app that suggests possible captions for photos uploaded by users."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: Our gaming company decided to introduce butterfly characters in the game. Create a butterfly image as a starting point to create a new character."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: We are running an online language learning platform. We would like to transcribe the spoken words of our students' recordings for the teachers to review."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: As a French teacher, I would like a tool to help me complete sentences in French by filling in the blanks with an appropriate word."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: Our company requires a Mandarin speaker for our new product video. Create speech for \"\u6b22\u8fce\u6765\u5230\u6211\u4eec\u7684\u4ea7\u54c1\u89c6\u9891.\"."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: We are creating a promotional video for a new app and require the generated video to be based on the provided text description."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: The restaurant needs an AI model to be able to identify the ingredients mentioned by their customers in the social media reviews they write."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: We are building an autonomous robotic vehicle for indoors. We need to estimate the depth of objects for navigation and collision avoidance."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: The company needs to create an audio sample of a text for advertisement purposes. Please provide instructions on how to synthesize speech from a given text."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: I have a database with both English and Chinese language content. My users want to compare the similarity between sentences in the database."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: Develop a learning-based agent to play the Acrobot game."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: I am building a virtual assistant for my website. I need a chatbot that can generate winning responses to make the site more interactive and interesting."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: I am creating a visual platform to showcase different cuisine styles involved in various regions. We need a text description of the cuisine styles from images."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: I am an artist who wants to generate images based on text descriptions. Help me create surreal paintings by using artificial intelligence."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: We are a transportation company, we want to identify the potholes in images and classify sections of the road."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: I want to classify the named entities in an article about politics."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: I have a quality control team that needs an efficient algorithm that can detect and segment defects in PCB images. What should I do?"}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: I am producing a movie, and I need to design an animation video of chefs in kitchen based on a simple image I took from the casting."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: I am building a social media platform to engage with users. I need to write contents using language models to attract the audience."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: We want to participate in a global event where we need to translate our brochure to various languages. We need your help to translate a paragraph from English to German."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: We want to create an audiobook app that will generate audiobooks automatically from any text. How can we generate spoken text from written text? "}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: We need to provide automated customer support for Korean users. They often ask questions about product usage or troubleshooting. Help us find their answers."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: A fitness coach wants to find the type of exercise from different tutorial videos."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: We are working on a project about the decision making of robots using reinforcement learning. We want to see the decision-making process of a robot in a Gym Walker2d environment."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: Develop a tool that classifies spoken commands within our new voice-controlled home automation system. It should primarily recognize numbers from 0 to 9 and control commands."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: We are building a translation application that will be able to translate text from English to German. What transformers model should we be using?"}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: We are hosting a news portal and want to categorize news articles automatically. The categories include politics, economy, entertainment, and environment. Provide a solution for this task."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We are a document management company, and we want to answer the client's question using the LayoutLM model."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: "}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: I heard someone talking about a popular new movie, but I couldn't catch the genre. I need an AI that can guess the movie genre from conversations about the movie."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: I'm a writer, I want to use my assistant to complete my partial sentences for me."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: Develop an AI bot for Acrobot game. Load the pre-trained model for Acrobot game and let the AI play it."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: We are trying to train a chatbot. It will understand human voices and give responses. Explain the procedure of transcribing speech to text in English."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: \"Yesterday, I went to the Google headquarters in Mountain View, California, and met their CEO, Sundar Pichai.\""}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: A website is focusing on categorizing photographs of animals from around the world. They need a model to help them predict the category of new images they receive."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: We are building a medical FAQ bot that can answer users' questions based on the provided information."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: We need to create an illustration for a children's book. The scene must depict a small boat sailing on a calm sea with a friendly whale swimming alongside it."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: I want to transcribe a Vietnamese audio file using a speech recognition model."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: As a language education company, we need to analyze sentences and identify the parts of speech in the text."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: We want to create an autonomous enjoyment tool for visitors to our website. Please develop a code that will allow our customers to play BreakoutNoFrameskip-v4 with a PPO agent."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: Our company is a smart speaker manufacturer. We want to translate an English text into a female Chinese voice."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: Our client often works with Spanish news articles. We need a tool that can summarize these articles for them."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: I would like to obtain depth estimation for given pictures to use in an augmented reality game."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: I want to create an image classifier for my personal collection of photographs of animals, such as cats, dogs, and fish."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: I am creating a mobile app to help visually impaired users. Can you help me describe the contents of an image with clear and concise captions?"}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: I am building a directory of questions people have asked about electric cars. Help me find answers to those questions from an dataset of articles about them."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: A legal firm is working on a contract and needs help to extract information from the documents. We need to create a model that processes the document and answers questions."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: We're developing a tool that needs to translate Spanish spoken language into English spoken language without processing the written text. Implement a solution to do so."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: I'm creating an audio book app that needs to convert text to audio. I need to convert a chapter of text to audio."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: Develop a recommendation engine for a news article platform that looks for similar articles based on article content."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: Build a question and answer bot that helps answer questions about subjects like history, science, and technology."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Our company is developing an AI tool for doctors to identify diabetic retinopathy from fundus images automatically. Provide a suggested implementation."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: Our client wants a creative visualization of the phrase \"A head full of roses\" for an upcoming campaign. Prepare a script to generate an image of this phrase using AI."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: Our company needs a mural for the office, based on the concept \"sunset at the beach with palm trees and a calming atmosphere.\" We require an image generated from this idea."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: As a research conductor, you need to extract specific answers for a set of given questions from a document."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: To improve our customer support, we want to analyze the language of incoming calls automatically. The model should distinguish between 107 different languages."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: http://images.cocodataset.org/val2017/000000039769.jpg"}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Develop a system that helps visually impaired people to describe and understand daily life objects surrounding them by asking questions about the entities discovered in the image."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: We have a series of audio recordings, but there is significant background noise which affects the audio quality. Please suggest how to enhance the audio files."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: A visually impaired user has asked for assistance in understanding an image and answering a question about it."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: I will need to analyze customer reviews to determine how they feel about our company's services or products."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: We are creating a Customer Service chatbot that needs to understand if a customer's message is a question or a statement. How can we utilize models for this purpose?"}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: Design an algorithm to analyze the actions performed by athletes in a football match for enhancing coaching strategies."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: A client is launching a massive advertising campaign for their new surfboard. They need an animated video of Spiderman surfing to attract attention."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: Write a creative short story about a brave astronaut exploring a new planet."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: We have been asked to create an anime image based on the description we are working with."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: As a person studying Chinese, I want to analyze a sentence to understand the part-of-speech for each word."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: I am working in a pharmacology project and I am writing a text. My coauthor mentioned something about the function of the enzyme, but I do not remember exactly the function of it. The enzyme is called ACE-2 (angiotensin-converting enzyme 2)."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: There is a Korean piece of text that needs to be transformed into audio for an online advertisement."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: I'm developing an app that can identify languages in real-time. The app should be able to process audio files and recognize the spoken language."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: I need a depth estimation of the picture of my room, so that I can create a 3D rendering of it."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: Imagine you are developing a mobile app for tourists to estimate the depth of objects with the main focus on landscapes. Explain how to use this model and give relevant examples."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: The company wants to use a model for classifying exercise types in a workout video. Analyze this video and determine the exercise categories."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: I want to create a gallery with photos that have descriptive captions. How can I use the provided model to generate the captions for my images?"}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: Analyze a given tweet to know if it expresses a positive or negative sentiment."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: I have a set of images of cameras and phones, and I want to automatically tell which category an image belongs to."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: As a language school, we have created some audio recordings of conversations between our students, and we would like to have the text transcriptions of those conversations in Marathi language."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: It's  the middle of the night and I have insomnia. I need my text translated from English to Russian to send some information to my collagues in Russia."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: I have a problem with my iPhone that needs to be resolved as soon as possible. What category does it belong to among Computer, Phone, Tablet, urgent, non-urgent?"}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: The company is looking to develop an AI system to analyze satellite imagery effectively. To perform this task, we need to use the Segformer model to segment the images."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: Can you predict carbon emissions for the input dataset?"}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: I am a human resources manager in a multinational company, and I need to extract personal names from a given text."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: We are developing a voice assistant and need to improve its speech recognition capabilities by transcribing spoken language into text, specifically in English language."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: \"Angela Merkel is a politician in Germany and leader of the CDU.\""}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: Create a summary of the news article about a cricket match between India and England."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: I am working on an astronomy project and want to generate a realistic image of the universe to use as a background for my presentation."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: A German company wants to create an audio tour of their factory for visitors. We need to convert the factory tour script from text to speech."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: We want to classify animals in images to tag them with their respective species."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: Describe how to create a program that translates an English email message into German."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: I have a sales invoice and I want to extract the required information such as total payment amount and invoice number."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: \"\u0935\u093f\u091c\u094d\u091e\u093e\u0928 \u0935\u094d\u092f\u093e\u0935\u0938\u093e\u092f\u093f\u0915 \u091c\u0940\u0935\u0928 \u0915\u0947 \u0932\u093f\u090f \u092e\u0939\u0924\u094d\u0935\u092a\u0942\u0930\u094d\u0923 \u0939\u0948\u0964\""}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: Identify specific biomedical entities found in certain health records."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: We are working in a German newspaper agency. We need to summarize an article so that a reader can grasp its main points quickly."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: Help me create a tool that can identify if an email text makes sense or if it is a gibberish message."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: John is studying Korean, and he wants an app that can read Korean text to him."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: I recently installed a new security camera. I need to identify the objects in the recorded video."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: We are an administration agency. We need to read scanned handwritten documents and convert the text for processing."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: Our company is working on a project to reduce carbon emissions. We want a tool to predict carbon emissions based on some features."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: A company wants to analyze their customer support calls to identify the emotions of the customers. Let me know how to proceed."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Our organization wants to predict the carbon emissions generated by various sources for the purpose of building policies against climate change."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: Our team is working on a smart city project and we have collected a large article explaining the benefits of smart cities. Help us to summarize it."}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: Please compare the similarity of the product descriptions of our latest phone models using sentence transformers."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: Our client has recorded a call with their customers and wants to know which parts of the audio file contain human speech."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: My friend sent me a link to an image of an animal as a riddle, I need you to tell me what animal it is."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: Program a bot which can take an image URL and identify the types of objects and their bounding boxes within the picture."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: Summarize the financial report of the company to understand the key points of the document."}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: We are working on a multilingual news app, and we want to offer summaries of the articles in various languages."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: We have a dataset containing images and questions about their content. We would like to implement a model that provides answers based on both the image and the text."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: We want to create a visualization for text input that represents mental health concepts. Develop a script that uses a given model to generate a relevant image."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: I need a tool to generate captions for different images on my website."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: I've just downloaded the pre-trained model for CartPole-v1. Please help me to load this model and test it on a given environment."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: I want to generate random images of cats to showcase them to my friends, is it possible using a computer-generated model?"}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: We are developing a customer support app that converts spoken language into written format and needs to be compatible with multiple languages."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: I have a low-resolution image, and I would like to increase its resolution to twice its current size."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: I am hosting a sports event and need to determine the type of sport being played based on video recordings."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive players in an image with the YOLOv8 model."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: We are an online store selling clothes. We need a solution to identify and segment clothes in images."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: Modify the given code to appropriately load the model, and predict the income category for a given set of input features related to the Adult dataset."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: Develop a tool to classify a medical image using BiomedCLIP."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: As a company creating autonomous vehicles for city driving, we will analyze city street images to recognize the environment."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: We're building an app that matches synonyms. Find out how well our sentences match each other."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: You have a product that allows generating text while chatting. Describe how you can use a GPT-4 model to generate conversation output."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: We are building a social media monitoring platform for clients. We need to categorize posts into emotions."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: I have an Italian friend who speaks English with a strong accent. From the recorded conversation, I would like to get his speech transcribed."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: Design an automatic parking assistant for cars that can identify different objects in a parking lot to assist drivers."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: To perform a document clustering task, I need to find the similarity between two sentences."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: A doctor wants to use an AI tool to help answer a patient's questions. We need to help him find the answers."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: I have a collection of videos from my life experiences, and I want to build an AI video categorization system that can classify the content of these videos into defined categories such as sports, birthday parties, and weddings."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: A quality control team in a factory wants to use an automated system to detect and segment defects in printed circuit boards (PCBs). Help them build a suitable system."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: In our audio filtering system, we want to identify the speaker's identity to categorize audio files by speaker."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: We are building a customer support voice assistant and need to analyze our customer's emotional state based on their speech."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: We are building a robotic arm that needs to grasp objects in three-dimensional space. Calculate the depth estimation from an input image."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: The marketing team needs a summary of a long article on the launch of a new cultural platform, ITsART, for promotional purposes."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: I want to create a customer support chatbot to answer questions about a product."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: Create a simple search engine for news articles where the user enters a search query and matches the articles based on semantic similarity."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: Develop a system that can evaluate if a product review is positive, negative, or neutral."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: Our company uses AI to read receipts automatically, and now we want to extract the text from a given image of a receipt."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: We are building a knowledge base system that finds answers to users' questions based on a set of pre-written documents. We need to retrieve the answer for each question."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: We got a lot of customer service inquiries this week. Let's analyze the content and generate automatic replies to some common questions."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Design a futuristic spaceship for our new game."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: A video game company wants to embed an advanced Text-to-Speech tool into their game to generate realistic voices for their characters."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: The image processing team needs to create an application that adds an artistic touch to photos by stylizing them according to specific text descriptions. Develop a solution to accomplish this task."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: \"What is the title of this document?\""}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: We need to develop a text-to-image application for generating custom images of animals based on descriptions for pet adoption campaigns."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: We are a seafood company, and we need to predict the weight of a fish based on its characteristics."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: We are holding a conference in French. What would you recommend for the key points to be extracted from the given French documents?"}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: We have an AI-based eSports analytics platform that analyzes the performance of each team in a Counter-Strike match. Analyze the gameplay footage to detect the location of players in the game."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: We need to develop a chatbot that can answer questions about a specific text."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: We have a new AI blog, and we want to use AI to generate text based on chosen keywords."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: As a city planner, we need a model to help us segment images into different objects on the streets, like buildings, cars, and trees."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: Our customer want to develop a reinforcement learning system using TD3 algorithm for solving the Ant-v3 environment."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: We have a list of documents and are looking for a way to find the similarity between any two documents."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: Our company is developing a virtual assistant and wants to add emotion recognition capabilities to it. We need to classify audio clips into different emotions."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: We want to generate images of people with a vintage style as assets for a history-related project."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: We need to transcribe podcasts so that our client can make them available on their platform as text files."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: Can you help me create a video classifier for my online platform that automatically recognizes and categorizes the content?"}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: Our customer is an artist who wants to transform an image of a landscape into a different style. Provide information on how to achieve this transformation."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: An AI tool is being developed by the company to help with creative writing. The software needs to create a sentence involving three specific words."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: Our team is developing a machine learning algorithm to recommend research papers in order to improve scientific productivity. We would like to extract meaningful representations of papers to recommend."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: \"A young and strong knight with blue eyes and blonde hair.\""}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: A client has requested a software for detecting celebrity faces. Develop a system that can recognize celebrity faces."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: Our company requires a reliable solution to extract speech from noisy audio files."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: I want to generate a unique abstract artwork for my home based on the prompt \"Magical Winter Landscape\"."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: We are a streaming platform, we need a technology to predict categories of the shows watched by our users."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: The company wants to generate a summary of the company's meeting minutes."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: Develop a depth estimation application using the neural network trained on diode-subset dataset."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: Here is the question \"What is the population of London?\" Now, arrange the following sentences in the chronological order they are relevant to the question:"}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: We are creating a tool for generating unique Minecraft skins for players. We want to add a feature to generate random skins automatically."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: We have a chatbot that is designed for engaging and entertaining clients. Can you help develop it further?"}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: Assist me in identifying the number of people present in a given photograph."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: I am a blogger, editing my blog takes a lot of time. I need to correct the grammar in real-time."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: I have a table loaded with financial data, I need to get the top 5 more profitable items."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: Collect all the personal information in a paragraph."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: We are trying to predict carbon emissions from a new dataset containing features that have an effect on carbon emission level. We should do this with a pre-trained multi-class classification model."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: Our company has a Chinese customer service center. We need to find and group similar customer requests to improve efficiency."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: I am a teacher and want to create an AI module to help answer questions from my students based on the course materials I have provided."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: Write a text editor for a German online newspaper, where the users can type in German sentences and get the translated English sentence.  "}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: We are building an AI-based software to help farmers identify infected plants from their fields. Determine the objects in a given image."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: Design a voice recognition system to recognize digits from 0-9."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Design a grasping algorithm for a robotic arm with a 6-dimensional input that optimizes grasping and motion."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: I recorded a meeting and would like to have the discussion translated into text. Please help me transcribe the audio."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: I am creating a database system for my company's sales team. They need to be able to ask questions about the data and have it answer them, like \"What is the total revenue of products made in 2020?\""}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: As a teacher, I would like a solution to easily answer questions from students about complex tables of data to save time."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: I want to build a tool that helps me detect if a sentence contradicts or is entailed by a given statement."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: I am an investment portfolio manager and I want to compare the annual returns of different stocks. Can you help me classify their performance based on a table?"}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: Develop a new wildlife-themed party banner image to be used for promotions and marketing of a board game."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: Write a pipeline to predict categories of text based on the topics they mention. Some topics could be technology, health, sports, etc."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: As a company focusing on advertising and marketing, we want to quickly turn announcements and new product descriptions into video clips that visually describe the text."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: I'm writing a children's book, and I need a picture of a friendly-looking elephant playing soccer in a sunny meadow."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: As a podcast editor, I need a tool to separate the voices in the audio recordings of my podcast episodes automatically."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: Create a model for our company's car fleet to estimate how much carbon emissions each car produces during usage."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: Our fashion company needs to automatically segment clothing items in images for our online store."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: The company is developing video games and we need to create background images that look like they belong to a church."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive player detection feed, we need to identify players in the game and on which team they are in."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Help users to reduce their carbon footprint by providing a prediction tool that calculates the estimated carbon emissions of their daily habits."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: The company is running a campaign to promote eco-friendly products, we need to identify those based on their carbon emissions."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: We need a unique, creative illustration for social media marketing campaign. Can you produce an image of a futuristic city with flying cars and robots?"}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: Create a set of questions from a text passage about Python programming language."}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: Show how we can convert a text input in Chinese into a speech output that can be played back."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: I need a tool to find information from a table in our company documents. We have various tables containing data about our employees, projects, and finances."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: We need to automate customer data extraction from public messages. Identify the people, organizations, and locations in a given text."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: To design a workout app, classify the type of exercise performed in the video."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: 'The author explains the concepts very clearly and with good examples.', 'The book is poorly organized and difficult to follow.'"}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: A user of our voice-based assistant wants to transcribe an audio input recorded on their phone. We want to provide them with text so they can interpret their piece of audio without listening to it."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: To create an illustrated storybook for children, I need to generate images based on the story's text."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: The company is planning to build a language tutor for teaching Esperanto. We need to transcribe audio files of Esperanto spoken by native speakers."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: We are a tech company, seeking to classify a test video dataset based on sports activities. The classifier should predict the sport activity in the video."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: Develop an audiobook app in Marathi for a local library. They want to convert their written content to audio format."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: Our team is developing an app that recommends similar articles. Can you describe what we should do?"}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: I want to automatically extract information from an scanned image of an invoice. I have the invoice text in a JSON format."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: I have some recorded meetings with my team, and I'd like to have them transcribed so people can easily read what has been discussed."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: I am a music teacher who is working on an automatic grading platform, and I want to gauge the sentiment from a student's feedback."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Develop the next-generation robotic hand that can grasp objects in a refined 6D space."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: The CEO is having difficulty understanding the presentations delivered in Spanish. Develop a solution to transcribe the audio."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: We are a customer review analysis company. We are in charge of a report where we have to extract client names and addresses from customer's feedback."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: We need to create a translation system that can be used in interpreting conferences and meetings."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: I would like to create a new version of a landscape photo with a more artistic interpretation. I will provide a text prompt to guide the transformation."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: I've been researching Charles Darwin. Here is a paragraph I found describing his work. Can you tell me his main contribution to the field of biology?"}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: Implement a mechanism for suggesting the likely content of a photo, given an image, from a list of categories such as people, animals, scenery, and objects."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: We are creating a voice assistant with a Taiwanese Hokkien accent. Make it pronounce the text \"Hello World\"."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: The team is trying to find out the points in a conference call where multiple people are speaking at the same time."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: I run a sports store and want to determine the sports activity in the product videos we receive from our suppliers."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: We are designing an exhibit in which visitors can ask questions about images. We want to create a system that answers their questions based on the images."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: We need a way to generate spoken audio in the Hokkien accent from text input for our language learning app."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: We would like an AI to design a greeting card based on the text \"happy birthday with a cake and balloons\"."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: A user wants to translate their French essay to Spanish for their Spanish class."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: We are presenting our app to a company of fitness coaches. We need the code to analyze a short video to suggest some important moments to include in the dashboard."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: We are working with an environmental agency on a project to predict carbon emissions based on input data."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: Create a study guide tool to answer questions about textual content provided to the user."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: We're developing an app that can improve the quality of audio files by reducing background noise."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: I want to extract the names of people and organizations mentioned in news articles."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: Our team is designing a chat bot to help extract information from invoice documents. Can you give us some suggestions?"}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: We own a small restaurant and we would like a menu recommendation system for our customers based on the orders they make."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: I am running a therapy bot for people who face difficulty in maintaining their mental health, and I need the bot to be interactive with the users."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: Create a voice assistant to help people understand if the movie they are watching creates a positive or negative feeling."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: I have a document with names, addresses, and other information. I'd like to extract the names and locations from the document."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: We are the developer team of a social platform, and we need to match users based on their interests. Help us match users with similar interest descriptions."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: As a writer, need help completing a paragraph in a book. Suggest some lines based on the current context."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: We are a linguistic research institute, and we need to perform feature extraction on a corpus of Russian text for further analysis."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: Our client is a medical research center. They requested a tool that can analyze the relationships between different biomedical entities."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: We are an online photo editing service, and one of the customers sent us a flying skate-board photo, which he said the photo was blurred. Help him to deblur the photo."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: We need to develop a system that recognizes and transcribes our meeting audio files into text."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: We are creating an app to detect a specific activity from livestream videos, e.g., detecting someone playing soccer."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: A local electricity company is looking to build a machine learning model to predict electricity consumption in their city for the next quarter. They need assistance in selecting and building the right model to predict the consumption accurately."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: We are creating a new language translation app and we need the app to speak translated text from English to Italian."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: We need an advanced AI player for our Pong game. Could you provide a solution that loads a pre-trained agent to use in this environment?"}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: Generate a realistic picture of a person's face and save the image to your local drive."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: We have an underwater vehicle that requires depth estimation for navigation. Help us to obtain depth information from images."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: We have a collection of recorded meetings and conferences that need speaker diarization to separate the speakers in the audio recordings."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: We are a transcription company that wants to transcribe the speaker's voice from a meeting into text for our clients using a pre-trained model."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: We are building a mobile application to estimate the depth of objects in photos taken by users. Use pretrained model that can accurately estimate depth in photos."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Help me interact with a chatbot that understands reddit threads in an empathetic manner."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: Generate a cute animal image that can be used as an avatar on a pet-lovers website."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: Help me understand the relationship between movie characters based on lines from a script."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: As a quiz maker for a history exam, generate a question suitable for the provided context and correct answer."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: We are an urban planning company, and we need to identify different regions in satellite images for better planning purposes."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: Develop a tool to transcribe speech in Vietnamese."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: We are a video streaming platform, and we want to categorize videos based on their content automatically for better recommendation and advertisement."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: I want to build a smartphone app to identify if a user's picture depicts a hotdog or not a hotdog."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: I built a robot recently, it can move around inside the house. I want it to estimate the depths of objects inside the house."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: Can you help me generate an image of a character with black hair, red eyes, and a serious expression?"}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: To improve the quality of our software for identifying plants and animals, we need to segment the images into different regions."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: A Korean food brand wants to automatically categorize their Instagram photos into various product collections like snacks, drinks, and main dishes. Help them find suitable technology."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: We want to create a 3D representation of an object given a 2D image. To do this, we need to estimate the normal maps of the object."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: Our company needs to extract competitor names from articles, and we want a model for this task."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: We are creating an AI tool to find semantic matches for user-inputted keywords."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: I want to compare the similarity between two news articles. How can I do that using a pre-trained model?"}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: We are building a large scale chatbot, which needs an understanding of the emotional content of a user's input."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We need to classify a video uploaded by a user in our app to provide more personalized content recommendations."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: An audio instruction for blind students is in demand. Let's create one in Telugu language."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: We are a news website and we want to provide voiceover for our articles in Spanish."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: Deploy a model to control a robotic half cheetah to run as fast as it could."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: We will be launching a website, and need an algorithm to categorize images automatically while users upload them on our platform for better management."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: An architect needs to automatically categorize areas within an image of a construction site into different sections such as buildings, roads, and trees."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: I received an invoice and want to extract some information from it. I have a scanned image of the invoice and need to find the invoice number."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: Develop a solution for a smart home device to detect emotions in the voice of people interacting with it."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: We have collected some tables and relevant queries for our online shop. Now, we need to create a Q&A system to answer customers' questions."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: As a voice assistant, we need to classify the emotion of the Russian speech we receive as audio input."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: We need to create an interactive Web UI using the EimisAnimeDiffusion_1.0v model to generate anime images from text prompts."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: I need to find the similarity between two sentences efficiently for my research project."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: Our company is working on a project that involves detecting and segmenting defects in printed circuit boards. We need a solution that can help us with this task."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Find a way to predict the carbon emissions based on some tabular data that contains various features affecting carbon emissions."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: We are an online monitoring site. We need to classify videos automatically."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: We are developing a product that translates a user's speech from one language to another in real-time."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: Write an API implementation that takes customer reviews as input and extracts features to analyze customer sentiment."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: A visually impaired student needs help answering questions about an image in their textbook. We need a system to process the image and understand the question to provide an answer."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: Our organization has a large database of technical documents. We would like to generate questions based on these documents to facilitate discussion during team meetings."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: Implement a sports activities recognition system for a sports streaming platform to suggest popular videos in various categories like High Jump, Long Jump and Discus Throw, etc."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: We are working on an art project and would like to generate an image that combines elements from an input image with some text guidance."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: culture, society, economy, health, sports. The task requires me to categorize an article written in Spanish."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: Develop a news summary for the management team to inform them about the current status of a specificcompany in Russian language."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: Translate a paragraph from Spanish to English."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: Could you create a review assessing tool to help the marketing team to analyze the user's sentiment about their product?"}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: We are working with investors and need to analyze the sentiment of the comments about the stock market."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: What should I do to translate a Russian news article to English using the Helsinki-NLP/opus-mt-ru-en model?"}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: We need to develop a system to field questions about images for an online storefront."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: Your company is developing an autonomous car, and you need to use depth estimation to help the car perceive the 3D environment more accurately."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: \"Can you recommend a good restaurant nearby?\""}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: Global Offensive players in a given image."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: We need to summarize long scientific articles for our users, who have no previous knowledge in the subject."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: We are building a virtual assistant that can analyze audio files and detect voice activities, overlaying speech, and perform speaker segmentation. Suggest an appropriate method."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: Let's make an image recognition tool to identify the content in images."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: We are constructing a language learning application for users learning Japanese. Generate filled Japanese sentences for input phrases containing masked tokens."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: Prepare a snippet for summarization of a long paragraph."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: I need to create a tool that analyzes an image and answers questions about its content."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: We are an agricultural company that wants to classify plants based on their physical features. Help us use the pre-trained model to make predictions on our data set."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We want to design beautiful online poker game cards with impactful images of buildings, especially churches, for a new digital table game."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: We require a high-quality anime-style image for our upcoming marketing campaign. The image should depict \"a magical girl with white hair and a blue dress\"."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: The company is building a quiz application for students, where they have to decide if the given statement is True or False. Help us in classifying the statements."}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Build a chatbot that recommends places to visit based on pictures of the places."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: Recently, we obtained a dataset containing information about clients' financial history, and we would like to predict their credit scores."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: Translate a Korean sentence into English in terms of a news article provided in korean."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: We are building a language learning app, and we need to convert French text into spoken language for listening exercises."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: I manage the social media for a startup and want an AI tool to classify the sentiment of each tweet."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: create an ambulance service company, we need text-to-speech for general communication with users in French."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We would like to build a product that takes input from python codes and translates them into tutorials with explanations."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: I want to create an intelligent chatbot that listens to me, and based on the sentences I say, it tells me if my statement was positive or negative. Please give me a model to achieve this."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: Please help our online store classify products in Chinese based on their images."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: As a writer, I want an AI to help me brainstorm possible opening sentences for the beginning of a science fiction novel."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: I am a pharmacist assistant, I need help answering clients' questions. We want to get answer to their question when provided context"}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: I am planning to build a predictive model to estimate the tip amount based on a given circumstance."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: I need to classify an online article in a language different from English; please help me classify this text written in a foreign language."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: We create content for our customer newspaper and we want to generate summaries for those articles."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: I want to create a machine learning model that can identify objects in images from the internet."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: We have a series of invoices which contains information about transactions. We need a solution to extract payment details from these invoices."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: \"Gazpacho is a Spanish cold tomato soup that offers numerous health benefits. It contains vitamins, minerals and antioxidants that help regulate digestion, prevent inflammation, and support cardiovascular health.\""}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: An intern in our company speaks only in French. The task is to translate his messages into English. "}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: Our team is seeking a way to extract information from scanned documents in a question-answering format."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: I want to know if google/flan-t5-small can be used a one-shot text generator for improving my business."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: I am an online store owner. I want to understand the sentiment of my customers based on the reviews that they have provided. Analyze their sentiment using a model that's capable of working with multilingual reviews."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: The company is focused on developing a tool that provides knowledge about computer programming to users. We want to find the most similar concepts based on user input."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: A toy manufacturer needs a system to identify the most suitable toys for their online shop from a set of images."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: We have a folder of scanned documents and need to extract information by asking questions about the documents."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We are building an AI-powered robot that can autonomously map and navigate an environment. We need to process images captured by robot's camera feed to understand the environment."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: I want a program to classify gym exercises from video clips."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: Our lab needs help identifying blood cells in an image."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: We've conducted a quick survey for identifying insects in our garden. We need to classify the captured images into well-known insect categories."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: I want to create a tool that can answer questions about documents with complex layouts such as invoices."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: My manager needs me to create an algorithm to check the attendences of the employees for each meeting from a long text."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: I work for an insurance company and I want to use the Titanic dataset to predict the survival probability of our passengers."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: A sports magazine is looking for a system that classifies news articles into different categories like football, basketball, hockey, cricket, etc."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Create a tool that transcribes Portuguese spoken language in customer service calls and provides transcriptions for further analysis."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: Develop an application for vehicles that allows depth estimation for detecting proximity to obstacles."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: We are developing a voice-activated home automation system, and we need to classify voice commands for actions such as turning on the lights or adjusting the temperature."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: Provide a way to extract certain information like name, location, and organizations from an article."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: Our news organization is looking to summarize long articles to make them easier to read by our online audience."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: Create a synthesized video of a dog playing with a Frisbee in the park based on a text input."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: We're developing a mobile app to recognize cats' breeds. Help us to classify images using the provided model and feature extractor."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: Please design a language translation system from Dutch to English for a mobile app, which will translate input text."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: We want to implement a depth-sensing app that uses a smartphone's camera. Please help to estimate the depth."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: Describe the process of using a trained PPO agent to play seals/CartPole-v0 reinforcement learning environment."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: As a university, we need to compile a list of frequently asked questions (FAQs) for incoming students. To do this, we need to analyze various documents and extract answers to these questions."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: We are designing a booking application, and we need to classify customer reviews into several categories based on their content."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: We are building a social media app. Help us detect if an uploaded image contains a cat or a dog?"}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: The marketing team needs to write a pitch for an ad campaign, but the original text is too long. Summarize the campaign idea."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: We have bought a package from an online store recently. We need to know about the total amount on the invoice."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: An artist needs help visualizing the environment and perspective of a landscape sketch. Assist them by generating an image incorporating M-LSD straight lines to control the diffusion model."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: We are building an application that reads documents with tables. We need to extract the data from those tables."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: In a smart street, the cameras are required to detect license plates in real time so later we can classify them."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: We are developing an AI-based application to summarize the top sporting events of the day. The model needs to be able to recognize the sport events from videos."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: In our robotics project, a robot needs to hop on one leg. We need to supply the robot with the next action based on the current state."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: A call center has asked for help to identify the emotions of their clients during calls. How can they perform the task?"}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: Produce a Mandarin female voice reading out the given Chinese text."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: We are now working on a language tool and we need the assistant to autocomplete sentences in Dutch."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: I have a Python code snippet, and I want to generate a brief description of what it does."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: An AI researcher is developing a chatbot that can respond to conversation in a natural way. Come up with a conversational pipeline for generating responses."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: As a company involved in computing integrations, we want to identify brands of electronics in photos."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: A newbie animal researcher tries to classify images of animals. However, they are not confident in their classification, so they ask you to help them by suggesting a model that can provide accurate classification results from an image."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: Develop an application to sort out the images of different animals posted on Instagram by users and categorize them into dog, cat, and bird images."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: I have an audio recording from a meeting and I want a transcription of the conversation."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Develop an AI-based application that can generate images of butterflies on command."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: Please help guide my chatbot to classify incoming messages as questions or statements."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: One of our customers is a Hospital. Their need is to remove all the information of the patient from a given report."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: Our customer support team needs to review customer sentiment based on recorded audio calls. Can your solution analyze the sentiment of these audio recordings?"}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: Develop an AI tool to identify the location of all the cars in a given image and inform if a specific car model is detected."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: We are developing a speech-to-speech translation system for a client. We need to convert English audio into Hokkien speech."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: Global Offensive (CS:GO) based on images."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: I want my phone to talk with me, everytime I want to know who is the leader of a country, I want my system to know it and answer me."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: Our team is developing a virtual reality software for interacting with simulated environments. We need to estimate the depth in images of the environment."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: We have developed a podcast platform, and we want to verify the speaker's identity in the uploaded audio files."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: We are working on an advertising campaign. We want to come up with creative headlines for our new product."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: Extract speech from a noisy input audio file containing a speaker talking in the background with overlapping sounds."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: In our healthcare program, we are researching Plantar Fasciitis, and we want to know what the best treatment options are for this condition."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: I want to build a software to help my team to quickly analyze the sales data of our company in a table format. I need it to answer questions about the data."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: A client works at a zoo, and they want a tool that can identify animal species from images. When an image is given, the tool/moment should return three most likely species names."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: As a journalist, I need to write a summary for an article in my next French news release."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: The team is building an app for animal recognition. The goal is to determine the type of animal in a photo."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: My boss asked me to generate a Python code snippet that will parse a URL and extract the domain part."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: An educational company wants to convert video lectures to text for providing summary notes to students."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: A group of content creating enthusiasts require a model to predict missing word in sentences."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: I want to generate voice from text files so I can listen to them while relaxing."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: Imagine you are creating an audiobook. Use an AI model to convert a text paragraph into speech."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: Our digital marketing agency needs to create a video ad for a travel company. The video should showcase a beautiful sandy beach with clear blue water, palm trees swaying, and a couple enjoying the sun."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: We are a company that needs to know if a product will cause carbon emissions above the allowed threshold, based on provided data."}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Develop a feature for a mobile app that helps users get information about images by asking questions."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: We are designing a robot to navigate through complex environments and need a way to estimate the depth of objects in the environment."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: Provide the code snippet for translating a Swedish text to English text."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: The customer support department wants to analyze the sentiment of audio recordings in incoming calls. The audio recordings are in Spanish. They need to know the sentiment of each call."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: I want to develop a chatbot in Russian that can talk about a wide range of topics like politics, economy, and technology."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: We want to create a recommendation algorithm for our clothing store website. Analyze the new winter collection images and identify the main articles of clothing."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query:  I'm creating a language learning app, and tasked with providing translation and pronunciation for a given text in English, French, Spanish or Italian."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: We want to ease our manufacturing process. We need to classify our machine parts and gathered defects into broken and working parts."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: We have some images and their URLs. We want to know their content and where the objects are."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: Our company needs to quickly determine if a new sentence logically flows from a given context. Can you create an API to help with this task?"}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: I'm currently building a chatbot that can impersonate a popular historical figure. I need this chatbot to return natural language responses based on user inputs."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: Can you help me create a real-time app that translates texts from French to English?"}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: How can I implement a question answering system to automatically answer customers' questions?"}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: Use AI to convert a text description into an image based on the Canny edge detection."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: Develop a head detection model for an American football match with a precision of 0.25 and 0.45 IoU layer."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Extract moving objects in a video frame from a traffic camera to count cars, motorcycles, and trucks."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: Our company is working on a chatbot that can summarize long conversations between users. We need to build a model that can understand and generate a summary from the given dialogues."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: Develop a system that will help self-driving cars to estimate the depth of objects on the road."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: As a shop owner, I want to create a color picker application. Generate a code snippet in Python for it."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: A home robot project is in progress. We are building a robot that can interact with the various objects found in a home environment. Extract useful embeddings from the images of these objects."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: I'm developing an audible book-app, I need to read out parts of the books."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: We want to implement a chatbot that can engage with users in natural conversations."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: I own a website for personalized avatars, generate one for me."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: A Chinese teacher would like to learn English. They are now looking for a text translation from Chinese to English."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: Our company receives global customer inquiries, and we have a list of questions. I need your help in multilingual question answering."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: We need an application to recognize different emotions for a call center."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: As an online retailer, our company needs to calculate shipping fees. To do that efficiently, we need to estimate the depth of objects in the warehouse for packaging purposes. Help us to estimate that."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: We are building an international news website that provides content in different languages. We need to categorize news articles into different topics such as politics, sports, and entertainment."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: CreateUser a set of questions for a language processing API based on its description."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Our new art project needs a unique butterfly image. Use a AI model to generate this."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: The marketing research team needs a technology news detector to extract the latest news for analysis."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: My company is working on analyzing customer calls in German. We need to classify the emotions of the customers' voices in the call recordings."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: I am working on a project to extract fields from invoices, and I need a pretrained model to recognize text from document images."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: I need a method to generate high-quality normal maps from input images such as an image of a rock."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: I'm working on a cataloging project for books. The books contain information about food and their nutritional value. I want to extract information from the documents to help people quickly find the information they need."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: I want to cluster similar patient symptoms in an emergency room management system, and I am looking for a model for text feature extraction to analyze patient descriptions of their symptoms."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: We are a security company and we need a classifier to automatically detect if a video contains suspicious activity."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: We are developing an application for Spanish-speaking kids to learn math, and we want to convert some math problems into audio in Spanish."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Distinguish whether a given movie description follows the genre of comedy, romance, action, or horror."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: I am building a digital marketplace for ecological photography. We need to find a way to identify the individual animals in the pictures that sellers send."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: I am a content creator, and I want to create a chatbot that will communicate with users on my behalf."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: Our goal is to find out which two texts are more similar to each other."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: Can you design a Multi-Lingual Question Answering model and clarify the steps to implement?  "}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: Our company is building a product for job search, and we want to predict the salary of a job based on some dataset provided."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: Our company is developing a new app for sightseeing tours. We need to identify key information about the historical places in the images uploaded by the users."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: In an office communication system, we need to detect who is speaking at what time and if there are overlapping voices."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: I am working on a conversational AI project and need a chatbot that can hold a conversation and respond like a character from a video game."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: We have two audio files in Dutch language, and we need you to transcribe both of them."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: I want to convey the story of a bear enjoying a beautiful sunset in the forest through an AI-generated video."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: I need a tool to estimate house prices by square footage, then integrate this into a real-estate application."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: My co-worker sent me his draft for a presentation, but I noticed some grammar errors. I want to correct the text."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: I have a blog and I want to create a clickable index to bring readers to the part that they want to read."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Our project needs to classify images based on zero-shot learning without using any image training data."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: We would like to build a story plot generator. Give us guidelines on how to use the API."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: Create an anime image of a girl with a soft pastel background and surrounded by flowers."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: Our organization is hosting an international conference. We need to match speakers with similar research interests, regardless of language."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: I am looking for a model to complete the sentences in my writing, when I hesitate and indicate with a placeholder."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: The company's automated store clerk needs to identify different items and answer questions in real-time. The system should recognize the products showcased and answer queries about them."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: We are trying to classify an image as a cat or a dog."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: Create a script to extract names, locations, and organizations from news articles, so we can build a knowledge graph."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: As a marketing company, we're working on a project that involves transforming images to match a specific theme. We require a tool that can generate a modified image based on the original image and textual guidance."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: \"Company\", \"MarketCap\", and \"DividendYieldPercent\". Design a query that selects the company with the highest market cap."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: Our company is in the process of translating our website to the German language to target German customers. We need an English to German translation for our website."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: We are working for an autonomous vehicle company. We need to know the distance of objects relative to the camera of the vehicle."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: We are a company working on building a diagnostic tool for medical staff. We need to detect blood cells in images."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: A social media platform wants to create AI-generated profile pictures for its users based on their description. We need to provide a way to generate these images based on their descriptions."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: A friend told me, there are some plants that can remove air pollutants. I need names of three such plants."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Help us translate and shorten the russian text provided by the CEO of our company to use in briefing their employees."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: We are operating drones for aerial surveillance and need to detect objects in the images captured by the drone cameras."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: We are an AI-based company working on detecting emotions in voice call recordings. Help us detect emotions in an audio file."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: Our marketing team need to analyze the medical advertisements, detect diseases in them and classify the diseases into different categories."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: Our company develops a new app for noise-canceling headphones. We need to improve the quality of the speech input by enhancing the signal from noisy recordings."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: Our company needs to calculate the carbon emissions of our production processes. We have a dataset containing related features."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: The marketing team is analyzing user reviews to improve the products. They need to find out which comments are related to each other."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: We need to develop a system capable of understanding the content in a text document."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: As a developer for a city traffic control system, we have to classify the videos into specific categories to identify any traffic violations."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: Predict the property of a specific molecule using Graphormer for a pharmaceutical company."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: We want to create a robotics marketing tool that can describe images through text form."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: I am building a chat program. Tell me how I can use BlenderBot to make the conversation better."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: We're trying to create a voice-over for the product advertisement, and want to convert some text to speech."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: We want to create an online tool to explore and understand programming languages. We need a model to provide brief descriptions and examples of programming languages."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: We have a scanned document and need the model to help us find the answer to our question regarding the content of that document."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: I am a writer who is suffering from writer's block. Generate 5 different story ideas based on the prompt \"A mysterious stranger arrives in town.\""}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: I want to automatically mark exam essays against a pre-defined model answer in order to save time grading essays."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: We have a company that plans to implement a relaxation room for employees. We aim to have random butterfly images in this room."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: Our company is managing a solar farm and we want to predict the electricity consumption for the next week. "}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: Design a system that can extract answers from legal contracts and documents."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: We are trying to create a control image using a neural network, and we want to save the output to an image file."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: You are building an audiobook platform. Your task is to convert chapter text into audio. Using the framework to synthesize text into realistic speech."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: \"The quick brown fox jumps over the lazy dog.\""}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: A software company wants to utilize computer vision to create an application that automatically identifies objects in an image and display the object names on the image."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: I run a news company that delivers news from around the world. Create a language model that can identify Named Entities (such as Person, Organization, and Location) in my articles."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: We need to create a Russian-speaking virtual assistant for a tech support chatbot. The assistant should be able to answer questions about software issues."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: Our media team needs a convincing and realistic picture of \"a cozy cabin in the woods during autumn\". Can you help?"}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: I'd like to use this model to predict carbon emissions, based on the given dataset."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: As a linguist studying Russian language, I want to analyze an input text according to the relations between sentences, and ultimately, reveal patterns and insights within the text."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: I am working in broadcasting and I need to separate the voice of a presenter from the background music."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: Our company processes structured data to predict customer preferences. Please create a model to help us classify the structured data effectively."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: Could you generate some images of cute objects for our new greeting cards design?"}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: The legal department of our company has received many new contracts with other companies. They need a quick tool to extract company names."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: We're making a virtual gallery featuring futuristic cars. Could you please come up with images corresponding to each description?"}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: The marketing team needs to classify user reviews into adequacy categories. Can you help with this task?"}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: We have more than five thousand forums and need to group related forums by the similarity of the text."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: I am a journalist and need a tool to summarize long articles quickly for my online blog."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: My smart home device needs to recognize the difference between a cat and a dog from an uploaded image."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: Our company is developing a browser extension that converts text-to-hand-drawn images. We need the model that is ideal for this."}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: Summarize the provided article in a clear and concise manner for a professional presentation."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: I want the story content of a sad man meeting a girl who can make everyone happy."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: My architecture firm is in need of creating unique church exterior designs. We want to explore different generated possibilities."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: Create a program to extract specific information from a form, like finding the email address from a scanned employment form."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: I need to produce a short video summary based on a text description of an event."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: Our company is now working on a pedestrian detection project. We need to detect the pedestrian from the video in real time."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: We are a marketing company targeting a Russian audience. We need to translate our promotional content from English to Russian."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: I have a text with a missing word, can you help me complete the sentence?"}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: We have a chemical dataset involving various chemical molecules and we want to compute the properties of each molecule."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: I am creating a visualizer for a podcast, and I would like to turn the podcast script into an engaging video. What machine learning model would you recommend?"}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: We are a fashion design company and we need to create a dress image based on the given text \u201dA beautiful red dress with a floral design\u201d."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: I am working on a project to recognize different types of flowers. I need the language model to show me a way to predict the species of a flower given its petal length, petal width, sepal length, and sepal width."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: A teacher assigned a passage reading to her students. After reading the passage, she wants to generate multiple questions related to it to check their understanding."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: The company is producing a blog about cryptocurrencies. We need to generate a paragraph regarding the future of blockchain technology."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: Design a unique butterfly using artificial intelligence to use as a personal training studio's logo."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: Our customer is an ai-based AI language translation. We are working to improve a text translation."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: I am an assistant on a support team for a popular streaming service. I need to quickly understand the conversation between my colleague and a client."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: Can you help me to analyze user reviews in English and identify individual keywords related to money, location, service, and product quality?"}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: A new user to your platform wants an overview on how to appropriately fill in masked words. The user wants to learn how to use the Masked Language Model with the distilbert-based multilingual model."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: Our company is building an application to help customers make decisions about restaurants. We need to identify whether the given restaurant review is positive or negative."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: We want to gauge public sentiment about political topics by analyzing vocal recordings and understanding the emotions conveyed in them."}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: If a given number is divisible by 5, print \"Fizz\", otherwise print the number."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: While taking online classes, my voice gets distorted due to surrounding noise. I need a solution that can enhance my voice quality."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: A film production company wants to categorize their video clips based on the content. Provide a solution to analyze video clips and extract relevant features."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: We need a way to summarize key points of financial news articles so that we can understand the main idea without needing to read the whole article."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: We are developing an app that can add captions to the user's pictures. Create a function using an API that can automatically generate the caption based on the image."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: We are developing a smart speaker product and need to implement a keyword detection function. Can you help us do that?"}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: I am a sound engineer and I want to enhance an audio file to remove noise."}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: A media agency wants to have a sentiment analysis on their customer reviews. Automate their sentiment analysis process."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: We need an application to assist financial analysts in quickly finding specific information from financial reports."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: Create a short video explaining the process of photosynthesis in a simple language."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: We want to write a story for our community festival pamphlet. Please come up with a story that starts with \"Once upon a time in a small village\"."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: Identify fake news and real news by checking how closely related the context of an article's summary and its title are."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: Our call center just started supporting Indian languages. We need to determine whether there's ongoing speech or silence in the customer calls."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: The customer service team is struggling to keep up with the number of inquiries. We plan to launch an AI-based chatbot to provide immediate assistance."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: How can we detect the action within a video automatically?"}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: I work in the cybersecurity field, we need to find duplicate entries in our incident reports."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: We have images of streets, and we need to calculate the distance between objects in these images. Please predict depth information of unseen images."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: Our client needs educational video clips for their upcoming e-learning platform. Create a short video based on the provided description."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: In our app, users can upload images and add text queries to find specific objects in the image. Build a system for this using text-conditioned object detection."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: As a sales manager at an electric car company, create regression models to predict a vehicle's carbon emissions based on their mileage, weight, and engine size."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: Chinese language study material is given to a bot trained in NLP question and answering skills. We now want to know the meaning behind a specific line in the text."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: I own a pathology lab and I want to scan blood cell images using a computer vision model. How do I detect blood cells in images using an AI model?"}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: An online streaming platform wants to flag violent content in the uploaded videos. How can we use the API to detect violence in the videos?"}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: \"Modern city life, bustling streets and vibrant colors\"."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: Generate a relevant image based on a text description."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: We want to build a system for categorizing product reviews into \"Positive\", \"Negative\", or \"Neutral\"."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: I have a bunch of descriptive text on different characters, I want my machine to generate images with different clothes and different suggestive content based on the text provided."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: We are building a news aggregator website, and we need to summarize articles to give users a quick idea of the content."}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We are building security cameras and we want to detect events using videos as input."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: We have invoice documents and need to extract specific data, such as the total amount, from these documents."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: We need to detect voice activity from a meeting to create transcripts of only the segments in which an individual is speaking."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: We are monitoring CO2 emission of the cars on the streets. We want to predict vehicle emissions based on engine data."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: Let's create an AI tool that generates images based on user input text, like describing scenes or characters in a story."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: We want to build a Chinese chatbot and need to tokenize and classify words for understanding user input."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Our client, a biologist, is researching butterflies. Generate some high-quality images of butterflies for the project."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: A social media platform is looking to automatically remove explicit content from user posts. The goal is to blur images."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: I want to build a tool that can transcribe Esperanto audio files. How can I achieve that?"}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: We want to generate text for our company's blog using AI models."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: low, medium, and high."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: We are building a prototype of a web application to describe an image in text format to make our content more accessible. How can I use this API to do that?"}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: Create an AI-based system that, given a sentence, can predict whether or not it contradicts another piece of information."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: I am writing a script for an educational video on biology. Can you generate a video using the text of my script?"}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: I want to build a web app that identifies and classifies various types of vehicles for my car dealership."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: We have a news platform, we need to have short summaries for our longer articles for people who are in a hurry."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: With the help of the provided model, I want to create a restaurant sentiment analysis tool that will categorize the reviews as positive or negative."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: I am a data scientist who works at a tech company. I have a dataset containing information about Olympic Games, and I want to retrieve the year when the games were held in Beijing."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: \"The young boy adored playing with his new <mask>.\" Use an NLP model to fill in the mask with the most appropriate word."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: I am building an application for my Japanese students, and I would like to let them practice filling in Japanese sentences with missing words. Can you tell me how to do that?"}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: Imagine you are visiting an art gallery in Berlin, Germany. You see a painting, and you think it shows a famous historical attraction. Capture the image on your phone and write a question about the painting in German. The model will try to answer your question."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: We are building an e-commerce platform for shoes. Help us automatically generate shoe designs to be displayed on our platform."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: We are a bank that consistently receives loan applications with various documents. Analyze these documents and extract tables from them."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: I want to implement a search engine with text clustering in different languages. Can you suggest a suitable model for extracting multi-language sentence embeddings?"}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: A person is learning a new language and wants to know the phonetic transcription of words. Help him with this process."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: As a video game developer, I need to observe a trained soccer playing agent for potential integration into my new game."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: I am working on a game, and I need a chatbot to interact with my users."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: Our company requires a system to better sort the images of cats and dogs. Implement this functionality."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: We want a model that can answer questions in Chinese from a given paragraph."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: An AI startup wants to translate speech from Hokkien to English for their customers in real-time. Provide a guideline to accomplish this task."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: I have a speech in English, and I want to convert it into Spanish speech using an AI model."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: We are working on a project that matches customer product reviews. We need our model to create embeddings of sentences to allow for semantic clustering."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: We are building a drone that can recognize various objects in the environment. We would like to process the images captured by the drone's camera for this purpose."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: We got a zip file which contains pictures of objects that need to be categorized into three classes \"animals\", \"cars\", and \"plants\"."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: Extract the named entities like people, organizations, and locations mentioned in a news article about a recent event."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: A health organization website wants to automatically answer people's questions based on a provided table with COVID-19 statistics."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: We are working on an application that scans a user's image and automatically sorts it into predetermined categories. We want our application to be able to sort images into categories like \"food\", \"landscape\", \"animals\", and \"vehicles\"."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: I am currently building an app that needs to detect names, organizations and locations from news articles."}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: I need to develop an application that can translate the texts of different languages. Translate the given text from Hindi to German."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: I run a painting shop, and I want to automatically segment the foreground and background of different images before I start painting on them. What do you suggest?"}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: A freelance worker is looking for an assistant to complete mutual-linguistic-texts in different languages. The model should learn to fill the gaps in the input sentences."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: We have a grandma in our family that will have the 1st robot, give us the command to use meta AI transformer for English to continue a sentence"}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: A finance company is developing a chatbot for users to find investment opportunities. Recognize the companies' performance from tables."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: I want to develop an AI tool to categorize videos into different sports categories like soccer, basketball, or swimming."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: I am planning to create a blog, in which I need to automatically classify articles/posts without any training."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: Analyze whether a given sentence is a question or a statement from a user's input."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: I have a travel company and I want my website's text to be translated from English to Spanish."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: It is said \"Reading between the lines\", but I need a model that can fill in the blanks in my text automatically when I'm typing."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: A chemist firm is looking for ways to efficintly find the properties of complex molecules. We should predict the properties of these molecules using graph-based machine learning."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: We are producing a digital assistant, and we want it to generate text completion based on the user's question."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: We have a huge collection of PDF files and need a solution to automatically extract information from them using natural language queries."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: We are trying to create a system for creating high-quality images of people's faces."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: We would like to transcribe Mandarin Chinese speech from a podcast episode to a text file."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: I need to predict housing prices in California, I want to use Machine learning and in particular Random Forests."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: Our content creators are stuck with writer's block. Give them a tool that can rephrase their writing to help get back on track."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: We have a CMS moving to international markets, so we need to analyze content in multiple languages."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Detect tables in a document and provide the bounding boxes for each table found."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: I have a Chinese document, and I need to find similar sentences in other documents for research purposes."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: Our manager is requesting to extract information from a table about monthly sales of different products. Help them find out which product had the highest sales in a specific month."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: We are building an autonomous robot to work in a warehouse. Please guide us to use the VC-1 model to process egocentric video data."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: Imagine you work for an animation company. They want you to create a short animation of a giraffe playing basketball using a text-to-video tool."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: Create a small chatbot that takes the user's input, analyzes the data, and produces an output based on a casual conversation with a game character."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: A new clothing brand is launching its website and needs help with classifying product images into different categories, like shirts, dresses, pants, etc."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: Generate a photo that would be representative of a landscape scene that includes a beautiful sunset by the ocean, a lighthouse, and a small fishing boat."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: We have a problem in our warehouse where objects are not placed at correct distances causing operational inefficiencies. We need to estimate the depth of objects to solve this problem."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: Our company focuses on creating personalized posters. We require an application that would generate images based on user given text inputs."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: A news agency wants to categorize videos based on their content. Help the agency to build a system that identifies the video's categories."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: Develop a creative idea for a children's story involving a bear in the woods and rainstorm."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: I want to create a document summarization tool that can turn any long text into a concise summary."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: I want a summary of a long news article to understand the main points."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: I want to build a multilingual news categorization application. I need a multilingual NLP model that can perform zero-shot classification to categorize news articles into different topics."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: Our company is developing a chatbot that can predict a word to fit in a masked sentence."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: Identify the entities present in a news article headline and categorize them."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: I'd like to find a tool to paraphrase a paragraph to avoid plagarism before submitting my essay."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: I have a large project to investigate the health condition of 1000 Vietnamese people. Help me understand the necessary information from the provided multimodal document."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: We are an educational institution that wants to detect student emotions through their voices during online classes."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: \"mysterious wizard casting a powerful spell\"."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: A software agency wants to build some artistic background images for their upcoming project. We need to provide them with sample art images."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: Our CEO is giving a keynote speech at a conference and needs an icebreaker to start the speech. Please generate a creative and interesting opening line."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: We need to extract information from a document image about a specific topic."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: We are building an app to classify household objects in real-time for people with disabilities. We would like to use an image classification model from a reputable source."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: We are a content curation platform dedicated to showing different images of pets to users. We need to detect the type of animal present in images."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: I have this French sentence \"Je t\u2019aime.\" I would like to have it translated into English."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We are planning on starting a new project, creating a virtual tour for a historical church. We need to produce images of old and famous churches as an inspiration."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: We're developing a solution for the municipal government to detect potholes in images automatically for road maintenance. Create a system to detect potholes."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: We are trying to develop an application to help users learn new languages and accents with synthetic speech. Use this API to generate speech audio of an English text 'Hello World' in Taiwanese Hokkien accent."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: We are looking to detect keywords from an audio file to turn on certain home appliances automatically."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: As a digital artist, I am searching for a model that can take a text-based description of a scene and generate a photo-realistic image based on the given description. I want this to be done extremely efficiently."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: We're developing a chatbot for a big tech company. It should be able to provide general information, as well as answer questions based on user input."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: A voice assistant can automatically adjust the brightness, color, and mood when playing music. We need to make the voice assistant detect the mood according to the song being played."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: We have started a fashion blog on vintage items and we need to generate an image that represents our blog's theme."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: Our company's voice assistants are relying on a system for detecting specific keywords in a user's speech. We need an English keyword spotting model that can recognize keywords in real-time."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: I am building an interactive tool to identify fruits based on images. I need a model to classify the images of various fruits."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: We need a quick method to create a German audio sample from a text input."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: We are tasked with creating an audio message in Simplified Chinese for our clientele."}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: The advertising department asked us to identify the emotions in the text of various advertisement slogans, as they believe that this will help them tailor their campaigns more effectively."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: I am reading a scientific article and I need to summarize the data from the article's table. Also, I have some questions about the table which I need to answer."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: The university is working on a project to develop an Automatic Meeting Transcription System using Speaker Diarization. Provide instructions and code for identifying speakers."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: We are building a chatbot for our clients with diversified interests. We would like to generate a variety of responses to engage users."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: I am a retail shopkeeper looking for a solution to categorize the items available in my shop into shelves, dairy products, cleaning supplies, and beverages. Kindly provide a solution for this."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: I need help finding answers to factual questions based on context from a news article."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: Tell me how we can build a customer support chatbot to serve Russian customers who want English support."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: We would like to create an audio book in multiple languages. Provide us text-to-speech instructions code."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: Prepare a text summarization system to provide me with a brief and concise summary of a news article."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: I am an AI developer who needs to unmask some missing words from a bilingual text."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: I have lots of meeting transcriptions which I need to summarize for easy reference. Can you provide code to create a summarization model?"}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: My boss needs all the data that is printed on a batch of invoices. I have the image URL of these invoices. Implement an OCR model to read the printed text on these invoices."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: We are now designing an AI assistant. We need the assistant to help users by returning some useful information based on the image and question."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: Our company has a dataset of articles, and we want to build a system to identify different types of named entities - such as places, people, organizations, and more."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: I need to generate a creative story about a pandemic zombie virus and their struggle to survive in the post-apocalyptic world."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: Our lab would like to use artificial intelligence to analyze a few research papers to get document-level embeddings."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: We are a startup that sells wine. We're looking to predict wine quality based on its characteristics."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: We need to process a podcast to distinguish between speech and silence sections for better comprehension."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: There is a product we are developing where we need to understand the user's input language and translate it into Spanish."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: A solar panel company needs an application to analyze their quarterly performance. The CEO wants to know the performance of their top 3 sales teams."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: I'm writing a research paper about famous scientists. I'd like to automatically extract the names of the scientists and their affiliations from the text."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: In research, I need to generate a creative title for my paper about machine learning and artificial intelligence."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: We want to build an application which segments different objects in an image based on their semantic, instance, and panoptic segmentation. What model is suitable for this task?"}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Design a bot that creates stories based on user's message prompts. The bot should contribute to the story as a narrator, describing scenes and characters."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: We need a model to determine the best category for an article about electric vehicles, choosing between \"technology\", \"health\", \"sports\", and \"politics\"."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: As a company, we want to automatically categorize photos based on their content. Provide a sample code to load and use an image classification model."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: We're building a bot that can recognize the structure of tables in images. It should be able to detect rows, columns and table elements."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: I got a message in Dutch from a business partner. Translate the contents of the message into English."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: In our university, we want to design an app that can detect and correct errors in students' assignments."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: We are designing an app and need to generate a unique avatar for each of our users."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: As a content rating organization, we want to verify if the given movie synopsis is appropriate for all audiences."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: A blog's content is translated automatically from English to several other languages. To verify the accuracy of translation, find out if the original English content and translated content have similar meanings."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: My company wants to evaluate the performance of a self-driving car in a simulated environment. We want to assess how well the car balances a pole on its chassis as it moves."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: I need a lighter model to help me with sentiment analysis of product reviews."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: Build me a chatbot that can talk like Elon Musk and provide me with innovative ideas."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: We want to build a toll booth system to detect license plates from the vehicle images coming from the security cameras."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: I'm writing an email in Portuguese to our customer. Can you help me autocomplete the sentence?"}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Our client wants to separate vocal and instrumental parts of an audio file they sent us."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: Our client is developing a robot to converse with people in a nursing home. We want to create an empathetic communication between the robot and the residents."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: The school is building a digital library to store the basic information of its books. Create a table visually for the user and help users ask the question \"which books do we have in our school library that were authored by William Shakespeare?\""}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: To improve the visual search functionality of an online shopping app, we need to classify an image without explicit training."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: We are creating a Spanish news classification system, please demonstrate how we can classify news articles into categories such as culture, society, economy, health, and sports using the available API."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: Create image variations using stable diffusion with guidance scale 3 and save them as a result."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: sports, politics, science, entertainment."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: Create a virtual assistant that processes data related to cars and engines, answering repeated questions based on a given table."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: Please prepare a text generator that being given a sentence in a foreign language can translate it to English."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: Write a code which translates the given text from English to French by using a pre-trained machine learning model."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: We are building an app that converts images of printed text to regular text. We need to generate text from a given image."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: I have a blog, and I want to introduce a comment moderation system, which can categorize comments automatically as 'positive', 'negative' or 'neutral'."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: Kindly provide a sample code to get a picture of a panda wearing a red hat using this text-to-image model."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: We are building an AI-based mobile app that can identify species of Iris flowers based on their measurements. Can you give us some insights using your model?"}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: Construct a question-answering model to facilitate our customers' inquiries about account statements and transaction histories."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: We need to perform image segmentation on an image provided by a client to analyze its content."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: I have a scanned invoice as text and I need to know the total amount."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: Can you please classify this sound, it might be a speech command or a random sound."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: Develop a tool to analyze city traffic images that can distinguish between roads, sidewalks, buildings, and other objects."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: I would like to have a model that detects defects on PCBs and segments the images to highlight the defects."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Summarize the conversation between two coworkers discussing a recent company meeting."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: Translate the Finnish sentence \"Tervetuloa Helsinkiin!\" into English."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: We want a solution to separate the voices of two speakers from a single audio file."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: A marine research company wants to predict the weight of fish based on different features such as length, width, and height. Let's provide them with a model that can perform this task."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: The marketing team needs assistance in answering questions based on a table of data for yearly revenue reports. Create a way to answer these questions using the data provided in the table."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: A team of researchers is developing a robotic navigation system. Obtain depth information of indoor environments using a computer vision model."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: Create an artistic image of a red rose with a soft golden glow from a low resolution image."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: I run an e-commerce platform and need to classify the images of the products into categories like electronics, clothing, food items and more."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: We are an AI-driven news aggregator platform. It is essential to display an abridged version of the long news articles on our page."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: Our company is building a chatbot. We want to have the functions to determine whether users' questions are relevant to a given topic. Help us identify similarities between sentences."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: We are developing a new update for our Minecraft site. Generate a unique, high-quality Minecraft skin for us."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: We need a navigation robot that can autonomously navigate a hospital. Can you develop an AI system capable of this task?"}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: I need a model to analyze soccer videos and classify each video into predefined categories like goals, free-kicks, penalties, etc."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: Our company is looking for an automated solution to process PDF files and answer questions based on their content, such as extracting invoice details."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: The customer is interested in creating a text-to-speech system that speaks the Russian language. We need a transformer that can convert text to speech in Russian."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: Let's say we have to work on monitoring HVAC units in a commercial building. Identification of the anomalous behaviour of the system is of utmost importance."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: Develop a program to estimate the depth of objects in an indoor scene, provided with an RGB image."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: Find the total revenue of Apple in 2019 for a finance expert who does not understand tables."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: Our company specializes in legal services. We need to extract information from an agreement to answer specific legal questions."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: We want to transcribe spoken words to written text.>Create a model that can be used to process audio files and convert human speech into text format."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: In a videogame, we need to identify the locations of dropped spikes, enemies, planted spikes, and teammates from a screenshot."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: I am a researcher and I want to find relevant articles based on similar sentences for a project."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: We have a database of legal documents and need to find the best model to complete sentences in these documents."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Imagine a mental health helpline in Germany. They want to use AI to identify the emotions of the callers and develop insights about the mental state."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: I need an API to build a chatbot that can maintain conversations about general topics and display empathy and personality."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: We are trying to create a high-quality image from text describing a scene with a dragon overlooking a village."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: I want to find the answer about why model conversion is important in the given text."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: We are a company committed to decrease CO2 emissions. Let's predict the carbon emissions of our factories in the future to mitigate the environmental impact."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: We have a Chinese e-learning platform that needs to complete a gap with the appropriate word (Beijing) in the sentence \"\u4e2d\u56fd\u7684\u9996\u90fd\u662f[MASK]\u4eac\u3002\"."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: We need to categorize the sales data of different products into categories of highest sales and lowest sales from the given table. Provide a code snippet to answer this using a table-question-answering model."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: Create a tool to classify the sentiment expressed in movie reviews written by users on social media platforms."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: Determine the depth information of an input image by estimating depth values for each pixel."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: There is an important company meeting, and we want to analyze the audio to see who spoke when. We need to separate the speakers' voice for the analysis."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: We have a company transcript service that utilizes speech recognition software. We want to transcribe an audio file."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: The manager asked me to remove the motion blur of some images taken by the factory's surveillance cameras."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: The user wants to develop an application to answer questions based on images."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: Generate a detailed image of a yellow cat lying on a park bench looking content using a Text-to-Image model."}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: As a news website company, we want to translate our written articles into audible content for visually impaired visitors."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: Our company works with annual reports in table format. We need a tool to process these reports and extract the rows and columns within them."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: We have a need for a virtual conference platform with an audio enhancement feature for noisy environments. Help us create one."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: To help users with questions about our product, we want to include a chatbot to answer questions about the website content."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: I could not understand a recent scientific paper. Come up with a working model that can help me extract the vital information."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: We want to identify effectively whether a new chemical compound could act as a potential drug candidate based on its molecular structure."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: As part of our autonomous vehicle project, we need to analyse the real-time images from the onboard camera and estimate the depth information for each object present."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: We have developed an anime art platform and now we want to categorize incoming artwork as generated by humans or by artificial intelligence (AI)."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: I would like a Python solution to transcribe audio files into text using an automatic speech recognition model."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query:  Our team is building a Visual Question Answering system to improve our customer service response time."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: Create a function that processes an image and outputs the category of the object in the image."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: We're an events company and need to organize a list of attendees with their roles. We want a solution to extract names and their respective roles in an event."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: My company aims to use AI for customer support purposes. We can create a question-answering utility that can help save time and increase efficiency."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: Please guide me on the steps needed to create multiple questions from a given text."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: We are providing a surveillance video to evaluate and predict for potential violence occurance."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: We are a voice-activated home automation system, and we need to classify voice commands for controlling devices."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: We need to transcribe the audio of a podcast for people with hearing difficulties."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: We want to analyze user-generated text for our dating app to find any important nouns like people, places, and organizations."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: Our client needs support creating a user-friendly app that allows users to easily ask questions about images they provide."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: Recently our company got some audio recordings from online meetings. Our responsibility now is to transcribe those recordings into text."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Utilize an inference API to predict recidivism rates in a local community."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: In a multi-cultural conference, I want an AI to predict the missing word in the sentence, \"John is currently working as a [MASK] in the technology sector.\""}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: As an AI developer, I'm writing a program to create vintage style photo images for creating unique background for websites."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: I am a musician, and I want to enhance the sound quality of the melody of my music piece using the API."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: I recently moved to the US and would like to find what states share a border with Texas from a piece of tabular data."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: The company is developing a language learning application that needs to identify the part of speech for each word in a sentence. Determine the parts of speech for a given sentence."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: We need to create a conversational AI chatbot for our newly launched e-commerce website to assist visitors with their queries, so they can have an interactive and intelligent conversation."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: We are building an application that will recommend a workout video based on the content of a video input. We need to classify videos into different workout categories."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: I would like to have a way to translate sentences from different languages into English."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: A teacher wants to create a quiz. They have a table of different animal classifications and ask which animal belongs to the specified category."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: Our company is working on social media posts. We want to generate captions for the images we will upload."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: I am an environmental consultant. I need to predict carbon emissions for a new factory based on some specific data points of the factory."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: Our interior design company wants to generate bedroom images to show our clients examples of how their bedroom could look after renovation."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: The research group needs to evaluate a TD3 algorithm on Ant-v3 environment. Provide them with the steps to load the pretrained model and obtain the results."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: Imagine there is a billboard which has multiple information such as a slogan, an image of product and contact number. Our company is trying to collect necessary information from this billboard through the image. Let's find out the slogan and some other relevant information."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: A company wants to digitize documents and provide AI assistance to answer queries about the document. Please suggest a solution."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: Help us in building a product that will determine whether a photo contains food or a dog."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: I am building an application that filters out pictures of dogs from a photo album. We need to know if a given photo has a dog or not."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: Develop a machine learning model to predict housing prices using the California Housing dataset."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: We have a news agency that publishes daily news articles. We want to add a feature to our site to generate summaries of articles."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: \"I stayed in Los Angeles and Santa Monica while I was on vacation in California last month.\""}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: Our client needs help in classifying images of different objects."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: A business researcher needs to classify customer opinions about local restaurants. We need a way to identify the most relevant category for each review."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: A company needs to analyze customer service calls in Spanish to better understand how to address their customer's concerns. They will need help categorizing the content of the calls."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: Evaluate a text saying \"I love the color of my new car!\" and decide if this is positive, negative or neutral."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: We run a gaming website, we need to upscale and generate high-resolution images based on text prompts."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: We are building a robot that needs to navigate through an unknown environment. We require depth estimation from images taken by the robot's camera."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Our smart speaker company is working on a feature that can classify different sounds. Can you provide a sample code for audio classification?"}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: I am currently running an online language learning platform and we want to provide text-to-speech feature for learners to understand how a specific phrase in Spanish sounds."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: Let's devise a method to convert Korean questions to answers in sentences."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: I am building an app to predict carbon emissions based on a dataset provided by the user. I need a model that can make these predictions."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: I need a voice assistant to tell me the weather forecast for Germany tomorrow in German."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: Architects want to analyze the building elements in each floor for automation purposes. They need to semantically divide and categorize them."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: Our company requires a sample text spoken in a Russian male voice for a presentation. The sample text is \"\u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u044d\u0442\u043e \u043f\u0440\u043e\u0431\u043d\u044b\u0439 \u0437\u0430\u043f\u0443\u0441\u043a\"."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: a bright living room with a large window overlooking the ocean and minimalist furniture."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: I want to create a system that takes an audio input and classifies it into predefined keywords."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: We need to identify which candidate (employee) would fit best for a given job description."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: We want to understand and create a relationship between different chemicals in a biomedical research paper."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: Our company organizes several events where a lot of people speak simultaneously. We need to enhance the audio quality of the recordings before turning them into podcasts."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: I have an Excel report and customers are very curious about the specific information inside. Please create a code to answer their questions."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: Jane is working for an online clothing store. Her task is to automatically classify the images based on their type."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: I am a writer, I want to build a conversational partner app for my character's dialogue in my novel."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: A doctor needs to get answers from medical articles to help their patients. Suggest a pre-trained model for question-answering that is specifically made for the medical domain."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: We are a car rental company. We need to recognize license plates of cars at the entrance of our parking garage."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: Determine if the given sentences are related or if they contradict each other."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: Can we restore the audio clarity of a noisy recording using speech enhancement techniques? "}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: Predict some CO2 emissions for our environmental company using CSV data that we gathered. It should show the predictions for each entry."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: We want to classify the emotions of couples during their first wedding dance based on the video."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: We are a news agency that needs to provide a short summary of each article we post. Please help us build this system."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: I want to see the emotions of my customers' reviews to have a quick overview of how they feel about our product."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: Help me write an AI model for converting text to images using Hugging Face."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: An AI assistant is needed for taking care of customers' concerns and questions. What can be done to make this happen?"}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: We received a Japanese message from a business partner. They have requested an audio sample for demonstration purposes that includes their message."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: Develop a solution that segments and labels images of an outdoor park."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: We've designed a virtual Japenese language assistant. We want it to recognize spoken Japanese and transcribe it into text."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: \"What is the role of neurons in the human brain?\""}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: In a debate competition, the topic is unkwown. Generate an opening statement and classify it as being in favor or against."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: The client, an environmental agency, needs a tool to estimate carbon emissions based on a given set of input features."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: Please assist me in completing a sentence with a missing word. The sentence is \"The rabbit quickly jumped over the __ log.\""}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: Can you please help an Image editing company how to use AI to detect whether a photo contains a cat?"}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: Our customer runs a forum and we need to find similar sentences within a large number of text strings."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: We need to develop a captioning system for an online photo gallery to help users understand the content of the images."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: We are developing an interactive application for learning the Arabic language, and we want the app to read various text inputs aloud to users in Arabic."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: We want to develop a robot capable of navigating indoor environments and performing object manipulation tasks. Provide a useful pre-trained model for these tasks."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: We have a website offering software tutorials in Finnish. We'd like to expand our audience by translating the tutorial text into English."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: Develop a chat application that recognizes customer emotions and sends predefined responses. It should support the recognition of angry, happy, sad, and neutral tones."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: Pop, Rock, Hip-hop, Country, Jazz. Please provide a suggestion on how to use the mobilebert model to do so."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: We have customer records in a table and we need to extract the information of customers with a certain subscription type."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: Sort surveillance footage of humans fighting from the recorded videos to detect any chances of violence."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: You are working with a chatbot development team. They asked you to classify if some text generated by a chatbot is adequate for the proposed paraphrasing."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: Our customer service requires a mechanism to identify the emotional state of the caller to provide a better response."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: I have a picture of a man standing in front of his house. Can you help me caption the image with information on the color of his shirt?"}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: I have a set of scanned invoices, and I want the model to help me find the invoice date, invoice amount, and the name of the service provider."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: Our organization wants to design a demo to showcase an AI model's ability to play \"SoccerTwos\" effectively. The model should perform well in a 2-player soccer game."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: Write a function to complete a partially complete computer program (code)."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: My company needs an advanced image processing tool to improve the resolution of the photos for our website."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: A large coffee company is looking for ways to improve their social media presence. We are investigating if using generated captions on their images can assist in increasing engagement."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: pop, rock, hip hop, country, or jazz."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: Design an AI-powered chatbot that will browse through questions and identify related answers in a long FAQ text."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: I am working on a project focusing on extracting data from various tables. The computer vision model needs to recognize rows and columns from a given image of a table."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: Our company is planning to develop an application to transcribe conference calls. We need a model that can offer accurate speech recognition."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: I want a video of a cat chasing a laser pointer for my presentation."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: We are running an online scientific journal. We need to understand and analyze the main topics of a newly submitted biomedical research paper."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: Our client is a social platform where users can upload pictures of their cats. We need to classify the breed automatically."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: The company needs to analyze the conversation data during meetings, and we want to detect active speakers and overlapping speeches."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: I'd like to build a model that can learn how to play Acrobot-v1 and optimize its performance using reinforcement learning techniques."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: We are building a robot that detects the activity performed in real-time video feed and responds appropriately. Tell me how to classify the actions using a pre-trained model."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: There is a painting exhibition, and we need to generate captions for each painting to explain them."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I'm a student and I need a tool that can help me to find answers to my questions from textbooks."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: We are compiling a report. Help us extract data from a large dataset in table form."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: Developers in our research team need to perform autonomous drone flight lane prediction based on real-time drone images captured from a camera. We are thinking of utilizing semantic segmentation to achieve this. Please advise which solution we can use."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: \"Once upon a time, in a magical forest\"."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: An interpreter is facilitating a live conversation between two speakers of different languages. Read the speaker's sentence in Romanian and translate to English audio in real time."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: Let's build a tool that can analyze the financial statements and extract relevant financial ratios."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: Our robotics team is working on a quadruped robot and needs a model for controlling the robot's motion."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: The environmental agency wants to predict the amount of carbon dioxide emissions for specific equipment based on the supplied dataset."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: Create a book recommendation system that generates a list of similar books based on the input book's description."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: We are creating an autonomous vehicle company. Help us find a model for real-time depth estimation."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: When I am exchanging text with my colleague, I want to automatically detect my sentiment/emotion without having to analyze it consciously."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: My six-year-old daughter loves butterflies, so I want to create a beautiful butterfly illustration for her birthday cake."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: My company wants to use a predictive model to estimate whether an individual's income is above or below $50,000 per year based on census data."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We are trying to transcribe and digitize historical handwritten documents. Use AI models to help us convert the image of the document to text."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: We are an AI-model company. Our goal is to extract written content from an image."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: It's necessary to obtain a system to grasp if there are any human voices present in a specific audio file."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: Our manager wants a summary of a complex dataset. We need to extract insights from the dataset in a question-answering format."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: An autonomous vehicle company is looking for object detection capabilities using object detection systems. They need a solution to understand and process various objects on roads."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: I am an accountant and have to analyze invoices or other financial documents regularly. Help me find the invoice numbers more conveniently from these images and PDF files."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: Your client is a construction company, and they want to analyze the road condition using the model. They need you to detect potholes in a given image and obtain their coordinates and mask."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: I need to extract information from bills and invoices, such as the total amount and the billing date. Can you help me set up a model for that?"}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: In a video conferencing application, we would like to implement a feature to suppress background noise. To build this feature, we first need to identify whether there is any background noise."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: We are publishing an AI article. We need natural language processing to fill the gap in the sentence."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: The city wants to monitor and predict carbon emissions to reduce pollution. Based on the given data, predict CO2 emission levels."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: In the forest, there are many animals. We have a ranger camera that takes photos, and we need to be classified for future use."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: We have a low-resolution image, and we want to increase its resolution to improve the visual quality."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: As a video streaming platform, we want to categorize user uploaded videos into different genres please help us categorize these videos."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: I would like to analyze customer behavior at a supermarket using a video clip. "}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: We develop a smart security system that recognizes the emotions of the residents based on their voice. We want to write a python script to classify the emotion from a user's voice recording."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: We need to extract features from a given piece of text for our machine learning algorithm."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: We are a company that creates contents for social media, and we need to rephrase advertisements to avoid plagiarism."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: We are given an audio file of a political speech, and we aim to visualize it as a spectrogram to analyze the frequency patterns during speech."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: I'm curious about the estimated depth of objects in an image. Is there an AI model that could produce depth information for a given input image?"}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: We are comparing how well the content we write matches a list of questions our readers have. Please guide us."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: We want to create a chatbot that can answer questions from tables."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: We are running a tournament for the popular game Hopper. Our goal is to create an AI player with the records of the top players."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: Produce a detailed description of a painting to be used for an art gallery website."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: I am trying to build an AI chatbot with a fictional character personality. I want the AI to provide responses based on the character's persona."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: We are building a video game for the children's museum. We need to create an AI player for the Breakout game."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: Can you provide a tool that would allow me to chat with an AI in a human-like manner?"}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: Let's make a summary of the academic paper I just read."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: Analyze an audio file to identify if there is any voice activity in it."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: I'm working on a plagiarism detection project and need to calculate the similarity between texts."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: I am working on a Robotics project involving a robot maneuvering through a room. I need to estimate the depth of objects in the room."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: We develop robots and smart cameras for security at shopping malls. Can you classify video samples for actions like sitting, walking, running, and fighting?"}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: We need an NLP model to predict missing phrases from a patient's medical notes."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: Develop a chatbot that helps users answer their tech-related questions."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: Come up with an image of an animal that can serve as a mascot for an eco-friendly campaign."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: We are a robotics company and we need to create a map of the environment in 3D using the camera."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: We need a solution that separates the dialogues and background music from a movie scene."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: I want to create a chatbot to have a conversation about mental health and help people feel better."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: A marketing company requires to come up with taglines that can define their brand. Therefore, identify the semantic similarity between sentences to help."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: We develop games, now we have a game called LunarLander-v2. We want to test an AI in the game."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: We need to develop a robot arm for a warehouse, which must pick objects of different shapes."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: I have a picture of a living room in which I set my voice assistance device. Can you please tell me about it?"}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: A customer wants to know if a product in a provided image fulfill their requirements. Find necessary information by answering questions about the product."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: We need a system that will provide the description of a given image based on a specific question."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: Our company is looking at measuring annual carbon emissions in real-time to comply with environmental regulations. Help us organize the data."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: We have a series of speeches and want to know the part of speech of each word in the speeches. Can you help us with that?"}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: Let's say we are creating an app that transcribes users' voice messages into a handy text format. To achieve this, we need to convert the speech snippets into text."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: \"How many people are in the room?\" and \"Where is the sofa located?\""}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: Recommend a Chinese NLP model to calculate the semantic similarity between sentences in a large dataset."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: I am a journalist, how do I get the text translated from English to German?"}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: Our company aims to build a chatbot that can hold a conversation in Russian. "}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: We are a company that works on designing self-driving cars. We need to segment and classify different objects in an urban environment for our autonomous vehicles."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: Train a model that can categorize German news articles and rank them according to the topics of crime, tragedy, or theft."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: The company needs to create images to illustrate a blog post about an alien invasion. Please develop an image illustrating an alien spaceship attacking a city at night."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: Prioritize identifying the city of an image to use in our app's new image geolocation feature."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Generate an illustration for an article about how artificial intelligence helps in solving complex environmental problems."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: I have a robot that needs to identify different species of fish. Figure out a method to classify fish images."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: An artist needs to generate an image of a park featuring various elements based on a textual description they provided (include the ability to inpaint parts of the image with custom masks)."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: Our company specializes in manufacturing PCBs, and we want to use AI to automatically identify any defects in the PCBs. We also want the AI to display the identified defects visually."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: You are participating in a group conversation and you want to check the quality of the voiceover given the text input. The conversation was in English."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Our company is working on an app that summarizes conversations between users. Please provide a solution on how to do this."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: While analyzing a legal document, I need to quickly find the answers to specific questions about the document."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: Our client, a graphic design company, wants an AI tool to modify existing images based on specific textual instructions."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: I am an AI analyst working on computer vision for vehicle parking. I need to detect all the vehicles in the image, including their locations."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: I want to describe the content of an image for a visually impaired user, but I don't understand it well."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: We have built an app to help people finding their lost pets. Use an image classifier to determine the breed of a dog in a photo."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: I am developing an application which lets users find similar movies based on a given movie description. I want to create movie embeddings and then compare them to find the most similar movies."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: Develop an image segmentation tool to help our AI understand images better on a platformer game built with Unity."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: I would like to create a system that takes a picture of a handwritten text and returns its written text."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: We are building an application to filter out sensitive content from user messages. Develop a solution to determine if a text contains hate speech or offensive language."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: Our company plans to launch a financial news website. We need an AI model to automatically generate summaries for the articles we publish."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: I am starting a smart home automation company, and we need to classify household items using images."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: We have a problem with autonomous vehicles and classification of traffic signs. Could you find a solution and classify the images we provide?"}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: We are building a medical image classifier tool, and I need to classify an MRI image to match it with a particular condition."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: Create a gaming bot that leverages reinforcement learning to play Atari's Breakout game."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: I want to predict the carbon emissions of my local industry based on their recent data."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: Now a professor wants to enhance the quality of the pre-recorded lessons damaged by noise for his students."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: The musician in our team wants to separate vocals from instrumental sounds. Can you use audio source separation to help him?"}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: We are building an application where children can practice their numbers by saying them out loud and receiving feedback on their pronunciation. We need to classify the spoken numbers from an audio file."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: We are developing a virtual change-room application, and we need to segment clothes on a person."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: I am building a library catalog system that needs to match user queries with book descriptions."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: Help me translate some text written in the Catalan language into Spanish with the pretrained model 'Helsinki-NLP/opus-mt-ca-es'."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: I have a smart home device, and I need it to classify the digits spoken by users, so that I can control my home devices accordingly."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: We need to create an advertising banner for a bicycle company using text-to-image generation."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We want to reduce the carbon footprint of our company. Please help us predict the carbon emissions of our company using the existing data."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: The company is working to develop a new autonomous drone navigation system. We need an assistance in understanding the distance of its surroundings."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: Develop a system to categorize images of items posted in an online marketplace."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Our company is organizing a conference on Artificial Intelligence next month. Please create the outline for the welcome speech."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive (CS:GO). How can I integrate an object detection model into the app?"}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: As an advertising company, we constantly need to generate original pictures for advertising campaigns. We need to come up with a new scenic image."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: Provide a summary of a given Chinese article using the most relevant information."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: ['travel', 'cooking', 'dancing']."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: Our company received a video for evaluation, and we want to classify the action in it."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: We are working on a background noise reduction tool to improve the quality of audio calls."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: Give me an example to build a virtual assistant that helps in recording meeting minutes by detecting overlapping speeches."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: We have an educational application for high school students. We want to create an interactive learning module that generates images based on the detected straight lines in the input image."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: We are in a cyber security team, we need to detect named entities in a text and classify them as person, location, organization, or other."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: A bot for an Instagram account wants to detect the content of the images (such as food, animals, cars, etc.) posted by users."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Patients are concerned about the eye complications caused by diabetes. We want to identify the severity of diabetic retinopathy from their eye images."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: We have a large set of text sentences that we want to classify into categories but we do not have any labeled data. We wish to use Zero-Shot Classification for this task."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: I am writing a novel in Korean language and I want to hear how it sounds when it is being read out loud."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: Generate an image from a description to move into a fully furnished living room."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: I am writing a research paper about countries and their capitals. I need to extract the capital of Germany from this table."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: In an online e-commerce store, chat support is trying to answer questions about the displayed products. The store wants to integrate an AI model to assist human agents."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: Find out if this DQN-based Reinforcement Learning model can be used to control a robot in a competitive environment, specifically in playing LunarLander-v2."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: The news article project requires an AI model that can summarize a passage and effectively answer comprehension questions about the given text."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: I want our app to classify objects and scenes in a picture of a living room."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: The city wants to get a trial of our software, which uses AI to detect potholes in the city streets. They want to see it in action."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: A new video game company wants to design an AI model for a lunar lander game. Guide them on using an already trained model."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: Researching innovative natural disaster response strategies, analyze images of disaster-affected areas with figure captions. Identify relevant elements in the image based on the provided information."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: We have an advertising company expanding to Germany. Our team needs to translate the German ads to English."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: Design a language assistant that can translate spoken Spanish language to spoken English language in real time."}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: I want to develop an AI that can answer questions from a given context."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: The company needs an assistant to answer questions from scanned documents."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: My company deals with chart analysis. We need a tool to analyze charts and answer our questions about them."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: I am thinking about founding a green NGO. I'd like to predict carbon emissions in a certain area so I can determine how effective our efforts are."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: Our store is located in Korea and our customer service uses a model to answer questions. Tell me how to set up an AI program to respond."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: Our client wants to build an automatic tagging system for images in their e-commerce platform. Can you construct a text-conditioned object detection model for this purpose?"}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: Our company is working on an application that automatically categorizes photos uploaded by the users. We want to incorporate an image classification model."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: To provide a better service for our blind customers, we want to extract text from their paper bills or documents and answer their questions."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: Our business wants to build a social media platform that automatically segments images and removes the background."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: As an insurance company, we want to categorize the age of customers by facial photos. Tell our agents which model to use and how to integrate it with the existing system."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: I want to generate text in the style of conversational responses so that they can be used in a customer support chatbot."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: In our smart home application, we are adding a feature for users to ask their smart home assistant questions based on a live video feed."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: We are a group of environmentalists. We have the data of different vehicles and we want to predict their carbon emission."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: We are a clothing store and looking to generate creative designs for our new t-shirt collection inspired by the theme \"space exploration\"."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: You want to create a language model that can complete sentences in French. The sentences will have a blank space in the middle, and the model needs to fill that space with the most suitable word."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: We are to create a code that automatically translates English text to German in a mobile application."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: As a transcription company, we have a large audio file of a conference, which needs to be transcribed."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Our sports startup has just started making sports equipment. We need a way to catalog cricket sounds from the audio recordings picked up during cricket matches."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: I want to develop an application to identify the emotion of each spoken utterance in a sound file."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Our new project is an AI-Powered content filtering tool that checks users' input data on various platforms. We need to check the appropriateness of an image based on given categories."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: We are working on a news application, and we need to be able to summarize news articles in Italian for our users."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: We need to develop an application for robots to estimate the distance of objects in their path. They should use camera input to provide depth information."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: I am working as a financial auditor and have to handle many invoices quickly. I need a solution to automatically answer questions related to the invoices."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: We need to identify objects in images for our smart security system to understand who is present."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Write a dialogue between a person seeking advice about starting a new workout routine and a fitness expert for a blog post."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: Determine a solution for separating overlapping speech from two speakers in an audio file to allow transcription services to function better."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: We are a medical company focusing on building a product to understand how COVID virus spreads in the body. We need to find virus instances, their locations and sizes in the images of lungs."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: A company is building a parking lot management system that needs to detect and read license plates of vehicles coming to the parking lot."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: We are working on a smart home security system. We need to detect if there is any suspicious persons or objects in the house."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: We're working on an educational project, and I need backgrounds for our flyers that depict butterflies."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: Working on an email campaign, I need to engage the users. I have a basic idea of the email, but a paraphrase version would be helpful to draft multiple emails."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: We have a medical diagnostics app where doctors can upload pictures of X-rays. We need to classify X-rays as normal, pneumonia, or cancer."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: I need a virtual agent for my company's support chat. The agent needs to be able to extract relevant information like names and dates from user messages."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: Please fill the given Python code with the most relevant keywords to complete the code."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: We have a website that provides recipes. The chatbox will be enhanced to answer recipe-related questions."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: We have recorded one of our focus group meetings and we want to analyze the emotional states of the participants throughout the meeting."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: \"A magical blue dragon flies above the enchanted forest.\""}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: We need to automate the production process. Develop a method to identify and segment printed circuit board defects."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: An online art gallery wants to use AI to automatically categorize art pieces provided by artists. Provide a solution to classify art styles."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: Develop a product classification system for an e-commerce website that manages a variety of fashion products."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: Develop a conversational agent that can generate responses in Russian for my customer service in the home decoration industry."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: As a graphic designer, I want to create a custom manga-looking scene with characters and objects from popular media, like anime and games in black and white lineart."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: Our team is discussing an English book. We need a summary of a long conversation about this book."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: An investor is researching a niche market and would like to find companies within the text."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: To understand the 3D layout of a scene from a single 2D image, we need to build a product to predict depth information from an image."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: We are conducting a social media campaign and need to monitor the sentiment of tweets about our brand."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Our photography company needs an automated way to generate captions for a set of images that describe the content in the image."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: Our team wants to investigate the accuracy of images in a dataset of animals. We need to classify the objects in the images using a pre-trained model."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: We're building an application that needs to generate a caption based on an image as input."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: We need to train a new robot arm for gripping. The environment is like a pendulum and the robot must learn how to balance the pendulum."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: Please create a prediction model to classify the quality of wine samples based on their chemical properties."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: I am an advertising agency. I want to know what the target audience is thinking when they see an image. Can you provide me information that can help me ask user-based questions related to an image?"}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: A company dealing with Korean-language customer engagement askes us to come up with a text generation model."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: Please assist me in creating natural language responses to user inputs."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: \"What time is it?\""}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: As content creators, we are planning to generate new 1024x1024 images for our upcoming project."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: I have a long scientific article about the gravitational forces. I need to get answers to some questions regarding gravitational forces from the article."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: We are designing a wallpaper for a mobile app and need a procedurally generated background image for the wallpaper."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: We are working on a creative social media project that converts text prompts into images. We need to utilize an AI model to achieve this."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: The company is working on a video-sharing platform and wants to identify user-generated content based on categories for better recommendations to users."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: Develop a system for reviewing contracts for real estate and identify the names of people, the contract start, and end date."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: Create a virtual assistant for a mobile app that helps users to identify emotions in audio files like voice memos or voice recordings."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: I am a designer, I need to generate a picture of an interior for presentation purposes by making use of the controlnet API."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: We are developing a social media application and we want our users to be able to instantly translate their text messages into other languages."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: Alice is a writer and she would like to translate a sentence in her novel from English to German."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: To identify and separate different objects in an image, create an image segmentation model."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: We need a wine classification model that can predict the quality of the wine based on its features."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: My team is working on an app that will help people with vision impairment to get a description of images; we need the app to also answer questions about the images."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: We are building a personal assistant that will read news articles out loud to users in Arabic, and we need to convert the text to speech."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: Design a bot that helps users in need of motivation and inspiration during their day-to-day activities."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: A Russian science fiction writer wants to turn one of his books into an audiobook using text-to-speech technology that generates natural sounding speech."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: We need to train a model for predicting carbon emissions, then use it to analyze data.csv."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: We are a real estate company looking to predict housing prices. We want to utilize this model in our operations to make smart decisions."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: Develop a tool to convert a text description of a customer support issue into speech for our customer service robot."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: Our web application needs a feature to turn regular images into artistic versions."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: I need a process to turn my research articles into concise summaries that are easy to understand."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: In my project I need to estimate the depth of the objects in an image taken from a single camera with no stereo input."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: We are creating a hardware IoT device that receives Romanian speech as input and returns spoken English translation."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: We are planning to build an indoor navigation system for visually-impaired people. We need our app to provide depth estimation."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: Our company is developing an audio processing system that will classify the recorded speech by language."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: Our search engine needs to rank documents based on their similarity to a query. Use a sentence similarity model to determine which documents are the most relevant."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: Our customer is an international call center providing assistance to English-speaking customers, but the hired agent speaks Romanian. Convert the agent's Romanian speech to English."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: Show me how to classify an image using zero-shot classification according to specific categories."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: I am creating a home automation system chatbot. I want the bot to be in charge of controlling the lighting in a living room."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: I want to extract locations and organizations from a given raw text."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: A hospital is dealing with individuals who have difficulty in communication due to their health conditions, as a solution we want to convert their spoken Dutch language into text."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: We are a team of researchers working on autonomous vehicles. We need to estimate depth information from a single image."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: I am designing a smart home system and need to recognize spoken commands. How would I use your model to classify audio inputs?"}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: The management team needs a system for answering questions based on the internal documents and meeting minutes."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: We should detect if the given audio contains either a bird, traffic, or a dog barking. The recordings come from a neighborhood setting."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: We need to find a model that can help us create an automatic summary for a long news article received from our source."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: \"\u092e\u093e\u091d\u0902 \u0928\u093e\u0935 \u0938\u094d\u0935\u092a\u094d\u0928\u093f\u0932 \u0906\u0939\u0947. \u092e\u093e\u091d\u0902 \u0909\u0902\u091a\u093e\u0935 \u090f\u0915 \u0915\u094b\u091f\u093f \u0906\u0923\u093f \u092c\u0940\u0938 \u0932\u093e\u0916 \u0905\u0936\u0940 \u0906\u0939\u0947.\""}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: A movie review website uses a temperature-based color coding to represent the review sentiments. For a given movie, provide the color coding based on the ratings and reviews of the movies."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: I put lifestyle advices on a weekly table, and need assistance to answer related question about it."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: I am building an app to assist people with visual impairments. Convert a text description into spoken words to inform them about their surroundings."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: We are classifying the emotions from a given local audio file using Hubert."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: Help me sort images of cats into different breeds by classifying the images."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: Identify an automobile's carbon emission classification based on input features."}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: A drone company wants to estimate the depth of objects captured by its drone's camera using a pre-trained model. Estimate the depth of a given image from the drone's camera."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: The company is working on a chatbot that needs to understand similar phrases from different users. We need a way to identify these phrases."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: I am working on a project to find the relevance of news articles to different categories. I need to be able to quickly classify news articles into categories such as politics, sports, and technology."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: As the marketing team wants to prepare a new engaging Minecraft campaign, they asked for a unique, distinctive Minecraft skin for their main character."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: A pets magazine requested our team to provide pictures of animals. They need both realistic and imaginary creatures for their new edition."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: I want to build a scene recognition model capable of returning a scene type label."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: I want to detect the emotion in a given text. It should be able to classify emotions like happy, sad, angry, etc."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: We have a large set of information and we need the model to retrieve the most relevant information to a given query."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: Your company is developing a new information extraction tool to better understand and organize client inquiries. The tool must identify the names, locations, and organizations mentioned in any text."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: I want to develop a movie recommender system that sorts film titles and also recommends categories to viewers."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: Create a colored image of a blue paradise bird in the jungle using Canny edge detection."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: Our customer wants an application that suggests similar topics based on provided sentences. Can you recommend an appropriate model for this?"}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: Show me how to process an image and extract the different categories of objects present in an environment using a pre-trained model."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: We are formulating a report for our supervisor. The report contains a table with figures on the company's revenue calculations. We need assistance with generating meaningful insights and description from the table."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: We are developing a mobile app for helping people count carbs in their food, like bread or pasta. We need to classify images of these food items."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: Can you provide me a solution where I can classify the items of the household and find which room it belongs to, like the kitchen or bedroom?"}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: Our team is developing an AI assistant to help monitor and classify different objects for a security surveillance system."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: I want to build a trip assistant who can gather the information, translate it, and find the compatibility among English, Russian, and Chinese."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: A social media platform wants to generate image captions to make their platform more accessible. Help them with this task."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: Our tax team needs to extract the total amount from tax documents. We would like to use a model for this purpose."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: Our company is expanding our user base and we need to localize our web application. Specifically, to have the ability to translate Catalan text to Spanish."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: I need to extract the billing amount for a document that I have in text form."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: We are a company providing product mockups and we need to generate images of people to be placed in the mockups."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: Develop an application to recognize spoken digits from 0 to 9 in voice recordings of customers."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: I want a system that reads french texts that I send it, and play the audio for me."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: \"I recently bought a new [MASK] for my kitchen\""}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: We're working on a mobile app for automatically generating photo captions. Use the GIT model for this purpose."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: Design a system to answer questions based on the given table about Olympic Games host cities and years."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: Create a social media post summarizer for an ecommerce store that generates captions for product images."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: Our company wants to detect and avoid potholes in streets using autonomous vehicles. We need a solution for detecting pothole segments in a road image."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: I am a movie director, I want script ideas for a new movie, and for that, I would like to use AI to inform me with a story"}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: Help the client to create a competitive service to recognize objects in the images sent by users."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: The financial consulting firm that we work for needs to analyze income levels of clients based on the provided dataset."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: We need to investigate odd activities in the security footage of our school. Identify whether a violent situation is occurring in the videos."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: We want to make an application to separate people in a picture from the background. Please suggest a code snippet for this task."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: Apprehend a robot athlete who needs to be able to categorize a sports activity during practice sessions."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: My startup focuses on reducing carbon emissions. We predict carbon emissions from different commercial industries based on their energy consumption."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: A fintech company wants to automate categorization of their customer's complaints to detect sentiment."}
{"text_id": 931, "text": "document: BART (large-sized model), fine-tuned on CNN Daily Mail. BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs."}
{"text_id": 931, "text": "query: Give me a summary of a news article about the latest advancements in electric vehicle technology."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: Our company has an art gallery. We're looking for creative ideas to generate paintings from poetry and descriptions. How can we accomplish this?"}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: Our movie reviewing website wants to implement a system where it does visual question answering on a movie scene. We need to retrieve an appropriate model to be used in our implementation."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: A transcription project requires the punctuation restoration for a text in multiple languages, including English, French, Italian, and German."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: In our language learning app, we need a function to rewrite a sentence in French with the negation."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: I am the CEO of a technology company. I need a brief introduction about my company for my LinkedIn profile."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: I want to transcribe a video of a lecture in English to text so that I can read the content without listening to the video."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: We have a Russian AI chatbot which is designed to take text inputs, process them, and generate the most suitable and responsive response considering its training data. Give an example on how to proceed with that."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: Create a video from a given text describing a scene. User wants a visualization of the scene with a sunrise over the ocean."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: I am creating an app that compares user-generated sentences and compares their similarity."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: We are collaborating with interior designers attempting to create bedroom layouts. They need some initial samples to show clients."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Our company is working on a project for mapping urban areas. We need to identify and segment buildings in satellite images."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: We want a better understanding of the product by generating an image from the product description."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: Write me a work schedule module for my project management app that summarizes lengthy project updates."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: I own a hotel and want to analyze the hotel's surroundings for better marketing purposes. Identify the objects in the photo and segment them accordingly."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: An e-commerce site wants to evaluate customer feedback on various products automatically. We need a tool to determine the sentiment of product reviews."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We are developing a home security system that can respond to intrusions by identifying any people in the security camera feed by analyzing their images."}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: I am a scriptwriter. I want to add emotion to the script dialogue, and I need help classifying the emotions of some phrases that I wrote."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: I have an interview recording that I want to transcribe. I need to separate the speakers from the recording."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: We are creating an app that allows users to take photos of everyday objects. We need an AI model to classify the objects in the photos."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: We need an autonomous robot to clean a football field with glass pieces. We need to first help it figure out the pieces of glass in the field."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: We're designing a chatbot for our website. We need to summarize long articles for our users before they read them."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: I want to create ideas for a movie script based on a given prompt."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: I want to build an app to translate English text to French in real-time."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: Our HR department is reviewing candidate cover letters, and they need assistance in creating a summary for each letter. "}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: I run an agency that posts photos of cats on social media. Come up with a way to generate images to post."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: We are building a transcription service that transcribes speech into text. The product needs to add punctuation marks automatically in the generated text."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: Create an AI model to automatically classify numbered audio files from a data set."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: I need a system that compares user written product reviews in multiple languages to decide their general sentiment. Determine how similar they are to both positive and negative reviews."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: To build a story writing platform, we need a chat product to extract AI-generated stories based on the prompts."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: The boss needs a content checker that analyzes company-generated video classification and provides suggestions on the subject matter."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: Find out if the photo I have taken is a picture of my dog or something he would like to eat."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: Please predict the flower species for a batch of samples from the iris dataset."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: Our company is processing thousands of images daily, and we want to be able to classify new objects or scenes in the images without needing to retrain the model from scratch."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: We need assistance to detect different types of food items in images from our social media marketing. "}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: We are a multinational company aiming to communicate seamlessly across our branches. We need to be able to translate English messages to French."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: A startup focusing on a waiter app needs an AB testing on the predictive service charges they apply. Will the tipping changes affect the amount of money a waiter gets?"}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: We are a startup focusing on market research service. Our work relies heavily on data analysis. Assist us in summarizing a table of revenue data."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: The AI needs to read the python code. Every python code needs to be read by AI."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: Extract organization names, location names, and person names from a given news article."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive players in order to prevent cheating."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: We are an e-commerce platform that needs to automatically classify product images submitted by vendors."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: As a telecommunications company aiming to provide better customer services, we need to detect whether a given customer complaint is a service issue, a billing issue, or a network coverage issue."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: Can you tell me the organizations in the German sentence \"Die Volkswagen AG hat ihren Sitz in Wolfsburg.\""}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Our team is developing a chat analysis tool, and we want to generate abstract summaries of customer support conversations."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: The managers want to reduce time wasted on reading irrelevant emails. They need a system able to pair similar emails to speed up the reading process."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: The company is working on a project to identify key entities in business articles. We need to extract names, organizations and locations from the text."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: Our client wants to extract clean speech from a noisy conversation recorded during a podcast."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: A travel agency would like to create enticing ads. Generate a descriptive caption from one of the images they provided."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: I want to translate audio records from Dutch to English text."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: A high-end art gallery is interested in transforming a normal image of a painting into a unique version with edge details to use on their marketing materials. "}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: We need a tool to analyze images and create descriptions for art pieces in a museum."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: We are building a lecture recording application for students. We need to filter out background noise and improve audio quality."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: I need an application to analyze short videos and classify the activities within them automatically."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: Our company needs to extract information from scanned invoices in order to automate the tracking of their expenses."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: Our company's sales team wants an automated tool to answer questions about data in sales tables. They wish to extract insights from the tables."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: \"A person is eating pizza\" & \"A person eats something.\""}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: I want to transcribe spoken language in an audio file and translate the transcribed text to a different language."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: Create a script to generate a random Minecraft skin and convert the image to RGBA format."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: Our company wants to provide daily summaries of major news articles to our customer. Summarize the provided news text."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: I need an AI for my app that shows a table and asks users questions about the data in the table, based on their input."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: Our company is planning an event about outer space. We need to generate images of the universe for promotional materials."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: I want to build a movie recommendation system to categorize movie reviews as either positive or negative. Kindly provide insights on how to achieve this."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: Our company wants to provide a service that transcribes audio from Russian-speaking customers to text, to improve our communication and support."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: Create a feature in a mobile app for grocery shopping that listens to users mentioning items and automatically adds them to a shopping list."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: We are a beach resort company. We need to know how many lifeguards we need for each beach, so we want to detect the number of people present in beach images."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: Our company works in the biomedical field. We need to analyze patient reports and extract biomedical entities for further analysis."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: Many people like butterflies, and we would like to generate images of butterflies to be used in our products."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: I am a songwriter. I need help to generate chorus for my new song."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: We are working on a social media monitoring tool and need a way to automatically categorize user reviews as positive, negative, or neutral."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: We are creating an obstacle avoidance system for autonomous vehicles. We need to estimate the depth of objects in an image to accomplish this."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: Create a tool that helps people predict the market value of their home."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: For some podcasts, there is a lot of background noise. The company is now strenghtening the speech audio."}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: We have an essay in English, translate it into French."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: We need to analyze the trend of topics discussed in a Korean news text. Please provide a code that extracts features from the text for further analysis."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: We want to create engaging social media posts to increase online presence for our company. Write interesting captions about a topic of your choice."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: I want to create a tool for the visually impaired that helps them understand their surroundings using a picture taken from their smartphone and providing them with a short description of the picture."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: I want my text to be passed through the Legal-BERT model to make it applicable as a legal document."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: Find out if a music clip contains multiple sources using this model."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: Our social media application needs a feature to generate captions for user-uploaded photos while giving users the option to suggest a caption theme."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: I need a script to analyze an audio file to detect who is speaking when, for a house security system with multiple microphones broadcasting in real-time."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: I run a autonomous car startup company, and I would like to train the neural network to pinpoint the depth from 2-dimensional photos taken from a monocular camera."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: I want to build a software tool that estimates the carbon emissions of different activities by using machine learning. Help me to use your API."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: Our company wants a method to identify similar reviews to show under each product."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: Design a robotic system with a language model that can interact with users intuitively, understand their requests, and perform tasks for them."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: I work for a custom shoe manufacturing company, and we need a visual example of a new shoe design for our team to work on."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: We are a news agency, and we want to create captions for the images we use in our articles."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: Find all biomedical entities from the given text about a patient's medical history and treatment."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: As the owner of a bookstore, I need to extract relevant information on books by answering specific questions about the book."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: I need to create a table with information on several cryptocurrencies (Bitcoin, Ethereum, Litecoin) and their respective mining methods, consensus algorithms, and native wallets. Then, ask the table for the consensus algorithm used by Ethereum."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: Design the solution to detect specific words in an audio file, like 'play', 'stop', 'pause' to control a music player."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: I have a document written in English, and I want to have a draft translation into Russian."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: An app allows users to upload images and automatically classify them."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: Our team is working on organizing a large collection of images. We need to classify them into categories such as animals, plants, and objects."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: We have a noisy audio file containing a spoken story, and we need to remove the noise so that the story can be better understood by the audience."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: Our company needs to sort customer support messages into categories like refund, technical issue, account related, and general inquiry. Suggest a method using NLP model."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: Translate a statement in English to French using the super model."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: A film critic website wants to analyze its user reviews automatically. They need a tool to classify reviews as positive or negative."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: I have taken a picture of a room and would like you to estimate the depth of objects in the photo."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: Tell me how this tool can be used to measure the similarity between two sentences, as part of my research about semantic similarity."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: I have a podcast project, I want to change the voice of the speaker while keeping the same content."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: Design a virtual assistant capable of responding to user input in a conversational open-domain manner."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: Develop a system to help a drone spot any potholes on roads so that it can report them back to the local municipality."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: Complete the sentence \"The weather today is [MASK] and I love it.\""}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: A company has requested your help with implementing a depth estimation system to enhance the capabilities of their autonomous robots."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Let's build a personal voice assistant app that can recognize the type of sound it hears. It needs to tell whether the user is playing a musical instrument, a dog barking, a baby crying, or heavy rain."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: Implement a system to predict the carbon emissions of several cars based on variables like production year, kilometers driven, etc."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: Build a chatbot for the game \"The World Ends With You\" that can converse by responding to player's input in a manner similar to the game character Joshua."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: We have an image URL and want to estimate the depth information from it."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: A toy manufacturing company would like to visualize a new concept based on a description. Generate a video of a remote-controlled robot walking on a playground."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: The client wants to build an automatic video classification application to detect food waste content in their video streams."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: I am trying to classify an image of my cat or dog."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: Identify the category of the object in the provided image."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Identify tabular information from scanned documents and extract location information for the tables."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We are an auditing firm. We need to identify the invoice number from an invoice image."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: I want to develop a robot-controlled system for picking up objects. Can you help me with learning model suggestions for grasping objects in 6D?"}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: We are building a game, How can we predict the possible approaches for a robot to cross a environment."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: As a language learning tool developer, we want to simulate a dialogue in Russian using the AI model."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: In order to monitor activity at our security checkpoints, we require an automated system to classify events in the surveillance video."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: Create a tool that can recognize the emotion in a given audio file."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: I have a new marketing article for my startup, and I want to understand if the tone of the article is professional, casual, or negative."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: I'm developing a web-based application to measure distances from my computer's camera for real-time estimation of depth."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: I am a game developer and I would like to develop an AI-based tool to generate skins for Minecraft characters."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: I work in a biotechnology company, and I want to analyze scientific papers. Extract and represent the information for better understanding using BioBERT."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: Imagine you are building a content recommendation system. Could you please set up the DeBERTa large model for zero-shot classification with possible candidate labels like 'entertainment', 'technology', 'sport', 'politics'?"}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: Create a program that produces a new image by reimagining the input image. Modify the input image with guidance like \"add more trees\" or \"make the sky darker.\""}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: A comic book company wants to create a butterfly character. Generate a butterfly image to inspire their design."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: Help me train a soccer playing AI that can coordinate with its teammates"}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: My teacher gave us a French text to analyze for our homework. She wants us to identify the names of people, organizations, and places in the text. Please help me with that."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: The user is about to travel and looking for tips to prepare for their journey. Create a list of informative passages related to travel tips for their journey."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: We need to send a business proposal to a Chinese company, but it's written in English. Translate the English text into Chinese using a reliable language model."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: health, business, sports, entertainment."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: We want to provide automated help to our board game investment community by being able to answer questions related to a given game's data table."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: I am an ecology researcher, I don't know what this flower is, can you help me tell based on its features?"}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: We would like to transcribe an Arabic podcast so that our non-Arabic speaking audience can access the content."}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: A company that focuses on art restoration needs to upscale low-resolution images. Help them to upscale the images using Swin2SR model."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: Design a system to recognize objects in an image based on given textual descriptions."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: The company has offices in Finland and the US, and there's a need to translate Finnish documents into English. What method do we use to make this happen?"}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: As a language teacher, we need a tool to recognize audio samples from learners to teach pronunciation."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: I took a photo and want to know if it contains a dog or food."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: We are organizing a virtual costume party, and we need to automatically judge the costumes of the participants from the uploaded photos."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: Design an autocomplete function to predict the missing word in a sentence."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: I have a scanned image of a technical manual from which I want to get a textual description. Can you create a code snippet that takes the text from this image and answers my question about it?"}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: We are collaborating with a wildlife conservation agency. They need help in classifying animals in their natural habitat."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: My company wishes to analyze customer care calls and automatically identify the emotions of the callers."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: Our company has recently developed a new toy robot for children. We need to build a classifier for the robot to recognize objects in pictures."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: Our research group has just completed an extensive scientific paper, and we need your help to provide us with a summarized version of it."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: Our company is developing a tool to predict the carbon emissions of a product based on its specifications. The tool needs to automatically analyze the product data and predict the carbon emissions as low or high."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Our company wants to generate a natural language summary of a long text input. Build a solution using the bart-large-cnn-samsum-ChatGPT_v3 model."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: We are a security company, we need a tool to verify travellers coming in hotdog compedition. Create a tool to check if a transportation ticket is attached."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: Our company wants to develop an AI player for the classic video game Pong. We need to set up a reinforcement learning agent to play Pong."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: Can you help me estimate the depth of objects in an image?"}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: Our team is building a new video conference app that removes noise from the microphone. We have an example .wav file wich we want to improve."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: Analyze a news article and determine which categories it belongs to."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: Develop a solution to predict CO2 emissions based on data provided by the factory's various sensors."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: Design a way to create a clear speaking audio file for our podcast which has automatic speech transcription."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: You are building new tech alert system such that a user can enter a problem or a query, and an email with an appropriate solution is sent."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: Our team is working on a speech translation app. We need our system to identify the language of a user's speech before translating it."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: Our company is working on a virtual reality project. We need to develop a method that converts textual descriptions of scenes into realistic video content."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: I want to know the number of boats in a picture of a beach."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: I have Chinese documents, I want to translate it to English to publish in foreign publication."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: My company needs to make decisions on recommending products to users based on their text reviews. We need to analyze the sentiment of those reviews."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: We are creating a digitization system for handwritten documents. We need to transcribe the text from scanned historic handwritten manuscripts."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: The tech company has decided to develop products in Vietnam. One of the features is an automatic speech recognizer that can recognize and transcribe Vietnamese audio."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: We have a call center and want to automatically analyze when a speaker starts talking and when stops talking."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: A marketing team wants to analyze movie trailers by automatically classifying emotions conveyed in scenes."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: A travel company wants to have an AI assistant to respond to the most frequently asked questions. Create a demo to generate a text answering a question about visa requirements."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: Our team is working on a project to extract the main points from multiple scientific articles. What model would you recommend to automatcally summarize the articles?"}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: We are now working on a project about different species of birds. Our client wants to know which bird species lay eggs in conifer trees."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: I took a picture and I need to know how many dogs are in the picture. Please analyze the image and answer the question."}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: Develop an app that performs sentiment analysis on Spanish texts."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: As a company specializing in document management, we need to extract the text from scanned images of printed documents."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: An AI-based Robotics company is exploring to developrobotic systems. They want to integrate depth estimation functionality for better object detection and navigation."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Imagine that I am the head of a marketing company, and I want our new chatbot to help sell our products. Can you create a conversational AI bot that will interact with our potential customers?"}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: I'm developing a fitness app and I want to automatically detect a person's activity in the video."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Our company is expanding its operations to Russian-speaking countries, and we need to quickly gather summaries from Russian news articles for our strategic planning department."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: A game company wants to use DDPM to procedurally generate high-quality avatar images."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: Create a voice response to a question, \"How are you today?\" in Arabic."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: \"A beautiful sunset over an ocean with a dolphin leaping into the sky.\""}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: I own a restaurant, and I want to find the positive reviews and the negative reviews automatically."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: Design a chatbot that replies to a user asking, \"What's your favorite color?\""}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: We are running a local news agency, and we need to analyze the sentiment of the financial news we collected today."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: As a software development team, we are working on an autonomous car project. We need a depth estimation model to perceive the environment around the vehicle."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: Assist the finance department in finding insights from their sales data table."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: Develop a new algorithm for addressing the limited availability of labeled data in a project that predicts income based on United States Census data."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: Create a code summarization function for our web development platform that gives a brief summary of any Python code block provided to it."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: I am a teacher, and I want to autofill some words in a sentence that my students are struggling with."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: We want a summarized version of a news article about Rishabh Pant's statement on a recent incident during a Test match."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: We are a multinational company and we need to transcribe a Chinese recording. Please provide a solution for this problem."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: Create a model that can fill in the blanks with the correct words in a given text."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: We are building a robot that performs object manipulation tasks. We need to use the pretrained VC-1 model to analyze the environment in front of the robot."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: We need to create a sentence corrector for our chatbot. Please make a sentence corrector to have our chatbot provide error-free responses."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: Help me build a model for processing French texts. In particular, I need to extract named entities like people, places, and organizations."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: We are building a social network for language learners that supports multiple languages. When a user enters a new phrase or expression, they want to learn in their target language, we want to provide the nearest matching expressions in our database that have similar meanings."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: A real estate company requested an estimation of the depth of an indoor scene based on a given image."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: We received an assignment where the instructor sent a mixed image between cat and dog, and the instructor was asked for the number of cats and dogs in the image."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: Implement a method to convert text into speech and obtain an audio in Russian for product demonstrations."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: I am running a chatbot and I want the chatbot to have natural human conversation skills. It should be able to adapt to different situations and roles."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: I am developing an AI model of an expert HalfCheetah robot in Gym. I want the AI to control the robot's movements and actions based on the input data from the environment."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: Generate a short story that starts with \"Once upon a time in a far-away land\"."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: A startup is developing a smart traffic monitoring system. We need to identify road traffic participants in images."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: We are a landscape architecture consultancy and need to develop an autonomous drone for site mapping. The drone will use images to generate semantic segmentation to help us better understand the environment."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: Design a simple name declaration using the given masked language model and data."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: We are a matchmaking application. Our AI-based matching algorithm uses face detection to match similar facial features. We need to generate a variety of human faces for testing the algorithm."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Create a natural language conversational model that can respond to users' questions and comments. The goal is to enhance user experience on our website."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: An international company has employees from different countries. We need to provide translations for important documents for clear communication."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: A historian needs help to recognize, read and translate handwritten texts."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: We built a smart city project focused on better understanding human behavior. Analyze a video and classify the activities performed in it."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: \"I hopes you got recieved thes attachmen with the report we discussed in meet yestday and pleas share you're opinion.\""}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: The CEO asked me to provide a summary of our company's financial sentiment from our latest analyst reports. Analyze the sentiment and generate a summary report."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: Develop a robotics assistant that can learn and make decisions to perform specific tasks using the Antheia/Hanna model."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: Your client uploaded a list of similar sentences and wants you to cluster them to find the most similar groups."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: Produce a transcript of an audio file containing a talk in Hokkien to be translated into English and transformed into speech."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: Estimate the weight of a fish based on its length, depth, width, and height measurements."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: I would like to generate high-quality, photorealistic images of human faces."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: We want to evaluate the AI capability of automatically analyzing whether humans and animals can be correctly segmented in a given image."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: I want to generate a piece of art inspired by WikiArt. How can I use this API to achieve my goal?"}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We need to analyze pictures for an auction company to figure out whether the animal being auctioned is a cat or not."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: There is an art project that needs help analyzing video clips and organizing them by categories. We need to determine what the video is about."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: I need to create a system to generate realistic human faces. We need to create a model that can generate 1024x1024 images."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: As a company developing a quality control for fruit farming, we need to segment images that show different types of objects and plants."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: Our construction company is working on a project and we want to ensure that all workers are wearing hard hats. We need a method to count the number of workers wearing hard hats in an image."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: I want to summarize a long news article in Chinese so I can quickly read about the main topic."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: Our startup wants to create a product categorizing Chinese cuisine dishes based on photos uploaded by users."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: Our platform is an e-learning and content creation platform, we would like to analyze the emotion of our users' voices in our video feedback system."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: I want a digital catalog for the food industry, and I want them to recognize if the food is considered a hotdog or not."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: Our company needs a tool to separate speaker voices from background noises in a recorded podcast."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: I am working on an application that suggests interior designs for rooms, and I want to estimate the depth of the room in the photos provided by the users."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: I\u2019m working on an app that assesses the quality of images for photographers. Help me classify images."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: Develop a chatbot for a website to translate speech from Hokkien to English and synthesize English speech for the users."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: We want to create a podcast transription that skips the silent parts. Detect the active speech segments of the audio to help us transcribe only the spoken parts."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: Detect the language spoken in an audio recording."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: I work for a movie website and I want to know the general sentiment of movie reviews before publishing them on our website."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: \"Benvingut al museu. La sortida est\u00e0 al final del corredor a l'esquerra.\""}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: I want to retrieve the text from an image on this URL https://i.postimg.cc/ZKwLg2Gw/367-14.png."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: We need assistance with answering questions during a history quiz meet."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: A company needs assistance in translating Italian user reviews into English for further analysis."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: We need to sort the images captured by the company's security camera into categories like human, animal, vehicle, and others."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: In order to provide the quick and accurate summary for a given text, create a summarizer for a news website."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: Build an AI model that takes an image of my room and a question about the room, and provides an answer to the question."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: Help me classify an email written in German into categories such as 'crime', 'tragedy', and 'theft'."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: Create a system that can fill in the missing words in a given Chinese sentence."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: I want to automatically generate various images of cats."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: Adapt a software to support accessibility features for visually impaired users. The software will read text from articles, and provide spoken output."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: A sports site is querying the Olympic Games data. Find out in which year Beijing hosted the Olympic Games."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: We need a chatbot that can interact with users and generate variety in its responses. Can you help provide different ways to express the same thing?"}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: Create an application to identify if a given image is a cat or a dog."}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: We are a high-tech startup that want to build a helpdesk bot. Help us creating a bot that is able to answer grounded questions."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: As a dean of a college, I want to analyze some course data containing course id, course name, and number of students. I will be asking some questions related to the courses."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: A small company is trying to create an image classification system to identify objects/categories in various images."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: Our client is a language school. We want to offer a new audio language translator tool to the school, so they can use it in their classes."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: Develop a system that can provide real-time object detection for a security camera."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: I need to identify wildlife animals from images taken by a trail camera."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: A farmer needs a solution to diagnose bean disease from images of bean leaves."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: As a public relations company, we need to help our clients with voiceovers for their ads. Please generate a voiceover from a text script."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Our company is working on an AI-based psychological counseling system. We need to identify the emotions present in the clients' speech in the German language."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: We want to develop a game chatbot. The users input sentences with missing words. The chatbot should fill in the blanks to make the sentence coherent."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: I am a student who wants to find an answer to my question. Can you find the answer from the following paragraph?"}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: We are building a software for foreign students to improve their English writing skills. We want to implement a grammar correction feature."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Our design team is preparing a children's book about space adventures. They need an illustration depicting a colorful spaceship on Jupiter's surface."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: We are a start-up that wants to classify whether a car emits a high or low amount of carbon emissions based on its specifications."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: In order to automatically transcribe a conversation, we first need to detect when someone is speaking."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: A group of language learners requested a tool that translates English texts to French. We need to develop this tool."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: Our team needs to build a software that is able to generate code in Python given natural language descriptions about what the code should do."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: I am learning Chinese and want to predict the next word in a Chinese sentence. Can you help me to predict the next word based on context?"}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: I want a program to detect and recognize the license plates of different vehicles so that I can automate the parking process."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: I have an article written in Chinese, which I want to summarize."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: We run an online podcasting service. Our new requirement is to help our users easily separate speakers in their recordings."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: The company is working on a new product that summarizes legal documents. To save development time, they would like to use a pre-trained model that helps answer questions about a document."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: Our company needs an artificial intelligence model for generating realistic images of church buildings for a virtual reality simulation."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: In an urban development project, we want to analyze satellite imagery to identify different types of land usage (for example residential, commercial, agricultural, green spaces)."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: Describe how to create captions for images using the 'git-large-coco' model and display a textual description generated by the model for any given image."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: I want to create an AI art exhibit that will integrate text or description with images and generate a unique art piece based on the input."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: A simple cart needs to balance a pole as long as possible. Implement the functionality to enable the cart to do that."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: Develop a chatbot to filter out gibberish messages before answering user queries."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: We have a meeting with a French partner tomorrow, but our translator is not available. We need to communicate with the partner in French."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: We have been collecting customer feedback for our airline. We need to summarize the conversations happened at the help desk."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: We are establishing a publication firm for financial news. We need to condense long articles from file 'news_long.txt' into summaries."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: Can you tell me more about the text-to-video in the Hugging Face? We are working to run a use case on generating a video description of what happened in the provided text. "}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: An environment agency wants to predict CO2 emissions from a given dataset containing several features."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: A homeowner needs a device to identify whether an animal in their backyard is a cat or a dog. Design a solution for them."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: I have drafted some text for a German voicemail greeting. Help me create an audio file from this text using Text-to-Speech and save it in WAV format."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: Our team needs to design an intelligent security camera system. We want a program that categorizes video clips from surveillance cameras as safety-related or normal activities."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: We are running a library service. A user needs to know the date the document was published. "}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: Our marketing team needs a solution to analyze positive and negative comments on the company's social media pages."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Our design team is conducting a project to generate taglines based on images. We need to extract meaningful information to be further used as inspiration."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: Our company needs to perform quality control on the wine we produce. Can you provide a model that can help us classify the quality of our product based on its chemical properties?"}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: I'm an educator creating a study app for students. I want to provide an image description option so students can understand the image better. Separate options for animal or sport explanations are provided depending on the context of the image."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: I am designing a game and want to include a DQN agent playing the game. I need to find if the agent can play the game easily."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Create a routine to analyze fundus eye images for diabetic retinopathy detection within our medical application."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: I am trying to build a voice assistant to recognize human emotions like sad, happy or angry."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: \"Nous devons moderniser notre \u00e9conomie et rendre notre \u00c9tat plus \u00e9conome.\""}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: We require a model for detecting planes in aerial images as part of our company's airspace monitoring platform."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: Your family is hosting a party. You need to select all photos with people celebrating."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: Develop an application that can convert French text to speech using a pre-trained model for French language."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: We are developing a chatbot for the Chinese market. We need to find similar sentences from our database to provide the right answers to the user's question."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: I have a noisy voice recording and want to enhance its quality using an audio-to-audio API. How do I do that?"}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: As part of our transition to environmentally friendly energy consumption, we need to predict which homes have higher carbon emissions using historical consumption data."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: As a media company, we need a way to convert text to speech for an upcoming podcast project."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: I am in need of a language model that can complete the missing word in a sentence. Can you provide me with an example setup?"}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: Design an AI system for me to identify the speaker from an audio file."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: Develop an AI for making announcements at train stations, based on written text. The target audience speaks French and expects a male voice."}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: Create an AI bot for online gaming platform to filter out offensive and inappropriate comments during chat."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: We are looking to build a fictional character introduction segment for our new role-playing game. They should describe their name, profession, and some unique feature."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: We are collaborating with a health and fitness company. We need to classify their workout videos into different types."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: My niece is going to have a presentation on Python Programming language and wants some questions to practice."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: I need my AI to perform similarity comparison between given sentences in multiple languages like English, Italian, and Japanese."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive and identifies whether they are terrorists or counter-terrorists."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: We work with an environmental organization and would like to predict the carbon emissions of various sources."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: John plans to automate the writing of blog articles for his website by generating content using the model. Describe how to implement it."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: Joe, a programmer, has a resume full of data, but we only require the name, location, and company he worked for. Can we extract the specific information from his resume text?"}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We are an environmental organization, and we want to estimate the carbon emissions produced by a set of processes."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: We have a user interface design company, and we need to generate the HTML code from images representing website design."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: Find out what object is present in a given image URL."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: As an autonomous vehicles manufacturer, we need to estimate the depth in our cars' camera images to ensure safe navigation."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: We are a company that works with products based on the internet, health, and politics. Analyze the sentences from the available news articles, and determine which category they fall into."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: I have two sentences from a news article but I am not sure about their relationship. Classify the relationship between two sentences from the news article as contradiction, entailment, or neutral."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: In a psychology project, we are trying to recognize emotions in spoken language. We need a model that performs this task."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: I'm creating an automatic email response system for customer support in Germany. To better serve our customers, I need to prioritize the inquiries based on their urgency."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: Develop an application for us to identify the breed of a dog from a picture."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: I am a researcher, I need to find similar Chinese sentences to \"\u4eca\u5929\u5929\u6c14\u4e0d\u9519\" among a list of sentences."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: A user is writing an email and needs assistance in filling in missing pieces of the sentence for it to make sense."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: We are a popular music streaming service that wants to recommend indie songs to its users based on their preferences, and we want to identify various indie song artists."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: I need your help in extracting features from the source code. Any hints on how to do it?"}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: Develop a script that uses a pretrained NLP model to complete sentences with missing words. The script should take a sentence with a masked word and predict the most likely word to fill in the blank."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: I want to create an app that allows users to translate spoken languages in audio format without converting them to text first."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: My main concern is to understand the text content to improve SEO. Analyze the text content based on the part-of-speech (POS) tagging model."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: I need to generate a questionnaire from a given topic to engage with the audience."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: The company is working on autonomous cars. I would like to estimate depth from images to understand the surrounding environment."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: I want to differentiate between positive and negative emotions and their intensity while reading social media posts."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: technology, crime investigation, and teaching."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: Your task is to design a noise reduction system for voice recorders. Get rid of the noise from the input file."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: Create a feature for a tourism website that answers questions from visitors about popular places and attractions."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: As we are preparing a report on biodiversity in a particular region, we collected several images of flora and fauna. Now, we need to identify the species present in the images using text queries."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: We are a company building a conversational AI. We want to utilize a pre-trained model to find the best response from a set of possible responses based on a user's question."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: We have a device that needs to give a brief summary of news articles. Help us configure it with the Pegasus summarization model."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: We want to create a decision-making system for our robotic arm to decide where to grab objects on the conveyor belt."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: The company wants to analyze audio files to identify the type of content in the audio. We need to understand the features of the audio files."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: We need to convert a chart image to a tabular data format. Also answer a question based on the data."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: \"Ich habe heute keine Zeit, ich muss zur <mask> gehen.\""}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: Develop a solution for separating mixed voices or background noise in an audio clip to improve its clarity."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: I want to transcribe a recorded conversation between three people that are discussing a project."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: We are building an e-commerce platform for selling fish, and we need to predict the weight of a fish based on its measurements."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: Our company is developing a smart security system with video analysis. We need to identify activities in the videos captured by the system."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: Create a summary of the top developments in the field of robotics from the last decade."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: We're here at the product launch of a new virtual assistant. It can create videos using input text. Tell us about it."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: Provide a solution to support different languages in our customer support system that can answer questions related to our products and services."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: Translate a text from Chinese to English."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: The marketing team needs a tool to transform textual descriptions of their products into promotional videos. Build a model that can create videos from text."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: My computer vision system needs to provide answers to questions about images automatically."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: For my research, I need to extract names of people and places from a certain text in multiple languages."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: I am developing an app to automatically transcribe voice recordings in Indian languages. What can I use to identify which parts of the audio contain speech?"}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: We are working on a comic book, and our artist has provided a line art image. I would like you to colorize the line art based on a prompt \"superhero fighting an alien\"."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: I would like to have a way to measure the similarity between different sentences. How can I do that?"}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: A company needs help with cataloging plants in their nursery. They have provided an image of one plant and would like to know which plants it has in the photo."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: We are traditional martial arts masters seeking to promote our teachings. As a content writer, highlight the similarities between the two sentences provided."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: We are a news agency and we need a system for automatically extracting the names of persons, organizations, and locations from articles in multiple languages."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: The manager wants a technology solution to find named entities in various news articles."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: A parent company is designing a child security monitoring system. They want to detect if a child is using a dangerous object (e.g., a knife or a hammer) based on their monitoring image."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: To help our clients with conference calls, we need to separate human speakers from the noisy background."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: Can you identify the topic of the given sentence from candidate labels?"}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: During the search event, we want to create an art to represent the company values. The design should be inspired by dolphins swimming around in a spiral pattern."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: Collect abstracts of research papers in Chinese language and find the pairwise similarity scores between all the collected abstracts."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: Our partner in the educational sector is preparing a question bank. We're going to develop a question and answer program to help them generate questions and corresponding answers."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: Our team wants to apply vision-based depth perception for an autonomous vehicle application. Estimate the depth map of an input image."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: Design a chatbot by using transformers model to generate response given an English description of the code."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: Create a voice activity detection model that can be used in conference calls to separate speech from background noise."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: We would like to enhance the audio quality of an old recording that we've dug up, and minimize background noise if possible."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: Need to locate the contract's party names written on a document with text and boxes."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: A car magazine wants to use AI-generated art in their next issue. They are specifically looking for a 1950s-style illustration of classic cars parked at a drive-in movie theater."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: \"The quick brown fox jumps over the lazy dog.\""}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: Customers at a transcription company have complained that their audio recordings have overlapping voices. Use audio source separation to clean up the audio files."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Create a chatbot that can have a conversation and provide empathetic responses based on a given dialogue context."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: Help us to translate an Italian subtitle to English for video communication."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: Our team wants to develop a software to detect the active speech from a recorded conference call."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: I am designing an advertisement for a new smartphone, and I want to create a video showing people using the smartphone in everyday situations. Can you suggest a model that can translate a description into a video?"}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: We are a sports analytics company looking to automatically recognize different sports activities in a given video."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: We have a virtual tour application and want to answer users' questions about a picture they are seeing."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: I have a prompt, \"A superhero jumps over a building and saves the world from\" andLooking for a short creative story based on that prompt."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: I would like to create a video library containing action movies that provides relevant information about the movies' content. Can you suggest a model and how to use it for this purpose?"}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: Our team needs to extract entities from user texts to better understand their content for tracking purposes, without exposing sensitive data."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: As a safety supervisor, I want to inspect the construction area automatically. For this, a program needs to be built which can analyze images of a construction site and identify workers wearing hard hats or not."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: To mitigate climate change, we want to calculate the carbon emissions of our company's vehicles. Find a reliable method to predict the emissions based on input data."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: The government has hired the company to analyze satellite images. We are supposed to check if there is any deforestation happening in a certain area."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: I am trying to extract information from a document, the text position is essential. The document has a table, I want to know more about the table details."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: As an analyst, we need to extract insights from visual data in charts. Produce a textual explanation from a given chart image."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: Design a function that summarizes the key aspects of a text and provides answers to questions about the text."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: I need to write an article about the impact of Artificial Intelligence on the environment. Please help me draft the introduction."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: I want a software to determine if an individual earns above or below $50,000 per year. Use the column information in dataset 'scikit-learn/adult-census-income'."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: \"A bright and colorful banner showcasing a variety of beautiful flowers in a lush garden, with a clear blue sky above and the sun shining brightly. The text on the banner says 'Welcome to our Gardening Extravaganza' in an elegant font.\""}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: The manager of a carbon trading company wants an estimation of CO2 emissions generated by various plants using their historical data. Calculate the CO2 emissions."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: We are an online discussion platform. We need to categorize the user-submitted content autonomously into different categories."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: I'm working on a project to detect whether an anime art is generated by an AI or made by a human artist. Let me know the best model for this problem."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: positive, negative, or neutral."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: As a magazine cover designer, we need to create some visually attractive variations of the original image for the upcoming edition."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: We want to classify images of animals with zero-shot learning."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: Our customer wants us to design a stimulating interior design for their bedroom."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: We are writing a blog post. Determine the primary source of origin for the chess sport."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: We are developing an AI system that could transcribe spoken English from a series of podcasts."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: As a customer support team, we are developing an AI chatbot to handle the queries of our customers so we can focus on more complex issues."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: I am working on a project that needs to answer questions using the given context. Please set up a solution for me."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: Generate audio output for a podcast. The host welcomes the audience and introduces the guest, Dr. Jane Smith, a robotics expert."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: politics, economy, entertainment, and environment."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: In a software development project, we need to estimate the distance between objects and cameras in 3D images to enhance user experience."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: Create a system that can answer questions based on a given context."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: We have a batch of scanned documents and need to extract information by answering specific questions about the content."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: We want to create an illustration of a character with pink hair and blue eyes for a book cover."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: I need to estimate the depth of objects in an image for my robotics project."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: We are designing a video sharing platform. In order to organize our videos into categories for easy searching, we want to automatically assign tags based on their content."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: A real estate company is developing a virtual reality tour app for potential buyers. The app features 3D reconstructions of the available properties for a more immersive experience. We need to estimate the depth of images captured inside these properties."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: Our client is an international trading firm that needs a program to analyze Chinese texts. Specifically, it should analyze and tag parts of speech."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: We have a list of 100 factories with their operational details. We need to predict the amount of carbon emissions each factory will produce."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: I am a startup in charge of live performing street arts. I am working on generating a video on some specific topics with AI."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: I have an audio file I recorded from an unknown person, tell me the spoken language."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: Samy is an artist who wants to obtain the top classification to recommend on his Instagram page. Could you check if the system is able to classify images?"}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: I manage a delivery company that has a dataset of customer details like name, address, contact number, package details, and delivery date. I need to find the address of a specific customer named \"John Doe\"."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: We have a software that needs to process a long context and answer questions based on it."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Detect tables within documents to automatically process data. We should be able to identify both bordered and borderless tables."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: A car company is looking for a solution to predict the carbon emissions per distance of their vehicles, based on their specific attributes."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: what piece of clothing is the boy putting on?"}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: We are a fashion blog and our latest post is about futuristic fashion. Help us to generate an image of a woman wearing a dress made of some futuristic and sustainable material."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: I am writing a fantasy novel and want to create illustrations for my characters based on the description of each character."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: The new project is about classifying basketball action videos to find out dribbling, passing, and shooting sequences."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: The company focuses on environmental sustainability. We need to predict carbon emissions accurately to help monitor and reduce the company's environmental impact."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: We have a pile of invoices from various suppliers, and we need to find which one has the highest total on the invoice."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: We need to create an article related to image recognition technologies. The article will require captioning images based on their contents. Can you help us with this task?"}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: Create an illustration of a castle surrounded by mountains and water, using AI to generate the image."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: I'd like to create an application that helps users identify whether a picture has a cat or a dog."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: A psychological center needs a chatbot to assist clients."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: Extract features from a medical text to analyze and represent the medical concepts and relationships within it."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: We are a game development company, and we want to add a trained AI to control our cars in the game."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: The customer wants to run analytics on historical transactions of their e-commerce store. They have a large dataset with several columns, including date, product name, price, quantity, and category. Help them to answer \"what is the total revenue generated on July 15, 2021?\""}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: I am a web designer and I want to extract a simplified HTML structure from a given web page screenshot."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: An artist is looking to create a painting inspired by a synthesis of cityscape, nature, and fantasy elements. Generate an image based on their requirements."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: We have a blog website and for better user experience, we need to correct the grammar of blog posts."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: We are an audiobook production company. We need to predict and restore missing punctuation in the provided English text."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: I want to build an app that translates real-time social media posts from different languages into English."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: I am an attorney, and I want to extract text from various court document images for reviewing the cases. Can you help me out?"}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: We run a podcast and after every episode, we want to convert the audio to text to make a blog post. We employ individuals from all around the world who have different accents and languages."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: I'm creating a personalized virtual avatar for my online gaming account. Can you help me generate a high-quality face image that I can use as my avatar?"}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: Our team is working on an AI project that analyzes news articles. We need a way to identify similar headlines."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Our customer service team is facing a huge volume of user requests. We need a solution that can generate comprehensive summaries of lengthy customer emails and messages."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: In the advertising field, we need to make a speech for our product. Please convert the following text into synthesized speech."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: Translate a Swedish message for a user into English for better understanding."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: We are developing an AI-based counselor that needs to recognize the emotional state of the user speaking."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: Your friend asks for help in summarizing a book chapter which can give them an idea about the content in a shorter version."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: Develop an app to summarize articles for a French-language news agency. It should extract the important named entities such as people, organizations, and locations."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: As a university, we want to make our lectures more accessible to a foreign audience. Help us to create an audiobook from our lecture transcripts."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: We are developing a robotic hand to automate manual tasks in a warehouse. The robot must be able to pick and sort objects optimally."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: Design a text-to-speech system that can synthesize speech in French from text input for an audiobook."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: We're designing a gardening app which is capable of recognizing various types of plants. Help me implement a feature to identify the plant from an image the users provide."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: We have recently adopted a dog from a shelter. To improve its training, we want to create an app that can automatically recognize dog breeds from images."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: We need to ensure safety on our construction site. Detect workers who aren't wearing helmets using a computer vision model."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: A pet shop hired us to make an app that uses AI to classify animal species. We need to classify if an image contains a cat or a dog."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: I am a student, I want to extract the information from the school grade report to analyze my academic performance."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: A client asked us to produce a website header with the image of \"analog style city at night.\""}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: Our company is designing a robotic arm for automatic assembly. Can we apply reinforcement learning to train the robotic arm to perform the assembly task?"}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: I am a traveler user. I just took a photo of a landmark, and I need to know how many people are in this photo. "}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: I have an important article I need to read, but I don't have time to go through all the details. Generate a summarized version of the article for me."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: I'm working on a multilingual website, and I need to autocomplete some specific translated phrases. What is required?"}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: Use the model to compare two pieces of text and return the logical relationship between them."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: We are a team of researchers studying public opinion on social media. Help us find the similarity between different tweet texts."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: Detect the theme of a German text to know if it is urgent or not."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: We are a clothing retailer who wants to create images of garments with certain patterns or designs based on text input. Provide a solution for this problem."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: We are marketing a product with the text \"Discover the wilderness\". We are tying to make a poster for it."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: Build an ecommerce website that helps customers in answering their queries about the products with the help of a model that can answer questions based on the product images."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: Develop an embedded model to create document-level embeddings of a list of research papers."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: I want to create a question encoder that can be used to find an answer to any question about dogs."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: Translate the product description text from Italian to English."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: Our business in the hospitality industry requires us to translate English spoken by our guests into Hokkien for our local staff."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: Our client has a kids learning application where kids learn counting from 0 to 9. They want to classify the audio recording of kids counting."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: We need to generate a question from the context and answer provided by the user."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: Build a mobile app that can identify different kinds of plants with the help of a model, so that users can find out if they have come across a poisonous plant while out in nature."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: We have recieved a photo from a drone. Create a newsegmentation of objects in that photo to help us identify different objects."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: Our customer wants to detect age groups from audio files. Is it possible using your API?"}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: A law firm needs assistance in extracting the primary question from a legal document."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: Our company needs a way to automatically classify actions performed in a series of videos collected from various sources."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Develop an assistant to detect genre of a song in a .wav format file."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: Our client is an artist in California, his request is to see a visual representation of the beach with palm trees and a sunset."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: We are a transcription service company and we need to restore punctuation in transcribed spoken language."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: As a company, we work with large datasets frequently. We need to extract answers from tables by asking relevant questions."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: Develop a fitness app that can identify the exercise being performed by the user in a video feed, and display the name of the exercise."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: We are running an e-commerce company. Our support chatbot should generate a funny message in the style of Elon Musk."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: My cousin has a birthday party coming up and would like to have a promotional poster created for it. I want a character with blue eyes, long pink hair, and wearing a party hat."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We are a bank that needs a solution for automatically processing client applications. Extract data from document images."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: I am designing customer support software. I need to find similarities between customers' questions and pre-existing articles in our knowledgebase so that we can suggest relevant information during a chat. "}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: As a restaurant owner, I want to predict the amount of tips my employees would receive based on the customer's total bill, in order to better understand my business."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: An artist is looking for a software tool to help them complete their unfinished artwork by filling in the missing parts."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: Develop a script to automatically detect objects in an image and generate a segmented map of different objects."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: A video game developer wants to implement an emotion-based dialogue system in their upcoming game. The game's characters should respond based on the emotion of the player's input in German audio."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: Develop a tool that can generate video snippets based on a textual prompt to showcase the latest technology trends in a conference."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: I am a writer working on ancient scripts. I have an image of an ancient stone with some text on it that I need to convert to computer text."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: We need a system to quickly classify a product review as positive, negative, or neutral."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: The hospital wants a system to detect blood cells in microscope images. Please set up the model to identify the blood cells."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: Create a program for real estate platforms to predict the distance from an outdoor image of a house to its nearest neighbor using depth estimation."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: Write me a brief discussion about the future of artificial intelligence."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: We are looking for a way to create unique Minecraft skins for players' characters without using any input or condition."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: As a language learning app, we want to find the similarity of two sentences in terms of their meaning in different languages for multilingual users."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: We are building a search engine for finding relevant articles with similar content. We need to use sentence similarity information."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: Our team is working on understanding and classifying actions from video clips. We need a model to analyze the videos for us."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: In a video-conferencing application, we want to implement a feature that detects when a participant is speaking in order to create transcripts and improve user engagement. We need a solution that can detect voice activity in real-time."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: I am a scientist working on a paper, and I need a system to paraphrase some of the sentences in my paper to avoid plagiarism."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Provide information about this artwork that was posted on our website to classify it into the relevant category."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We are creating a game and want to add AI soccer players that can play against human opponents. Use the pretrained agents to add this functionality."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: "}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: We have a specialized news service that needs a reliable way to classify which topic an article is about among politics, sports, and technology."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: Our company website has both English and German customers. We need a solution to display our content automatically in both languages."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: I am building a Japanese assistant for my home. I need it to read text in Japanese out loud."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: A company involved in document digitization wants to detect tables in scanned images of documents."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: Create an application that helps Arabic users learn to play instruments by transcribing and translating YouTube content to text for music lessons."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: Our company needs a tool to analyze user feedback and classify it into emotions like anger, disgust, fear, joy, neutral, sadness, and surprise."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: I'm working on an application that can generate a relevant caption for any given image. I want to set up a pipeline that will use the Git base model to output a suitable caption."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: Generate me several versions of a creative story or poem about dealing with rainy days, using GPT-2."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: Our sales department needs a chatbot that will engage with the customers and provide product information when asked."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: Suppose I am a tourist guide and helping Italian travelers visiting the United States. I want a model to translate an Italian text to English."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: Develop a chatbot to help users find local theaters and events in the Russian language."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: Our marketing team needs a tool to analyze videos related to our products to understand customers\u2019 actions."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: We would like to generate a short video using the text \"A cat playing piano\" as a prompt."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: Help me predict the future electricity consumption for the next three days based on the historical data."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: We wish to make a German medical document accessible to our Spanish audience by translating it."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: Our application needs a feature to identify entities in the user's text messages."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: Create a zero-shot text classification to label news articles into relevant categories."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: As a researcher, my goal is to automate the process of anonymizing sensitive information in the dataset."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: We have a user-facing app that collects customer feedback. It uses an image sent by the customer and a relevant question. Provide a mechanism to get appropriate answers to the given question."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: We are a creative agency and need to generate visual content ideas for an advertising campaign based on the new electric car launch."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: To improve our online support, we need a tool that can translate customer questions from Portuguese to English."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: Our customer needs a creative description for a product. Write a paragraph describing an innovative high-tech vacuum cleaner."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: We want to classify videos that involve cooking. Identify the model and suggest a possible approach."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: I am looking for a computer vision model to identify the type of beans in a given image."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: Write a complete sentence in Portuguese and fill in the missing word to make it meaningful."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: Analyze a dataset about the host cities of Olympic Games to find out which city organized the games in 2008."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: To expand our blog reach and cater to a Spanish-speaking audience, we need to translate our French blog posts to Spanish."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: A store owner asked us to write software that identifies and predicts which type of product is in the picture."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: Create a Python environment that helps me predict carbon emissions based on various input features. "}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: Our marketing department wants to convert all recorded customer feedback to text to analyze and improve our services."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: We are building an advertising campaign and want to create videos based on text descriptions. Generate a video of a dog playing with a ball."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: We have a chart image, and we want to fetch the underlying information from the chart as text or a table."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: We are building an AI-driven speechwriting tool for the company and are in need of a way to generate a starting point for a speech about technology."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: We need to create an audiobook for children. We would like to convert a given text to speech in a Taiwanese Hokkien accent."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: I am working on a project that identifies the closest answers to the questions about tourism. Can I use a Question-Answering model to accomplish my task?"}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: I want to create a tool that automatically predicts whether movie reviews are positive or negative after reading them."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: There is a new traffic management technology being developed, and we need to provide an AI module that can help classify images from the traffic cameras."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: The company is building a personal assistant for organizing CEO's flight bookings and generating answers to user's flight-related questions. For instance, when CEO's friend asks \"What's the flight duration from New York to London?\", the system would generate the corresponding answer."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: I am a financial analyst, I want to estimate the income of customers from their available data in a csv file, named 'customer_income.csv'."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: Develop a technology that checks typos and corrects sentences from resumes and cover letters during a job interview."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: I am a filmmaker creating a series of short films. I need to sort them into genres like thriller, sci-fi, romance based on their plot description."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: A small fashion startup is looking to generate some unique avatars for their users."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: Our company is an eCommerce startup. Customers comment on products they buy. We need to find products' positive and negative points from customer reviews."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: I want to search for products within this user review statement to see which products were mentioned by the user."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: An advertising company wants to rephrase their slogans without losing their original meaning. Help them achieve this."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: We are currently drafting a proposal for an astronomical observatory. In order to illustrate our project, I need an impressive space-themed image."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: We are graphic designers working on a project and henceforth need to convert a text description into an image of \"a red balloon flying in the sky\" with scribble effect applied."}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: Imagine you are working with a publishing agency. Using the text provided, create a captivating image for the book cover."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: I want to create concept art for a story scene. The scene will have a river flowing through a dense forest, and a wooden bridge crosses the river."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: Create an AI-based recommendation system for our news aggregation platform, where we can provide recommendations by finding articles similar to the one that the user is reading."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: We need a summary for a long article in Spanish."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: Evaluate the VAT refund policy of a company by answering questions. Remember, the same document got a text and table representation."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: A logistic company needs to ensure safety in its warehouse. The company wants to create a system that detects forklifts and people in the warehouse."}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: Our team needs a Chinese text-to-speech solution that can convert Mandarin text to natural-sounding speech."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: For our image categorization project, we need to extract features from images in high resolution."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: We are working on a customer support team. We need to classify incoming messages to determine customer satisfaction."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: We have an AI-driven online education system. We want to analyze the vocal nuances and fluency of our students by extracting features from their speech recordings."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: Can you provide me a model that can automatically answer questions from given passages?"}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Our traffic management department needs assistance in identifying traffic signs, vehicles, and pedestrians from surveillance camera images."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: The city is partnering with a start-up to help reduce vehicle emissions. Please find out the emission levels based on the given data."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: We have a large number of audio recordings of people reading numbers from 0 to 9. We need to create a system to identify the number pronounced in each audio recording."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: The company is building a depth estimation feature for its mobile application, and they are looking for a solution to generate depth maps from a single input image."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: Develop a feature that classifies user queries as either questions or statements for better assistance."}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: The CEO asked the assistant to translate an important English email into French to send it to their French partners."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: Develop a solution for our app where users can detect objects in their photos."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: I am running a social media account for my company, and sometimes I struggle to come up with captions for our photos. I need a tool that could generate descriptions for images posted on our account."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: I am starting an e-commerce that sells soccer jerseys. I'll need to detect the presence of soccer jerseys in user submitted images."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Create a program to generate random images of butterflies."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: Create a futuristic automatic hair cutting tool, utilizing an AI-powered personal assistant, capable of generating a graphic design based on a text description of hairstyles."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: Your organization is using an application to help employees find information in various scanned documents. The application can answer questions about the contents of the images."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: \"an autumn landscape with trees shedding leaves along a peaceful river at sunset.\""}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: An app project needs to copy the captured images from the live environment and paste the text copy over the app chat."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: We have an online shopping platform. It has products of various classes like electronics, clothing, etc. We need a way to automatically classify these items."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: We need a tool to analyze the depth of the objects in the provided images to classify them by their distance to the camera."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: I want a tool to automatically classify videos into different genres. Can you give an instruction and an example on how to do it?"}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: Our customer has provided an image and wants to know the type of object in it. Please build a zero-shot classifier that will help us understand the object in the image."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: The company is working on audio processing and needs to separate an audio file with multiple speakers."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: Mimic a conversation with a character named 'Dave' who is a World War II historian, and I just asked him about his opinion on the most significant battle in the war."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: Our German-speaking customer is asking for a speech recording of the text \"Mary hatte ein kleines Lamm\". Create an audio file for this task."}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: I need a Python function that generates random numbers between 1 and 100."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: As a medical doctor, I need to summarize the abstracts of various research papers for my patients."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: I have a podcast in Dutch, and I need to generate its transcript for the hearing-impaired."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: We got a lot of tables for cell phone specifications. Our boss is asking which phone has the highest performance concerning processing power."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: Create a German language named entity recognition tool that can identify person names, location names, organization names, and other names."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: A graphic designer has requested a high-resolution image representing a futuristic city skyline at dusk with flying cars and spectacular architecture."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: Analyze a restaurant's Yelp reviews to determine the overall sentiment of customers. The Yelp API data can be used as the input and the model should classify the reviews into positive, negative, or neutral sentiment."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: I am working on a Python code project and I would like to generate a Python function that can sort a list. Can you provide the code?"}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: We are working on transcribing a group meeting. We need to identify who speaks and help to write the conversation transcript."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: The botanic conservation agency is looking for a tool to categorize flower images."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: I want my web app that identifies plants to have 1k classes. Build the model for me."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: I am a student, and I need to generate ideas for my school project on climate change. Can you help me generate some ideas?"}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: A robotic science fiction novel is being written. Generate a few sentences to understand the behavior of the robots in the novel."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: I am writing a novel, but I have a low vision. I am looking for a way to convert the text out of my laptop."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: We are working on street management; our supervisors are walking through the city and capturing images. We want to detect potholes in these images for repairs."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: Help our international business team to translate an English product description into French."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: Our company is developing an application that recommends restaurants to users. We need to analyze the sentiment of Yelp review texts to provide the best suggestions."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: I need a text-based system to segment a picture of a natural scene with animals into distinct regions. The regions should correspond to animals, plants, water, etc."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: We are designing an autonomous driving system that needs to perform semantic segmentation of real-time video feeds to identify roads, buildings, trees, and people."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: Our company needs to translate our user interface and documentation into other languages for better user experience."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: I want to summarize an article written by a journalist in English. I need a fine-tuned model that generates a summarized text from the input."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: We are building an AI application to convert a given picture into a specific art style like oil painting. Please help us create an oil painting image of a man."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: The sports club is looking for a tool to analyze basketball videos and categorize them by the types of plays being executed. They want the tool to analyze videos, such as layups, dunks, three-pointers, etc."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: We are developing a language learning app and want to filter out gibberish sentences from user inputs."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: We are trying to make an algorithm for our company to measure the sentiment of our product reviews."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: Our company develops a cat only social media platform and we need a system to create realistic cat images to test our app."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: I need to build a chatbot for my food delivery app to enhance customer experience."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: Our latest smart home device project requires speech command recognition. How can we implement it?"}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: We are building an e-learning platform, and I want to classify user queries into categories such as academics, technical issues, payment, and account management."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Our customer is a probation office that needs to identify individuals at high risk of recidivism using the COMPAS dataset."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: We have a collection of videos and we want to classify their content. Can you help us with that?"}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: I have a Python code snippet and I need an AI model to generate a brief summary of the code for documentation purposes. What model would you suggest?"}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: I have a list of tasks that need to be grouped based on similarity. Help me identify the similar tasks."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: I have a dataset in the Indonesian language, and I want to get the hidden representation of the data using a model specialized in the Indonesian language."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: One of our customers wants to translate their Romanian speeches into English. Recommend them a suitable method."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: Our company manufactures custom art pieces for interior design. We need you to generate an artwork with a beautiful sunset scenery in the woods."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: Our company is trying to assess its carbon emissions control efforts. They want a tool to predict the company's emissions in different categories based on various features."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: I have a smart home device and I would like it to recognize and announce the names of different animals. Can you provide code for recognizing animal names from an audio file?"}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: We are a robotics lab that focuses on developing algorithms for drones. We need to estimate the depth of the environment for effective navigation."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: How can we measure the depth estimation for computer vision applications?"}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: We plan to create a virtual interior design application, and we want to generate realistic, high-quality images of furniture items for users to visualize."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: Create a beautiful AI-generated image based on a given description."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: We are developing a customer support interface. The bot needs to suggest a list of frequently asked questions semantically similar to the user's question."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: I have this plain text containing foreign names. Can you recognize these foreign names for me?"}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: We are a company trying to predict whether a certain product will result in high or low carbon emissions. We need a quick and efficient way to predict the carbon emissions class of our products."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: \"Ik ben echt van plan om ___ te eten.\" What is the most likely word(s) for the blank?"}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: Our customer wants a chatbot for their website that can respond to client inquiries fluently."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: I have an online store, and I want to automatically classify and sort the products' pictures with their respective categories."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: I am developing a tool that needs to identify entities and code snippets within a text from StackOverflow questions and answers."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: We want a system to check the similarity of customer support queries and enable quick response by finding related questions."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: Please generate a simple summary of a given paragraph"}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: We are building a runtime analytics platform for self-driving cars. It is crucial to accurately segment and classify different types of objects in the image."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: We are doing research on fish populations for ecological projects. We want to predict fish weight based on our data."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: I have a startup that transforms PDFs into excel sheets. I would like to extract tables from the documents."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: We need to generate an image of a futuristic city with skyscrapers, flying cars, and colorful neon lights from a detailed text description for a sci-fi movie poster."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: Our client is a fashion magazine looking to generate stunning fashion images for their next issue. Create an image that could be used as a full-page spread."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: \"The quick brown fox jumps over the lazy dog\"."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: I want to create a product description for a painting with vivid colors depicting a peaceful forest with a lake. Think about the delicate reflection on water and the warm sun rays shining through the trees."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: In a given sentence, we must identify the entities (i.e., persons, organizations, and locations)."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: Our marketing team is looking for diverse images for a campaign, and they want to use AI-generated images. Generate an image for them."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: We are AI researchers who are building a tool that translates English speech to Hokkien speech in real time."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Implement building segmentation on satellite images to be used for city planning."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: Our client is an international company and they often need to translate their messages from English to Spanish. We want to help them translate a sample message."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: Our startup is developing an AI assistant, and we want to convert user voice commands to text for further processing."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Write a short article about the benefits of using artificial intelligence in the education sector."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: Our new project involves getting the depth of images and using that to give a 3D view. We need to use depth estimation for this."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: We are developing a creative app to generate images of butterflies. Provide a code snippet for that."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: We are going to teach robots to walk and pick up objects through reinforcement learning. Analyze an environment with artificial intelligence."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: I need a program that can analyze pictures of art and classify them into different artistic styles."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Create a machine learning model capable of classifying movie subtitles as action, horror or comedy."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: Can you please provide a solution to carry out automatic speech recognition for a new language we are working on?"}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: We would like to analyze sports movements and classify them into their respective sports using video data."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: I am a millennial who likes to dig into song lyrics. I need a tool for comparing song lyrics to find out the most similar songs."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: We would like to develop a system for detecting potholes in an image. The output should be bounding box coordinates and masks for the detected potholes."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: We want to create a virtual world based on text-to-image generation. Generate an image of a mountain range with snowfall at sunset."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We are a gaming company and we want to develop soccer-playing agents using an already trained reinforcement learning model."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: I want to create a video of a flower blooming from a text description using AI."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: Can you read the following text to identify the nouns, pronouns, verbs, adjectives, and other parts of speech? \"Once upon a time, in a land far away, there lived a brave little girl who loved exploring the forest with her friends.\""}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: Our client is a smart-car manufacturer. We need to estimate the depths of objects within the range of the autonomous system's camera."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: We are building a comparison website and we need to understand whether the given pair of sentences are in essence the same or not."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: We are working on a project to generate images from text, specifically architectural interiors. We need a tool that takes a text description and creates a photo-realistic image of the room described."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: A German newspaper editor wants to quickly determine the main theme of an article. The editor will provide the first few sentences of the article."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: Build a program that extracts information from an image of a scanned document by asking questions about it."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: I have an image and I want to find a high-level category for it from a list of possible categories written in Chinese."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: I want to build a program to detect which audio command is being said in any given audio input. The command options are \"up\", \"down\", \"left\", \"right\", \"stop\", \"go\"."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: We need to paraphrase a document containing various sentences for better readability."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: Develop a conversational AI to talk about AI chatbots' history and their current capabilities based on input text from users."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: We want to create a system that can identify objects in images without requiring specific training for each object."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: Please provide a code snippet to classify an image of a cat taken from the internet with a classification model."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: We are an e-commerce company, and we want to classify the images of the products we receive from suppliers."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: We need to utilize a depth estimation model to predict the depth of objects in an image."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: Provide me with a summary of the following article. Keep it short and to the point."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: We are building a pet-related Instagram page, and we want to generate high-quality and diverse images of user favorite cats."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: As a teacher, I would like to transcribe and understand the content of a lecture given in English in an audio file."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: As an e-commerce team lead, I am recently analyzing the product reviews. I need to find out which reviews are most similar to each other."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: We are trying to find the most suitable job profiles for people from different countries by filling some missing country names."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: We have a small database in the form of a table that contains information about employees. How can we leverage the TAPAS model to retrieve the salary of the highest-earning employee in the company?"}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: Help me understand how powerful my new Pokemon is. Predict the HP based on features like attack and defense."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: A content creation team is developing educational videos for children. Analyze the video and determine the category of the content being presented."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: I need a placeholder graphic for an article about artificial intelligence."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: We are building an app for law students that helps review contract documents. Predict the most appropriate word to complete a sentence."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: Our team is working on a computer vision project and we need to estimate the depth of objects in an image. Suggest a model and provide a code example to implement this."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: Write an engaging opening sentence for a story about a runaway circus elephant."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: A Chinese e-commerce website needs a zero-shot image classification system to automatically categorize products in their inventory."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: We are a video production company that wants to use AI to generate video clips from text descriptions."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: Help me identify the similarity between two sentences in a document."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: Our company is developing a game and we want to use AI to create a smart player in mountain car environment."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: Develop an application that takes a quote and converts it into audio so it can be used as a daily motivational reminder."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: We are trying to find information on a table about in a soccer competition. Here is the table:"}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: Create an intelligent system to describe the content of an image. It should be able to categorize the objects present in the image as either indoor or outdoor."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: Our users have an app that records their speech in real time. They want to transcribe their conversations."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: We need an image captioning model that can answer questions within the context of an image."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: Help me build an extraction system of location names, person names, and dates from the text."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: Our customer is a gardening company requesting a summary of an image of a plant's health."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: Our customers are researchers who use tables frequently. We need to create a tool that can answer questions based on a given table."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: Can you analyze the text from a journalist to understand who is going where and when, and can you classify all the named entities in the text?"}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: We have a table with information on various flowers' bloom periods, appearance, and care requirements. Help us answer a question about when a Cherry Blossom blooms."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: We are launching a global news platform and want to translate English headlines to multiple languages simultaneously."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: In the advertisement world, there's a high demand for creative images that haven't been used before. In a retail store, we want to generate a unique and highly detailed image of a medieval knight holding a glowing sword, standing in front of a mysterious castle at night, under the moonlight. This image should look like a professional artwork suitable for a wall poster in the store."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: As a finance and banking company, we have some customer loan data in a table format. We are trying to predict if customers will default on loans or not."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: A startup is developing an exercise-tracking application, and they need help identifying the exercise type in a user's uploaded video."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: Our client needs to generate a unique image of a cat for their website. Let's use the DDPM model to do that."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: I want to start an AI story-generating competition in which participants build models."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: We are organizing a business meeting next week, and all participants need a short introduction message we can send to them."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: As a website owner, I would like to classify images uploaded by users into categories such as animals, vehicles, nature, and food."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: We have a large amount of text data in Russian and we need to get a numerical representation of it to use in Machine Learning algorithms."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: To analyze sentences in the tech industry news, we need you to recognize the relationship between sentences based on their content."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: Summarize the German text provided below."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: Our team wants to build an AI-powered chatbot to answer customer queries. We require a model that can understand user questions and provide accurate responses from a given context."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: We are a startup company that specializes in document analysis software. We want to develop a feature that answers questions about document content."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: My niece has a butterfly-themed birthday party next week, and we need inspiration for the party decorations. Can you help us by generating some butterfly images?"}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I'm an accountant who needs to extract information from invoices. Create a system that can identify the invoice total, date, and vendor from invoice images."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: We are a Gym, there are some videos from our gym goers training. I'd like to know if these videos are about weightlifting, yoga or aerobic exercise."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: Our customers are interested in depth estimation. Guide me with an instruction using the provided API to serve my customers."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: There is a list of customer reviews and the company wants to detect duplicate and similar reviews to reduce redundancy on the feedback page."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: I need to search in the table for some data. Explain how to do this."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: Our company has a collection of audio recordings with multiple speakers, and we need to determine the speakers' turns."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: Design a model to recognize text in an image from a handwritten document."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: We are trying to create an image from the description \"ocean with a beautiful sunset and sailboats\"."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: I have several images with descriptions, and I want to generate the text description based on the images using a Pix2Struct model."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: We have an e-commerce platform that sells various products. We want to categorize the product images uploaded by the sellers."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: We want to create a tool to provide depth estimation for robot navigation in a warehouse."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: Our advertising team wants to create an AI-based tool to generate random human-like faces for their campaigns. We need high-quality generated images."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: A friend of mine asked me an interesting question, and I need to show her the relevant information to answer her question."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: Determine a story starting from \"Once upon a time in a small village, lived a lonely woodcutter.\""}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: Help me to design a language translation system for a hospital emergency ward where the doctors need to translate English to Chinese."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: We run a construction company and want to improve the safety of our worksites by detecting forklifts and people using computer vision."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: I want to create a learning-based agent for Acrobot-v1 using the pre-trained DQN model from the RL Zoo."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: Summarize the given text and then extract the answer to the given question within the summarized text."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: Our customer in the autonomous industry wants to build a navigation system for their vehicles. They need to understand depth information from camera feeds."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: My friend, a psychologist, asks for my help to provide him answers from research papers abstracts."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: A startup is building an innovative voice user interface for their mobile application that can transcribe spoken words into written text."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: The editor of a science magazine asks you to come up with an introduction paragraph for an article on artificial intelligence."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Address customer inquiries about organic lotion products through chatbot service."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: We need an audio classifier to understand the emotions of callers in our customer support system."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: A gaming company is developing a new game and wants to implement an AI that plays Pong with no frame skips. Help them implement a pre-trained model."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: Create a tool that extracts names of people, organizations, and locations from a given text."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: Our chatbot software has received a sentence, and we need to know whether it's related to our healthcare service offerings."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: \"The new Tesla Model S includes a major interior redesign with a 17-inch screen that fills the dashboard. The electric car also boasts an impressive 520 miles of range for the Long Range version and up to 163 mph top speed. In characteristic Tesla fashion, the vehicle includes cutting-edge technology features such as a SmartShift feature that predicts which gear a driver will choose next, all without a traditional display unit. Elon Musk calls the Model S 'the ultimate in luxury and performance' and believes the car's design language will influence future electric vehicles.\""}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: We have a contact center with an engaged team. We need a tool to analyze the emotions in their conversation to monitor their stress level."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: I'm working on a language learning application to help non-native speakers improve their English grammar. I need a model that can correct their English grammar."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: An advertising company wants us to generate realistic human faces with high-resolution to use in their campaigns."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: I need a brief summary of a lengthy news article."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: In our app, the user can see the summary of their conversations for the day so that they don't have to read all the texts again. "}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: I want to create multiple variations of a given image using deep learning techniques."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: Our company is building a software to analyze satellite images for land use. We need to segment different regions in the images."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: Develop a solution that describes the content of an image."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: As a car manufacturing company, we want to reduce the carbon emissions of our vehicles. Analyze the given dataset to predict carbon emissions and identify the factors affecting them."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: I would like to create a language model API that can generate conversational responses for a personal assistant application."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: I work for a sales team tasked with the job of gaining insights from customer feedback. Determine if a given review contains positive or negative sentiment."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: We're designing an app where users can send in a picture and get a caption generated from the photo. User input a picture to get caption."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: We want to create captions from images to understand the contents and context better for our visual recommendation algorithms."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: I want to create an email message for my team that is introducing a new machine learning model we have developed. Can you help me fill in the blanks in the following message?"}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: Design an automated financial report for a global corporation. It should include an English-to-Arabic text translation for their Middle East clients."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: I want to build a simple and efficient solution to identify the type of Iris flowers based on some parameters."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: My friend downloaded an image, but she is Polish, and we need to create a Polish trivia around the image. The trivia question should be in the format \"What is in the image?\""}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: Create an application that generates cartoon-like images based on real-world photos provided by users."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: I want to create a customized image for my Instagram post in which I need a beautiful pink waterfall in a mountainous region. Help me get it done."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: Need a musician, who can convert a text to speech sample for me."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: I am working on a home automation system which can visually recognize objects in the user's surroundings and answer user's questions about them. Calculate the number of calories in my meal."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: We are designing a butterfly garden and require images of butterflies for inspiration."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: I have recorded a conversation between different speakers, and I want to identify unique speakers in the conversation."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: I am working on a Korean QA bot for the learning purpose of kids going to primary school. Can you guide me where should I start?"}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: We are now building a VR game. I want to generate a celeb face using an AI model to put as a game character."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: Our customer, a manufacturer of sporting goods, wants us to determine what type of sports equipment is in the images they provided."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: I'm living in Italy now and I receive some communication like emails written in Italian. Convert them to English for me."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: As an advertising agency, we need to create a remarkable visual that represents the product's features."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: I need to transcribe an audio file of a conference call into text."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: I want to transcribe a podcast and analyze the content. Please tell me how to convert the podcast's audio file to text using API."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: We are setting up a hotdog stand and we need to analyze and obtain feedback on our hotdog images. We would like a system that will determine if it is a hotdog or not."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: I've a picture of a vehicle, and I'd like to know if it's a car or a motorcycle."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: We want to identify the type of animal in a certain image. Please show us how to use an image classification model for this task."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: Develop an application to extract the answer to a specific question from a given document using the text and layout information."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: I am working at an environmental organization; we want to predict the carbon emissions of different facilities based on their features. How can I use this pre-trained model to make predictions?"}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: An English teacher needs to translate the pronunciation of English words or sentences to French pronunciation."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: We are a research group working on a text summarization project. We need to extract features from the text."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: We are running an accounting firm and require a module that can extract information from our clients' invoices."}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: For a smooth UX of my news website in Spanish, I want to only display articles that are positive. Please analyze an input article and return whether the sentiment is positive or not."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: I have a robot that picks up objects off the floor, and I'd like to use a depth estimation model in the robot's camera system to tell it how far away various objects are on the floor."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: We have a surveillance camera installed in a warehouse, we want to analyze the footage from this camera to detect and segment different objects in the scene."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: Let's analyze a case where a user wants to ask questions in different languages from the context they provide."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: I am a student, and I am studying for a test on history. Help me find an answer to the question \"Who first discovered America?\" from the text that I've provided."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: I want to predict the depths of objects in an RGB image. Use a model to read the input image and output the depth map of the scene."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: Let's create a personal virtual assistant to answer a certain question."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: We are an athletic clothing company, and need to generate a human pose estimation image of a runner."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: Our company focuses on providing statistical information for soccer matches. We have a table with data and we need to answer questions about match statistics."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: Generate an image of a \"cat sitting on a tree branch\" using Diffusion-based text-to-image generation model."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: I need to find the similarity between different semantically similar statements in a dataset."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Our advertising team needs a tool that generates captions for the images in our new marketing campaign."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: We need to analyse the sentiment of a company's latest earnings report."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: I want to summarize the key points in Russian conversations. Can you assist me in performing text summarization of Russian dialogues?"}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: I want to build a personal news summarizer so I can read summarized versions of each article flying through my news feed about Python releases and updates."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: A customer service department is looking for a chatbot to help answer customer inquiries in a friendly and efficient manner."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: Write an AI program that reads a text file and summarizes the content into a few sentences."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: I want to develop a software that presents the content of an image in text, which can then be read out loud to a visually impaired person."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: We are an environmental organization, and we need to analyze and predict carbon emissions of a city. We have data in CSV format."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: I am writing a script that groups a set of product reviews by finding the semantic similarity between them."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: We have a Swedish newsletter content that needs to be translated to English."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: We need to complete a Japanese sentence, predict and fill in the missing word."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: I am a school teacher and want to develop an application that can help my students answer complex questions about tables and data. The questions could range from mathematics to world history. We require a method to answer questions about the given data."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: A school wants to create an educational app for kids, and they need a built-in feature that can answer questions based on given context."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: In an online language class, we want students to provide sentences, and the system to give back the spoken version of the sentence."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: A relevant answer to the question below must be extracted from the given passage."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: We are a company that translates webpages, and we need to translate a user inputted English paragraph to Russian for our Russian users."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: Help me write a 100 words story about a dragon and a knight."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: I recorded an audio file in a language I don't know. Can you identify which language it is?"}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: Create a tool that can filter podcast episodes based on the speaker's identity and find the top 5 matching speakers."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: I'm interested in transcribing some Russian audio files I have. Can you help me with that?"}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: We're a podcast streaming platform and we want to classify the content of new podcasts as \"Adventure\", \"Self-improvement\", or \"Education\"."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We have a student club that meets every two weeks to play virtual soccer. Provide them with a tool to play against a machine learning agent."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: Build a learning-based reinforcement agent to play Pendulum while minimizing total cost."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: Our upcoming project requires a summarization of GitHub repositories. We want to automatically generate repository descriptions from the README files and the code inside the repositories."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: A medical research institute wants to automatically classify microscopy images of cells. They need an AI model to identify the type of cell present in the images and classify them into categories such as epithelial, mesenchymal, or immune."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: We are an online library. We need an AI model to categorize book/movie reviews."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: As an international nonprofit organization, we need to classify news articles for content topics, but the articles can be in multiple languages."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: How can I separate vocal from the music in an audio file consisting of vocals and music mixed together?"}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: As a gaming company, we need to create a bot that can efficiently control the pendulum arm in the Pendulum-v1 environment."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: There is an audio clip from a business meeting, we want to transcribe it into text."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: I own a company focusing on green building infrastructures. I need to segment images to identify the environment and landscape components, including buildings and vegetation."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: We are building a platform that transcribes podcasts. Please help us convert spoken words in an audio to text."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: There's an upcoming competition where we need to create programs from a functional description. Can you devise a solution for this?"}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: Our project manager is travelling and has an idea for the next project. Help her write down the idea in a short paragraph, with addition of knowledge on similar projects."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: I am an environmental scientist. I need to extract information about different plant types from an image of a lush green forest."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: The medical technology company needs to identify potential disease symptoms mentioned in their database of clinical notes from patients."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: An organization is committed to reducing its carbon footprint. Can they assess each company and predict if they are above or below the limit of emissions?"}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: The newspaper is looking for a creative writer to generate automatic headlines. Write Python code that can be used to generate catchy headlines for news articles."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: A publishing company is creating a digital platform for children's books. We need to generate illustrations for the stories. We want one illustration of a \"dessert island filled with treats\"."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: Retrieve and display the coordinates of tables detected in a given image."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: I am developing a multilingual chatbot for my clothing store. Analyze the similarity between our customers' inquiries in different languages."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: \"5 best things about traveling to Paris.\" Write a catchy introduction sentence that would grab the reader's attention."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: Our company needs assistance in writing marketing material. Write a brief introduction about our new programmable robot for kids."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: I want to analyze images of cats and automatically determine their breed."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: Determine which fruits are in an image and differentiate each individual fruit in the picture."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: Given Japanese text with a missing word, predict the most appropriate word to fill the blank."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: A utility company needs help in extracting tables from their utility bills as part of their digitization project."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: I am building an interactive robot that assists my guests. I want to detect the emotions in our guest's speech."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: Our company is in need of an image recognition tool that can determine whether given images contain animals or not."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: I am an app developer and I am using the google api for image description. How do I use the google's pix2struct-chartqa-base to have sentences in the images?"}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: We are a smart headphone manufacturer, and we want the device to automatically pause music playback when the user starts talking. Please help analyze the audio coming from the microphone to detect when the user speaks."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: We want to know how well our pre-trained agent performs in the LunarLander game. Report the mean and standard deviation of rewards after completing some game sessions."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: \"This new technology is changing the way we communicate with each other.\""}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: As a company building a custom Minecraft server, we want to provide unique skins for our players. We need an AI to generate realistic-looking Minecraft skins."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: Our team is developing a comprehensive document management tool and needs to cluster similar documents in storage."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: music, speech, and noise."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: I work at an online store, and we have thousands of products in our inventory. I have a table including product names, prices, and categories. Help me extract information from that table."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: I need a depth estimation model for my computer vision project. I want detailed instructions on how to obtain this depth estimation model and how to use it."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: I have a website about birds and I need to generate artistic edgy images based on bird pictures."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Our accountant team needs to extract tabular data from scanned financial reports. Implement a table extraction tool using the API provided."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: As a real-estate agency, we have a database of home transactions. We need to answer questions about the data."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: \"Just <mask> it.\""}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: Recently, our company has become very popular among NFL football teams. They need a mobile app that could help them to automatically count the number of helmets in an image."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: I am preparing for a quiz competition. Can you help me create a model that can effectively answer questions when I provide the context?"}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: As a developer for a fitness app that includes guided workout audios, create a tool to detect spoken numbers and unstructured content in the audio data."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: Para ser feliz en la vida, uno debe [MASK] sus miedos.\""}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: Our client provided an image containing various objects. They want us to create an algorithm that can perform semantic segmentation of the input image and identify different regions based on their semantic meaning."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We need a question answering system to retrieve answers from complex structured documents like pdf, forms, passport images."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: \"Learning new languages is an [MASK] skill.\""}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: A tourist emailed a picture of a street sign to translate it into English."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: I need to extract handwritten text from an image URL and provide the output as text."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: Implement an image segmentation model that can detect and segment defects in printed circuit board (PCB) images, such as dry joint, incorrect installation, PCB damage, and short circuit."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: There is a parking lot nearby our company. We need to develop a model to detect license plates."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: As an AI developer, I need to create an agent to play the CartPole-v1 game to test if it can keep the pole balanced."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: I have been imagining this scene in my head - a warrior girl in the jungle. Please generate an illustration based on this description using the provided ControlNet model."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: Develop a system to automatically identify plants and animals in a given image. We need to differentiate and label different types of plants, animals, and their surroundings."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: A user has an image of a handwritten shopping list, and they want to know what the total sum of items in the list is?"}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: We are in need of a solution that reads out Marathi text forcefully and helps new language learners in the pronunciation."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: Customers are calling our customer service line, and we need to route their calls based on the emotion expressed in their voice messages. Provide a method to identify emotions in voice messages."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: technology, sports, politics, health, or entertainment."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: Generate a text to answer the question, \"How can I make my garden more eco-friendly?\""}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: We are designing a mobile app for tourists, and we want to implement a feature that allows them to ask questions about an image they took while traveling."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: We need to extract company names from a document in order to build a dataset of clients."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We are coaching a soccer team, and would like to use this API to simulate training sessions."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: I am a journalist. I need to complete a French sentence based on my draft with a missing word."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: We need an Artificial Intelligence model to train our robot to land a Lunar Lander."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: Navigate to the proper API and figure out how we can process a document to extract question-answer pairs."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: I am working for a government department in China. We need to implement a system that can get answers from legal documents in our database. How can you help us?"}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: I need to analyze urban street scenes taken by a vehicle in my delivery fleet. I want a model that will help me identify the objects and classify them as belonging to different categories like cars, pedestrians, cyclists, traffic signs, etc."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: We are creating an audio guide for a museum. Turn the texts about paintings into audio files."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: Develop a recommendation engine for an online store that offers personalized discounts based on user's favorite categories of mobile phone images."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: A company wants an AI that can translate English text to another language. Propose a way to accomplish this."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: Create a system that translates English text into Portuguese for a language learning app."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: I have a list of sentences that I want to translate from English to German. Help me out with this."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Our company is automating the invoice processing system. We need to extract specific information from invoices in image form."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: I want to create a computer vision tool that can generate images of church architecture. The generated image must give the feeling of sacredness and grandeur."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: We are a healthcare provider that wants to provide a system to translate English prescriptions to Portuguese for our patients."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: I want to extract features from biomedical text for further analysis, such as clustering or visualization."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: We want to create a system that can identify emotions in voice recordings."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: Propose an approach to compare job descriptions in different languages and rank them based on the input job description provided."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Our company is developing a music app that detects genres of songs. We want to classify songs into respective categories based on their audio characteristics."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: \"A cool robot playing guitar at a sunset beach\"."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: I am working on an e-commerce website, and I want to let users search for products based on image inputs."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: We have a document in English and we need to translate it to French."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: Our customer is a clothing store, and they would like us to generate an image of a person wearing their clothes."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: Can you help me answer this question from the given table data? What is the total revenue of company B for the year 2021?"}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: I'm running an advertising campaign, and I need a photo of a city skyline with a giant rubber duck floating in the river."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: Our team is working on AI-based video tagging to automatically sort and organize a library of videos. Implement a video classification model to help us."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: Develop a code to estimate the depth of objects in a given image using the pre-trained model."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: Add a depth estimation system to our robots to improve their navigation capabilities in our 3D printing facilities."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: I am looking for a quick question and answer service for data stored in my JSON file."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: We are building an application that allows users to chat with people who speak different languages. Help us translate text between languages."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Our company needs a predictive model to analyze the risk of recidivism in our rehabilitation program."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: Can you help me create a conversational bot that could interact with people, and also provide them with general information?"}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: I am a farmer, and I'd like to use a small AI model to classify diseases in beans by analyzing images from my phone."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: I need to create multi-language search engine for my website. Visitors write questions in their languages and I give them answers in the same language. Can you help me with generating the answer?"}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Help me generate a marketing poster where a smiling businessman is holding a laptop in front of a row of wind turbines."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: A teacher wants to convert a sentence in a student's paper into a different sentence with the same meaning. How would she do this using the provided API?"}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Develop a system that will identify the presence of diabetic retinopathy in patients using their retina images."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: We have a recording from a meeting and we want to transcribe it. Identify the active voices in the audio file for us."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: Can you help me translate this Dutch email to English? Our Dutch counterpart just sent us this email but nobody in my team understands Dutch."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: We need to process voice recordings and remove silences to save storage space. Write a code that does voice activity detection and removes the silent parts."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: One of our customers is working on medical imaging. They have a microscope slide image and want to count the number of different blood cells present in the image."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: A user is asking for a way to change the voice of an audio file to their liking."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: There's a huge article on recent advancements in cancer research, and I need a concise summary of it."}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: Design an AI-powered fact-checking tool that analyzes a claim based on the provided context and answers whether the claim is true or false."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: \"The quick brown fox jumps over the lazy dog.\""}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: \"In the distant future, humans have colonized multiple [MASK] systems.\""}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: My company is having a farewell party for a retiring employee, and we want to entertain the guests using an AI-controlled soccer game."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: Incorporate speech-to-text technology to transcribe a conversation during a business meeting."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: The sports channel wants to build a tool that automatically tags their videos with the name of the sport. Can you create a model for it?"}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: Design a text-to-speech application that reads children's stories aloud in multiple languages, primarily English, French, Spanish, and Italian."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: As a developer, I want to estimate the depth of objects present in indoor scenes using images."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: As a parent, I want to find out if videos are safe for my kids by classifying the content in the videos."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: We are building an audiobook application. We need a feature to read a selected paragraph of the book in Chinese."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: Prepare a tool that can analyze medical reports and identify biomedical entities within the text."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: I am at an international conference and need to understand a speaker speaking in English. I need a real-time English to French translation to keep up."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: We have aerial images from our recent inspection of a construction site. We would like to identify and segment the buildings within these images for further analysis."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: Our client is a bank looking to classify potential loan applicants based on their financial history. They have a dataset with several features such as credit score, income, and employment history. Help them build a model to predict whether an applicant will be approved for a loan or not."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: A company noticed that some employees are accidentally sharing personal information in emails. We need to build a solution to redact sensitive information from all emails."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: I need an AI that writes a simple Python program to check if a number is even or odd."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: My friend just sent me a document written in Russian but I can't read the language. Could you please translate the whole document from Russian to English for me?"}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: While I'm reading a scientific paper, I want to extract an answer to my question from a given paragraph."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: We need a solution to create a short video highlighting the positive impacts of renewable energy sources on the environment."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: We are an online platform that wants to predict how much tip a user will give based on the factors like total bill, sex, smoker, day, time, and size. Determine an API for regression on tip and supply sample code."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: Invoice Number, Date, Total Amount, and Company Name."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: We are a company working on analyzing sports footage. We need a solution to detect helmets in American football."}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: A community wants to build an application to predict fish weight based on the measurements. Build a model to predict the weight of the fish."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: The company is building a product to improve audio quality in video conferences. We need to detect voice activity and filter out background noise."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Create an application to identify a celebrity from a photo of their face and provide a brief summary of their achievements."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: My friends and I are creating a game night, and we want to integrate a learning-based agent to play the CartPole game against the players."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: A business partner has sent you a document in German, but you need it in Spanish. Provide the translated document in Spanish."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: In the next meeting with the CEO, he wants to present an interpreter for a French-speaking guest. Prepare a model for real-time translation."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: I have an IoT-enabled smart home, and I want to estimate the depth of objects in captured images for better interaction with my smart devices."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: Develop an application to generate Python scripts that are useful in your daily life."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: We are developing an app for identifying animal species by images. The app should recognize cats and dogs, among others."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I have an invoice template with an invoice number. Tell me the invoice number."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: We own a website, and we need to create attention-catching images based on textual prompts like \"a kitten playing with a ball\" to engage our users."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: Create a program that generates images of cats using the DDPM-EMA model."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: We have to make a chatbot to answer various user queries. We are utilising a GPT model."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: An author is writing a story and needs to find an appropriate word to complete a sentence."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: We are a travel agency. We need to create summaries of news articles about various destinations for our clients."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: As a chemist, I am looking for a highly effective machine learning model to predict molecular properties. Suggest me a good model for my project."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: The client wants us to use the model for a customer support chatbot. Please design an easy-to-use chatbot that can answer customer queries."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: We are creating an AI system for a school to assist teachers in grading essays. We want to classify essay categories."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: The project manager is looking for a tool to analyze the emotions expressed in their team's app reviews on the app store."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: We are building an application to detect audio classes, like animals, humans, and vehicles. The audio sample provided needs classification."}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: For our customer support system, we require a model that can answer questions based on a provided context, like product descriptions or instructions."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: Create a function that translates the given input text into English."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: We are developing an autonomous robot with language understanding capabilities, and we need to determine whether the given output sentence logically follows the input sentence."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: We need to extract the text from an image of a document for a client."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: We are developing a language app, and we want to embed user input into a language model to perform tasks like translation, summarization, question-answering, etc."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: We need an OCR engine that can read the license plate numbers from images and return the text."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: In our organization, we need to automatically group and filter emails based on their content. Can a technology help us with this?"}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: We need to generate summaries for the customer support chat transcripts to be sent to the management."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: We have a project to make a self-driving car. We need to analyze images from the car's camera to determine object distances."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: We are a software company that wants to integrate depth estimation in our product for visually-impaired users. We need to estimate the depth of different objects in the environment."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: We want to create an eye-catching advertisement for our store. Create an image for our new summer clothing collection."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: Develop a tool to scan the videos of exercises and find out which exercise the person is performing."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: Develop a system that can extract entities like location, organization and person from large paragraphs of texts."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: We want to develop an AI-based code generator. It will take human-readable descriptions and turn them into working code in a variety of programming languages."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: I need to extract text from a Japanese manga image to provide subtitles for foreign viewers."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: We need to analyze a podcast where several people are talking. Additionally, analyze the speech of each person separately."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: A social media platform wants to identify misleading or disinformation content. Create a method to detect if a given post is related to politics or science."}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Our virtual reality marketing team has to design campaigns around various products. One strategy is to answer questions about the images of the products."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: Our company wants to provide code snippets to programmers for commonly used tasks. Create a system that can generate code based on text inputs."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: We are a news agency developing an AI tool to automatically classify news articles into topic categories. We need a model to make predictions for the category of an article based on its text."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: To ensure quality, we have to detect the defects of printed circuit boards (PCBs), visually."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: We have thousands of text data, but we need to embed the passages into embeddings to find the context, can you help me?"}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: Our organization is working on a real-time vision system that requires depth estimation from a single image. Help us load the model for depth estimation and set up the pipeline."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: The mobile app we are building requires a function to convert text to speech in English, French, Spanish, and Italian."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: Our startup is creating a soccer game platform; we want to train an agent to play it and make it more competitive."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: the app will tell your meal suggestion aloud in a human voice. We would like to include Text-to-Speech functionality in our application."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: I need a report to be summarized for a meeting. Perform summarization of the text provided."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: We are an e-commerce company. We need a tool to help us classify product images without having prior labeled data."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: Please find a way to count the gender of speaker as a blessing to settle the case."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: We are creating children's books and want to generate colorful unique images that have not been seen by anyone."}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: We are conducting a demo for a machine learning tool for converting speech of one person to another person's voice. We are going to use a sample speech from a dataset to demonstrate voice conversion."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: The user wants to automatically trim a podcast and remove the silence parts. Use an API to detect the spoken parts in the podcast."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: Our audio dataset contains recordings of spoken digits between 0 and 9. We'd like to identify the digit spoken in each audio file."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: I am a student learning different natural languages. I want to complete a sentence with a missing word."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: Our client wants to develop a mobile application for selling sneakers. Automatically generating shoe designs will be helpful for the company."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: Develop a tool for a construction company that can predict the depth of a building from an image taken by their surveyors."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: I own a toy store and I want my website to answer frequently asked questions about the toys we sell. Please build a question-answering model for that task."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: We are trying to build a product that reads out German text, please provide an example of how to do it."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: The business needs a Japanese voice assistant that reads customers' messages and passes them to customer support."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: Our company provides transcripts for legal meetings. We need to determine the different speakers in the audio recording."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: Let's detect car accidents in a live traffic video feed and send notifications."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: Generate a short video clip of a person practicing Tai Chi based on given text input."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: We just received a lunar rover project. It's crucial for the rover to navigate and land safely on the lunar surface."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Identify and give me the location of the bordered and borderless tables in document images."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: We are building a search function on our website, which checks the two sentences are close or not. Calculate the similarity score between these two sentences."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: From a given text from our news portal, can this model detect person names, locations, and organization names?"}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: Our goal is to deploy a learning-based agent to compete against itself in a SoccerTwos scenario in Unity."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: \"Ela estava com uma [MASK] na m\u00e3o.\""}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: A renowned pharmacist from the United States has written an article talking about a new drug that they have successfully tested on mice. This will be able to cure a rare disease that was incurable previously. We have to make sure the generated content is tailored to closely match the field of expertise."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: Our customer is worried about old low-resolution family photos. Can you help with enhancing those images?"}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: We have a multilingual community page, where people post in different languages. Prepare a language identifier to categorize the language of the post."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: Our company needs to extract specific information from some scanned documents. Answer questions related to these documents."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: I need a tool that transcribes my voice notes from numbers to text."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: Let's build a machine learning application to analyze and recognize different activities happening in a video."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: Identify entities in a text, such as names, organizations, and locations."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: I want to generate a series of ice cream designs with colorful patterns. What kind of image generation model should I use?"}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: We need to accumulate key information from different sources available in various languages, including Spanish. We need the translation from English to Spanish."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: I am an environmental administrator and I want to know the Co2 emission in grams based on specific data input."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: Our client wants to build a chatbot that fills in the blanks in sentences intelligently, ensuring that the sentences make sense."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: You have been asked to summarize a scientific article for a news outlet. Extract the main points from the article."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: Our traffic surveillance department aims to detect vehicles in real-time on the streets for monitoring urban traffic."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: My company loves to utilize NLP technology to answer sequential questions related to a table of product information."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: A website for pet adoption features a profile image of each pet. We need to automatically label the images with the type of pet, such as cat or dog."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: Find out why model conversion is important for a user."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: We need to automatically translate user comments on our website from their native language into English."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: Our company is creating a promotional poster for a fantasy film. We need to generate an image of a magical forest with fairies and unicorns."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: Create a system to determine whether a text piece is generated by GPT-2 or not."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: I am seeking to speak at an event about distance learning. Review my chat transcript with the event organizer and provide a short summary of our conversation."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: How can I ask questions about a given document and get accurate information?"}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: A real estate company wants to create 3D interior plans for their clients based on 2D images. We need to estimate the depth of the rooms in the images."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: \"De kat slaapt op de _____ van de bank.\" "}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: We are interested in automatically analyzing surveillance footage of public areas to predict potential security risks."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: My son dreams of being a wildlife photographer. I'm in charge of a pet house. We have 10 different mammals in our stands, all sharing the same space. Please ensure that the models can classify the mammals."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: We are running an art gallery and looking for a creative tool to generate images based on quotes."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: Imagine we have a text as \"a yellow car in the night\", create a visual image matching this text description."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: We're building a tool for developers to generate Python code snippets. Please set up a model that can help us achieve this."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: I want to create a chatbot that can understand the relationship between sentences and respond accordingly."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: We are building a smart doorbell that identifies the sound of a doorbell. We need it to recognize the doorbell sound and classify it correctly."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: Come up with a solution for detecting objects in images using features present in the image."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: Analyze a 16-frame video snippet for us. We need to classify and understand what action is being performed in the video."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: Build a robot control in loading and unloading a spaceship for LunarLander using a PPO model."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: \"Artificial intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction. Particular applications of AI include expert systems, natural language understanding and speech recognition.\""}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: We want to make a simple project where users can ask questions about information on a given webpage."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: I am asking the model if my recently purchased dog is cute. It needs to transform my question into a dense vector."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: I am a product owner and we are building an agriculture advice tool which answers questions regarding crop diseases, pests, and farming techniques. We need a question-answering capability for this tool."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: Develop a lightweight conversational AI agent to interact with users on a Raspberry Pi device."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: A Romanian traveler is in London and needs assistance translating spoken Romanian to English."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Our task is part of an urban planning project, where it is necessary to segment buildings in satellite images to calculate the built-up area."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: Our city planning department would like to analyze satellite images for land use classification. We need a tool to segment and classify different areas like roads, buildings, and vegetation."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: We are working on a project to analyze traffic patterns using real-time traffic camera feeds. We need a model that can detect and count vehicles such as cars, trucks, and buses."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: We have a children's book company and need to create creative story beginnings."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: We are a travel agency, and we want to automatically generate captions for images to improve our website."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Our team needs a unique image of a unicorn climbing the Eiffel tower for the project."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: I've been tasked with creating an image of a unique landscape, featuring a bustling city between snow-capped mountains under a golden sunset, all based solely on a description. Can you help me with this?"}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: We want to build an app to provide description of images."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: I'm building a video recommendation system. Therefore, I want to classify videos into categories based on their content."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: My niece is an aspiring historian. She's found a dataset with the years and host cities of all the Olympic Games. She needs help finding out in which year Beijing hosted the event."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: Our team is planning to collaborate with some Chinese developers on a project, and we need to translate some Hindi text into Chinese. Help us with this translation using a deep learning model."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: Automatically turn grayscale pictures into a colored image by applying image segmentation for detecting regions of certain objects."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: A colleague is writing a Japanese chatbot. Assist them in completing sentences by predicting the perfect completion."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query:  The real estate company wants to predict housing prices. Find the best way to predict and justify it."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: In real estate, we have a new sale contract. Can you assist us with finding out the price of the house?"}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: I am a manager at an architect firm. Kindly help me identify the presence of tables in the floor plan layout provided to me."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: We are a content discovery platform that categorizes articles into different categories. Identify if the following two sentences are contradictory, entailment, or neutral."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: Our team is using aerial drone photos to analyze the urban landscape. We need to separate buildings, roads, and vegetation using image segmentation."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: \"This is the story of a brave explorer venturing into a dark and mysterious forest. The explorer overcomes numerous challenges and obstacles, discovering ancient ruins full of secret treasures. Their journey reveals the rich history hidden within the forest, waiting to be uncovered by those brave enough to venture inside.\" Turn this into a video summarizing the scene."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: Determine the emotion conveyed in a social media post."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: In order to add a lunar lander game analyzer in my gaming app, I want to evaluate the gaming scores achieved by the DQN agent over 20 episodes."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: I am a reporter and I need to discuss international politics in a chat with AI."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: Our game will predict the action or activity performed in the video clip. We need your help to build the classifier."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: Our startup plans to create a platform where users can find new video content related to their interests. We need to classify user preferences automatically."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: Our customers are a global company. Many of them speak different Romance languages. We want to provide them with localized English instructions."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: Our marketing department is working on a campaign video. To help them improve the video, we need to classify different parts of the video based on their content."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: We are writing a blog on technology, and we want to measure the similarity of the selected paragraphs to make sure they cover diverse aspects of the topic."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: In a mobile game, we want to introduce a feature to automatically remove unwanted parts from images uploaded by users. Please propose a solution for this."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: We have created a simulation game based on car racing. We want to train an AI to play the game well."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: We have a customer review we need to analyze, extract the features, and place into a support vector machine (SVM) model for classification."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: A customer is facing a problem in their restaurant. They need an AI chatbot to handle their customer support."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: Our client is an esport gaming company. They want to develop an object detection model especially for the game Valorant."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: I need to find out which years correspond to the Olympic Games held in Paris from a dataset."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: Build a lesson plan generator to fill missing gaps in a sentence provided by the teacher. The generator should recognize the correct answer _blank_ from the context."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: I need a summary of what happened during an eventful family vacation, highlighting the key experiences."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: We are a music platform that needs to separate multiple voices from mixed audio files."}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: I want to create a classifier that allows me to determine if an image contains a dog or a cat."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: What model should we use to generate summaries of financial news? What library and APIs do we need for it? How to use this model to summarize the financial news?"}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: Design a system that detects objects in an image in the game \"Valorant\""}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: We have an e-commerce website. We need to classify uploaded product images into categories without training data."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: A company is launching a new fitness app, and they need an inspiring slogan for their marketing materials."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: An app is handling disputes among their users. We need to classify if the dispute is related to a financial issue, delivery issue, or customer support issue."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: Analyze the sentiment of a foreign language tweet."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: Our marketing team is creating promotional materials for Minecraft and we want to generate some unique skins for the Minecraft characters."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: Help me analyze scientific paper titles and abstracts to find papers with similar content."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: I am having a problem, I received a comment on a blog post, but I suspect it's an AI-generated content. Identify whether the text is AI-generated or not."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: I am a data scientist, and I have an inventory management sheet in CSV format. I need help to get the model name for a reporting tool to make calculations based on the data in that sheet."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: A user sent a picture of a document and has a question about it. Help them find their answer from the document."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: Generate a creative brief for a mobile application that promotes physical fitness for children."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: We are aiming to create a short animation based on a textual description, \"A cat playing with a butterfly in a garden.\""}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: We need to analyze a podcast on Indian heritage and culture for a client who is doing research. Identify the segments where the speaker is talking."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: I want a tool for my blog dashboard that shows a list of articles and sorts them based on how relevant they are to a given topic."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: You've been hired by a Russian literary magazine. They need an AI that can generate summaries for Russian articles based on their features."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We want to build a plant species identification app, so we need to classify plant images."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: Our team is working on a product that answers questions about information in Korean tables. Implement an API to gather information from tables."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: Develop a CO2 emissions prediction system for our new eco-friendly cars using our dataset."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We are a finance company and going over 10 documents. We would like to get the tables extracted in those financial documents."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: Our customer wants to create a tool to extract data from charts. We need to extract the information contained in charts and present it as text."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: Design a system to recommend related papers or articles to a user based on a given document."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: As a circuit board manufacturing firm, we want a lightweight detection system that detects defects in our PCB products and highlights the areas with defects."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: Our website has just launched in several countries that speak Romance languages. We need to translate user comments from those languages to English."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: Our marketing team wants to transcribe Arabic audio files into text. Please provide a model and code to perform this task."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: Your task is to develop a natural language processing system that can carry out dialogues with humans."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: We need to perform part-of-speech tagging on customer reviews to analyze language patterns."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: In order to propose a machine learning tool to a security department, we need to analyze the video in order to classify any suspicious activities."}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: Summarize the following news article about YouTube's policy change regarding anti-vaccine content."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: Our business needs Spanish to English speech translation without generating text."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: In our department, we want to implement a document question-answering system to handle various queries related to legal or financial documents."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: Recently I started learning pyschology, I want to ask some questions about a certain topic. I would like a chatbot to help me with that."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: I need a recommendation system for a student writing an essay based on input essays. It should rate other essays that are semantically similar."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: Our online shopping app needs a feature to automatically categorize the products based on the uploaded images."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: We want to translate German hotel reviews to English to analyze customer satisfaction."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: Our client is a game studio looking to create a new game. The plot of the game revolves around an \"archer arcane style magical princess with golden hair.\" They are seeking image generation for this character for promotional content."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: I am building an AI assistant to summarize long reviews for the restaurants. It should help me decide whether the restaurant is good or not at a glance."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Our customer is designing a real estate app that visualizes the size and layout of rooms in 3D. We have been asked to estimate the depth of objects in 2D images."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: We want to extract textual data from an image. The image is a screenshot of a website with data about a seminar."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: Your newly hired engineer suggested using your model for satellite image processing. She asked if you can detect planes in the images acquired."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: We run a sustainable living network that helps people estimate their carbon emissions based on the data they provide us with."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: The marketing team is building a social media campaign for our product. We would need to describe images used in the campaign."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: I am an owner of a gym and have a video of a certain activity. I need to know the name of this activity."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: The marketing department needs help to analyze a series of graphs and turn them into understandable data tables."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: Design an application to help translate conversation. Given audio input, it should transcribe and translate the conversation."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: We need to create a new line of sneaker designs, so we would like you to generate some sample images for inspiration."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: A customer is requesting lyrics of the song to be read out loud. The lyrics are in Japanese. Use a text-to-speech model to generate an audio file from these lyrics."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: I need some help fixing grammar in my essay."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: We need to create a high-resolution image of a futuristic city skyline."}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: The HR team is receiving a lot of CVs from different countries with different languages. They need to translate CVs into English."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: We want to create an application for segmentation of objects in images. The app aims to isolate and recognize various objects in a given still image."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: In order to interact with the Multimodal Image-to-Text model, we need help to create captions for our images on social media."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: Implement a deformable DETR model to detect objects in a given image URL."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: We're building a software to assess emotions during voice calls. Can you suggest a solution to classify the emotional state of the person based on their speech?"}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: Analyze part of speeach tags for a paragraph of text."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: An online news platform is interested in automatically tagging essential information about its articles (e.g., dates, people, events, organizations, locations). Develop a solution."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: An audio content verification system is being built. How can we extract audio features for speech analysis?"}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: Sally wants to fill in the blanks in her sentences but needs assistance. Write a code example to complete her sentence."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: We're building a virtual assistant to support people's practice of spoken numbers (0-9) by verifying if they pronounced the digits correctly. Show me how to use this model to accomplish this task."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: I am building a parking app that shows how far you can park from the entrance, the model should estimate the depth of a parking lot based on a single image."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: We want to summarize the main points discussed in a long conversation between people. Please help us with a model and example code."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: I want to translate a short story I wrote in German to Spanish so that Spanish-speaking friends can read it."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: We need a tool that can answer simple questions based on a given text."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: Our company's research and development department is focusing on adapting deep reinforcement learning techniques for creating agents. We would like to leverage TD3 model for Ant-v3 environment."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: Our team needs to quickly answer questions based on a large table of data. We need an appropriate NLP solution to facilitate this."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: We own a fleet of self-driving cars. We are looking for a way to segment objects in front of car."}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: I am designing a game and I want the model to generate the game's characters, weapons, and tools. These generated images should be based on textual descriptions provided by the game designers."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: I have a tour agency and my clients are from various countries that speak romance languages. I need a system to translate my tour information into their language."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: Translate a machine error message from English to Italian."}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: I am a mobile app developer and sometimes struggle to come up with code snippets for specific use cases. I need a tool that could provide me with code examples."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: Create a program to have a conversation with a chatbot that can generate responses like a human."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: A tutoring platform wants to create question generation system so that tutor can check student's understanding."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: A real estate agency has asked to build a system to extract information from images of houses and provide details like the number of rooms, the type of flooring, and if there is a backyard or not. How can they do this?"}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: Implement a CO2 emission prediction system for vehicles based on vehicle features."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: There is a document provided, can you find the total cost listed within that document?"}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: A fantasy novel writer is looking for an illustration of the main character for their book's cover."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: Create a story starting with the line \"Once upon a time in a faraway land\"."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: Hello, I have a text with missing words. I need some help to predict the correct words that fit in the blank spaces."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: Our company sells products in many different languages, and we receive customer queries in various languages. We need to be able to identify which language the query is in, so we can route it to the appropriate support."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: We are working with medical researchers to extract its data from a chart. Can you decode the chart data for us?"}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: I am making a multilingual decision-support system app that transfers smartphone captions to different languages. Add the feature to classify Indonesian sentences text to retrieve the hidden context."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: We need to produce an image description of a prompt that reads \"royal chamber with fancy bed\"."}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: Our company wants to analyze if two given texts have a logical relationship or not."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: Our company wants to analyze the images from our security cameras to determine what is happening in the scenes."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: A new project demands us to identify speakers from an audio clip. We need to figure out an identifier for each speaker."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: Develop a solution to identify the category of the location given an image URL."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: I am an online platform targeting an international audience, and I would like to translate all texts from English to German."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: Create a tool to predict carbon emissions from different industries based on input data."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: An entertainment company wants a tool to automatically translate dialogues in movies to other languages."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: I'm creating news chatbots for flight center and I want to extract useful information like names, dates, and locations from the text."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: We are collaborating with a wildlife conservationist to identify species in their photos."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: Our e-commerce platform receives a large amount of German customer feedback. We need to determine their sentiments for improvement."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: Our organization receives a vast amount of invoices. We need a solution to automatically extract specific information like the total amount, invoice number, and the date."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: Help me build a system that can answer questions related to a table, such as \"how many people?\", \"what is the total price?\" and so on."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: We are currently planning a marketing campaign in Silicon Valley. We need to understand the key entities mentioned in a report."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: Help me design a personal assistant to extract the total amount and other information from my scanned receipts and give relevant answers when asked."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: We need to generate multiple variations of the same sentence. We can use a paraphrase-based framework for this task."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: I am a writer who often needs help generating ideas for new storylines. Provide a tool that completes story prompts."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: We are working on sentiment analysis on social media content. The content needs classification as positive, negative or neutral."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We received an invoice from a supplier. Can you help us extract the invoice number?"}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: I have a customer support ticket classification problem. Group these tickets to a few categories using sentence similarity."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: Our company is working on a project that requires answering questions with respect to the provided tabular data. We need a solution for questioning the contents of tables."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: \"Ich m\u00f6chte ein Auto kaufen. Welche Farbe empfehlen Sie?\""}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: I have a collection of video frames and I need to classify their content into predefined categories."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: My senior scientist wants to extract meaningful features from Russian texts for topic modeling. How should I proceed?"}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: I want to build a robot for household chores. I need to find categories of chores the robot was able to do."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: A fast food restaurant wants to keep track of the number of hotdogs in their images of food items. They want to automate this by classifying images as hotdog or not hotdog."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: We need to monitor the speakers present in an audio recording of a meeting to assess their participation in the discussion."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: Construct a system that can provide answers for questions based on a given dataset."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: \"Time dilation is a difference in the elapsed time measured by two observers, due to the relative difference in the velocities of the observers. It is a key concept in special relativity and can occur when two observers are either moving relative to one another or are located in different gravitational fields.\""}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: Assist me in identifying the names of German places and people within a text."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: Develop a system that can recognize the actions performed in a video clip."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: We want to analyze an audio recording from a conference room to identify the quality of the acoustics and separate speech from background noise."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: I am a scientist working in a biotechnology company. I need to find the structure in scientific articles to get insights from them."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: Develop a model to process images of documents, illustrations, user interfaces and natural images, then have it generate a relevant description and caption."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: I need to code a simple program using text. Let's start with some Python code to print \"Hello, World!\"."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: Implement a tool which can be used to detect voice activity, overlap speech detection, and re-segmentation for different recordings."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: We are a sports analytics company, and we need to analyze videos of players in action. Automatically classify the type of action being performed by the player."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: Design an algorithm to summarize long Chinese articles for inclusion on the main page of a news website."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: A marketing company wants to create a high-resolution image with inputted text related to \"a futuristic city with flying cars\"."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: I need a description on how to generate anime-style images of a landscape with cherry blossoms."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: The company is working on a document analysis tool and needs to extract answers to specific questions from the text."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: I invest in cryptocurrencies and tend to follow the market news heavily. I want to analyze the sentiment of the latest cryptocurrency news article."}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: Our team at a travel agency receives customer feedback in multiple languages. We need translations of that feedback from customers for our report in English."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: My friend is from Poland, and he is asking questions about a picture while looking at it. Can you help me understand what might be the answer to his question?"}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: We are hosting an auction for rare paintings. For this auction, we need to find a description of a painting."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Our company is receiving phone calls in Portuguese. We want to convert those calls into text for record keeping."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: \"Young explorer with a green jacket and a backpack, standing near a waterfall.\""}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: Our client is a sports broadcasting company. They need to analyze a video and classify the specific type of sports activity being shown."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: Sally needs adialtive chatting for her presentation. She needs to understand the type of movie she is watching based on a video clip."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: A travel agency wants to analyze their customer feedback to determine whether their customers are happy or upset."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: How would you give me a brief summary of a long article?"}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: I want to develop a tool for analyzing the price of houses in the United States. I want to predict a house price based on its size."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: A translator software is needed for people who travel between England and France to communicate fluently in both languages using spoken speech rather than text."}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: An education app needs a way to automatically complete sentences when a word is missing, in multiple languages."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: We need to extract specific data from a structured table containing customer information."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: Generate a random synthetic image of a galaxy."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: \"\u4e2d\u56fd\u7684\u9996\u90fd\u662f[MASK]\u4eac\u3002\", what should the answer be on blank space?"}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: I am building an expert system for an automotive repair shop. I want to match customer complaints with potential solutions based on similarity."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: Our goal is to find out the total amount from an invoice image."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: Our content creation team seeks to improve the quality of articles written in Italian. We want to compare their written articles to high-quality articles in the same domain."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: We have a large corpus of JSON blog articles. We want to determine which article titles are most similar to each other."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: We are a PR agency, and we need a summarization system to summarize news articles in Italian for our clients."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: We are building an AI chatbot to respond to customer inquiries. Make the bot generate a proper response if a customer complains about a late delivery."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: How can we build handy design-style space illustrations to use as desktop wallpapers?"}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: I need a program to tell customers which products are recommended based on comparing their source of protein to a table of nutritional information."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: I need to analyze articles for a newspaper publication. Help me classify them into Politics, Economy, Entertainment, and Environment categories."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: Please inspect an image of a printed circuit board, and then provide information on defects and their locations."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: I want to build an application that helps me answer questions related to images automatically."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: I am trying to develop a voice assistant application capable of text-independent speaker recognition from an audio recording."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: Let's build a fun social network where the users have to guess what areas in the picture are segmented by a specific object. "}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: We are launching a Japanese language dating application and want to autocomplete the profile description sentences for our users. Help us create this feature for our app."}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: I want to create a bot able to answer queries based on tabular data."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: In our modeling project, we want to create a 3D representation of a room from 2D images. For this, we need to estimate the depth of objects in the images."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: We are trying to estimate depth from an RGB image captured by a vehicle-mounted camera to evaluate object distances for autonomous driving applications."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: Our company is creating a product to detect whether an image contains cats or not. Recommend a way to classify images."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: We are working on a project that involves replacing missing words in a given sentence. We need your expertise in this."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: I am a journalist who just recorded a noisy interview. I want to remove the background noise while preserving the speech quality."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: We are an audio company and need a TTS solution to generate audio files for our guided meditation app."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: A local consultant has been hired to categorize whether certain vehicle types will be within the limit allowed for acceptable carbon emissions. In order to enhance the categorization process by providing a faster and more accurate prediction, provide an actionable example of how to use the machine learning model previously trained."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: A content creator wants to estimate human poses in an image. They need assistance in understanding body positions in the picture."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: Please provide a method for answering questions from an input text. It should be fast and accurate."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: Our customer support center has received a voice call, and we would like to translate the call from English to Hokkien."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: We are developing a meeting transcription app. We need to detect sections of the audio recording where people are talking."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: We are a team working on a voice assistant, and we need to detect user emotions from their voice input."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: \"The most famous soccer player in the world is <mask>.\""}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: Our marketing team needs insights from images of our products. We need to identify the most relevant categories related to the images."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: We are trying to improve the safety of forklift operations in a warehouse. We should find a model that can detect the presence of forklifts and people."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: I work for a company that creates smart TVs, and we want to automatically classify the genre of movies played on our platform."}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: The company is building a virtual assistant for travelers to answer any tourist spot queries. Imagine I am the tourist and help me find the cost of the entry ticket at the Eiffel Tower."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: Help a user create a tool to recommend if market a product for this person based on a photo of the user."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: I want to enhance the audio quality of a given audio file, removing background noise and making the speaker's voice clearer."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: We have a team of archeologists who need to estimate the depth of ancient structures in photographs."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: As a financial consultant, I need to extract answers from pictures of financial documents."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: We are designing a product that guides users on how to use an image classifier to recognize various animals."}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: We are trying to build a moderation system for our website comments section. We would like to prevent harmful content from being posted by checking the text for toxicity before it is published."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: We are producing robots for home purposes. The robots should be able to recognize various objects in the home and classify them according to their function and usage. What is the most appropriate model to accomplish this task?"}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: I have a Python code snippet that is incomplete. I want to complete it using bigcode/santacoder."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: Our company is creating a new app which allows people to find the location of an image by analyzing the image itself. We need to find a suitable method for achieving this."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: I have a technical manual about a product we are selling and we want to create an online FAQ to answer customers' questions."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: Build an AI powered voice assistant that can detect when multiple people are talking."}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: We are working on a project of visual storytelling. We need to generate images from text descriptions."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Our client is looking for a solution to predict carbon emissions from different industrial sectors. Let's help them categorize it."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: We are a small animation studio. We focus on making animation films. We want to have a dialogue between two characters in our animation. Can you generate it for us?"}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: I write a blog about healthy food. I need a catchy title for my next article."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: We are a consulting firm for movies and shows production. We need to analyze the voice acting of a specific actor within an episode. Please identify the emotions conveyed in their dialogues."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: I want to create a real-time translation application that can be used to translate spoken language from Romanian to English during meetings."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: Our customer, a green energy company, wants to predict carbon emissions based on their data. We need to help them predict the carbon emissions."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: We need a machine learning model that can identify dog breeds in photos in order to improve our dog breed identification app."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: Our team is developing a robotics walking simulator, and we would like to leverage an AI model to create realistic walking behavior."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Generate an empathetic response to the question \"Why do good people suffer?\" in a conversation."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: I want to create an image segmentation model that is trained on COCO instance segmentation dataset to specifically identify an object in the image."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: A student is working on a project and they need to know the difference between convex and concave polygons. I need a reliable source to get information."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: I want to build a model that will control a bipedal robot efficiently. Can you help me with an API?"}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: \"I love this new phone! The camera is amazing. #HappyCustomer\""}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: I want to create a chatbot that can answer questions regarding various programming languages."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: \"La vita \u00e8 come una bicicletta. Per mantenere l'equilibrio, devi continuare a muoverti.\""}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: We need to rate customer reviews for our products on an online marketplace by identifying positive and negative comments."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: The company's budget department needs to find specific information within financial spreadsheets. We need to find answers in tables using natural language questions."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: We are an investment company, and we would like to classify the sentiments of our analysts' reports."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: We are an AI company working on text recognition and extraction. We want to transcribe handwritten text from an image."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: We are designing a voice-supported home device, and we want the device to give automatic responses when engaging with users vocally."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: Our company developed a GPS device for personal cars, and we want to provide voice navigation instructions using text-to-speech technology. Make sure the generated audio is clear and suitable for navigation purposes."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: We have a news article that we would like to summarize and identify named entities. "}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: A volunteer at a local animal shelter needs help with classifying animals in the photos they've taken."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: I'm running an online tutorial platform. I need a model that can answer questions based on a visual document provided."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We are a real estate website and need to find houses similar in price and location to the one provided."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are working on moving our robot legs in a flexible way. We want to study how a robotic cheetah moves using GPT-3."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: \"\u06af\u0644\u0627\u0628 \u062e\u0627\u0646\u06d2 \u0633\u06d2 \u06a9\u0646\u0648\u0627\u06ba \u067e\u06be\u0648\u0644\u0648\u06ba \u06a9\u06cc \u062e\u0648\u0634\u0628\u0648 \u0622\u062a\u06cc \u06c1\u06d2\u06d4\""}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: We are building a German-speaking AI assistant for senior citizens and require it to speak German fluently. We would like to implement this with the text-to-speech system."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Our next product is a chatbot for customer service. We'd like to get the chatbot generate its answers by understanding questions given by the customers."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: I have data about the latest office supplies in a table form. Help me find the most expensive office supply by querying the table."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: I need to complete a sentence in Brazilian Portuguese where a word is missing."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I am a middle school history teacher, and I need to provide open book tests to the students. I want them to read the context and have the AI answer their questions."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: We're trying to classify flowers for our botanic garden project and need a model to determine the type of iris given some measurements."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We want to build a real-time speech translation device to identify the language being spoken in any audio file."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: I need to create a budget tracker for my team. I want to store the expenses in a table and be able to look up the expenses for each team member by asking questions."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: A company is developing a mobile application for safety in construction sites. They wish to create an AI system that detects workers' heads wearing safety helmets."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: Determine the natural activity happening in a given video and classify it into one of the 400 possible Kinetics-400 labels."}
{"text_id": 57, "text": "document: Protogen x5.8 is a text-to-image model that generates images based on text prompts. It was warm-started with Stable Diffusion v1-5 and is rebuilt using dreamlikePhotoRealV2.ckpt as a core. The model uses granular adaptive learning techniques for fine-grained adjustments and can be used just like any other Stable Diffusion model."}
{"text_id": 57, "text": "query: We are an ad company, and we need to generate a photorealistic image of a red sports car in a mountainous setting."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: We need to build an AI tool to help human agents answer questions about pictures from our customers."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: Based on our podcast collection, we are going to create summaries of it. We have to identify the parts where there is some voice activity."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: Create a script that can enhance a noisy input audio file using the pretrained model for speech enhancement."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: We have some audio from a recent company podcast. Please help us transcribe the audio into text."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: I am developing a blogging platform and I want to generate taglines for blogs written in Korean."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: My team members and I have a huge list of sentences to compare for similarity. We need an efficient way to measure the semantic similarity between each pair of sentences."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: I'm creating a virtual assistant that can greet the user in the morning. Implement an Indian regional language greeting to welcome the user in Telugu."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: We are working on a project for carbon emissions analysis. We need to estimate the carbon emissions from different sources."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Help me summarize an article from a Russian newspaper."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: We need to write a press release for a Japanese audience. We could use some help with sentence completions."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: As a student learning German, I'm participating in an online chat, and I would like to translate all its German content into Spanish."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: Create a vivid image of a beautiful place with analog photography style in your mind."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: I am working on checking spam mails, I need to find similar paragraphs from a collection of email texts to classify a mail as spam."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Design a tool that creates poster images for a butterfly-themed event."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Our company is developing a marketplace for antiques painting in Chinese. The goal is to categorize paintings into existing categories."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: We are developing a fitness app that shows live workout sessions. The user speaks about a workout, and the app will display a short video of the workout."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: I have a long news article, and I want to use natural language processing to create a summary of the article."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: I have an old recording with a lot of noise. I want to clean it and make it more audible."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: You are building an automated transcription service for a podcast company and need to identify who is speaking in each segment of the audio files."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: Create a video based intrusion detection system that analyzes video frames and identifies any unauthorized activity in a restricted area."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: We are building a surveillance system that detects cars in the parking area of a mall. Help us with the process."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: We need to predict whether a person makes over $50k a year based on their US Census Income Dataset attributes."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: A developer wants to automatically convert an incomplete or incorrect Python code snippet to a complete, correct version."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: Our customer often receives images in a blurred format, we need a solution to generate the clear form of the image."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: A smartphone app needs to integrate image recognition capabilities to classify objects in images."}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: Write an AI that can respond with an image that follows a given input prompt description."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: Generate a short introduction about the upcoming technology conference in our city."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: We are creating a football analysis tool to find on-field players. We need to detect player helmets and faces."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: We own a start-up for developing acuity tests for assessing hearing in infants. We need to build a classifier to detect beeps in a noisy recording."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: My friends and I are building a positive review classifier for phone apps. We will want this classifier to define reviews like good, normal, and bad.. Please create this bot that will sort the reviews for the apps."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: We are building an animal species identification platform. We need to figure out whether an animal in a photo is a cat or a dog."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: Construct a community based forum, which helps users to give insights about the whereabouts of their favourite celebrities."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: We are writing a novel. Can you predict the missing word based on the context?"}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: I need to unmask text to complete a sentence from a popular book."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: I would like to create a fact-checking chatbot. I need the model to be able to answer questions in any language."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: We are building a movie recommendation system. We need to determine the sentiment of movie reviews in German."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: I'm building a customer support chatbot to handle user's inquiries. I want the model to generate human-like responses upon the user's request."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: A novelist is working on an app that generates the next paragraph based on the summary of the text novel users previously read. Develop the functionality for generating the next paragraph."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: Can you help me generate a text description from a product image on the website?"}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: Your Japanese friend wants to complete a sentence but can't quite remember the word that fits in the gap. Help them fill the gap in the sentence with a suitable word."}
{"text_id": 133, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 133, "text": "query: I'd like to extract information from a complex document by asking questions about its content."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: Our marketing team needs to study the audience on social media platforms and mine their reactions. Detect named entities in German tweets for better targeting."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: I'd like to have an AI that can create a picture of an astronaut standing next to a bicycle on Mars with a flag held high."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: Our company is working on a project that requires the classification of images without training a model. We need a zero-shot image classification model."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: We need to create advertisment designs for a car brand, and we want to combine the descriptions of the car with the visually of the car."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: We need to identify which sentences in a list of customer reviews have similar content to help us understand common trends and patterns."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: Help us answer the question about a university's tuition fee given the following college table."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: We are building a smart camera for home security examining the scene of entrance, stairs, cameras, and also should detect animals, determine the breed of dogs and cats, and when the camera recognizes them, to open the door for them to enter or leave the house."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: We want to automatically tag items in our e-commerce website with corresponding category labels."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: We have a half-written Japanese marketing statement, and we need your help to complete it by filling in the blanks."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: I want an AI chatbot to generate engaging responses to user prompts for a new online dating platform."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: We are a company providing an image recognition solution. We are asked to build a tool that can identify the most likely class of an object in an image."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: A fantasy novel writer needs a visual representation of their character \"A mystical wizard with a golden beard and a staff adorned with glowing jewels\" to be created from scratch."}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: The client recently developed a new high-resolution image display technology. We need to upscale all low-resolution images in the database to the new standard."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: \"La Tour Eiffel se trouve \u00e0 Paris, en France.\""}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: We are a production company working on a TV show, and we want to identify the emotions expressed by the characters in our show's dialogues."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: I want to generate an image of a royal chamber with a fancy bed using AI."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Currently, our urban planners require an image segmentation tool that can help identify buildings in satellite images."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Our design team needs to create a banner for a new blog post. We need an image based on the blog post title, \"Top 5 Gardening Tips and Tricks.\""}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: We are a power plant analyzing carbon emissions data to find ways to reduce our carbon footprint. Classify and predict the carbon emission level in grams from a given set of data."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: Write a code that would help with completing sentences, given a partially completed sentence with a missing word marked with `<mask>`."}
{"text_id": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 64, "text": "query: The CEO needs to understand the content of an image by reading a description in text format."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: Global Offensive (CS:GO). Please implement a solution to detect players in-game."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: Determine the depth of objects in an image for an autonomous robot to identify and navigate better in its environment."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: The accountant in the firm needs the information about past expenses from the dataset to close the financial year. Help them fetch the total expense for the year 2018."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: As a vehicle safety company, we need to detect potholes to provide our customers with accurate road safety information."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: We are working for a medical center. Recently, we encounter some medical questions that are difficult to answer. So, we need your help."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We are developing a software to forecast carbon emissions. Will this model be helpful for our needs?"}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: We are building a medical device that helps the doctors with recognizing different types of blood cells. Can you help us with object detection in medical images?"}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: Adam has a startup that sells food products to consumers. He is in need of a recommendation system to display relevant nutritional information. Generate a model that can accomplish this."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: The company is building an AI application that filters commercials from audio podcasts, and we need to identify if a given audio clip is a commercial or not."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: We are building a product for an insurance company to determine if their user should purchase an insurance policy based on financial information."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: There's too much noise in the audio recording we just did, is there a way to get an audio file with better sound quality?"}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: I have an audio file of my customer's call. I want to transcribe and translate it to text."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: Imagine you work at a law firm and you need to answer questions related to a specific document. Develop an algorithm to do this task."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: I want a method integrated with the Hugging Face pipeline to detect tables in a given document image."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: We are an environmental organization and we plan on creating marketing materials about butterflies. Can you generate some cute butterfly images for us?"}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: Can you help me generate an AI art based on the text prompt \"peaceful forest with a small river and a wooden bridge\"?"}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Design an application to detect diabetic retinopathy in a patient using retina images."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: We need to identify the sentiment (positive, negative or neutral) of recorded customer calls in Spanish. Please provide the necessary information to achieve this using an AI model."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: Our factory needs software to identify defects in printed circuit boards (PCBs) from the images taken during quality control checks."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: We have received product reviews where customers have mentioned food items. We need to extract the food items from the reviews."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: Can you please convert my company report from English to Spanish?"}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: We intend to create a social media post about a scientist studying plants in an underwater laboratory."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: We are a startup company looking for a way to classify the type of bird from an image."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: We need a model that can predict if a given sentence implies either politics, economy, entertainment, or environment in multiple languages."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: A pet store wants to create an AI-generated advertisement that features an assortment of pets. We need to generate images of cats, dogs, and hamsters."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: Develop a multi-lingual paraphrasing tool to rewrite the given text."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: We are building a smart application to help people with disabilities in understanding their job possibilities. We need to analyze their data. We will start with a tabular Transformer model for Structured Data Learning"}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: A photographer is looking for butterflies picture for inspiration, and she would like to create new designs based on butterflies' patterns. Generate a cute butterfly image that she can use for inspiration."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: We are a media company building a documentary on Titanic passengers. We need a model to predict the survival of passengers based on their details."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: How can we leverage this model to answer questions about tabular datasets? We need to analyze financial data and answer questions."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: We're curating an archive of historical events. Help us retrieve relevant information about Marie Curie."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: I am in a middle of creating a blog post with this sentence \"We took a trip to the <mask> during our vacation.\" Unmask it, please."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: \"I can't believe I managed to pass the exam, I am over the moon!\"."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: I am trying to improve my Japanese learning assistant for my children, could you please text suggestion in Japanese?"}
{"text_id": 487, "text": "document: This model is a fine-tuned version of cambridgeltl/SapBERT-from-PubMedBERT-fulltext on the squad_v2 dataset."}
{"text_id": 487, "text": "query: Write an example of code that answers the question \"What is the main treatment for hypertension?\" using a given medical research document as input."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: My client is a company that translates documents. Prepare a machine learning model that can translate text from French to English."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: Our startup aims to build an auto-completion tool for programming languages. Help us extract features from source code."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: We need to create a summary of a news article about a recent financial event to be published on our company's newsfeed."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: Our office is in a loud environment, and we record meetings for minutes. We need to remove the noise from the recordings."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: The department plans to analyze text from several customer call transcripts."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: I need to implement a search functionality for my company's intranet system that should be able to accurately find relevant documents based on the user query."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: A lawyer needs help in extracting specific information from scanned legal documents and would like to have an AI-based solution to extract relevant information."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We are a calligraphy archive and want to transcribe handwritten text from the images of ancient scripts."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: I'd like to figure out what animals are in a given picture. Create a model that takes the image and a text query and returns the detected objects in the picture."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: We are a company in the entertainment industry that needs to create promotional posters for new anime characters using textual descriptions."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: We want to develop a computer vision application to estimate the depth of objects in images. Help us create a depth estimation model."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: Create an automatic video content recognition system to detect and classify actions taking place in a video."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: We are a multinational company. We need to translate a marketing text from English to German."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Create a virtual assistant that can describe an image of my favorite vacation spot and give me some travel tips."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: Create a python script to identify if a given anime image is created by AI or a human."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: I have some audio files and need to segment them based on when a person is speaking. Can you do that?"}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: We run a restaurant and want an algorithm to predict the tip amount for our customers."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: I am creating an online photo gallery that contains buildings images. Make sure that the image is segmented and passed through the model, which will enable me to identify objects in the images."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: Develop a system to automatically analyze public opinion of a company's social media posts by the sentiment expressed in the comments."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Our company recently decided to produce a podcast. We need help with noise reduction for the target audio."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: We are creating images for the universe to be used in a campaign. Generate a realistic image of the universe."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: An organization is developing a platform to answer questions based on images. Implement a solution that can answer textual queries about a given image."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: Implement a strategy to provide a weekly weather report for a selected city to ensure users stay well-informed about the weather conditions."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: We want to understand the sentiment of user reviews for our online store. Use a model to analyze the review and tell us if it's positive, negative or neutral."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: Develop a table question-answering system to help our customers access information about our product catalog."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: The company is planning to expand their market to Russia. They need to translate marketing documents from Russian to English."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Our company works in developing robotic arms, and we are aiming to improve the efficiency of our robotic arm to pick up objects with greater precision."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: \"The movie was good.\""}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: Our media company wants to generate a Sci-Fi story for our readers. How can we start the beginning of the story?"}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: I am a chatbot developer; I need to optimize my paraphrase creation for my replies. I aim to select the most adequate generated paraphrase."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: The company's management wants to monitor its carbon emissions. They need to generate a report if the emissions exceed the allowed limit."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: We are a sports company and need statistics about past Olympic Games. Find in which year Beijing hosted the Olympic Games."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: I found an image online and I have a question about the image. I need you to generate possible correct answers to my question concerning that image."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: We plan to build a restaurant-booking chatbot. This chatbot not only needs to provide a greeting to users but also provide details about the restaurant if they have any questions."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: I am designing an app for the visually impaired that helps them to recognize objects and answer questions based on an image. I want to use the multimodal visual question answering to achieve this."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: In order to find similar tweets, we need to determine how close two sentences are semantically."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: How many people are in the given picture?"}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: We need to create a 3D model of an indoor environment to build a robot that needs to navigate on its own. We have different views of the indoor environment and want to create an approximate depth map of the scene."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: Our bot should be able to tell if a person is demonstrating a certain athletic skill, such as sprinting, swimming or weightlifting, from short video clips."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Develop a chatbot that can have interesting conversations based on the user's personal preferences."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: Write a script which will take a sentence with a missing word and predict the most likely word to fill the gap."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: Generate a Minecraft skin for a user who wants to represent themselves as a superhero in the game."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: Design an advertisement for our smart speaker that automatically generates great image captions."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: You are building an App to help visual impaired individuals to navigate in space. It requires to estimate the depth from any given image."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: Create a classifier to predict whether a person earns more than 50k or not, using their age, occupation, and hours worked per week."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: I run an online art store and I want to classify the art pieces uploaded by the users into different categories like abstract, landscape, portrait etc."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: We are an environmental consultancy company that needs to predict carbon emissions for a client's business."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: I want to build a program that connects to my home security system and recognizes whether an object appears to be out of place or not."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: We would like to build an application that helps students understand academic articles by answering questions related to content present in tables."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: The company needs a chatbot which can answer in 100 languages, classify sentences in many categories."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: We need to extract important details about World War II from a history book."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: Predict the health points of a Pokemon named X with a special attack of 50, defense of 75, and a speed of 100."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: I want to generate task-specific embeddings for a given sentence \"The time complexity of this algorithm is O(n^2)\" with the instruction \"Compute the textual representation of the algorithm complexity\"."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: John is a businessman from the United States who took a holiday in Finland. While visiting, he received urgent emails from work in Finnish. Therefore, he needs to translate these into English."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: As a news reader, I have no time to analyze the long news article. Please help me to find named entities in a given paragraph so that I can quickly comprehend the content."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: A research group has just published a scientific article. We need to summarize the article for a general audience."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: We are a call center company that answers customer calls. We need to quickly transcribe our clients' speech from the phone conversations they are having."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: Develop a monitoring report by using AI on a new climate change awareness campaign started by a non-profit organization."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: As a representative of the governor's office, you need to answer questions from the public using an AI-based chat system."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: I have a food blog, and I need to classify images of food into different categories so that they can be tagged and displayed on the appropriate page."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: One of our customers uses an app to transcribe voice messages. We are integrating into the back end to transcribe the audio using the OpenAI Whisper API."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: As a journalist, I need a way to transcribe the audios of interviews into text format."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: I have an article about a newly discovered planet, and I want to get a summary of it for my astronomy class."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: As a company working on self-driving cars, we need to estimate the depth of the objects in the car's camera view."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: I have a painting and need to write a description or a story about the painting. The description should be creative and interesting."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: We want to build an Optical Character Recognition (OCR) system to read the text from images automatically."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: As a writer, I need to write an article on the effects of climate change on the world food supply. I could use some inspiration! Please generate ideas for the article quickly."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: We design smart glasses that provide visual guidance for blind people. We need a depth estimation model to determine the distance between obstacles and the user."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: The board members have requested the quarterly review to be translated into Chinese."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: We need a question answering system for multimodal documents."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: We have many recordings with lots of background noise. Is there a solution to remove these noises from the recordings?"}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: Develop a program to recognize spoken digits from an audio file."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: We are asked to create AI-generated bedtime stories for a publishers children story book. Let me know what steps to take."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: We are a media company in need of a creative way to generate multiple illustrations based on textual descriptions."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: \"This technology is great, it uses ___ for natural language understanding.\""}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: Develop a system to clean up a messy podcast audio file with background music."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: A housing company is trying to build a model to predict housing prices in California. Help them build a model based on RandomForestRegressor."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: A publisher needs to convert the text in a Japanese manga page into a digital format for their online release."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: A platform allows users to post reviews on movies. Determine the sentiment of the movie reviews provided by the users."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: I am an energy trader, and I need a model to predict the energy consumption for a day based on various parameters like temperature, time of the day, and humidity."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: Identify the key activity in a video and recommend whether it's suitable for children ages 5-12 to watch."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: Design an app that can quickly classify food items to help users choose a healthy meal."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: We are a publishing company and we need to create text teasers for a new book we are promoting."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: Predict the electricity consumption of a residential building using a dataset containing historical hourly readings."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: As a history teacher, I would like to create a question-answering system that can answer questions about historical events using a table of such events as its input."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: We need to classify if a video contains any real-life violence situations or not."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Can you translate images of documents and make them searchable by their text content?"}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: In order to create a search engine for our e-commerce website, we need to classify and analyze product images to determine their categories."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: A teacher is asking the question, \"What is the capital of France?\" and we want to help her students find the answer."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: Our research team in Groningen is shifting to work with Dutch text analytics. Help us build a NLP model for processing and understanding the language."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: A research lab needs a summarization tool to summarize key points from their long research papers."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: We need to retrieve some information from a support document. Help us in getting details about a topic from given text."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Create a program to help me identify bird sounds among ambient noises in nature recordings."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: I want to build a question-answering system that finds the most relevant answer from a list of given contexts."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: Identify the type of objects shown in this image - https://clip-cn-beijing.oss-cn-beijing.aliyuncs.com/pokemon.jpeg"}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: Our marketing team is seeking a summary in Russian of a long dialogue between coworkers."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: Our client is a travel agency and wants to develop an app that will geolocate the city from an image taken by a user during their trip."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: Design a feature for a mobile application that processes images of documents with tables and extracts the table content."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: Imagine you work in customer support and handle user issues. Your database team forwards you sales numbers for specific products. Based on provided sales numbers, provide an answer to a user's question about salesrank."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: Can you help me convert the provided Persian text into a video?"}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: We need a solution to compute the similarity of given sentences."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: We want to create an application that generates pictures of churches to be used as concept art or inspiration."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: We are a clothing company, we need someone to translate descriptions of our products from English to French."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: Identify the object present in the provided image."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: Design a program that can take a document with both text and tables while answering specific questions from it."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: Identify the emotion in the sentence \"I can't believe I finally managed to score the interview with my dream company!\""}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: As a business intelligence company, we want to analyze a table of data and extract relevant information to provide insights."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: We need to build a mobile app that recognizes objects in pictures taken by the app. It will be used for guided tours in museums."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: Design a system to classify and organize video files based on content."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: An online education platform wants to categorize their math video tutorials on Number Theory and Algebra. The model will help them to do so based on video content."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: Our client wants to predict the carbon emissions generated by their company based on a set of input features. Help them get the predictions."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: Please give me some advice on how to create a football video game using artificial intelligence including poca agent playing SoccerTwos."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: As a geospatial analyst, I need to segment an aerial view of an urban environment into buildings, roads, parks, and other features."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: We are organizing a conference dinner and need to sort the attendees by their dietary preferences and pick the right menu."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: Identify the named entities such as persons, locations or organization in the provided sentence."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: I want to test Legal-BERT to guess the completion of a sentence in the context of law, like contracts, agreements, and rights."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: We received some feedback on our podcast production. Our podcast listener satisfaction has been decreasing lately. We need to enhance the audio quality of our podcast."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: Design a code to build a model that can classify objects in different categories for an image classifier to be integrated into a mobile app for visually impaired customers."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: The newsroom needs a tool that quickly analyzes news articles and finds which ones discuss similar topics. Please use sentence embeddings to accomplish this."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: Recommend a movie soundtrack for a user based on their past listening history which includes audio features and other relevant information."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: An interior design company needs a system for their store to identify which furniture items are in a given room image."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: We are a smart city developer. We want to get the segmented map of our new development area."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: We have a dataset of scanned documents containing information about various museum exhibits. We want a solution that can help visitors extract specific information from these documents by answering questions based on the content."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: We want to build a sports video analysis tool that helps to categorize different sports actions."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: We run a data center, and we want to predict carbon emissions for the data center based on input features."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: Our webshop is getting a lot of Dutch customers. To provide better support, we'd like to generate Dutch sentences all around our webshop."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: We are an e-commerce platform. We need to classify the products that users are uploading."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: I need an intelligent agent to analyze videos and classify the primary activity taking place in the scene."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: Could you help me build a question and answer interaction tool from a specific context?"}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: Translate a German news article into English for the company's international website."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: Can you help me build a program to answer questions from a legal document that was given to me in an email?"}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: Let's extract the answers from the document. Use the model to find the answers when given the bounding boxes and questions."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: Our company is designing a conversational bot. We are looking for a way to answer user's questions from a given context."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: Building a monitoring system for manufacturing, to check for any defects on printed circuit boards (PCBs). Help me identify PCB defects."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: Develop an application to transcribe the spoken language in an mp3 file and display the text."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: I need a summary of a news article."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: Detect important features from images to help our new information filtering service."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: Summarize french news articles for me."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We have a large database of football player statistics, and we want to build a product that can answer different questions. For example, the product should output the number of goals scored by a player when we input their name and season."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: Our client needs a solution that can estimate the depth in a given 2D image of an indoor scene."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: We need to analyze the emotional tone of a podcast episode to better understand the audience's reaction."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: Jennifer wants to create a chatbot for the students. The chatbot needs to receive questions as input and return answers after processing the school documents."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: Design a computer vision solution to identify rare bird species. Prepare the main code segment to be used for classifying the bird species in images."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: Implement a document processing system that is able to extract information and answer questions from an invoice or a billing document."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: Provide information about a pre-trained text-to-text transfer transformer that could be used for tasks such as machine translation, article summarization, and question-answering."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: Create a system that identifies potholes in images and segments them."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: I am writing a science-fiction themed novel. Help me complete the sentences by predicting appropriate words in place of any blank areas in the sentences."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: Our client wants to upscale images in a coffee shop application."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Our customer needs an application to extract information from received invoices. The app needs to extract invoice number, date, and total amount."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: An AI researcher is keen to learn about the benefits of model conversion. Could you provide him with an answer?"}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: We would like to know if our newly launched marketing campaign is doing well in the Spanish-speaking community. Sentiment analysis could help us to have a better understanding of their feedback."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: John, a fiction writer, is creating a dialog between two characters. He needs help creating a response for one of these characters."}
{"text_id": 405, "text": "document: camembert-ner is a Named Entity Recognition (NER) model fine-tuned from camemBERT on the wikiner-fr dataset. It can recognize entities such as persons, organizations, locations, and miscellaneous entities."}
{"text_id": 405, "text": "query: \"Apple a \u00e9t\u00e9 fond\u00e9e le 1er avril 1976 dans le garage de la maison d'enfance de Steve Jobs \u00e0 Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne14, puis constitu\u00e9e sous forme de soci\u00e9t\u00e9 le 3 janvier 1977 \u00e0 l'origine sous le nom d'Apple Computer, mais pour ses 30 ans et pour refl\u00e9ter la diversification de ses produits, le mot \u00ab computer \u00bb est retir\u00e9 le 9 janvier 2015.\""}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: We are a company producing smart TV's and we need a model to generate textual information about images and answer questions."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: Given an image, we want to predict the theme of a wedding based on the image of the decoration."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: A music lover wishes to know a unique sentence or statement that speaks about renewable energy in the context of electric cars in a conversational tone as if it were tweeted by Elon Musk."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: We are analysing phone conversations. We need to transcribe the speech into text."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: I want to create a random high-quality image of a person for my design work."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: I need to extract important details related to medical findings from a research text."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Urban planning engineers have an interest in identifying and creating building maps from satellite images."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: I am looking to create a personal AI-powered decor assistant which can provide short descriptions for the uploaded pictures of furniture for my online shop."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: As a bank, we need to predict whether a client will default using the given bank loan application data."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: A manga translation company needs to extract text from manga images to be translated. Converting Japanese text inside manga images into a machine-readable format would help their team."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: Develop a tool for our customer service department that automatically detects emotions from the caller's voice."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: We want to create an emotion analysis tool that can detect emotions in spoken content, like phone calls or interviews, to provide better customer support."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: An urban development company wants to analyze city images to inform infrastructure plans. Extract features using a semantic segmentation model."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: I need a virtual assistant in German that can detect network problems and classify them into different categories like hardware issues, software issues, network downtimes, or internet speed problems."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: An online educational platform needs a text classification system to categorize blog articles into subjects like history, science, and art. Assist them in achieving this."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: An user of our application has a scanned legal document and wants to extract relevant information by asking questions related to document. Utilize a model to help the user."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: We are analyzing social media posts, and we need to extract text from images to understand the messages being shared."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: We are developing an application that can classify human activities in video clips. Please help us detect activities from given video data."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: In a short story about cats and dogs, we need to find out who the main character in the story is."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: \"I want to have a ____ for breakfast.\""}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: Our team is working on a project that needs to identify common gestures from videos. Help us find a suitable model."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: My technology can identify regions in images. I need to integrate depth estimation to augment the generated data."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: Design a method that would allow detecting license plates in an image taken by a surveillance camera in a parking lot."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: We are running election polls and have compiled detailed statistics on previous elections. We need to find out which city had an election in the year 2008."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: I need to create an image classifier for a mobile app. The first step is to find a model with a compact architecture."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: We are a company that develops interactive advertisements. We need to generate images of superheroes with unique attributes based on textual descriptions."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: We are building a chatbot, and we need to detect named entities from a given text. The chatbot could receive various texts, so use a model that supports multiple languages."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: I am planning a trip to San Francisco and need to double-check if this image I found online is really from this city."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: Considering the adult dataset income classification, create a binary model to predict the likelihood of an income less or greater than 50,000 dollars."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: The psychologist team is building a tool to help with mental health support. But they want a fast AI to quickly classify emotions in the patient's spoken words."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: Our customer is a data journalist. Let's find a quick fact from the statistic data for an upcoming news report."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: Create a question answering form to prompt users to complete a sentence by filling in a mask."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: We are operating a robotic arm needed for autonomous construction sites. In order to control the robotic arm's movement, depth estimation will be used."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We work in an environmental agency in charge of controlling the carbon footprint of our town. We need assistance predicting carbon emissions for new households."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: Translate German sales emails to English so that the sales team can address the clients' needs."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: I work for a Podcast App which provides auto transcribing of podcast in different languages. How can I use the API to transcribe podcast in English?"}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: Support a group of students who are learning French. We need to translate an English sentence into French."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: Our client requests a particular scene where an astronaut is riding a horse on Mars. Can you generate this image using text description?"}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: We are working on a financial analysis project in our company. Our analysts need a quick summary of financial news covering stock, markets, currencies, rates, and cryptocurrencies. Summarize a given article in a short paragraph."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: I need a model that can provide me with creative marketing taglines that are unique and can be catchy based on some inputs."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: Perform a classification of CO2 emissions using given Data."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: I want to build a conversational AI agent to integrate with my application. This agent will generate responses based on user input in a conversation."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: Develop an application that helps users with English language learning by suggesting the correct word in a given sentence with a missing word."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: We are a startup company focusing on data analytics, and we need a tool to compare similar sentences in a dataset."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: Our organization wants to become more sustainable and eco-friendly. Help us predict the CO2 emissions of our ongoing projects based on provided data."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: Implement a language model to fill in the blanks in a given French sentence."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: \"Buenos d\u00edas, me gustar\u00eda reservar una habitaci\u00f3n para dos personas en su hotel para el pr\u00f3ximo fin de semana.\""}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: Our team is a non-profit focusing on translation for diverse languages. We need a translator that takes into account less spoken languages."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: Encode a call center conversation and convert the audio to text using automatic speech recognition."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: I have a table of monthly expenses, and I want to build a program that analyzes this table and answers questions like \"What is the total expense in January?\" or \"Which month had the highest expenses?\""}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: As a designer, I often need to generate creative ideas for character concept art. Can you help me create a concept of a character with long black hair, wearing a red kimono, sitting next to a pond with cherry blossoms in the background?"}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: We need to answer questions related to a table containing information about various cars such as their make, model, year, and price."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: Our world-wide company wants to translate its English news to Portuguese so that it reaches more people."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: You are to extract important data elements from invoices to facilitate a better decision-making process."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: \"Welcome to our world of imagination and creativity.\""}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: I have an online clothing store and I want to create ads with text descriptions. Generate images based on the text descriptions."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: In order to improve the sound quality of our recordings, we need a speech enhancement tool to eliminate background noise."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: Create an AI system that translates input text from one language to another, specifically German to English."}
{"text_id": 1, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 1, "text": "query: We need to analyze biomedical texts and extract features important for downstream tasks."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: Create an autonomous agent that can efficiently recognize audio commands, such as the numbers 0-9."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: Isolate statements that have a political bias. Classify the detected bias into categories like left-wing, right-wing, and centrist."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: I am building a categorization model for my blog posts. They will be categorized based on their similarity. I need a model that can compute the textual similarity of the posts."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: We are going to launch a search engine for pet images. We want to classify whether an image contains a cat or not."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: We are a call center company, we need an automatic text response system for our clients when they have some questions."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: We have a list of articles, and we want to create an overview of each article by writing a short summary."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: As a teacher, I need to transcribe audio filesof students' speeches into written text in English. How can you help?"}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: I have a cooperative team project to create a food recipe finder. How can I create a conversational component to interact and provide recipe suggestions?"}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: I want to build an app that categorizes news articles. Can you help me detect if a news article is related to technology, sports, or politics?"}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: Create an AI application that identifies objects in images and sorts them into categories, such as animals, vehicles, plants."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: I am trying to convert an image into readable text to automatically update my customer information in a banking system."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Detect tables in document images and print out their confidence scores and locations."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: In a IT support group, we need to categorize incoming requests into hardware, software, or network issues."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: We are offering a course on Python programming for beginners. Please suggest a crisp course description using the openai-gpt language model."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: Our company wants to predict carbon emissions of cars based on several factors. We need a solution to analyze it and give us the output."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: We would like to improve our customer support with an chatbot that can reply to general customer questions."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: As a French learner, I want to surf on the English part of the internet, but I cannot understand the language well. I need some help to translate selected paragraphs from English to French."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: Please help me to build a conversational AI to assist the customers of my online store."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: We are working on an application to analyze the content of satellite images. We need to be able to distinguish individual elements (such as vegetation, bodies of water, buildings) from one another."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Please help me generate a short story on the theme of \"the adventures of a young llama\"."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: Our research team needs to build software to extract company names from articles to analyze trends and opportunities."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: A parking payment system is asking us to identify the license plate in the parking lot footage."}
{"text_id": 36, "text": "document: Stable Diffusion v2-1 is a diffusion-based text-to-image generation model developed by Robin Rombach and Patrick Esser. It is capable of generating and modifying images based on text prompts in English. The model is trained on a subset of the LAION-5B dataset and is primarily intended for research purposes."}
{"text_id": 36, "text": "query: A fashion designer is looking for inspiration for a new red dress design with a futuristic theme."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: As a medical institution, we have a lot of patient records. We need to anonymize the patient names and protected health information in these records."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: I want to implement a voice activity detection feature in a meeting transcription app."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: Our company is building a stock market prediction tool and we need to predict the closing price of a stock based on historical data."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: The client desires an application to describe the elements present in images of documents and user interfaces."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: We have been hired as consultants to develop a chatbot for a restaurant to answer customers' frequently asked questions."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: Can you provide me with a solution that can answer questions about a table of sales data from different stores?"}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: Extract information from invoices in order to automatically populate payment details and amounts on the app."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: Given a dialog context, show me how to generate an empathic response using GODEL-v1_1-large-seq2seq."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: Offer a recipe recommender system based on the ingredients in the user's refrigerator."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: We are in the process of creating an advanced AI-overview system to extract titles from documents."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: \"The quick brown fox jumped over the lazy dog.\" and \"A fast brown fox leaped over a lazy canine.\""}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: We are running an animal rescue organization, and we need to identify the type of animal from different captured photos."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: As a multinational company, we need to extract named entities such as persons, organizations, and locations from news articles in multiple languages."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: Create a story for a children's bedtime audiobook based on the input text."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: Engage in a dynamic conversation with the person who loves Star Wars."}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: In my speech therapy class, I need to help a russian studen with speech impairment. Can we predict if this statement is true or false from his narrative or statement?"}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: I want to train a robot to balance a two-link pendulum on a fixed motor in minimum number of actions. What algorithm can help me with training and evaluation?"}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: The radio station is looking to segment their recordings into individual speaker contributions. Assist them in doing this."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: Our client is a startup that provides remote language learning services. They need a Russian conversational chatbot to interact with their customers."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: I need help with my yearly personal finance report. I want it to accurately track my revenue and expenses, and report the yearly balance. Additionally, I need this to be done empathically."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: Can you show me how to run a BreakoutNoFrameskip-v4 game using the PPO algorithm?"}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: \"The dogs runing very fastly\""}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: In our support center, we receive many different messages from our customers. We need to find similar questions to avoid redundancy and make our job faster."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: Use a generative model to create images of people's faces for a marketing campaign. The images should be 1024x1024 pixels in size."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: I want to create a language identification system to detect the language of given text."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: I want to build a game for kids where they need to complete sentences, so I need a model there to complete these sentences."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Our blog's introduction about the history of artificial intelligence needs to be catchy, we need something to hold users' attention. Can you help?"}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: My father would like his biography translated from English to Romanian."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: Develop a reinforcement learning game that is able to play and interacts with the environment using PongNoFrameskip-v4 reinforcement learning system."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Our company wants to categorize real-world sounds within the environment to improve the functionality of our devices."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: I need a tool that can extract answers from a table with various data entries. The tool must be able to understand the context from the column and row headers before displaying the relevant information."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: As a smart home developer, I am building a home security system that classifies the activity in front of the camera. Help me classify the activities based on video data."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: We are working on a brochure for our company. We want to apply a creative edge effect to one of the images to make it stand out."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: We would like to develop a mobile application that helps users recognize objects in images. We need a recommendation for a deep learning model to use."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: Develop a computer vision solution that recognizes and segments objects in an image provided as a URL."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: I would like to create an audio clip of a given text in a Taiwanese Hokkien accent."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: Design an app that helps people identify and categorize the sounds they hear in their environment, such as traffic noise, children playing, rain, etc."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: We are a company that is creating a code learning platform. We need assistance in generating Python code examples for our content."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: I need an automatic tool to detect names of people, locations, organizations, and other miscellaneous names in a long article."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: Let me generate some butterfly images to include them in our natural reserve's promotion materials."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: We work at a data visualization company, and we are asked to find which Olympic Games were hosted in Athens."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: We are developing an image description generator for the tourism industry. We need a model to classify attractions, foods, and places to visit."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: Discover the names of people, organizations, and locations in the given text."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: I need a tool for recognizing objects in an image given a user's question about it."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: We are a pharma company looking for drug reviews on different forums. We want to automatically fill masked words in sentences to form proper context."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: A bakery just opened in our neighborhood and needs a logo. Generate a logo with a text prompt describing their new baked goods."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: Use a pretrained model for sentiment inferencing to find out if stock-related comments are positive or negative."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: As part of my thesis, I've written a long document about the benefits of solar energy. I want to use this model to generate possible questions that can be asked about my document."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: A journalist is interested in writing an article, so the journalist needs help with extracting entities from a text document."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: We are building a text classification platform to categorize emails into different topics, such as inquiries, complaints, and marketing."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Create a system to automatically categorize customer reviews into relevant categories for analysis."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: Ask the assistant to help suggest subjects for emails without using repetitive words."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: I am the CEO of a media company that produces journalistic content. I need to determine the topic of an article."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: The marketing team needs help interpreting a chart about product sales over the past year. Provide them with a structured data table based on the chart."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: Our online gaming platform needs a way to generate catchy and engaging descriptions for new video games. We want to give it the name or the setting to create a captivating paragraph."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: We want to create a visual representation of a scene with \"a dark forest with a hidden cabin\" based on textual description."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Analyze a dataset of convicted criminals to predict the likelihood of recidivism."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: \"My cat just knocked over my coffee and now it's everywhere!\", and I want to know which emotion corresponds to it."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: I have a data containing years when cities hosted the Olympic Games. I want to create a function that answers a question related to this data."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: Provide me with a solution to infer the sentiment of stock-related comments to make better investment decisions."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: Analyze a photo and provide a brief description."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: A history professor needs help to predict the fate of various Titanic passengers based on data like their age, gender, and passenger class. Help the professor with this task using an appropriate model."}
{"text_id": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 797, "text": "query: We need to separate the background noise and clean up an audio speech file. We have some important meeting recordings in a crowded place."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: I want to create an AI-based chatbot that can provide answers to questions and carry out a conversation with users."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: Please generate an image based on the description \"a person running in a park\" using control points generated from a reference image of a person walking in the same park."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: One of my interests include digital art and I would like to generate an image of a sunflower using text input."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: Please create a computer vision application to segment images and recognizes objects such as trees, cars, buildings etc. for a smart city project."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: I want to create an application that classifies different video clips and categorizes them based on the content. This way, we can create a catalog of videos for users to browse based on their preferences."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: We have a large warehouse filled with a variety of products. We need a system that can identify these products and sort them into appropriate categories based on their images."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: We are an illustration studio and are working on a series of illustrated picture books. We would like to use text-to-image models to generate a few initial sketches."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: We are making a mobile app that will provide information based on pictures of objects. Describe the process of how the API works and how we can utilize it in our app."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: I want to analyze an audio file and determine its emotion in terms of arousal, dominance, and valence."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: We have developed a multimodal system and I need to find an answer for a specific question asked from an invoice in an image format."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: We have hundreds of comments in our customer support, and we need to normalize the text and find the most relevant words."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: Our publishing agency is working on a children's book about space. We need an illustration of an astronaut playing with a puppy on the Moon."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: Transform my email regarding my resignation into a polite and formal letter."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: The newspaper company wants to analyze articles to understand the entities mentioned in them, such as people's names, places, or organizations."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: I need to translate an employee manual written in English to Russian for our company's branch in Russia."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: Our client is working on a map-based application and needs to segment images of city streets for better navigation."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: We are building a mobile app that identifies objects in a picture. We need a fast and reliable image classification model for object recognition."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: Some influential people on social media have posted images that require classification. Can you identify if the images are related to fashion, food, or technology?"}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: Generate a report on classifying images of birds to be used by clients in the software."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: We are building a search engine for a wildlife conservation project. We need a program that can spot leopards in photographs."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: Create a fantasy-inspired image based on the description \"dreamy fairy forest with sparkling waterfalls\"."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: In order to understand customers better, a digital marketing company needs to analyze public tweets related to their client's product. They want to classify tweets into positive, negative, and neutral sentiments."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: I am building a digital DJ application. I want the functionality of separating vocals and instrumentals in an audio file, so the user can have more control over the mix."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: We are a crowd-sourced real-time reporting startup. Using AI to distinguish between an image of a road accident and a traffic jam is of high interest to us."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: I have an image containing a few animals, and I need to know if there are cats, dogs, or birds in the picture."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: In our company, we are creating promotional texts, and we want to see how a pretrained model can fill in sentences given specific contexts."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: I want to predict housing prices using a machine learning model. The model should be trained on US housing data."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: In our education software, we are looking for answering student's questions."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: Create a function in python that combines two lists into a dictionary."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: I would like to create a voice-over for a virtual character in a video game by converting a line of text to speech."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: I work for a research group that investigates natural disasters. We need a summary of the latest news articles about floods."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: Develop an algorithm that, given an image, provides a detailed description and can answer questions about the image's content."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: I am creating a news feed for people with diverse interests. Identify the most appropriate topic for this news article."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: We have a lot of images and we would like to have a simple category assigned to each image to determine what the image is about."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: A news agency is trying to determine the main subject of its news articles, and we need a way to analyze the named entities so they can better tag articles."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: We are a civil engineering company specialized in road repairs. We need to detect and segment potholes in road images."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: A CEO is taking a walk in a rainy weather. He is holding an umbrella. We need a clear image of his face. We have low-quality image. What can we do to achive this?"}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: We are creating an AI tool to help users in obtaining answers from data tables. Develop a method to bring this functionality."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: We need to build a language learning application that translates spoken sentences and also generates the translated audio output."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: Write a storyline for a new children's TV show about a group of animals that live in a magical forest. We need artwork for the show's intro scene."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: The company recently received a batch of documents in Spanish. Translate these documents into English to facilitate easier understanding and processing."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: I'm an exhibit designer, and I need a tool that can generate pictures of animals in the museum's new exhibit simply based on text descriptions."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: Develop a program that generates a Python function to calculate the area of a rectangle, given the length and width."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: Our customers are phone conversation analytics companies and they are looking for insights from phone call multichannel audio recordings. Detect any conversation to prevent dead air during phone calls."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: Develop a reinforcement learning model to guide virtual agents walking along a 2D terrain."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: Develop a tool to automatically detect and count the number of cars in a parking lot from surveillance images."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: We are going to analyze customer reviews for a hotel. First, let's find which customer reviews are more related to the hotel's breakfast offering."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: We want to analyze an interview transcript from a podcast and get a summary of the key points being discussed."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: Design a postcard for a travel agency with the theme \"Enjoy the surreal beauty of the Northern Lights\"."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: We are a smartphone company and we need to build an app to respond the question about an image taken from the smartphone."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: Provide me the necessary code for developing an application that needs to analyze financial data from a table and answer questions given by users."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: As a mobile app developer we need to classify the given picture in order to sort it into the appropriate category."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: We have a recording of a business conference. It has a lot of background noise. We need to separate the clean speech from the noisy background."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: We are working on a project to deploy a reinforcement learning model in the space game LunarLander-v2, and we would like to use this model to control the lunar lander's movements."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: We need to extract answers from PDF documents that contain tables, images, and text. Help us to find out the relevant information through documents."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: Our company is building a phone customer service system that requires voice recognition to perform tasks."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: Compose unreal images of bedrooms for an interior design project."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: A team working on the development of a new website catering to English-speaking tourists in France would like to identify important information about various tourist attractions from the text gathered."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: My AI application wants to play Ant-v3 game, provide what I need to run the game and use the Reinforcement Learning model."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: We are making a new social app. We need to remove noise from user submitted voice recordings."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: I want to create a search engine for a document repository, ranking the most relevant passages based on a user's query."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: We are building a grammar correction application, and we need to identify the part-of-speech for each word in a sentence."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: I have a long conversation and I want to extract the most important ideas from it."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: A podcast creator is seeking assistance in translating an English podcast episode into French. The creator needs to process the English audio clip and receive a translated French audio file."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: I run a real estate platform and I need to estimate the depth of various rooms to help my customers visualize the space."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: I want to transcribe a recorded podcast but only text portions spoken by the host and ignore guest comments."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: I am working in a warehouse. I need to classify all the goods based on the pictures taken and to get the semantic segmentation for better understanding."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: We want to build a robot for the use of elderly people to remind them to take their medication. As a first step, the robot should be able to recognize pills from images."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: Provide information how to extract specific data from invoices with different templates."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: Our delivery drones need to recognize landmarks in images so they can calculate their relative positions. Help us find the best solution."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: My startup is working on an AR application that measures the distance between objects in an image. We are testing out different depth estimation models."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: Can you analyse a table of sales data for different regions and answer questions about the total revenue for a specific region?"}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: I wish to generate a concise summary of a Chinese news article."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: I want to analyze a table dataset about the revenue of different stores and answer questions about highest, lowest and average revenue."}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: We need to compute semantic similarity scores between pairs of sentences to classify related news articles effectively."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: Our product is focusing on enhancing the audio quality of user's recorded conversations. We need a tool that separates noisy tracks from the clean ones."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: We are an architecture firm that wants to quickly visualize different room designs. Generate an image of a \"modern living room with large windows\", using text-to-image technology."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: We are an AI startup providing canned answers to frequent customer queries. Our customers need more variations of each answer."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: A culinary media firm wants to automatcially categorize cooking tutorial videos by classifying the content of the videos into one of the 400 possible categories."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: I want to have a chat with an AI that can answer my questions."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Analyze a set of images and generate English captions for these images."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: Create a simple reinforcement learning agent to play a CartPole game."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: I have an image of a table in a document, and I need to detect the structure of the table, such as rows and columns."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: \"\u5317\u4eac\u662f\u4e2d\u56fd\u7684\u4e00\u4e2a[MASK]\u57ce\u5e02\u3002\""}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: Our users want to provide a general summary on how predictive autonomy can be done, and how to predict results."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: We need an algorithm to find related sentences for our project on identifying similar questions in a knowledge-sharing portal."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: Develop an AI tool to help teachers with their classroom regulations that can classify videos with different types of activities."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: Create a virtual assistant for musicians that can separate instrument sounds and vocal tracks from a given audio file."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: pets, farm animals, wild animals?"}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: We are going to make an international chatbot that can classify different intents for customer service inquiries in multiple languages."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: A legal consultant working for our company will need a smart personal assistant to find answers in legal documents. Implement the model that can answer questions based on a text context."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: My robot cannot understand English, but I want to use it to answer questions in multiple languages. Can you suggest a model for this?"}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: Detect whether there's violence in a video. To do this, build a violence detection model using the latest technology from the computer vision domain."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: Our marketing department is creating banners for Gothic-themed events. They need some pristine examples of gothic-style church images."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: I want to classify the objects in an image to determine whether the image content is related to a customer complaint."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: I am an individual who loves traveling. Describe the scene in the picture I took during my last trip."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: I am an architect looking to develop a virtual bedroom model. Create an image of a bedroom that I can use for my project."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: We are now working on a product that uses the XLM-RoBERTa for providing helpful suggestions and correction to the text."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: \"Bonjour, j'ai besoin de directions pour arriver \u00e0 la Tour Eiffel.\""}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: A friend of mine wants to identify a speaker using a recorded 16kHz speech sample."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: We are a media company and we would like to create statements by filling in the missing words in given texts."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: Language barriers in calls have become a major problem for our company. We need to find a way to translate voice calls between people speaking different languages."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: We have many articles with mixed content. We want to find only articles related to climate change by calculating their relevance score to a query on climate change."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: I am building a video analytic tool used to classify activities occurring in a video."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: I want to analyze the data of vehicles to understand their impact on the environment, particularly their CO2 emissions."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: A traveling company is working on providing travel information in both English and Spanish. The company needs to translate travel-related sentences from English to Spanish."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: We are an e-commerce website. Help us to automatically label the products we received daily with brief descriptions."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: Detect if audio contains voice or not for a transcription service."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: We have a scanned document with a text. A user needs to get an answer to their question regarding the contents of that document."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: I am part of a security team and I need to transcribe a meeting recording in English to investigate a case."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: Our company is working on transcribing some audio files, we need to transcribe this audio file."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: We have a table of imported products from different countries. Find the number of products from Germany."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: Our e-commerce platform has received many reviews from customers. We need to find out the customers' sentiment for improvements."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: I'm trying to create a restaurant review analyzer that can help me determine if the review is positive or negative."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: Assist me in transcribing a podcast episode. The goal is to automatically generate text from the audio file."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We are developing an online communication platform. To improve user experience, we need to predict the language spoken in audio clips."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: We are now analyzing the reasons a meeting is not going well, can we encode the sentence into an embedding and classify them in a way they can be compared?"}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: Our corporation is analyzing press releases to better understand the content. We need to extract named entities from these press releases."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: Can you provide a creative beginning for a sci-fi novel?"}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: We are building a platform to classify videos from a sports event. We need to get information about the sport being played in each video."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: The restaurant's manager would like to predict tip amount. How can I train a model to predict the tip based on the available features?"}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: Our company is developing an AI-driven pet adoption platform. We are creating a feature that generates a variety of cat images to attract adopters."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: The company is looking to build a lunar lander game for mobile. We need an AI to control the landing with the highest performance."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: I want to predict and analyze carbon emissions of a factory over time to help reduce its environmental impact."}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: Can you create an image classifier that recognizes images of animals, fruits and running shoes?"}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Our team needs to separate overlapping voices from a meeting recording."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: The company wants to translate the slogans of potential partners from English to Chinese so that they can make an informed decision on co-branding."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: We need an assistant that will notify us of the price changes in cryptocurrencies by reading the prices to us."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: We are working on an AI to help kids with their homeworks. We want to plug in a predicted word in a masked sentence using natural language processing."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: Our team is working on a project to summarize various scientific articles to create a user-friendly excerpt."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: Develop an application that can separate a mixture of sounds into individual tracks using the pre-trained Asteroid model."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: I need an AI assistant to help me with writing articles. It should be able to fill in missing words to complete sentences in context."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: We need a chatbot that can engage users in an interesting conversation by answering users' questions in a friendly and knowledgeable manner."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: We are an online learning platform, and we need to transcribe the Esperanto speech in the lesson."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: Develop a program that can classify the objects on the images."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: I want to develop a smart traffic camera software that can detect and count the number of vehicles in a given frame."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: \"I have always wanted to [MASK] a marathon.\""}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: There's a demand for customizable Minecraft skins. Develop a tool to generate random Minecraft skins for players."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: We are a company in the business of home maintenance and repairservice. We need to create an email template for one of our services so that we can fill in the customers' information."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: As a customer service company, we need to transform voice files into text files in order to solve customers' requests."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: The supervisor wants to create a summary of a long transcript for a team meeting."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: We are a team working on a project, calculating the budget allocation for each department. For simpler budget discussion, we need to answer questions based on a table."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: I am a civil engineer, and I need to build an AI system to estimate the depth of an object in an image."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: \"Hello what a nice day to go to the park I really love the sunshine and fresh air how about you\""}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: We are building an environmental consulting company and want to predict CO2 emissions using the model."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: Our customer is an advertising firm. We want to design a billboard about an astronaut riding a horse on Mars. Generate this image for us."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: \"The advancements in artificial intelligence have revolutionized the way we live.\""}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Create a chatbot to represent a bot with a specific personality, and use it to provide personalized responses when talking about work and ambitions."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: We are an entertainment company and want to know if a movie review is positive or negative."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: We are an organization working with visually impaired individuals. We need a system that takes an image and a question as input and provides text-based answers."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: We are looking to establish a business relationship in Italy, and we need to translate our company's introduction documents to Italian."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: Suppose you work in a restaurant. Your manager wants to predict the amount of tips each waiter will receive. Estimate the tip amount using the given data."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Develop an application to automatically generate images of butterflies for a biology project."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: A legal office needs a model to extract essential information, such as names, dates, and relations, from scanned documents while answering relevant questions. Help them create a suitable model."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: Our team is developing a game and we need to generate images for items in the game based on their descriptions."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: I am a smartphone app developer focusing on accessibility. We need to caption images that visually impaired people can easily understand."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: I want to see what is the best answer in my list for my question among these responses."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: I work for a car dealer and our inventory is in a spreadsheet. I want to find out the total number of SUVs in the inventory."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: A government environmental monitoring unit uses the provided dataset to predict the carbon emissions; please design a solution for them."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: We are building a self-driving car prototype, and we need a method to estimate the depth of objects in the vehicle's field of view."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: Inform a fellow Italian supplier about your product's features in their language."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: As a governmental environmental agency, we received a document about pollution in the city. We need to find the topic of that document."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: Our new voice assistant can make calls to users. An important feature developers requested is detecting silence during a call. We need to understand when the user has stopped talking in order to make important decisions."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: Identify the most important information in the German text and provide an abridged version."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: I have a platform for communication in my company. If a user writes a message to me, I want to generate a reply for them."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: Our company specializes in document analysis, and I need a model to detect and extract tables from document images."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: Help our users extract information from a CSV file of sales data."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: My company is developing on self driving cars, we need exact depth estimation of camera frames to make sure the car is driving in a safe manner."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: Our environment department is interested in predicting CO2 emissions based on some tabular data, and they want to use an existing Joblib model to make predictions."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: 'The truck jumped over the fence' and 'The vehicle leaped across the barrier'."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: For a project, the team needs to visualize the spectrograms of bird vocalizations in order to analyze their patterns. To achieve this, they should obtain the spectrograms for a set of audio files."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: We want to transcribe an audio file of a meeting to extract the important points discussed in the meeting."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Our school has been receiving reviews on social media platforms, and we need to categorize them into positive, negative, or neutral sentiment."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: I am building an AI bot that will complete sentences for me based on context. Please guide me on the best way to do it."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: Our client is a photographer who needs a tool to upscale a low resolution photo they took."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Determine the speech-to-text of conference call recordings with international business partners from Portugal."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: As a startup, we want to create an assistive tool for people with hearing issues. This tool should help to transcribe recorded spoken words into text."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: Develop a system for identifying objects in a cityscape image so that we can help a self-driving car navigate safely."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: We are a company manufacturing blood analysis equipment. We need a machine learning model that can process microscope images and identify different types of blood cells."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: I want our company to generate a short topic summary for a recent news article to be shared with our team members."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: We are a transcription service company. To save time, we need to convert an audio file to text."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: We want to integrate a feature that automatically generates captions for images on our website."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: Determine the depth of objects in an image taken from a drone to better understand their heights and distances."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: Can you analyze important text details from medical forms and help create a medical history summary based on the input data?"}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: A team is developing an audio conferencing app and needs to improve the audio quality for the participants by monitoring background noise and reverberation. "}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: \"Hugging Face is a great company.\""}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: We need creative ideas for a product catalog featuring cute butterfly images."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: Design a prototype of a chatbot for our event management company."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: We are launching an online review platform for household items. Having the customer reviews text, we need to categorize the reviews based on sentiment."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: In order to optimize the user experience in our food delivery app, we're aimed at classifying user reviews to detect positive and negative comments about our partner restaurants."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: We found an article about our new home security product. Our team would like to know which objects are present in that article photo and need detailed segmentation."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: We are integrating an AI Chatbot on our website, and we want to be able to automatically fill in incomplete sentences from users."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: Make a program to ensure safety compliance for construction workers by detecting hard hats in a given image."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: We have been asked to generate a butterfly image for a school project without any specific requirements."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: I am a software engineer and I have an audio file. Identify the birds in the backyard with natural sounds like chirping, dogs barking, and children playing."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: Our customer is currently using our image recognition and correction app. They want to inpaint part of an image based on given inputs."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: I am managing a newsletter. I need to end each letter with a summary of the news articles."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: We want to translate an English sentence into Russian."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: We are working on an AI-based system to answer questions related to images in the Polish language. Implement the code using the Hugging Face Transformers API."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: We wish to use a visual question-answering system to identify the color of the shirt a person in an image is wearing."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: I'm a software engineer working on a robot that can walk in unfamiliar terrain. I need an API to detect depth from monocular images so the robot knows where and how to step."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: Assist me in writing a futuristic story set in the year 2200 about humans and robots coexisting in harmony."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Our company is working on reducing carbon emissions. We need a model capable of predicting emissions rates based on input features."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: In order to measure the general sentiment regarding a product, we are analyzing a user feedback text from a review."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: The marketing team needs to promote a product by creating a banner with a clear background. We need to separate the product from the background."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: During the Halloween day, our friend is wearing a costume, but I can't identify the exact costume. Help me identify the costume in the picture."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: Our client is a podcast company who needs to separate speakers in recorded conversations."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: Bob was looking to create an example of an autonomous AI to help balance a pole on a cart, and he needs a trained agent to run on the CartPole-v1 environment."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: Our city is planning to repair potholes. We need to analyze a series of images to find all pothole locations."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: As the head of the research team, I need to classify the spoken language within a variety of audio clips collected from around the world."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: The marketing team wants to predict user behavior on a new program they are launching, based on a dataset of past user behaviors."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: I am a doctor and during my clinical activities, I need my medical reports' text to be completed. Fill in the missing word in my report. "}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: A blind person needs a smartphone app to read aloud text documents. Develop a solution for this person."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We need to support a smart robot to recognize indoor objects and perform manipulations by processing egocentric images."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: The company is building a recommendation system for users based on their preferences in the movies. Analyze the video to find the movie genre."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: Our company focuses on depth estimation in real estate. We require depth estimation for various room images."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: We are an e-commerce store that needs to analyze product inventory data to answer questions about our stock availability."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: Let's pretend we are a marketing company. We want to build a visualization concept board for a children's book based on a particular scene description."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: Stella wants to impress her Russian friends by communicating with them via WhatsApp in their native language. Help her translate her texts."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: Construct a conversational AI bot that can help finish sentences by replacing masked words with suitable words."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: We are hosting an international conference with many speakers that use multiple languages. We want to add punctuation to the automatic transcriptions of the speakers."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: Design a language translation service for a startup company. It should be able to translate texts from one language to another."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: We need a simple way to analyze the structure and relationships of words in sentences for language learning. Could you provide an example?"}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: Implement an image classification system to class wise categorize the images."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: A company is developing an AI customer service chatbot. Based on the customers' typed messages, the chatbot is expected to generate spoken answers that can be played to the customers in real-time."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: I have a plant and I want to find out what plant it is. Can you help me identify it?"}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: A real estate company needs an app that estimates the depth of rooms in photos to be uploaded to their website."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: A customer call center wants to filter out background noises from their employees' calls to improve call quality."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: An educational organization has a lot of Chinese articles to summarize. We need a model to help us generate summaries."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: A group of startups wants to build a voice assistant for travelers. They want to identify the speaker's nationality based on their speech."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: We have a drone company that needs our help in image segmentation for mapping purposes. It is crucial for us to identify various land surfaces based on the images."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: I want to create summaries of cooking recipes from images of the recipe instructions. "}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: We want a method to extract features from Russian text and obtain sentence embeddings effectively. Implement a solution for obtaining these embeddings from a list of sentences."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Our client wants to create a book cover based on a description they provided. We need to generate an image from their description."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: I want to build an app that recognizes the types of food by just uploading an image, classify the food type from the image of a dish."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: Analyze the provided image and detect the object."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: I need to set up an AI Chatbot to get recommendations on which movies to watch based on my preferences, and I want to ask the bot to tell more details about the best recommendations."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: I am an amateur astronomer and I would like a generated image of a galaxy."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: We are a podcast platform looking to have a TTS model for playing text-based podcast summaries for the visually impaired."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: They are asking to build a system for transcribing spoken commands to the text that later can be translated to the required language."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: Develop a model for categorizing movie reviews as positive, negative, or neutral to help users find the best movies based on ratings."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: Parse a speech file that contains business instructions in Esperanto."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: Design a system for a Spanish language learning app to convert the text explanations of language concepts into speech."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: We need a speech-to-speech translation model for our international calls that can convert between languages without relying on text."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: Our client wants to create an application to identify the dog breeds from user provided images."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: I am an insurance officer who works with Korean customers. My company receives a claim in Korean, and I want to write a response to the clients in Korean."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: Generate a video about a day in the life of a software engineer for our conference."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: Our company is in the process of creating a French-speaking chatbot. Can you classify a given text without including the translated labels?"}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: Create a program that takes an image URL and the question \"What's the subject of the image?\" as input and returns the answer from the model."}
{"text_id": 679, "text": "document: DeBERTa V3 improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It further improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. The DeBERTa V3 base model comes with 12 layers and a hidden size of 768. It has only 86M backbone parameters with a vocabulary containing 128K tokens which introduces 98M parameters in the Embedding layer. This model was trained using the 160GB data as DeBERTa V2."}
{"text_id": 679, "text": "query: \"The sun always rises in the [MASK].\""}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: Our company is developing a new programming language, and we want to identify similar code segments from high-rated repositories. The plan is to use pretrained weights for CodeBERT."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: Develop a solution to automatically recognize and convert texts in images into machine-readable text."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: As a healthcare provider, we need a tool to classify the type of patients' problems."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: Create an automated process to detect tables in a given set of images, regardless of whether they're bordered or borderless. "}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: Help me to answer the questions about the gas station biodata throughout the year."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: Implement an AI-based application to estimate the depth of objects in a photograph to assist photographers in understanding the depth of field."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: The company needs to extract information from a specific table. We are finding a solution that processes tables in a user-friendly manner."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: A Chinese speaker wants to learn English. They have a sentence in Chinese, but the English equivalent is missing a word. Find the best word to complete the English translation."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: I am an Architect, working on building a small-scale community park. I want some ideas about design and features to be included in the park."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: We are a company that is developing a web app that converts images into textual content. We need to analyze images to generate text descriptions."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: We are developing an app that can answer questions based on given images. We need an endpoint to process such questions."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: We are managing an online booking system for different events. We need to answer customers' questions based on the available data."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: Our team is working on a project to build a digital assistant that generates a sentence given a list of input words but we need to ensure it's a coherent sentence."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: The company is building an online encyclopedia. We need a way to provide quick answers to user queries."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: A drawing application wants to convert a user's text input into an image using scribble."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: I am building an app to provide summaries of news articles in multiple languages. Use a pretrained model to help me achieve this."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: We now need to generate ten sentences regarding how climate change affects the environment."}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: We have a project that aims to translate spoken English into spoken Hokkien. We need the English speech translated and converted into Hokkien speech."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I am a data science student doing a research on European countries. Please help me extract information from various sources about their capitals."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: We are a language learning platform. We want to build a small app to help our users translate Swedish texts to English."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: We work in a library and we need assistant that can read handwritten text from a postcard."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: I have a picture of an object and I am not sure if it is a cat or a dog, please help me."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: We are making an educational platform for programming languages. We need a feature that helps students autocomplete code snippets they are working on."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: We want to classify an image of a handwritten digit."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: Create a model that can answer questions related to data tabulated in given tables."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: Customers want to analyze the emotion in their users' voices to provide better customer service."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: We are a company focusing on occupational safety, and we want to ensure that all our workers wear hard hats on site."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: I have written \"My office is located in the [MASK] floor,\" but I have forgotten which floor it is on. Can you please predict what the correct word should be?"}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: Develop a system that analyzes spoken language for a customer support call center to provide insights on conversation quality."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: Would you be able to give me the possibility of using the vilt framework to answer a customer question with a picture provided about our e-commerce products?"}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: I need to build a web application that translates messages from French to English in real-time for users who chat with each other."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: A business is considering making environmentally friendly investments. Please analyze the carbon emissions data of potential investment companies in a tabular format to assist them in their decision-making process."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: Your toy company wants to create an interactive toy that answers questions about objects shown in images. We need to find a suitable pre-trained model for this task. "}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: Create a pipeline to classify audio clips containing spoken digits from 0 to 9."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: We are an advertising company developing commercials for our clients. Generate a video clip from a description of our clients' products."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: The users of our app need to extract text from the images of food recipes they want to cook. We need to create this feature."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: Develop an application that recognizes speakers in a conference call."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: Our startup is working on a podcast transcription application, and we need to transcribe a short audio file."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: As a gaming company, we would like to build a computer player for our car-racing game."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: Help me create a system that takes a low-resolution image of a car and description, then generates a high-resolution version based on the description."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: My friend loves animals and wants to classify images of his favorite animals. We need a tool to classify them."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Help me create a conversational AI model that can respond to user queries. The responses should be personalized given the specific persona facts of the AI."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: I need an image classifier to predict whether the given image is a 'dog' or a 'cat'."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: Our company is creating a virtual art gallery, and we need to generate high-quality images of various art styles based on text prompts."}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: There are journalists writing articles about food. We need to categorize these articles into different genres like French cuisine, Italian cuisine, Chinese cuisine, vegan, and dessert."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: I am a developer for a traffic control system. I need to identify traffic lanes and traffic signs from images."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: As a company, we would like to get concise insights from Korean customer reviews in our products."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: I am an author, and I have writer's block. I need help with ideas to continue the story of a detective who is trying to solve a murder mystery."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: I am building a voice assistant for iOS, and I need to understand different accents in English, so I should convert the input speech into a text vector."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: To improve object detection and recognition on the production line, we would like to test the Deformable DETR model."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: We have a real estate company, and would like the model to predict the housing prices based on the property features."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: I want to analyze German sentences and get their sentiment."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: We want to summarize a long article in Spanish to include in our newsletter."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: We are building a language model for an online educational platform, and the model will be used in essays and documents creation. The model should be able to predict the masked word effectively."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: Please analyze the photos to understand the unique tastes and preferences of a person who loves cartoon characters."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: \"I went to the store to buy some [MASK] for my sandwich.\""}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: A podcast producer wants to remove background noises from the audio files before publishing them online. Provide a solution for this requirement."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: We want a model that can complete sentences in multiple languages."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: We are building an app for communication. We need to improve audio quality by cleaning surrounding noise from recorded speech."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: We are building a conversational bot, help us ensure the generated paraphrases sound natural and relevant."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: Our city management department is finding it hard to understand the visuals from overhead traffic cameras. Help us extract traffic information from these images."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: Estimate the depth map of a given image for our autonomous driving project."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: I need to separate the vocals and instruments from a given audio file."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: I want to build a speech-to-speech translation application. Translate spoken Czech to English audio in real-time."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Our client is working on a new children's book featuring cute butterflies. Generate an image of a cute butterfly."}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: We need to have a conversation with our users regarding their experience with our new product."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: \"What galaxy is known as the Milky Way's twin?\""}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: Identify the emotional state of a speaker in an audio file to evaluate the effectiveness of our therapy program."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: Our company requires a solution to improve the sound quality of audio recorded during meetings. Implement a function that will enhance the quality."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: We are building an app for photos lovers which detects different segments and objects in images uploaded by users."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: We are running a chatbot for a bank as part of their customer service team. It needs to answer client questions."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: Our company is committed to lowering our carbon footprint. We are in need of predicting the carbon emissions for a given data file for analyzing our energy consumption data."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: Create a marketing poster for our new online gaming platform, which should include an illustration of an anime character holding a game controller."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: Our client is a new start-up that has just launched their online customer support system. They want their API calls to be able to translate spoken input from English to Czech for customers who prefer Czech as their preferred language."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: \"Voy a la tienda para comprar algunos comestibles\"."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: I have an old recording from my grandparents, and it has a lot of background noise. Help me improve the audio quality."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: Our medical laboratory is diagnosing a blood sample slide, and we want to detect blood cells including platelets, red blood cells, and white blood cells."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: I want to analyze a set of images of plants and identify the most common features in the images."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: Our software development team needs assistance in code comprehension, and we want to use a pre-trained model that could understand and generate code."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: I'm going to present a business update to a group of stakeholders, and I want to use artificial intelligence to summarize the key points of a lengthy document for my presentation. Prepare me for the presentation."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: Our customer is a robotic manufacturer of cleaning devices. They ask for our help on solving user's questions about the maintenance of their devices."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: Summarize the main points of a science article discussing advancements in nanotechnology."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: I am building an application for learning Mandarin Chinese. I want to convert the written text into audible speech so that users can listen to the pronunciation."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: I have some noisy audio coming from my home assistant and I want to clean the audio using ConvTasNet for clear command detection."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: I am working on a book recommendation system. I need to find books with similar descriptions to recommend to users."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: Our user uploaded a picture of a hand-written recipe from their grandmother. Give the user the recipe in plain text format."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: Create a short summary of the company's annual report for the press release."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We are an insurance company. We need to develop and use a solution to automatically extract tabels from our customers insurance policy documents."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: My robotics club needs to build an AI system to simulate a two-link robot, then create an agent that learns how to swing the robot to reach the goal."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: I am developing a travel app, and I want to build a feature to answer user's questions about countries' population and GDP."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: In the medical domain, we have a sentence with a missing word. We'd like to figure out the most likely word to fill in the blank."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: I need a model to generate images based on text descriptions with additional input conditions, like containing soft edges."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: Generate an image for a new clothing line using computer vision for inspiration."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: Computer Vision Video Classification"}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: Write a smart AI chatbot that can complete sentences with missing information."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: The company we work for develops electric vehicles. We wonder if you can analyze a dataset to predict CO2 emissions."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: The real estate company we are collaborating with wants to have an estimate of houses' prices in California. Provide a way for them to predict house prices based on given features."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: I am going to run a German historical archive. I want a system that should categorize the biography of people based on its name, location, organization."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: I want to build an AI content moderator that can filter inappropriate content and classify them into violence, nudity, hate speech, spam, and fake news."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: To engage our audience, we request an algorithm to find the most similary post from our previous articles."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: Create digital artwork with the help of AI."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: We have a database of all the transactions over the last month, how much money did account holder \"John Smith\" deposit during this time frame?"}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: Develop a chatbot, trained on conversation data from video games, to interact with the user."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: Recently, a legal team has adopted an AI model to extract relevant questions that may arise from within their client's documents. Develop a model for them."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: Create a system that receives sentences in English, Italian, and Japanese, and suggests the most similar sentences between the languages."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: A comic fan wants to extract text and dialogues from a Japanese manga image."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: \"Hej, hur m\u00e5r du? Tack f\u00f6r m\u00f6tet ig\u00e5r! Det var mycket givande och vi ser fram emot att arbeta tillsammans med er i framtiden.\""}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: Our application needs to work with multiple langauges. In order to do this, we want to find the sentence embeddings of user input in different languages."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: I work at an educational institution. I need help generating writing prompts for my students."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: I am working on a project that requires the translation of English documents to Portuguese. Can you help me to create a code that can translate my documents?"}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: Our company has partners in Spain and we need to extract a summary of their long emails in Spanish."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: I am building a model to extract the high-level features of a given text, which will be used later for a recommendation engine."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: Boost the resolution of the photos captured with a telescope."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: I want to create a mobile app that recognizes numbers from zero to nine by listening to them. Please show me how to use the model for this task."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: We are a business publication, and we need to extract the names of people and companies from a given text."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: You are asked to create a system that translates spoken language from Hokkien to English, maintaining the audio format. You should use an existing Speech-to-speech translation model for this purpose."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: We have a dataset of exercise videos, classify each video as either yoga, weight lifting, or aerobics."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We are a research organization, and we need to find relevant papers based on the content of a specific paper."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I want to extract the necessary information from an invoice for finance tracking software. Can you find who the customer is on the invoice?"}
{"text_id": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 797, "text": "query: Give me an audio separator model that removes noise from speech and enhances the voice quality."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: I want to design a question and answer based support system for our website. The users can ask questions and receive a correct answer among several possible responses."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: Offer a multilingual solution to help people to complete their sentences when they struggle with language."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: Implement a solution to understand if a statement can be inferred from another statement or if they contradict each other."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: Develop a tool to measure relevance of articles by how much they relate to a given query."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: As we are working on a news app, classify news headlines into categories like technology, sports, and politics."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: The company is working on a photo sharing app. We need a solution to predict the class of an image."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: I recorded a meeting from my phone, and now I want to split the conversations between different speakers. How do I do this?"}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: I want to find out how AI has played a role in reducing human bias during the human resources and recruitment process."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: Determine the category of objects in an image for inventory management."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Build a customer support bot to manage service inquiries."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: Develop a video classification system that is capable of identifying human actions in videos."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: \"I enjoy eating <mask>.\" Translate this sentence into French later."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: Develop an application that can transcribe an audio file containing conversation between a group of friends."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: \"The capital of China is [MASK].\""}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: I am building a robotics system that needs to navigate my house while avoiding obstacles. Please help me estimate the depth of objects in an image."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: Our client is a robotic company and wants one of our robots to navigate an environment. We need to estimate depth information from a given 2D image."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: Develop a reinforcement learning agent that can play a soccer game with multiple players on each side of the field."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: Our company is working on an AI-based language translation tool. We need to create a translator using a pre-trained model."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: Create a program that extracts names, organizations, phone numbers, and dates from a resume."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: My company works with clients from France, and I need to provide customer support to them over the phone. The tool should be able to translate English speech to French speech."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: We need to properly label different news articles to categorize them."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: Our company is working with a Chinese news agency to analyze their news articles. We need to identify topics mentioned in the article."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: Develop a tool for generating realistic images of cats that can be used on a website."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: A website needs an NLP powered solution for sorting out a list of available movies according to the mostly related genre."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: We need to predict if a person's income is above 50k based on demographic factors."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: I am a musician. I want to isolate the vocals and instruments from a recording of a live performance."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: A gaming company wants to understand the locations of players within the game. Identify the players in a given screenshot."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: I need a program to analyze a news article and extract the names of people, location, organizations, and other entities mentioned in the text."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: A company receives multiple documents daily and needs to extract specific information from them. Develop a method to answer questions regarding the content of these documents."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: I am building a surveillance system for a factory. I need to identify dangerous actions in video footages."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: I am sending a low-resolution image of a historical document and would like it to be enhanced."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: A homeschooling group of parents is asking for an application that can answer questions from a text. Can you provide a model that does that? "}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: Our company focuses on creating environmentally friendly products. We need to predict the carbon emissions for a product based on certain features."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: We are an app development company working on an app to help blind people recognize their surroundings. We need a function to answer their questions about a specific image."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: Provide a language model that our company can use to translate English to German, answering basic questions and reasoning."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: We're interested in building a soccer playing AI agent. Please find a model suitable for the SoccerTwos environment."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: Quickly process an incoming message to scan for any potential personally identifiable information (PII) that might need to be redacted."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: A virtual game festival wants to include an AI to help the players in the Gym Hopper environment. Implement an AI-based solution to play the game."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: I'm creating a text-based adventure game, in which the player can fill out a missing word in a sentence to continue with the story."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: I had a conversation with my friend, and now I want to summarize it so I can quickly remember the main points."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: The company is trying to develop a conversational chatbot for customer support. It should be able to provide help with products and answer questions."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: Develop a suggestive phrase for a dentist billboard using a masked language model."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: I am a German literature researcher. I want you to help me find person, location, and organization names in a piece of text written in German."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: We have a product that allows users to ask questions about data visualizations. Suggest a model to answer questions about data charts based on an image of the chart."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: In our meetings, we have often multiple speakers talking at the same time. I need an automatic solution to notify us when this happens during our online conference calls. Help me implement a method."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: Detect objects in a given video game screenshot for better gameplay insights and visualizations."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: A delivery company wants to make package identification more efficient. They want to identify different types of shipping boxes within a warehouse using an object detection model."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: We have developed a smart speaker system and want to detect keyword commands from audio clips."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: Our company wants to create an AI-powered video surveillance system to monitor suspicious activities. We'll be detecting activities such as running, fighting, and stealing."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: Create a chatbot that can answer questions in multiple languages and help users with translation."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: Whoever picks Nancy enjoys sunny days. Nancy picks only those friends who spend the most time on the beach. I would also love to have friemd named Nancy. Find out if Nancy go to the beach often?"}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: Can you punctuate my transcription of an Italian speech that I have been translating from English?"}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: A friend wants to automate the process of extracting names, locations, and organizations from paragraphs of text. Explain how they can do it with the Flair library."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: Detect the species of some given Iris flowers based on the measurement of sepal length, sepal width, petal length, and petal width."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: We are a company working on the development of new materials. For that we need to classify molecular graphs for different properties. Help us to find a machine learning model that works well with graphs."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: I am a digital learning assistant. Help me understand how to answer questions based on visual content, specifically images."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: Predict if a region has high CO2 emissions based on tabular input data provided in a CSV file."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: We are building an app that identifies Iris flower species by their sepal and petal measurements. We need a model to predict the species based on these measurements."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: We need to classify videos from our recent event to make a highlight reel."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: I need a tool that transforms my text into images. The images should be produced in three unique art styles that can be mixed and weighted."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: I want to analyze the sentiment of German-language reviews from different sources such as Twitter, Facebook or Amazon."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: We are developing an application for Marathi language users. We need to automatically transcribe the audio content."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: \"Hello, how are you?\""}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: We are building a productivity app where users are allowed to add simple tables to track their tasks. We need to answer questions related to user's tasks."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: Craft a horror book cover for an upcoming novel from the author."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: I am a researcher in the field of material science, I need a graph model that excels at predicting the quantum properties of material."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: We are building a code-search tool for our internal programming project. We need to extract features from the code and the accompanying text."}
{"text_id": 410, "text": "document: Stanford de-identifier was trained on a variety of radiology and biomedical documents with the goal of automatising the de-identification process while reaching satisfactory accuracy for use in production."}
{"text_id": 410, "text": "query: A hospital wants an AI system to remove any sensitive information from anonymized patient cases before sharing them for research purposes."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: I want to build a product that can separate singing voices from background instruments in a music file."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: I am a researcher in going to build a robot who can follow my commands, just now, I need to load the pre-trained VC1 model and use the model to compute the embedding for an image."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: I need a system that classifies submitted products into categories such as \"sports\", \"electronics\", \"fashion\", \"automotive\", and \"books\"."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: The company is launching a website for pets, and we need to classify customer uploaded images of their pets."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: Our client is a radio station that aired an announcement in German and wants to convert it to a digital audio format."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: I have a table about the different applications of AI in healthcare. I need to identify the best-suited AI technique."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: I am writing the ending of my Japanese story, but I need help completing the final sentence. Help me find a word that fits in the blank."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: We are a computer vision startup focusing on classifying sports activities. We want to classify videos, given a video input."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: I have a gallery website where users upload their artwork. Images taken by users may be blur. We need to design a photo sharpening algorithm."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: We are building a real estate website. Implement a model to predict housing prices based on input features such as location, number of rooms, and age of the property."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: The company is developing a depth-sensing system that adapts the properties of window blinds based on how far objects are from the windows. We need to estimate the depth information of an input image."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: I am a marketing analyst and want to extract features from tweets for better understanding of social media sentiment. "}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: I need a text completion bot that utilizes the DeBERTa V2 xxlarge model."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: Assume we are working on a project which requires converting handwritten notes to text format for a digital database."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: In a book, a dialogue between two characters is taking place. We need to continue the dialogue in Russian."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Our client is a Russian newspaper company, and we are working on a summarization feature for their online articles."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: I am conducting a research on the speeches of famous personalities. Let's transcribe the audio of a speech to analyze it."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: I need to classify the images of clothes into their respective categories."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: Our company wants to use a chatbot for handling customer support. We want the chatbot to be capable of understanding human emotions and providing reasonable responses to customer queries."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: To improve our customer support quality, we are building an automated FAQ answering system. We need to find the most relevant answer for a query from our knowledge base."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: We are building an information portal for employees, which distills vast amount of information. Write a script that can summarize a Russian document."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: Our security team wants to know if there is violence or other harmful activity happening in the surveillance videos."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: We are trying to divide a satellite image into categories like land, water, buildings, and vegetation for mapping purposes"}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: I want to build a voice assistant that can understand my emotions from my voice and generate custom responses based on it."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: Working as a traffic police officer, I need to identify different vehicle types on roads using image segmentation."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We are building an online tool for auto-generating images of churches. Write a code to generate a church image."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: We are a tech startup for cats, we are building an app that could generate different pictures of cats."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: We are developing an app which detects the object in the photo. We are currently working on detecting the main object in the image."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: Analyze a job applicant's LinkedIn summary to find if they mentioned any specific organization and their role in it."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: Convert a given audio file of a customer support call to text, so that an agent can read and understand the customer's concern."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: I am trying to measure the similarity between product descriptions and customer reviews to find the most relevant reviews for each product."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: The company requires transcriptions of recorded meetings. Create a system that can transcribe audio files into text."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: I want to create a shoe design using AI-generated images for inspiration."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: An artist friend of mine wants to know if an anime artwork is generated by a human or an AI. How can we implement this functionality?"}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: Analyze an image containing a report and find out the title of the report."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: I run a podcast and I am using servers to process the podcast. I want to identify and search the author of the words uttered within the podcast."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: I need a system to read a text and identify the part of speech for each word in that text."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: We are building a warehouse safety system, and we need to detect if there are any forklifts or people near dangerous areas."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: In our English language online learning platform, we want to offer various ways to express the same sentence to improve fluency. Transform the given English sentence."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: The company is creating an app that will automatically translate spoken language from one language to another, allowing for real-time communication between people speaking different languages."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: We are building a phone call operator. Help us implement an audio processing component that will be able to separate speech from silence."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: As a legal firm, we deal with many long and complex documents. We'd like to create summaries of these documents to save time for our staff."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: We have an article about the presidents of the United States. Extract the names of people and their locations in the article."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: I am a car salesman in China. I need to find how many km per liter the hybrid model of the car does."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: We need to create an application that can summarize a movie script and provide a brief video description. Please provide the steps and necessary code to complete this task."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: Let's assume that we are a software company offering programming tutorials and support. Help me set up a conversational bot to answer users' code-related inquiries."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: I have a list of search documents and a question. Help me find the most relevant document that contains the answer to my question."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: Iris-setosa, Iris-versicolor, and Iris-virginica."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: Can you make a question answering model where it can predict information related to vaccines in a particular area due to outbreaks?"}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: Our sports organization wants to classify videos related with sports activities. Kindly provide a video classification solution."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: We want to create an application for the visually impaired that estimates the depth of objects in front of them. Build a solution for this task."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: Assess the environmental impact of your company's products by estimating their carbon emissions with a classification model."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: Design a system that describes different scenes in images to provide more interactive experiences for visually impaired people."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: Our customer was looking for an AI assistant to provide natural voice message for future users."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: We are assisting a customer who wants to classify their pet collection into dogs, cats, and birds."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: Our client wants to build an AI model to serve news summaries of daily updates."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: As a part of our content department, we're working on creating an article on health, we need to find some related phrases to \"healthy lifestyle\" within the health field."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: Can you make a model that predicts the HP of a Pokemon based on its attributes?"}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: We have hired a playwright to write a story for us. Help them draft dialogues and play the character of the king."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: Develop a system to convert English audio to Spanish audio for a company that makes video tutorials."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: I am writing a story and have just written a sentence with a missing word. I need the most appropriate filler word based on the context."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: I am on the phone with my friend, and the audio has an important conversation. I would like to transcribe the audio to text."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: I work for an advertising company. I am looking for generating a tagline for a new yoga apparel product that my company is promoting. I have an image of the product that I want to use as input for describing the product."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: We are now interested in classifying an online image. Teach your audience how to classify it."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: Summarize the way DialoGPT is used for Chatbot applications, be sure to mention the steps to use it, input-output examples and possible use cases."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: What are the key features of a piece of text?"}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: I'm a student in health science. I want to design an app to help answer questions about a patient's symptoms."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: My company is involved in Carbon Emissions measurement. I need a system that can predict the category of emissions for a given dataset."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: A German learning platform wants to analyze the sentiment of user reviews for their courses. Help them classify the sentiment of these reviews."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: Use AI to generate an image of a house staging by removing the clutter from the original room image while keeping all the furniture and decorations."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: I received an invoice via an email. I need to find out the vendor name, invoice date, and total amount from it."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: I am writing a news article about a company's management change. I need to highlight the names of key people and their roles in the article."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: I am an artificial intelligence scientist. I want to extract important information from a table that provides a list of countries, their continents, and their capitals. How can I build a model to answer these types of queries?"}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: We work at a call center and we need to analyze the emotion of customers' complaints that comes in the form of audio files in Spanish."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: We need to create an application for monitoring carbon emissions at our company's facility. Use machine learning to predict CO2 emissions."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: We want to build an application that estimates the depth of different objects in images related to archaeology."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: To track the activities of competitors, we want a tool that extracts company names, locations, and important people. We need to automatically identify these entities in the text data before it's sent to the user."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: Provide instructions to convert spoken language into written text using the wav2vec2-xls-r-300m-phoneme model."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Our customer is a photography studio and wants to quickly classify images of pets without any training example."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: We are developing a parking assistance system that needs to estimate the distance to objects in a 3D scene. Can you create a model using depth estimation?"}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Find the code creating a personalized conversation about a vacation including the persona profile of the bot and turn-level goals."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: We have a guided tour campaign, and we need to translate the tour information from English to Hokkien."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: I have a scanned image of a hand-written text. Can you give a code example that reads the text in the image?"}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: I work at an international IT company. We need a multilingual NER system that can recognize names, organizations, and locations."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: My company develops a medical software that analyzes blood cells. We need to accurately detect blood cells in images."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: I am looking to classify images of flowers like roses, lilies, sunflowers, etc. I need an AI that can identify what kind of flower is in a picture."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: We need a model to help us with a question and answer game in our new app."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: We need to analyze the emotions in Russian audio files."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: I own a travel agency. I want my clients to be able to ask questions about the destinations. The final answer must be extracted from the text that describes provided travel itineraries."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: We need to build a data analysis tool that can quickly resolve queries based on a given dataset table."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: To create a virtual reality experience, we need to estimate the depth of objects in a given input image."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: Create a tool to determine the distance between multiple objects captured in an image."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: Our team needs help estimating the depth of outdoor scenes captured by a camera. Please suggest a suitable model."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: We are working on an AI tool to help researchers analyze scientific papers. Please help us implement the process of identifying bio-medical entities from the text."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: Create an image of a sunny beach with a single palm tree and a surfer riding a wave to display on our travel website."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: Build me a conversational AI to extend the features of a chatbot. This chatbot will have a conversation about the latest technological developments."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: We are running a butterfly-themed event and need to generate butterfly images for our marketing campaign."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: A small startup team is creating a documentation website for programmers where they are adding code snippets. We want to extract important entity and keyword from the documentation to make it easier to search."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: An audiobook company wants a software to convert text in Arabic to an audible speech. "}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: I have a list of book summaries, and I'd like to find which books have similar content or themes. Provide me code to do this task using mini-all-MiniLM-L12-v2 model."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: We are a team working on developing self-driving cars. We need to estimate the depth of objects in the car's camera images."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: I want to create a navigation system for a self-driving car. The system should estimate the depth of objects in the scene."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: Create a transcribe function to perform speech recognition on various Japanese audio files and produce a text summary of the spoken content."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: The regional finals for a self-learning robot are coming up, and we need to train a model on the Gym Hopper environment in order to perform well."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: We are developing a security system to identify restricted areas for drones to fly over. We need to segment imagery into key structures and landscapes."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: I'm competing in a quiz competition soon. Can you please help me prepare by telling me what group of people would have a specific profession?"}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: We need a quote for our company's twitter account. The quote should be related to teamwork."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: We would like to classify all the legal documents into their respective categories. Develop a model that can help us with this."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: Create software that could detect the sentiment of a text in multiple languages, such as English, Spanish, and Chinese."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: Help draft an email in English and ask you to translate it into Chinese."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: I'm making a virtual reality app simulating historical places. Can you generate a church image to be inserted into the application?"}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: Create an assistant that generates advert slogans in the style of Elon Musk's Twitter."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: We are working on a project to build a pothole detection application. How can we use the yolov8s-pothole-segmentation model to achieve this?"}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: I want to write an article in French, but I sometimes forget words. The model will help by suggesting words based on the context of the sentence."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: We've recorded several audio files in Dutch and we'd like to convert the spoken words into text."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: We want to create a mobile app for dog owners that detects the breed of the dog from its picture."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: I am an owner of a startup and I want to build an intelligent assistant that can answer questions about images, for example, what color is the object in the image?"}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: Our team needs a cute image of a butterfly \ud83e\udd8b as a mascot for our children's educational program."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We are building a robot to help in the warehouse. The robot should be able to interact with objects for stocking and inventory management."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: I would like to categorize mushrooms from a photo I took in the park, and I am trying to understand if it is edible or poisonous. Can you provide me with a code snippet for zero-shot image classification?"}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: A civil engineering firm urgently needs to evaluate the land and buildings for a new construction project. We must extract and analyze the building layout from a given satellite image."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: Our company needs to transcribe audio files in multiple languages. We need a language identifier to recognize which language the content is in."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: Provide a suggestion for a birthday party planner to hold an event for 25 guests."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: I am experimenting with chatbots and want to implement a chatbot that can have a conversation about a variety of topics."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: Develop a way to transcribe interviews for reporters."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: Help me translating English text to German while preserving the context."}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: Help me to create an assistant that can determine the logical relationship between pairs of sentences and classify them as entailment, contradiction, or neutral."}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: I have a list of figures and events from history. Help me in understanding the context and answer my question 'Who invented the telephone?'."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: We need to translate a Chinese news article into English."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: The urban planning department of our city needs to identify different objects on a satellite map to improve public services."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: A text is in Spanish and I need it to be translated into English."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: Discover part of speech tags for given sentence."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: I am learning French, and I need to fill in the missing words in some sentences correctly."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: I've got a table with Olympic Games information regarding years and cities. I want a model to answer questions like \"In which year did Beijing host the Olympic Games?\"."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: I signed up for a Spanish online course, and I need to submit my answers to homework questions in Spanish. Translate the answers to the questions for me."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: We have a video streaming platform, and we need to classify the videos in the correct categories to show recommendations to our users."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: I work for a news agency, and I need to quickly categorize news articles into one of the predefined categories."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: Construct a fill-in-the-blank system capable of completing sentences with missing words."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: We want to make an application for users to play Breakout against an AI trained by an algorithm able to learn from the scenario."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: I am interested in generating a video from a text description of a scene depicting animals in the wild. Can you help me with it?"}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: Develop a chat component that will interact with the users to help them answer their questions in a realistic conversation using the available knowledge base."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: In your research paper, you need to find similarities and differences between specific medical terms in order to draw conclusions and make recommendations."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: We are an entertainment company, and we want to predict the popularity of our movies. Can you help us with it?"}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: We are building an AI-based project to answer the public's most asked questions. Determine the similarity between a given question and the possible answers for that question."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: In Korean, I need to create a program that extracts the answer from a table dataset provided to it based on a query."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: Our company needs to extract text from printed receipts for a new automated expense tracking application."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: We want to build an application that can classify an image of food dishes into categories."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: Say there is a multinational corporation asking for a translation from a potentail buisness partner's country document in Italian, French or Spanish to English."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: I received an email in Spanish from a client, but I only speak English. I need a translator to understand the content."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: I am designing a dream house for virtual reality, I want to generate a synthetic image of a bedroom using machine learning."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: Our American-Russian clients would like to communicate in their native languages. Could you please help me find a way to translate English text to Russian?"}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: We need to create a story about a superhero who can teleport to different magical lands to solve conflicts in our video game. Could you help us come up with a narrative for that?"}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: Let's say you have a video and you need to classify the main action in the video. How would you implement it?"}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: Please help me transcribe an audio file with speech in Marathi language."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: Help me understand the functionality of the following code snippet by generating a helpful code description for it."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: We own a flower shop and want to use AI-generated pictures of butterflies to decorate our web page. Can you provide an example of a code snippet for a butterfly image?"}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: Before starting the graphical design for a new website, our copywriters need a module to extract all proper nouns from texts."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: Design a summarization program that will generate abstracts in French."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: Our client is running an e-commerce website and the client needs to identify which color of shirts is most popular according to customer chats. Can we take a picture of the shirts and answer customer questions about them?"}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: I want to compile an audio summary of the latest Vietnamese news. Please transcribe the Vietnamese audio file into text."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: Detect the activity being shown in the given video."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: We want to create an app that can organize articles for users. First, we need a system to discover similarities among articles based on their content."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: An civil engineer company is working on constructing a building, and we need a depth estimation of the proposed site by analyzing the image."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: Create different ways to communicate any given text maintaining its fluency."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We are an architecture studio that designs unique temples. Create an image of a church for inspiration."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: We plan to rank our products based on the match with the customer's query in the description. Could you please suggest me the right model and how to use it?"}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: Our company wants to help users transcribe multilingual speech using wav2vec2 model, which supports multiple languages for Automatic Speech Recognition."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: We are publishing a newspaper and largely writing news summaries. We need an AI to help us create summary texts."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: I am a writer who wants to create a creative conversation. Now, I am preparing a conversation between me and a character named Alex, a software developer."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: We are working on a German chatbot that processes user messages. Recognize the named entities in the given text and display the results."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: We have a customer support agency. We need to convert recorded conversations in Russian to text."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: We need to create a recommendation engine that will find citations that are similar to a selected passage of text."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: I need to build an algorithm to estimate the depth of the objects captured in an image."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: Write the transcription of the audio I listen. The audio is related to science discussion between two professors."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: 'A soothing landscape with the sun setting over a tranquil lake surrounded by trees.'"}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: I am a researcher studying on an article about Neural Networks. The article is too long, so I need to generate a summary for a better understanding."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: I'm developing an app to analyze tweets from multiple languages. It needs to provide sentiment analysis without translating the tweets first."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: How can we build a system to answer questions about the content of an image?"}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: I'm running a Spanish news platform, and I want to categorize daily news articles in terms of interest areas, such as culture, society, economy, health, and sports."}
{"text_id": 297, "text": "document: This model is a diffusion model initialized from https://huggingface.co/google/ddpm-bedroom-256 and trained for 5000 steps on https://huggingface.co/datasets/huggan/wikiart."}
{"text_id": 297, "text": "query: Develop a system to generate background images for an art gallery website. The images should be suitable for use in visual branding elements on the website."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: We have an AI-powered image sorting system. We need to differentiate between cat and dog images."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: I am involved in a project where we analyze movie reviews to gauge the sentiment of the audience. I want to utilize a pre-trained model for sentiment analysis."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: Our content creator asked if he can measure similarity between our stories' entries in the collection."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: I want to create a mobile application that allows users to identify different fruit species using a photo. Please help me classify the images."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Our customer is building an emotion-tracking app for German-speaking users. We need to analyze the emotions conveyed in their voice recordings."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: We are a news agency, and we just published an article. Summarize the main points of the articleto share on social media."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: I want to analyze my soccer match videos, classify the actions of the players, and how the game is being played."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: I work at a call center and sometimes we get unclear audio. Please clean up the noisy audio of the last customer call."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: Create a program that generates Minecraft skins for players using generative art."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: We are an AI-driven company and we want to classify spoken commands from an audio file that includes keywords such as \"yes\", \"no\", \"stop\", \"go\", \"left\", and \"right\"."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: As a manager, I'd like to check how knowledgeable my team members are. I will provide a series of questions and answers for them to study from. What is a good benchmark for their acquired knowledge?"}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: As a language translation company, we would like to transcribe and translate audio files available in different languages."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: \"Recent studies show that owning a dog is beneficial for your health. Researchers found that dog owners tend to have lower levels of anxiety and depression. Additionally, many dog owners report increased levels of physical activity due to regular dog walks.\""}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: Create an artificial image of a bedroom using the DDPM model."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: We are a company that provides multilingual services to customers. We need to translate Dutch texts to English."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: 'dog', 'run', 'park'. Can you use a model that generates a sentence using these words?"}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: Develop a depth estimation system for the autonomous vehicles of a transportation company."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: I am a historian working on the life of Abraham Lincoln. I would like to analyze large texts to find names and related places."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: I have a short piece of text that I'd like to turn into an audio file so that I can listen to it when I'm out for a walk."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: We need information about the year Beijing hosted the Olympic Games from the following table."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: We're working on a software to classify CO2 emissions based on input features in a census dataset. Find an appropriate API."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: \"Discover your new favorite [MASK] at our store now!\""}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: Our research in agriculture improvement is now trying to establish depth estimation for trees in a forest."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: I need a software that will classify videos in the park if it's a person, animal or equipment."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: Create a system that can take a multimodal document as input and answer questions about the contents of the document."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: I oversee an insurance company and have a large number of documents related to claim settlements. I often need to extract specific information from these documents. Assist me in retrieving the claim amount and date of an accident from a document."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: We want to create a fun game by completing sentences in French. We want the machine to help us by suggesting words to complete the sentences."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: We are building an article summarization engine. Now we need to compare each new generated sentences with the original sentences to make sure they maintain the same meaning."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: Develop a software that can separate speaker voices from a given audio file with multiple speakers."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Develop a chatbot that can engage in an open-domain conversation while using different personality traits without giving explicit hints."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: I want to discover the most influential blog posts by how similar they are to all other blog posts in my data."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: Our team is building a robot that can navigate indoors. We need to estimate the depth of objects in its view."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: Our company is developing smart glasses for the visually impaired. Can you set up the API to estimate the depth of objects in the scene?"}
{"text_id": 886, "text": "document: This is a GradientBoostingRegressor on a fish dataset. This model is intended for educational purposes."}
{"text_id": 886, "text": "query: A fishery company wants to estimate fish weight from the fish data they provide. Set up the analysis and present a proposed solution."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: We are hosting a video competition in our organization. We need to analyze videos and predict their actions."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: We are an environment consulting agency and need to predict carbon emissions given the appropriate input features."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: A French speaker asked us a question, and we don't understand it. Let's translate it into English."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: We are building an online chat platform, and the platform needs to have a function to find similar messages."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: I want to create a surreal image for my art exhibition. My concept is an alien ship landing in an enchanted forest filled with glowing plants."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: I am a detective and I have a piece of info to get the person name from it because we want to open a case for him. "}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: We're going to create a poster that includes a fantasy-themed and high-quality anime character image."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: I want to understand more about the French Subjunctive, can you find a passage for me that explains it?"}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: Our team is giving a presentation on the impact of technology on society and needs to generate some additional ideas to include in our slides."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: As a news agency, we need to write image captions for our articles."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: crime, tragedy, and theft."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: I am building a mobile app for taking photos and need to estimate the depth from a single image."}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: I would like to create an automatic system to categorize hotel reviews based on the descriptions provided by customers."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: The company is developing an application to assist visually impaired users. We want to predict the depth of objects in the images captured by the app."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: We are an international company that operates in different countries. We need to communicate with our team members over voice, regardless of their language. Help us to set up a model to translate an audio file (in English) to a different language like Czech."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: I have an audio file of a conversation in English. Please transcribe it."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: I am building an application that will help medical students by answering their questions. How can I use this model to answer questions related to medical content?"}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: I want to translate mp3 voice messages into text to answer them in written format, in Portuguese."}
{"text_id": 143, "text": "document: A model for visual question answering in Portuguese and English, capable of processing PDFs and images to extract information and answer questions."}
{"text_id": 143, "text": "query: I need an AI model that can read invoices, receipts, and statements then answer questions about them."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: As a content management team, we need to extract semantic textual similarity features from a given sentence pair."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: Our client wants to transcribe audio files of his students speaking Japanese for language proficiency evaluation."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: We are running a meeting with representatives from speakers of the Hokkien dialect, and we need to translate their speech to English in real-time."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: Our customer wants to synthesize high-quality images of human faces. We want to use a Neural Network capable of this. Configure a pipeline for such a task."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: I am building a website for reading novels. I want to generate a few lines of text so that it can display a story on the opening screen."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: \"A brave teddy bear saving a cat from a tall tree\"."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: I am working on a project to analyze medical education materials from different sources. I would like to find similar documents in different languages."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Our company would like to create an automatic image captioner that could provide relevant and coherent descriptions for social media platform pictures."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: Design a solution to answer questions related to a set of given tables."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: I am an entertainment producer, and I would like to generate speech from text for an upcoming performance."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: We want to categorize product images in our catalog into different categories such as clothing, electronics, home, and accessories."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: We are an online streaming service company that wants to leverage audio analysis to provide personalized recommendations. We require an audio spectrogram transformer for this purpose."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: Our team is using a NLP pipeline to improve a chatbot's conversation abilities when given an incomplete sentence. Can you helped us with that?"}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: Could you help me translate an important message in German to Spanish?"}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: Develop an AI agent for Gym Hopper environment using Decision Transformer model."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We need a way to extract tables from an image to easily sort out our inventory data from the image."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: As a consultant to various news agencies, provide a summary of today's headlines in Spanish."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: Users need a text-to-image generator to visualize their descriptions."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: A warehouse manager is looking for a way to automatically detect forklifts and people in images for monitoring purposes."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: breakfast, morning, coffee."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: A hotel manager wants to analyze their customer reviews to understand the overall sentiment and improve their services."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: Working for a customer, our goal is to transcribe audio interviews to create a textual document for further analysis."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: Given an audio file, please help me identify when human voices are active, what the speech-to-noise ratio is at any given moment, and estimate the C50 room acoustics."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: Suppose we are journalists working on COVID-19 pandemic article. We need to know the information about the effectiveness of wearing masks in preventing the spread of COVID-19."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: We are making a visual aid system for the visually impaired. We need to estimate the depth of objects in their surroundings."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: I need to condense a lengthy news article into a brief summary."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: As a logistic company, we want to process an extensive list of addresses and identify detailed information such as names, cities, and countries."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: I want to develop a solution that can automatically identify and categorize different objects in an image. I would like to know which API I should use for this task and how to use it."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: How would you help our customer to create fresh content and maintain consistency in the text?"}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: I am building a chat service where I would like to engage users into a conversation about various topics."}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: Extract relevant information about individuals, organizations, and locations from a given text."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: We are looking to digitize the text from an image in our archive section."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: We are producing customized images for a gift shop. We want synthetic visualizations of aesthetics that could be used for various personalized items."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: Our team is working on transcribing a podcast episode. We need to identify the parts where two or more speakers are speaking simultaneously."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: We are a podcast company with an audio track. However, the audio has background noise and multiple sources of sound. We need to separate the sources and improve audio quality."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: Develop a model that can classify whether a given question is about science, technology, arts, or sports."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: Create a text translation system that can translate English text to Spanish. The considered input texts are related to booking a hotel."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: A book author wants to receive illustrations for his new fantasy book series each time he mentions a new object. Illustrate a castle for him."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: We are developing a storytelling app for kids. We need to convert our stories into speech files with a soothing voice."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: We're developing a feature for our website to display generated images of fictional characters. The model should create a high-quality image of a non-existent person."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: We need to create a custom trading card game. Can you generate an image of a mystical creature based on a description?"}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: Our website has users from multiple countries, we need a system to translate customer queries from English to simplified Chinese."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: We are a customer service company focusing on enhancing our chat services. We want to employ AI to automate tasks."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: Can you build a product that translates English spoken works to the French language?"}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: I am a lawyer and I need help extracting important information from legal documents to assist me in answering client's questions."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: A client requests an AI-generated painting of a royal chamber with a fancy bed. They also want to provide a rough sketch as a guide for the final result."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: I'm a content creator and I want a tool that translates English articles into German language for my German audience."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context. We want to generate a natural response to have a conversation with this model."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Our team is exploring 3D reconstruction. We need to estimate depth information of an image containing an object."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: I need a story for my new English language book for children, starting with \"In a small village near the mountains...\"."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: A publishing company needs a system to detect tables in scanned documents. We need to use a model specifically for table detection."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: I am hosting a photography event, and I would like to segment objects from their background automatically."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: Create a digital poster for a music festival featuring a diverse line-up of bands and artists using a futuristic cityscape as the background."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: We are creating an AI-based customer service platform for our online store. Develop a conversational chatbot that can help customers with their inquiries."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: Our customer is building a chatbot to improve customer interactions. We need to implement a way to generate responses to customers based on their communication history and the existing context."}
{"text_id": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 797, "text": "query: I would like to separate the speaking voices in a noisy audio recording."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: We need to segment and identify objects in a specific image for a security application."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: A finance company needs an automatic way to extract summaries from the financial news articles they receive daily."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: I am part of a small team of programmers working on a project. We want to leverage our codebase to provide better indexing of modules, functions, and variables. How do we achieve this using artificial intelligence?"}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: We are building an app for personal trainers and need to identify the type of workout being executed from a video."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: As a medical researcher, I am working on clinical texts. Help me guess missing words or phrases in these texts."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: Our mobile app development team is trying to translate user messages from English to French. Please help them to demonstrate how they can integrate the language translation code."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: Our music streaming service wants to analyze the audio content of songs to create playlists for different moods. We'll need to extract audio features from the songs."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: While building a food identification application, a feature needs to be added to differentiate between hotdog images and other images. We need to classify incoming images as hotdog or not hotdog."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: A video game company wants to implement a reinforcement learning model for an AI-controlled character. The character called \"Half-Cheetah\" needs to move as efficiently as possible."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: Our company creates talking toys, like teddy bears. We need to generate speech from text in a child-friendly voice."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: We are presenting a new tool that can convert English text into videos which will have Bruce Lee showcase the given text."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: Develop a voice-based personal assistant software that can transcribe my spoken notes to text."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: Sum up the main content in English, translate it in French."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: \"John is standing under the rain near his broken umbrella.\""}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: I am working with a real estate company. They have several exterior images and they would like me to create a variation of these images that are similar but still visually different."}
{"text_id": 705, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 705, "text": "query: Develop a chatbot service that can find the similar questions asked by customers."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: I want you to use the latest Hugging Face Transformers library to create an audio classifier that can help me detect voice commands amongst the numbers 0-9 for a smart home application."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: We need to create a unique Minecraft skin for the user. Please create a procedural skin generation."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: A person is taking part in an online quiz and comes across an image-based question. They need a text description of the image to answer the quiz question."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: We are working on a project that requires transforming an image into different styles."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: I need a way to estimate the depth of objects in an image for an autonomous vehicle."}
{"text_id": 456, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 456, "text": "query: I am looking for a table about Olympic Games and I want to find out the year when Beijing hosted the Olympic Games."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: Provide support to classify images provided by the user as either containing a dog or food."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: We are building a virtual assistant to help visitors in a museum. The assistant answers common questions regarding the museum history, exhibits information and general guidelines."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: For an e-learning platform, use a text-to-speech converter to create narrations of passages from educational texts."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: We'd like to predict tips at our restaurant. Implement and run the baseline model and provide sample results."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: Determine the best API to use for text to speech conversion in an audiobook project."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: In the new CRM we are developing, we need sentence embeddings to be generated for a list of customer feedback on our new products. We would like to use those in a clustering algorithm to identify major areas of feedback."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: We have developed an app to analyze users' emotions based on their voice. The app is designed to recognize emotions in Russian speech."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: Write a recommendation of which online news sources I should read, focusing on articles about autonomous vehicles and urban planning."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: Analyze a Python code snippet and provide an appropriate summary/documentary about its functionality."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: We have a system to parse documents and we want to enable the users to ask questions about the content of those documents."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: We want to create a high-quality image for a virtual reality game environment with a bedroom theme."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: Design a book cover with the title \"The Magical Journey\" and a thrilling fantasy theme."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: We are creating a program to intelligently caption photos for social media posts, and would like to know the emotion of the person in the photo."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: Our team works on generating AI-generated quotes, and we need to create multiple alternative endings to our given sentences."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: We're working on a project that generates images based on textual prompts and needs a neural network capable of conditioning diffusion models on extra conditions."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: Real estate companies need a tool to predict the prices of US housing. Develop a simple API for them."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: We need to develop a customer support system that transcribes customer calls in Dutch."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: Create an automated content generator that translates English text to Arabic language for a website. We want to make our website accessible to the Arabic-speaking audience."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: Evaluate if the submitted artwork for our online gallery was created by an AI or a human artist."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: Write an API call that can recognize spoken languages from audio files I will provide."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: We've been having problems with spam calls lately. I am wondering how I can use this model to quickly identify the type of the call, so I know whether to answer or not."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: We are launching a virtual reality app that lets users experience different architectural styles. Generate an image showcasing a church with specific architectural details to use in our app."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: The marketing department wants to use a signboard in their advertisement. We need to extract text from an image of the signboard for them."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: I need you to classify different customer complaints based on their type (e.g. billing, technical issue, account management, or service quality) so that I can better organize incoming support requests."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: My kid is learning about food items. He took a picture of his dinner and is now curious about whether it is a hotdog or not."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: The user is trying to extract tables in an image, let's recommend them to use the table extraction API in the AI model as:</default_output_extract_tables>"}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: Come up with an end-to-end solution that will predict/estimate the depth of images using a pretrained model."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: We are building a safety compliance checking system for construction sites. We need to find if workers are wearing hard hats in the given image."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are building a machine learning model to optimize our production line using the Gym HalfCheetah environment."}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: We are designing an AI-powered chatbot for our website. We want it to talk like Elon Musk. How can we set this up?"}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: A medical student needs help finding answers to questions related to a research article."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: Create a speaker identification system to find out who is speaking in an audio file."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: Create a summary of a blog post about autonomous vehicles."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: A new audio book platform wants to convert audio recordings of books into user-readable text format with correct punctuation and capitalization. Build a solution to automatically transcribe the audio books."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: Find the most relevant passage to answer the question about the population of Berlin."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: We need to know whether two sentences, one being a news headline, and the other being an advertisement description, are similar."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: We want to add a feature for transcribing speech for our podcast application in order to offer subtitles for users with disabilities or users who prefer subtitles for a better experience."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: We are working on a customer service application. We need to generate responses to customer's messages."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: We are developing a fitness application that helps people track their progress in various physical activities. We need to identify the type of activity from short video clips."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: We are a digital publishing company; we need to convert book summaries into FAQ sections based on user's questions."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: We want to estimate carbon emissions produced by residential areas using tabular regression. Help us use this model to make predictions."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: A magazine recently approached us with the task of analyzing relationships between headlines and the actual story content. We need to automate this process."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: We are developing a video-based fitness app. The app must analyze exercise videos and classify the type of exercise performed."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: We need to segment images containing animals for a project on wildlife conservation."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: The company wants to predict the CO2 emissions of various products. We need a classification model that can help them with this task. "}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: I want to create a concept image featuring a futuristic city with tall buildings and flying cars."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: In our translation app, we want users to translate Romance languages (e.g., French, Spanish, Portuguese, etc.) into English from emails, websites, and other sources."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: I own a library and I would like to create an intelligent assistant that helps locate a book using OCR scanning and matching with provided text."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: A mobile app needs to use audio classification to identify numbers spoken by users."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: I am a student working on a science education project of categorizing scientific articles into different levels of complexity. I need to calculate the sentence similarity between the provided abstracts."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: I work in a real estate consulting firm. We have a list of properties and we need help in estimating the prices of the properties to make a recommendation for our clients."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: I need to create a Study Guide for my students, highlighting the most relevant passages about a certain topic."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: Design a system to estimate the depth of an object captured in a given image."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: I am a teacher, I want to classify a sentence into teaching category."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: I am working for a Korean restaurant. We have data of our customers and their food preferences. Help us in building an assistant that answers questions based on this data."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: My 13-year-old daughter has a school assignment about a scientific paper. Can you provide her a summary of the given scientific paper to help her understand the content?"}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: I want an AI that can complete Japanese sentences with the most relevant word."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: We are launching a vintage-themed clothing line and would like to generate promotional images featuring an analog-style cityscape."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: A hotline receives phone calls containing information about security threats. We need to transcribe Arabic speech to ensure Arabic information is stored and analyzed."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: I am building a website with a quote of the day feature. I want the quote to be available in multiple languages. Translate an English quote to Romanian."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: We are a book market. We need to process each book image to automatically get their title and author."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: We are a publishing house and we need to create summaries for the books we are releasing."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: We are holding a hotdog-themed contest at the company picnic. Determine if people are wearing costumes that look like a hotdog or not."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: A client of ours is interested in understanding the sentiment behind comments on their website which is in German langauge. We will give you some sentences and you analyze the sentiment."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: A client from an educational institution is building a smart video library and needs to classify their educational videos based on their content."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: I am a researcher studying COVID-19 articles from different media sources. I want to get similar sentences related to COVID-19 from different articles."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: An audiobook company is requesting to transcribe their audio data into text format. Let's provide them with a solution that will transcribe their audiobooks."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: We are developing a game and want to generate anime-style images based on specific character descriptions like \"a warrior with a sword and shield\"."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: Can you help me understand how to use this algorithm in a robotics development that learns to balance a pendulum?"}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: I want to generate a bird-themed video with the story of a bird saving a forest from a fire, with emphasis on a majestic bird flying above the flames."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: sys.exit(exit_code)`. It is an exit function for an application."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: We are building a website where users can input text and receive the visual representation of it as an artistic image."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: We have a list of customer requests, and we need to extract important information such as name, location, and product mentioned in each request."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: My kids want to play a game where they write a sentence with a missing word and the AI has to guess the missing word."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: I have this paragraph of text about Python programming language and I would like a few questions generated from it."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: We are conducting a research project for an astronomy magazine's cover. We could use some images of the universe."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: We are an international organization who prepares to make an announcement to the Arabic speaking-world, the announcement is in an .txt format. We need a translator."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: Develop a Telugu-speaking voice assistant that takes input in text format and provides the output in audio format."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: I am an architect and I want to create a realistic aerial view of a park with a lake, children playing, and trees around."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Our company provides data extraction services, and we have to extract tables from images."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: There is a new social media app where users want to generate smart captions for their photos automatically. Design a feature that generates creative captions for their images."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: Provide a method to convert a text in Arabic language into speech."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: My six year old kid has created a poem and wants a video to illustrate the story. How can I create a video based on the poem?"}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: To aid in the prevention of climate change, we want to estimate carbon emissions based on various parameters."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: I need a system to extract information from forms like invoices and registration forms. The model should be able to answer questions regarding the extracted information."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: Our company wants to develop an app that can create video gags from text inputs. We need a model to generate a video from text."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: We want to build an audiobook app. Our goal is to convert the text of a book into speech so that users can listen to it without any manual conversion."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We need to convert a handwritten image into text. The image can be found at https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: We want to recognize emotions from voice notes left by our customers as their feedback using a model that outputs emotion probabilities."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: You are an AI developer, and you are building a chatbot to communicate with users. I need you to generate a response sentence for the user context \"The weather is too hot today.\""}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: Our company handles a lot of old hand-written documents that need to be transcribed into digital format. We need an automated way to transcribe these documents."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: Create a powerful translation tool that translates an English sentence/question into German."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: We have a customer support team to address customer complaints. Help categorize the complaints according to their subject and urgency."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: I'd like a chatbot that can help me identify named entities such as dates, names, and organizations within a given text."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: Analyze an image and classify whether it is from a residential area, a playground, a stadium, a forest, or an airport without a training dataset."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: I need to know what kind of emotion there is in an audio recording."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: I want to create a virtual fitting room that can detect clothing based on images of people in clothes."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: We are working on a chatbot that can condense long conversations into shorter ones for easy access to important information."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: I'm working on a project that extracts information from textual images, but I need to find the answer to specific questions related to those images."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: Detect depth information in images using depth estimation model for a computer vision application."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: Your company plans to expand into the Chinese market and requires you to translate the homepage information for the Chinese audience."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: Create a system that predicts sentiments from a set of movie reviews."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: We are working on a project to organize documents by topic. We need a way to group similar sentences together."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: We would like to know the total amount of an invoice with its image and provide an input question."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: \"a beautiful mountain scenery during the sunset\". The generated images should be of good visual quality."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: Can you help me create a program to turn text into speech for a text-to-speech audiobook we're building for visually impaired people?"}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: I have a website providing tour guiding in the Alps. It has German content, and I need to translate it to Spanish."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Create a funny meme description based on a given image."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: I'd like to create an image captioning application for my app users that are visually impaired. Can you help me generate captions for the images they take?"}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: You are working on a book which language you are not familiar with, you want to consult to fill the blanks of a sentence."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: We want to create an app that reads news articles out loud. Use a text-to-speech model to convert the text into an audio file."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: I want to make a chatbot for my website that simulates a conversation using microsoft/DialoGPT-small."}
{"text_id": 95, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. The overall model parameters are about 1.7 billion. Currently, it only supports English input."}
{"text_id": 95, "text": "query: \"A footballer scoring an incredible goal from a free kick.\""}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: We are building a tool that generates alternative dialogues for movie screenplays. Please help us transform a sample dialogue using the model."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: I have a dataset containing features related to carbon emissions, and I want to predict the emission levels based on the provided features."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: Generate a conversational AI that talks like Palpatine from Star Wars."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: Our new marketing campaign for the global market is launched today. Please translate the following Spanish text to English for our website."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: Help me analyze a paragraph and identify the different entities within the text. For example, find organizations, locations, and more."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: Create a text-to-speech conversion system in Telugu, using a male voice."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: I want to deploy an AI model to classify images of objects using vision transformer and Hugging Face."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: I want to build a mobile application that can detect the active voice of speakers in a recorded audio and process the transcript. Tell me the hyperparameters to use."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: We need to compare product review comments and find the similar comments."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: Create a model to find the most relevant context for a given query from a list of possible contexts."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: Since my friend is a big fan of audiobooks, develop a text-to-speech model to read text from books aloud."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We have a client who wants to extract tables from scanned documents. Build a program that analyzes a given image and identifies tables within the document."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: Our company designs advertisement posters. We need to create an image reflecting \"a sunny beach day with people playing volleyball and enjoying ice cream\"."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: We're an AI language translation application wanting to offer new languages. We need to translate answers to most common travel phrases into German."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: To create educational content for children, we want to generate sentences that use specific sets of words, like \"apple\", \"tree\", and \"pick\"."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: Develop a safety system at construction sites by detecting workers wearing hard hats in the images taken from security cameras."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: Our team is building a device that needs sound source separation for noisy environments. We need to separate the voices from the background noise."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: We need to predict housing prices for a real estate company in California. Develop an accurate model for this purpose."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: We are launching a soccer agent AI to play with our customers in the virtual world"}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: Write a Python function named 'sum_numbers' that takes two numbers as input and returns their sum as output."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Develop a way for our art gallery to sort images based on certain descriptions such as \"landscape painting\" or \"portrait of a woman\"."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: We are building a search engine to help our customers find similar texts. The goal is to process the search results and return ranked recommendations."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: I want to classify a specific image of a bird to get the species name using a pre-trained model in Chinese language."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: A customer asked, \"My son is feeling sick with a fever and sore throat. What should I do?\" Recommend a passage with the helpful information from a list of passages."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: We wish to build an image classifier for a mobile application to recognize objects in real life."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: We want a model that generates an image of a cat based on a text description provided."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: To implement a Python script that generates an unconditionally generated image of cute butterflies using pre-trained pipeline from Hugging Face Transformers library."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: A new animal welfare center is opening in the city, and they want to create a unique, beautiful image of animals playing together for their promotional posters."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: We're developing a customer support chatbot to handle high volume of inquiries. We need it to process long customer support chats and generate concise summaries."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: To understand our customers' preferences, we need to analyze descriptions of their favorite books and find similar books accordingly."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: Identify the named entities in the given sentence, such as people, places, and organizations."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: We are a customer support team. We help people to find happiness with the help of our expert advices."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: Design an AI-based tool to analyze tabular data and provide answers to questions involving multiple tables that are related."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: I have an online shoe store. Can you generate an image for me to use as a banner for my store homepage using the phrase \"Stylish running shoes surrounded by nature\"?"}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: We are creating video game concept art, and I would like to stylize a character as an oil painting while preserving its important features."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: We need an efficient way of analyzing customer reviews by matching them into general soundtracks like anger, sadness, happiness, neutrality."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: I just read an article and want to find an answer to my question, \"What is the main benefit of converting models between FARM and transformers?\"."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: I have an image and I would like to transform the appearance according to a textual description. The system should be able to use the input image and the given textual guidance to create the output image."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: My new employer wants to determine employee sentiment for internal feedback. Describe the model we can use and how to create a tokenized version of the feedback text."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: \"I love this new product!\" and \"This customer service is terrible.\" How can I find the sentiment of both messages?"}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: We are building a robot lawn mower. We need the robot to estimate how far objects are to avoid them while moving around."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: Our marketing department needs realistic-looking images of landscapes following an analog style for an upcoming ad campaign."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: We are setting up a robotics framework for self-navigating and following different object types. For now, we need a software to detect objects in images."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: A customer support agent requires sentences to be rephrased so as to form useful conversational responses on the go."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: Create a script to straighten the lines in the image of a room using the sd-controlnet-mlsd model."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: I want to develop a self-driving forklift that is able to detect other forklifts, and pedestrians automatically. How can I do that?"}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: Develop a model to classify an image of a product that helps people with disabilities."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: We want to build an application to detect similar articles in the news. Please suggest an API that can generate sentence embeddings for similarity comparison."}
{"text_id": 99, "text": "document: GIT (GenerativeImage2Text), base-sized, fine-tuned on TextVQA. It is a Transformer decoder conditioned on both CLIP image tokens and text tokens. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is to predict the next text token, giving the image tokens and previous text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 99, "text": "query: Develop a solution to provide descriptions of the actions happening in an image, and answer any questions about the contents of the image."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: Our customer needs to translate a French document to Spanish as soon as possible. Help them accomplish this task."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: I am a designer working on a high-quality portrait of a fictional celebrity for a magazine cover. How do I generate the image?"}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: Build a system to transcribe Vietnamese in sound file format from interviews."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: Create an audiobook for a given piece of text and save the generated audio to a file."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: You are tasked with quickly summarizing financial news articles for a group of investors who need digestible summaries."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: A construction company needs to measure the area that the buildings are occupying in an aerial photo."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We received a scanned legal document from our client. We need to find out about the total amount of money involved."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: Create an image of a serene beach with palm trees and a hammock between them, using a library that helps to generate or modify images based on text prompts."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: Analyze an image and tell me the position of a cat and a dog in the image."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: The City Council of our city needs to predict carbon emissions to create policies against climate change. We have to process and classify data to make accurate predictions."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: I am a musician, I want to create a song lyrics for a pop song about love. Generate some song lyrics for me."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: I want to build a game character and I have a brief description of their persona. Create a dialogue with the character based on their persona."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: We have collected data on employees' salaries, benefits, and years of experience. We are organizing a seminar on salary expectations and negotiation, and we need to know the average salary for employees with 5 years of experience."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: My child is forming sentences now. We want to use AI to help him complete sentences when he makes a mistake or from a saved template."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: A school teacher is teaching human anatomy. She wants auto-generated questions from her text book."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: My company wants to develop a product to quickly classify images. They want a pretrained model to be used for street signs, cars, and other common objects."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: For a school project, some kids will say a number from 0 to 9, and the AI-based system has to recognize and classify the number accurately."}
{"text_id": 77, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 77, "text": "query: Design a tool for users to have automated image captions for their social media account. Users can upload the image and provide a short context/description for the desired caption."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: I am developing an application to facilitate online learning. This service will help users find answers based on a table they provide. "}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: A group of friends are building a multilingual radio streaming and they need a solution for transcribing their Esperanto audio content."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: A digital content creator is looking for a way to create a visual representation of the text \"A cat sitting on a green grass by a tree\"."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: We want to record voice meetings and quickly create the transcriptions that can be attached to meeting minutes."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: Our company is implementing a virtual assistant that needs to read text in a Spanish male voice for our visually impaired users."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: We are designing a software application to extract specific information from scanned documents. Let's find a suitable model for this purpose."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: A web-based chat application needs to implement text conversation between the user and the AI virtual assistant. Utilize the Cadet-Tiny model to achieve this functionality."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: We received an email from our users which is written in French. Please classify this email into sports, politics, or science."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: We are building an autonomous robot for navigation purposes. We need to estimate the depth of the surrounding environment of the robot to navigate smoothly."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: Our team is working on autonomous vehicles. We want a depth estimation model for the front camera to better handle the driving environment."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: Can you help me create a program that can find an answer to my question from a paragraph of information?"}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: I need a deep learning model to answer questions from Vietnamese visual documents. Can you provide any API for this task?"}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Explain a user-friendly solution for creating image captions, answering visual questions, and engaging in chat-like conversations using the AVAILABLE API."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: Build an AI system to categorize news articles into a few different topic areas, such as technology, politics, science, and sports."}
{"text_id": 597, "text": "document: Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, both asking and answering questions, and displaying knowledge, empathy and personality appropriately, depending on the situation. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter neural models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models."}
{"text_id": 597, "text": "query: I'm looking to create an engaging and intelligent virtual assistant to help answer questions and engage in general conversation. The virtual assistant must be able to understand context, rephrase information and provide satisfactory answers to questions."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: The end-user wants unique images that are visually appealing to print and put in their home."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: I need a chatbot which could answer my answered questions using semantic search by comparing my question with things written in the text."}
{"text_id": 389, "text": "document: This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is used for sentiment analysis on movie reviews and achieves an accuracy of 0.928 on the evaluation set."}
{"text_id": 389, "text": "query: A movie theater is collecting customer feedback and reached out to us to analyze the general sentiment within the responses."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: We are working on a web application that allows users to analyze Instagram images and provide context."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: We're developing a platform for sports analytics. We need to classify a video which sport is being played."}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: Our client is a real estate agency. Currently, they require a prediction of house prices based on their features."}
{"text_id": 807, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. The model can classify a speech utterance according to the language spoken. It covers 107 different languages."}
{"text_id": 807, "text": "query: Our company is developing an app that needs to identify the language spoken in an audio file."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: A scientist is working on a project. He needs help with summarizing scientific papers for easy understanding."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: I want to discern the emotions in an audio recording of a person speaking."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: I'm creating a security system with CCTV cameras and I need to identify aggressive behavior in the footage."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: We are building an AI chatbot for our website. We need to integrate a language model to generate responses."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: The company is working on a new robotics project. We need to estimate the control parameters of robotic arms."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: I am creating an application to detect and classify events in sports videos. I would like to integrate a video classification model to understand the type of event happening in each video frame."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: The company is working on a fun project that detects cookwares on the kitchen table. We want to use a machine learning model to segment the kitchen objects."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: We are developing an augmented reality app which needs depth estimation of the environment for proper rendering. Create a classifier to estimate the depth of the environment from an image input."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: I want to take a photo and find out whether the animal in it is a dog, cat, or bird."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: Recommend a movie to my friend based on a Twitter review which contains the opinion of the movie."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: A user needs to get a summary in Spanish of a long article they found about how to take care of peacocks."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: A tech artist asked to create a photo-realistic image based on a given text description."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: Develop an application that can answer user's query about information in an image."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: Help me create a reinforcement learning model capable of simulating an agent navigating through the Gym Hopper medium-level environment."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: You are a German weather reporter looking to create spoken German weather updates using Text-to-Speech. Transform the text \"Heute ist es sonnig und warm mit einer Temperatur von 25 Grad Celsius.\" into speech."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: Our team is developing a podcast transcription service, and we need a way to transcribe audio files into text."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: Design a virtual assistant that uses an image link as input to answer any questions about the picture."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Our client needs inspirational quotes on success that they can post on their social media page."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: We are a video-production company and we want to create a text-to-clip simulator to help enhance the collaboration of production with customers and show what a potential completed video might look like based on their textual description input."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: I am building a product to recommend scientific research papers to users based on their past reads. I need to find the similarity between the research papers."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: As a lawyer, I want to extract specific information from a digital legal document. I need to know which API would be best for this task."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: We are building a game for kids to understand emotions better. We want to use this API to classify an audio file with a child's laughter or crying to relate with different emotions."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: We have created a chatbot which is supposed to respond to customer queries. Help it to respond empathically."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: Construct a sentence that describes the capabilities of the BioBERT language model in the field of biotechnology."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: John has bought a new car and he recently uploaded a photo of his car on social media. We want to automatically tag that photo with a car's make and model."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: We are thinking about adding object recognition to our security cameras. Is there a pretrained object detection model we can use?"}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: Recently, we started a project where the goal is to analyze the sentiment of movie reviews. We need a way to determine the positive or negative sentiment of a movie review."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: I am building an app, I want to create animal character that generates images based on text prompts."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: We are a social platform where users can post and leave comments. We want to check if the user-generated comments are appropriate or not."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: We would like to classify various plant species using their characteristics."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: A language learning platform wants to build a speech-to-phoneme model to assist users in checking their pronunciation."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: We are looking for a solution to improve the quality of an audio recording by removing background noise."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: We are a company that wants to predict future carbon emissions using historic data. We require a trained model to predict the carbon emissions."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: We need help with a question-answering service for construction material. We have a document with a list of materials and their specifications."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: In order to improve customer service, I need to determine if a review received on our website is positive or negative."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: We run a dance studio to teach different dance styles. Capture a video of a person dancing and classify the dance style."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: We are an organization that focuses on the environment's health. We need to categorize power plants based on their carbon emissions."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: Construct a pipeline for punctuation prediction on a given text and apply it on a text about a historical event."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: Our company is using chatbots for customer service. We are looking for a standard text generation solution for creating automated answers based on Russia language model."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: Develop a platform for virtual tours with generated videos based on user description. Tourists can input a description of a city or tourist spot and see it through generated videos."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: Provide information about houseplants that remove toxins from the air for a gardening blog post."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: Identify the employees with their respective years of experience, role, and location using a given table and provide the total years of experience of employees in a specific location."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: As a photographer, we want to predict the depth of different objects in an image."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: We want to predict the word that follows 'Yesterday I bought a new'."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Imagify needs images to be captioned for kids to learn names of animals and objects. Can you give them a tool to simplify that?"}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: Our users are asking questions based on images provided by us. Provide them with an AI-based visual question answering system."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: We have an image of a room and we want to calculate the depth of objects in it."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: Please help me build a model that can recognize code and named entities in StackOverflow dataset."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: Our company wants to extract text from historical hand-written documents. Help me in selecting the best API for this purpose."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: A travel agency is looking for promotional material for their next social media campaign. They want an image of a beautiful beach with blue water and white sand, surrounded by palm trees."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: We are running a muffin bakery kitchen, and we need to classify pictures to check whether our products are produced correctly."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: We own an e-commerce website where images are uploaded by sellers. We want to build an interactive feature that can give answers depending on the image features and the user question associated with the product."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: For our marketing team, please extract a textual description of a given image."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: We want to create an interactive website showcasing different types of butterflies. Visitors should be able to view generated images within each category."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: I'm working on a call center project. We need to analyze the emotions of our Russian-speaking customers."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: Identify the missing word in the Brazilian Portuguese sentence \"Tinha uma [MASK] no meio do caminho.\" using state of the art BERT model."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: Global Offensive. In order to do this, I want to detect players in gameplay images. How can I achieve this?"}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: I need a function that I can use to create a conversation assistant that generate a response based on a situation narrative, role instruction, and conversation history."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: An audio recording with two people speaking was mistakenly recorded over background noise. We need a solution that separates the two speakers."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: Create an application for urban planners that can help segment and analyze satellite images of cities."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: We want to create a short video clip that showcases a superhero-themed pizza commercial. The commercial should involve Spider-Man delivering pizzas to customers in a city setting. The video should be 5 seconds long and 256x256px dimensions."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: We have recently started an online Q&A platform. We need to find similar questions asked previously to provide instant answers."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Write me a code that generates a text that describes the difference between two programming languages, Python and JavaScript."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: As a content publisher, I need an automatic way to identify the names of people, organizations, and locations mentioned in a given text."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: An urban planner wants to analyze the composition of a cityscape image to decide on the best course of action for improving urban spaces."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: We are an e-learning company, and we want to create an app for students to record their lectures and automatically transcribe them into text."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: We want to analyze the possibilities of different outcomes of a set of different flowers."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: Generate a short summary of a news article, which will be suitable for sharing on social media platforms."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: We are a news organization and we need to automatically caption the images we use in our articles."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: To better understand the product, create a program that classifies an image from a URL."}
{"text_id": 110, "text": "document: A Visual Question Answering model fine-tuned on the VQASI dataset by tufa15nik using the ViLT architecture. The model is designed to answer questions based on the content of an input image."}
{"text_id": 110, "text": "query: A blind person wants to know what appears in an image that he captured. Could you quickly answer the question by processing the image?"}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: I want to translate the content of my website into Italian for my Italian customers."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: An artist approached us to help them visualize their idea. Create an anime-inspired landscape based on their description."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: Our team is exploring plant species in the ecosystem. Identify the species of a flower with its attributes."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: We want to analyze aerial photos of a city for urban planning. To achieve that, identify the buildings and roads in these images."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: My 5-year-old daughter is learning grammar; create a tool that enlightens her about several grammar aspects."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: Our company has a call center, we want to transcribe Chinese calls from the customers to text for better customer support."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: I need a model to estimate depth from a given single image."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: Write a system that completing partially written sentences. The model must suggest the best possible completion given the context provided."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: We are working on a children's book, and we need to create an illustration of a \"friendly dragon playing with kids in a park\"."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: Summarize a Spanish news article to ease the process of content consumption for users."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: Implement a reinforcement learning system using the trained Proximal Policy Optimization (PPO) model to play the LunarLander game and determine its performance."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: Our client needs to analyze satellite images for their urban planning project. They require a solution that helps in identifying building structures in those images."}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: We are working on extracting tabular data from an image of a document that has multiple tables. We need a model that could detect the tables to ease the process."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: As a school teacher, I want to tag the words in a sentence of my students' essays according to their part-of-speech."}
{"text_id": 825, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-base on the MESD dataset. It is trained to classify underlying sentiment of Spanish audio/speech."}
{"text_id": 825, "text": "query: I am working on a podcast platform and I want to create an automatic sentiment classifier for the Spanish audio content."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: I'm in real estate business, I need to understand the type of buildings in a given image. Identify the various building types in the picture using the MaskFormer model."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: \"I'm going to learn how to make a perfect cup of tea.\" and would like the model show which category among ['cooking', 'sports', 'dance'] it belongs to."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: My company is an industrial manufacturer and wants to predict carbon emissions based on a given dataset. We need the tabular regression model to estimate the emissions."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: As a software developer, I'm interested in translating Python code into English. How do I use an API to make this happen?"}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: I work at a hospital. We want to analyze the medical history of a patient to extract and highlight any relevant life events."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: We are an ecommerce company and want to generate descriptions for the products in our inventory"}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: Generate a high-quality image of a 3D indoor scene to be used in our website's background."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: To improve user experience, our company is building an interactive AI powered monitoring system for video surveillance. We need to classify activities in the videos."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: We are building a sports activity recognition system that can classify activities from video clips in our application."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: I am a school counselor with a lot of Russian students. I want to analyze a recorded speech from one of the students to understand their emotions."}
{"text_id": 488, "text": "document: This is the deberta-v3-large model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 488, "text": "query: Help me making a code for answering questions about biology books for my children before they make the questions directly over a conversational AI."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: We need to summarize a chat conversation between two people in a single sentence."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: A friend wants to separate the voices of two speakers from an audio file."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: I am building a transcription service for podcasts. How can I use this API to convert speech to text?"}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: I have a dataset of water quality measurements from my city. I want to identify any anomalies in the dataset using an autoencoder trained on this dataset."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: Our sports website requires a video classification system to automatically categorize sports videos."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: As an architectural firm, we want to generate renders quickly based on text inputs from clients. How can we do this?"}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: We are working on our company chatbot and would like to know how to improve its response engine."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: A project manager is conducting a meeting. Make a table query answering system to assist the project manager during the meeting."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: We are organizing a butterfly-themed event, and we need to generate some butterfly images for promotional material."}
{"text_id": 178, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al."}
{"text_id": 178, "text": "query: A software company is building a mobile app that uses computer vision technology to recognize images of landmarks. We need to classify the images."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: Create a conversational model to help in analyzing a meeting scenario where the speaker talks about project updates. The model has to respond like an attentive audience providing feedback and asking relevant questions."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: Our startup is working on a robotic arm to sort items. We need to classify the movement of the robotic arm in videos."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: We want a reinforcement learning model that could play the SoccerTwos game with the player utilizing Unity ML-Agents Library."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: I am building an application to classify images of various dishes. I would like to identify the type of dish like pizza, burger or salad."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: We have built a mobile application for users to share photos of their plants. Help the users determine the plant genus from a URL they provide."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: We want to create an application that helps users identify objects within images by answering their questions about the contents of those images."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: We need to extract names and locations from the given text."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: I have a list of text snippets, and I want to find which snippets are semantically similar to a given piece of text."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: Design a program that tells me the area of production in agriculture for a specific year of a data table."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: As an editor at a publishing company, I want a text generation tool that generates five ideas for the opening scene of a science fiction novel."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: An agriculture company wants to develop an app to identify healthy and unhealthy beans. Build a bean image classification model."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: In a warehouse management system, you need to extract the text from product images and store it in the database."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: I want to identify and classify the animal in an image using zero-shot image classification."}
{"text_id": 105, "text": "document: BLIP is a new Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes the noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. The model achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA."}
{"text_id": 105, "text": "query: A tourist company wants to create a guide application to answer questions related to a given image. Help them create the application."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: We have a service that helps users to transcribe their speeches into a written format. It has to be fast and accurate."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: An opera play director wants an AI-generated conversation between two characters in different languages. Generate a conversation in Spanish and French."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: Create a video for our social media advertisement campaign. The video should show a happy family enjoying a beach vacation."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: \"A fox and a crow fought for a piece of cheese.\""}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Help me to generate a new short story introduction with the sentence \"A group of explorers discovers an unknown land.\""}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: We need to create a chatbot that will translate sentences from English to French, create summaries, and answer questions."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: We are a smart city company looking for solutions to repair roads on time. Please help us identify potholes in images."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: We manufacture an infotainment system. Can you experiment with voices of the text-to-speech model to find different variations for our automated announcements?"}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: Let's say I am shopping for a gift and I want to find images of cats and dogs in one picture. I need a way to classify images based on text descriptions."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: Help me create an application to distinguish between noise and human voice in a meeting recording."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: We are writing a children's book and need an image for our main character's bedroom."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: I would like to convert a description of a scene into an image that matches the description."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: We are looking for an AI product that can provide a succinct caption for our input image."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: We're a multi-language e-commerce platform that needs an accurate automatic translation of product descriptions from English to German."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: Develop a tool using a pretrained model for a web agency to automatically categorize pictures on websites."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: We are working on a trading platform and we need to analyse user comments to identify whether they are bullish or bearish."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: Help me summarize an important news article to get the main information quickly."}
{"text_id": 268, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on M-LSD straight line detection. It can be used in combination with Stable Diffusion."}
{"text_id": 268, "text": "query: We want to develop an AI that can convert the input image based on straight line versioning."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: I want to get answers to questions I have when reading long news articles. I need a model that can handle the questions I have."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: Provide the list of instructions to generate an anime-style image of a character enjoying a lake's sunset."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: I am wondering if I can find a way to analyze the similarity between customer reviews on an e-commerce website."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: A social media platform wants to categorize videos uploaded by users based on their content."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: I want to develop an AI-based chatbot that can offer customer support for my online retail store."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: A market research analyst needs help in determining the sentiment of financial news articles related to a specific stock."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: We are a real estate company and we want to use a model to extract information from scanned documents of lease agreements. Explain how to use the given model to extract information."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: Determine the entities present in a given text string."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: business, technology, lifestyle."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: Our team is creating an application that needs an AI chatbot capable of answering questions as a specific character from a story."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: As a researcher, I am trying to retrieve answers from the table for my research."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: We are building a cat recognition system for automated cat feeders. We need to make sure that the cat is on the list before issuing food."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: I am looking at a picture of a beach. Can you tell me how many people are in the picture?"}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: I am an architect, and I need a tool that analyzes an aerial photo of a neighborhood and recognizes different objects like buildings, roads, and trees."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: I am building a recommendation system for a website, and I want to recommend similar articles to users. Can you suggest how to find the similarities between articles?"}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: Kate is an English speaker who wishes to cook a recipe that is written in Chinese. She would like some help in translating the recipe from Chinese to English."}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: A movie production company is compiling a database of movies from different countries. They need to identify the language of the film based on the audio."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: We are creating an audiobook in English. We need to produce the narration using Text-to-Speech."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: We have some interviews and want to have a clear structure by diarizing each speaker in the discussion."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: To help the users, we are building an application to automatically identify workout exercises in a video."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: My company needs to identify animals in the images we receive. Specifically, we need to identify the presence of cats and dogs in the images."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: We are a company that specializes in autonomous vehicles. We need to estimate the depth information of the surrounding objects."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: As a real estate agency, we want to predict the potential value of a house based on its features. Use a pre-trained model to predict housing prices."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Create advertising content in the form of text for promotional material based on the image provided."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: I need to translate an audio file in Spanish to English and keep it in the same audio format."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: My manager is asking me the quickest way to access a table for a Python script he is developing."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: I have a text in Spanish and need information about named entities from it."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: The manga team would like to create an anime storyline based on their recent manga. They need images aligned with the script."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: I am working on an accommodation sharing platform, please analyze the sentiment of the review below."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: You have a collection of images of planets, and you would like to categorize them using zero-shot image classification."}
{"text_id": 814, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 814, "text": "query: We need to classify the emotion in a customer service call recording to assess the satisfaction level of the customer."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: Based on the biomedical content of the given abstract, extract the relevant features to be used in a bioinformatics analysis pipeline."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: A law firm needs assistance in understanding certain clauses in a contract. We need to extract specific information from the contract without reading through the entire document."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: Please help in generating some creative sentences for marketing purpose."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: I would like to create a chatbot that can answer customer support queries for our company."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: My team and I are organizing a Korean trivia night for a group of language students looking to practice Korean language. We need to gather interesting questions in Korean and be able to provide answers to them."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: 'Which country has the highest GDP?'"}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: We have a book summary, I want to convert this text summary into an audio book."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: There is a machine-transcribed text of a patient's medical record. I would like to improve its readability by adding punctuation."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: Our company is building a creative project that writes fairy tales for kids. Use AI to generate a new fairy tale."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: We wish to create a service to transcribe audios from customers who speak Indian languages. We need to detect voice activity and discard the silent parts."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: I need a code snippet that takes user input and display it in reversed order."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: We are a company working with international clients. To deal with language barriers, what can we do to translate Dutch messages to English?"}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: We have a scanned legal document. We need to find the answer to the question \"What is the total amount mentioned in the document?\""}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: Generate an image of a futuristic cityscape with flying cars, using vivid colors and a warm but dystopian atmosphere, inspired by a mix of Blade Runner and Akira. The image should have sharp focus and a complex, detailed background."}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: We are working on a home improvement application that requires image segmentation. Find an image segmentation model and provide code to segment an image."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: I am a computer science student and I need a model to generate Python code that carries out specific tasks."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: A user wants to know the capital of France from a given text passage. Provide a solution using BERT large model."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: A company would like to train a speech recognition model with numbers. Recommend a suitable pre-trained model for digit recognition and provide instructions on how to set up the model."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: A company is developing a smart monitoring camera for client security. It requires the camera model to classify video feeds into different activities."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: We need to detect objects in a given image using a model."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We are trying to add the GTA5 AI model that has some limitations on the data it processes and train it with a limited GPU."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: Summarize an article about the benefits of exercise to fit into a paragraph."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: Our company needs a summary of a French language article to present to our English speaking investors."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are producing intelligent robots, we need to make the robots move more like a half-cheetah to make it faster."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Our digital art gallery wants to offer a new service for customers to interact with images. The virtual assistant should be able to describe the artwork and answer questions about it."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: We are a language school, looking to generate interesting stories for our students to learn English from. We would like a short story that starts with \"Once upon a time in a magical forest\"."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: I need a tool to generate clear images from blurry ones. Please provide a solution that helps me with that task."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: Developing a learning agent to play CartPole to compete with the human players."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: Let's say I have a large scientific text with lots of information. I need detailed steps on how I could generate a summary that can help understand the main points of the text."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: A car rental company needs to estimate CO2 emissions for their vehicles. Create a program that estimates the emissions based on given vehicle data."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: I am tasked with creating a machine-learning workflow for a platform that makes use of computer-generated charts. The users will be able to submit queries and receive answers from the graphs utilizing the query data. "}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: We are a car company; we are building an autonomous vehicle that navigates in unknown indoor environments such as parking lots. We require the system to identify its surroundings and make intelligent decisions."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: We are building an automated code review system that will provide recommendations or fixes for the code. We need the AI model to be able to understand and generate code."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: I am a data scientist, and I have been given an important task of analyzing data from different companies for a report. I need to make the required comparisons based on the details from a csv file."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: Our company is working on the development of a self-driving car prototype. We need to implement a reinforcement learning model for controlling the car."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: You are a fiction writer, and you want the program to come up with dialogues for your story using a character's persona and previous dialogue history."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: Design and provide a way to answer questions related to financial data in a table format."}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: Our boss requested a summarization of the meeting conversation, so that we can put it in the report."}
{"text_id": 853, "text": "document: A binary classification model trained on the Adult Census Income dataset using the XGBoost algorithm. The model predicts whether an individual's income is above or below $50,000 per year."}
{"text_id": 853, "text": "query: A bank wants to predict potential defaulters. Discover useful insights that can help identify whether an individual's income is above or below $50,000 per year."}
{"text_id": 388, "text": "document: Model trained with SemEval 2017 corpus (around ~40k tweets). Base model is BERTweet, a RoBERTa model trained on English tweets. Uses POS, NEG, NEU labels."}
{"text_id": 388, "text": "query: A marketing company wants to launch ad campaigns for businesses based on user opinions collected through social media. They need to classify these opinions into positive, neutral, and negative sentiments."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: Our client is a sports analytics company. We need to analyze and classify actions in a given video clip."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: We're a team working on molecular modeling and exploring new molecules' potential. We'd like to leverage recent advancements in ML to classify molecules based on their graph structure."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: Our company provides a social media management tool. In order to make our tool more understable, we need to detect the tone in the provided news headlines."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: We wish to transcribe Vietnamese speech from an audio file and convert it into written text."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: I'm planning a vacation and would like to create a list of landmarks for each day. To keep track of my itinerary, I want to convert the text descriptions into audio files."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: Our client is an e-commerce site. They need to determine the categories of the items using the images."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: Our client wants a system that takes a German text input and converts it into an audio file. Please help them develop this by suggesting the best API to use."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: Our company is in need of some high-quality images of cats for an advertising campaign. Can we upscale and refine low-resolution cat images based on text prompts?"}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: Develop a solution to generate a high-quality image of an urban scene with futuristic architecture based on a text description."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: Our company focuses on autonomous robots in warehouses. We need to estimate depth using a pretrained model."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: A company wants to use an AI-driven live-chat system that can communicate with customers and handle their queries."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: Design a solution to transcribe a customer support call recording in multiple languages."}
{"text_id": 161, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 161, "text": "query: I want to estimate the distance from my camera to each object in a given image."}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: Our marketing department needs an AI-generated image for their upcoming project. The image should feature a serene landscape with a lake, mountains in the background, and birds in the sky."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: The marketing team wants to transcribe the speech from our latest TV advertisement so it can be translated for international audiences."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Need to build a model that predicts the carbon emissions from the given data."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: Let's find out how many people can live in the International Space Station at once. Get the information."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: We are building a customer-support chatbot that can answer questions and engage customers in conversation."}
{"text_id": 303, "text": "document: Unconditional Image Generation model for generating Minecraft skins using diffusion-based methods."}
{"text_id": 303, "text": "query: Develop a tool for generating unique and visually appealing Minecraft skins without any given prompt or condition."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: We are working on a sports video analysis project. We need to classify the actions taking place in the video."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: I want to create an app for tourstists. They will upload an image and the app recognizes the highlights of the city."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: Create an audiobook for me by turning the following paragraph into an audio file."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: Our client is developing an application to help users complete their sentences. I need a model that can suggest a word to fill in the blanks in a given text."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Write a text summarization function for a news application aimed at the Russian-speaking audience."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: We are working on a project to analyze and classify the content of videos from various sports events."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: I have a home soundbar at 16 kHz, and I want to remove background noise so I can clearly hear the person speaking."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: We are a company trying to analyze phone calls for better customer service. We need to automatically detect and identify the different speakers in customer support phone calls."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: The company is filtering social media comments for the brand image, and we need to identify NSFW comments to take them down."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: Find a way to detect potential violent situations in video content using the information above."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: Our company needs to quickly process document scans to answer client questions. Help me create an AI assistant that understands documents in a multimodal way and can answer questions from images containing text and visual layout information."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: Our client needs help developing an AI app to beautify beach photos. Write me a code to analyze beach pictures and identify unique objects within the frame."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: Our company operates in China, and we want a way to summarize long articles about our products in Chinese before sharing them with our clients. We heard that Randeng-Pegasus-238M-Summary-Chinese is a good summarizer."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: We are a team of urban planners. We need to segment images for better understanding of how objects are allocated in urban areas."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: Create an image classifier capable of identifying images in Chinese language zero-shot image classification."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: Our company is trying to build a drone. We need to create a function to estimate distances using photos taken from the drone\u2019s cameras."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: Can I transcribe a podcast to distribute the content as an e-book?"}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: Our team is working on a project that needs to generate a realistic image of a blue paradise bird in the jungle using the ControlNet model."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: I want to predict emotions from an audio file using the \"Rajaram1996/Hubert_emotion\" model."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: I need a system that can identify whether a given image contains a cat, a dog, or a bird."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Design an aerial autonomous vehicle that scans an area, identifies, and segments buildings from satellite images."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: We are an educational institute that needs to create an assistant tool that can answer questions based on images found in textbooks. Implement this tool using the available API."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive (CS:GO) players in a given image URL and visualize the result."}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: Our company wants to develop a clothing catalog that captures the trends popular in various age groups. The idea is to extract the different types of clothes people are wearing in photographs."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: Implement a chatbot to answer customers' questions in the customer service section of an eCommerce store."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: I have a dataset as a table containing details about the artists and their paintings. I need to know which of the paintings has the highest price."}
{"text_id": 797, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 797, "text": "query: I have two people speaking in a recording, and I need to separate their voices into individual audio tracks."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: The environment agency needs a system to predict CO2 emissions, and they want to use the trained model we provided."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: Can you generate a story about an adventurous cat and a rat going on a quest to save their town from a flood?"}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: We are creating an AI assistant in Chinese language that helps the user navigate in the city which needs to communicate via text-to-speech."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: You have a scanned document which contains information about a car. Extract the make, model, year, and price of the car."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: At our hotel, we are creating an English-language information video for our guests. We need a pleasant voice-over."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: Nowadays, people spend much time on learning a language. We want to provide an efficient way of learning a new language by summarizing texts in the target language."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: My Chinese teacher gave me a paragraph to read, I don't understand a part of it. Could you help me get the answer to my question related to the paragraph?"}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: Design a news cover image of a food festival that is going to be held next week."}
{"text_id": 508, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is used for zero-shot text classification tasks."}
{"text_id": 508, "text": "query: I'm running a blog with different categories like technology, business, science, and health. I would like to create an automatic classification system to categorize new articles into these categories."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: I have some content for a blog article and need it to be paraphrased. Create a new content in such a way that it retains its original meaning but is not a direct copy."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: Ron is holding a zoom talanoa involving 3 people. He needs to split the conversation so everybody's script can be assessed independently."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: I'm planning to build an AI story generator for my blog. Can you recommend a solution for generating a short story from a sentence?"}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: We were approached by a civil engineering company. They asked for our help in designing their solar-energy housing models. Tell me which method you use and how you would do it?"}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: Identify if a given statement contradicts a recommendation on a book review site."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: We are building a software that classifies whether the given image is a cat or a dog."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: The users are encountering difficulties in understanding the main ideas in an article about a chemical reaction. Generate questions to help grasping the key points."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: The company is developing a social media app where users can interact. We need a way to find similarly themed posts that users might be interested in."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: I have lots of videos that I need to organize. I want to build an AI to sort the videos into categories like sports, cooking, and education."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: Write a legal sentence that completes a partially given sentence with a missing word."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: A travel agency is looking for attractive images to be featured on their promotional material. Please generate an image of a scenic church."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Our client wants to create a summary for an article about a new tech product. We need to summarize the article for them."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: Develop a machine learning model for a company that needs to determine whether an employee's income is above or below $50k a year."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: We have a self-driving car, and we want to estimate the depth of objects in the scene captured by the car's camera."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: Help someone improve the grammar in their message using Happy Transformer."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: We need to know if a query has a question associated or it is just a regular sentence."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I need a way to answer questions from a given context as I am constructing robots that provide useful information to the user."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: Propose a solution to convert a news article into an audio file for a visually impaired person."}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: Your customer has an audio file with a lot of noise in it. They want you to enhance the audio by reducing the background noise."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: We need to process invoices and get features from an example invoice document."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: Generate high-quality images using the Denoising Diffusion Probabilistic Model (DDPM) trained on an unconditional CIFAR10 dataset."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: We are a sports broadcasting company; we need to analyze and classify sports events in our videos."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: I just started my journey in the healthy food recipe Instagram world, I need some help to classify my recipe ingredients in my caption."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: I want to create an HD wallpaper of a seaside beach landscape guided by the description \"sunset at a calm beach with white sand and blue waters\"."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: We are a video analytics firm, and we would like to classify a video we have on file to better understand its content."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: We are building a touchless system for hand gesture detection in a warehouse. Please provide me with a suggestion for a video-based gesture detection model."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: I am an artist and would like a DNN to tell me the best material for the artwork I am creating. What material should I use?"}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: As part of our dating app matching algorithm, find out if two user descriptions are similar enough to recommend as potential partners."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I need a function to interact with a chat bot that can answer my question \"what's the population of France?\" but the context should contain the word french and might not contain the information I am looking for."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: Your Catalan friend wrote a text about her last trip, and you want to read it in Spanish. Translate the text."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: Our company offers custom video greeting cards. We would like to create a video based on the given text \"A joyful dancing penguin with a birthday cake.\""}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Develop a creative application that does not require and input data, like writing stories but with images."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: I'm collaborating with a film production company. We set a meeting with them and we needed to talk about a new movie project with a fictional story. Give me ideas for the plot."}
{"text_id": 585, "text": "document: ShuanBot is a conversational chatbot model based on the GPT-2 architecture. It can be used for generating human-like responses in a chat context."}
{"text_id": 585, "text": "query: Our company's website needs a chatbot that answers visitors' questions. The responses should be coherent and informative."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: Extract some features from a Korean text in order to use them for decision making."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: I am having trouble handling customer support emails in German. I need help in identifying the topic of the email, whether it's related to computers, phones, tablets, urgent, or not urgent."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: A Language learning platform has a transcript creation feature that transcribes spoken language to text. Implement a transcriber for the platform."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: A friend of mine and I want to build an internal tool for sentiment analysis using the imdb dataset."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: The local department of transportation needs to detect potholes in images from road inspection drones."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: Your company needs an easy way to extract information from documents. Provide a solution using the LayoutLM architecture."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: Our company is working on a customer support ticket classification system, and we need to identify which tickets are similar."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: Our client is looking to classify images of animals but does not have any labeled data for training. We want the model to be able to classify these images without requiring labeled data."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: I want to segment images into different classes like humans, animals, and objects to design visual reports."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: Create a program that can tell if a picture of an animal is a cat or not."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: A geologist is working on a project and needs a model to help them identify different geological features in satellite images. Find an appropriate model."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: I want to teach an English-speaking toy to understand when someone is speaking in a Romance language to be able to properly respond."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: We are developing a space-themed children's book. Please deliver the illustrations for \"an astronaut riding a horse on Mars.\""}
{"text_id": 549, "text": "document: philschmid/bart-large-cnn-samsum is a BART-based model trained for text summarization on the SAMSum dataset. It can be used to generate abstractive summaries of conversations."}
{"text_id": 549, "text": "query: We are building a chatbot to help new users understand our services. Summarize a conversation without text being cut off."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: We are building question-and-answer system to provide the summary of news articles as answer."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: As a scientific research company, we are currently researching new chemical compounds. We need to classify molecules of the newly discovered compounds to determine their properties."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: I need to create a movie pitch with a mix of comedy, adventure, and romance themes. Let's use AI for that."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: We want to have a picture of a red flower in a meadow."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: I want to create a video based on a description of an artwork in a museum."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: We need to analyze the depth of an image shared by the user on our application to analyze indoor spaces."}
{"text_id": 192, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k with augmentations and regularization."}
{"text_id": 192, "text": "query: We are a company that recently built an e-commerce platform. We want to use image recognition technology to classify the items on the platform."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: A student has a reading comprehension test about the importance of model conversion. Generate an answer to the question \"Why is model conversion important?\" from the given context."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: The city is constructing new buildings and, as a result, wants to analyze aerial images to identify buildings, roads, and green spaces."}
{"text_id": 267, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 267, "text": "query: A kids' channel is creating images for its book series, they require an image based on \"a group of colorful animals playing together.\""}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: I want my smart camera system to detect planes in the images it captures."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: Our firm is interested in building a robot that could navigate the Gym Hopper environment with an expert level of performance. Therefore, we need to find a suitable pre-trained model."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: I am a professional landscaper who wants to create an app that uses computer vision to classify plant images for identification purposes. Help me with this task."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: A student is looking for the answer of \"Why is model conversion important?\" from the text provided."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: I am having trouble with my printed circuit board and I would like to find the defects that might exist. Identify and segment the defects on the PCB image using AI."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: A travel website wants a chatbot that can answer questions about countries, like capitals, famous sites, and cultural events."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: I am an architect, I want to quickly sketch an idea for the next waterfall-lawn design with an analog style."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: My company needs to predict CO2 emissions from a dataset containing information about car specifications."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: We are a real estate company and we need depth information of the houses that we are going to sell."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: Our company is building a new gaming environment with reinforcement learning techniques. We need a model that learns to play games in an Hopper environment."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: I am an environmental manager, I need to predict the similarity between parcel codes based on their carbon emissions."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Create an OCR engine which detects the total amount from an invoice image."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: Create a code to summarize long texts about scientific topics."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: We are processing a text from a history book and need to extract named entities in it."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: We need to create a program that can help us find laptops and cups from images."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: Help me create a resume screening tool, which can extract the name, organization, and location from the given text."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: A new meme format called \"anime art\" has started. The company needs to classify whether the memes are made by AIs or humans."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: For my language school, I need to build a chatbot that can take in a Japanese sentence and suggest the words to fill the blanks."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: Analytics department needs to get the answer to their question, \"What is the total revenue?\" using the table provided."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: We have an image and a question related to the image. Find the answer to the question."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: We want to analyze company data and find the most similar text strings based on meaning."}
{"text_id": 576, "text": "document: Randeng-Pegasus-238M-Summary-Chinese is a Chinese text summarization model based on Pegasus. It is fine-tuned on 7 Chinese text summarization datasets including education, new2016zh, nlpcc, shence, sohu, thucnews, and weibo. The model can be used to generate summaries for Chinese text inputs."}
{"text_id": 576, "text": "query: The marketing firm is working on publishing Chinese news articles on their website. They need a brief summary of each article for readers."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: We want to build a smart text editor, and the model will suggest the appropriate word when there is a masked word to solve."}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: As a social media platform, we want to identify and flag toxic comments to maintain a healthy online environment."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: Our political news chatbot needs to identify which text messages from users are asking questions, and which are just statements."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: Describe a method to create a new image from the provided lineart image with visual characteristics of a specified artist using the ControlNet model."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: Develop a system that can extract answer from documents in image format by answering a specific question."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: As a researcher, I need to analyze a biomedical paper to extract bio-medical entities from it."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: Develop a model for a wildlife conservation organization to generate synthetic images of butterflies for educational purposes."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: My company is launching a news application, where we will be summarizing articles. I would like to automatically summarize articles for the application."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: The customer has a dataset of headlines for different news articles. We would like to identify which headlines are related."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: The customer service team needs to monitor and record the amount of talking in incoming calls for a study. Please provide a method to breakdown the inputs by voice activity detection."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: We want a system to complete sentences for our upcoming narrative game in the fantasy genre."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: One child user asked me to provide a tool to help him practice Russian, so I want to get a speech recognition model."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: I would like to build a product based on a model that can classify spoken digits from 0-9 utilizing the audio input from the user."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: I need to find if my two input sentences are related in meaning or not."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: Can you generate a high-quality computer game background image of a bedroom for our game?"}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: Our client has an AI-driven game that needs a trained reinforcement learning agent to control a cart-pole system."}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: I want to generate a short creative story about living on a distant planet."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: Help us create an object detection pipeline for our surveillance system to identify potential security threats."}
{"text_id": 220, "text": "document: A YOLOv8 model for detecting forklifts and persons in images."}
{"text_id": 220, "text": "query: A logistics warehouse supervisor needs a method to identify the presence of forklifts in images they take during daily operations."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: Our company is receiving customer feedback in various languages. We want to sort these feedbacks into categories like 'customer service', 'product quality', 'delivery', and 'user experience'."}
{"text_id": 193, "text": "document: Swin Transformer model trained on ImageNet-1k at resolution 224x224. It was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches (shown in gray) in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window (shown in red). It can thus serve as a general-purpose backbone for both image classification and dense recognition tasks."}
{"text_id": 193, "text": "query: Develop a tool to organize a collection of images into folders named after the objects depicted therein."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We are an NGO working on preserving nature. We need to classify images of nature from our collection whether they are related to mountains, oceans, forests, or deserts. "}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I usually receive bills from my business partners that are scanned pdf files. I want to create a program in Python to extract information from the scanned images."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: We are building a solution for a company to categorize news articles based on their content. We need to classify news articles."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: We have a storytelling platform, and we want to create illustrations for our stories based on the text."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: Can you find instructions for the creation of human pose images under diffused diffusion, which works with hugging face model?"}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: We need a Finnish-to-English translation of a document in text format."}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: As an author, you want to rewrite paragraphs in your book without losing the original meaning."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: Our VR company is working on creating a space-themed game. We need to generate images of the universe as backgrounds for different scenes."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: Provide information on how to use the API to answer questions based on data stored in a table format, like finding the highest sales figure in a given year or the average temperature over the past month. The table should contain column names and rows of data."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: We are a street maintenance crew and need to analyze the street images to segment sidewalks, trees, and vehicles."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: I have a text written in English and I would like to translate it to French. How can I achieve this using transformers and T5-Base?"}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: I have a french language movie production that we want to generate a title for. I am going to provide a prompt which contains a masked token, generate the title for me."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: Our data analytics team is predicting global carbon emissions, please provide us the tabular Python code to use the pretrained model and get predictions."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: In our computer vision application for drone navigation, we want to segment the images captured by the drone."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: \"The defendant is found not ___ and is released immediately.\""}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: Our company is starting a project in France, and we need to translate our English documents to French for our local partners."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: Create an application that automatically generates cute butterfly images."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: We prepare a medical report management system for clinics. The data is available on images and I want to extract the texts from the images."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: I want to create a voice memo summarizing the meeting we had last week."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: Our team is designing a video game and we need a model that can generate some concept images based on a description of the scenery and objects."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: \"a cozy cabin in the woods.\""}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: Translate the given German text to Spanish without knowing any specific language names."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: ###Instruction:You work on a project as a developer where you're building a chatbot to handle basic customer enquiries. The chatbot should be responsive and be able to engage users in real-time interactions."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: You are an expert in writing a code that reads an image and converts into text. Create a sample code that will describe the specific image."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: I am a graphic designer. I would like a tool to determine if an image I am working on is a cat, dog, or fish."}
{"text_id": 374, "text": "document: StreetCLIP is a robust foundation model for open-domain image geolocalization and other geographic and climate-related tasks. Trained on an original dataset of 1.1 million street-level urban and rural geo-tagged images, it achieves state-of-the-art performance on multiple open-domain image geolocalization benchmarks in zero-shot, outperforming supervised models trained on millions of images."}
{"text_id": 374, "text": "query: The tourism company needs a tool to automatically recognize the location of tourist photos from a list of possibilities."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: Create a tool to classify short meeting videos as 'productive', 'unproductive', or 'neutral'."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: Your friend wants you to help them generate images of cute butterflies for their art project."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: Our company works with a Brazilian supplier. Some emails are in Portuguese, and we need them to be translated to English for a better understanding."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: \"The best way to advertise a product is by [MASK].\""}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: We are building an application that helps users complete sentences in Chinese. The user writes a sentence, and the application fills in the missing words."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: We are building an AI-powered storytelling product for kids. Help us generate a kid-friendly story given the prompt \"Once upon a time in a magical forest\"."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: Imagine a scenario where we want to classify an image without training it on any dataset and just want to make an inference. What approach should we follow?"}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: Help me find the information from a table related to years when different countries hosted Olympic Games."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: A language school wants to launch a translation game between English, French, and German. Help them create a function that utilizes a language model for the translation."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: As a movie production company, we want to categorize movies to review and understand the competition. Help us classify these films using an AI model."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: We are working on an e-commerce website project which needs to identify products by analyzing their images."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: We have an FAQs section on our company's website, and we want a model to find the most relevant FAQ for a given user query."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: We are developing a music discovery app that identifies its genre by analyzing its audio spectrogram. Integrate a feature extraction method to obtain spectrograms from audio files."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: technology, sports, and politics."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: An educational company wants to create a short story for kids about a lion and a mouse. Help them come up with the start of an engaging story."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: As a car dealership, we want to identify the make and model of the cars in our inventory from photographs."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: We are developing a chat app and we need to find the language of the user who is sending a message."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: I am part of a startup aiming to reduce carbon emissions. We are building an application that predicts carbon emissions based on user data."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: A publisher just sent us two paragraphs. We need to check if they are semantically similar or if they are simply paraphrasing the same idea."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: The marketing team is working on an advertising campaign project, and they need to enhance the low-resolution images they have collected."}
{"text_id": 224, "text": "document: A YOLOv8 model for blood cell detection, including Platelets, RBC, and WBC. Trained on the blood-cell-object-detection dataset."}
{"text_id": 224, "text": "query: I am a medical professional and want to make sure that I can identify blood cells accurately and quickly from images. Please help me build a script for this."}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: The user needs to translate text from English to French for a business meeting."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: I am a Swiss student, I want to know the topic of an article in French to make a compilation for my studies."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: We need to recognize Valorant game objects within a game screenshot to analyze player strategies."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: We have a gym and we want to detect the type of workout that a person is doing from a video."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: In order to recommend books to users, we want to identify books with similar themes or topics. Analyze book descriptions to find similarity."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: Develop an AI to control a game character and optimize its performance with reinforcement learning."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: I want to develop an AI art gallery website that generates unique images of people's faces."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: We are in the Titanic. We would like to design a recommender system to predict whether a passenger would survive or not during the voyage based on their age and gender."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Implement a text-based virtual assistant to identify Portuguese speech from audio recordings."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: We're a French company which wants to have a matching system to match French words and English words."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: There is a lot of Dutch spoken content on our website. We need to obtain transcriptions to get insights to improve user experience."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: Our company is working on a project that requires generating illustrations for a children's book. Can you provide an image of a dragon reading a book at night under a tree?"}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: To help the computer vision module to design a better drone, it is required to design a lightweight image super-resolution algorithm and integrate it on the computer."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: We are an international business company, and one of our Spanish customers shares their document in Spanish. Translate it into English."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: \"\u041e\u043d\u0438 \u043f\u0440\u043e\u0432\u0435\u043b\u0438 \u0431\u043e\u043b\u044c\u0448\u0443\u044e \u043a\u0430\u043c\u043f\u0430\u043d\u0438\u044e \u0440\u0435\u043a\u043b\u0430\u043c\u044b \u0432 \u0438\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0435 \u0441 \u0444\u043e\u043a\u0443\u0441\u043e\u043c \u043d\u0430 \u043c\u043e\u043b\u043e\u0434\u0443\u044e \u0430\u0443\u0434\u0438\u0442\u043e\u0440\u0438\u044e. \u041f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u043e \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0430\u043a\u0446\u0438\u0439, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u0438\u0432\u043b\u0435\u0447\u044c \u0430\u0443\u0434\u0438\u0442\u043e\u0440\u0438\u044e \u0438 \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u0442\u044c \u0438\u0445 \u043f\u0440\u043e\u0434\u0443\u043a\u0446\u0438\u0435\u0439. \u041a\u043e\u043d\u0442\u0435\u043d\u0442 \u0440\u0430\u0437\u043c\u0435\u0449\u0430\u043b\u0441\u044f \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0441\u0435\u0442\u044f\u0445, \u043e\u0441\u043d\u043e\u0432\u043d\u0443\u044e \u043a\u043e\u043d\u0446\u0435\u043d\u0442\u0440\u0430\u0446\u0438\u044e \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u043b\u0438 \u0432\u0438\u0434\u0435\u043e\u0440\u043e\u043b\u0438\u043a\u0438 \u0438 \u0441\u0442\u0430\u0442\u044c\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u043b\u0438 \u043c\u043d\u043e\u0433\u0438\u0445 \u0437\u0440\u0438\u0442\u0435\u043b\u0435\u0439.\""}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: In our business, we need to categorize customer feedback into specific topics such as product quality, customer service, and website design."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: As a game developer, I require a high resolution concept art for a unique dragon character in a fantasy world."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We are an AI company planning to build a product that can transcribe handwritten texts. Help us get TrOCR large handwritten model ready to use."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: I want to generate anime-style images based on a few user-given prompts."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: We have a home automation system and need a voice command recognition system to control lights, fan, and music through speech. Provide the code for it."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: We are an e-commerce platform, and we need a solution to answer customer queries about the contents of product images."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: You work as a data scientist and need to analyze customer reviews. Extract features from the review text for analysis."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: As an eye specialist, we need to develop a classfier which can tell about the severity of diabetic retinopathy (none, mild, moderate, severe, proliferative)."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: We are developing a new children's book and want a whimsical illustration of a kitten playing with a ball of yarn."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: We need to transcribe speeches given in Japanese language and store it as text file for furthur analysis. Code needed please!"}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: I want to use this classifier to analyze plant data and classify plants based on their features contained in a CSV file. What should I do? Please provide code."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: We have a historical book club. We need to identify the names of historical figures mentioned in a given text."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: We received data on a few houses and their features in a CSV file. Let's predict their prices using the trained model."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: I need to create an application to track voice activity during video conference calls to record only when someone is talking."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: The company wants to translate the latest newsletter from English to Portuguese before sending it to the subscribers in Brazil."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: As a movie review website, the team is working on classifying movie reviews into positive or negative categories automatically."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: A dance school has requested us to estimate the human body poses of the dancers in their performance images."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: A user uploads a voice memo in Marathi and wants to have the content transcribed automatically in text. What can we do for them?"}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: \"It was a beautiful day, so we decided to go to the\""}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: We want to extract useful information from a paragraph for a news application; sort out the keywords."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: I have recorded an audio in Esperanto, can you transform it into text for me?"}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: Design a conversational AI to chat with a customer in the Russian language, and help them in finding a restaurant."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: We would like to utilize an image generation tool to produce an eye-catching album cover."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: We run a professional association that organizes conferences. We need to easily find information from the conference program booklet regarding the keynote speaker list."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: As a photo tagger, we need to assign tags to a given image."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: Measure the depth of the objects in an image using a depth estimation model."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: I want to create an app which detects the license plates of any parked vehicle in my city."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: My friend has visual impairment, so I want to create a German-speaking TTS for him, so he can listen to his emails or articles."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: We are using drones to monitor traffic. We need to identify the cars and other objects in real-time images provided by the drone."}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: As a company providing public announcements, we are required to convert German text into voice for broadcasting in Germany."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: My team is working on a project and needs to understand if two given sentences are similar or not."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: Develop a high-quality dialog for a conversational AI built for a video game based on a given character persona."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: The client needs to identify the contents of an image with just a few categories without training a new model."}
{"text_id": 787, "text": "document: Speech-to-speech translation model with two-pass decoder (UnitY) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 787, "text": "query: Translate a recorded TED talk from English to Hokkien using a speech-to-speech translation model and return the translated audio."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: Design a system that can differentiate between different spoken commands."}
{"text_id": 342, "text": "document: VideoMAE Base model fine tuned on UCF101 for Video Action Recognition"}
{"text_id": 342, "text": "query: The company is building a surveillance system and wants to automatically detect and recognize specific actions like walking, running, or fighting in video. Write python code to achieve it."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: Come up with an approach to find the relation between consecutive description of image depictions."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: Our company is designing sneakers for an online store. We need to generate new shoe designs."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: I have a list of news articles and I need a solution to measure the similarity between each article to a certain reference article. Can you suggest a method?"}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: Hi, we are building a product for international travelers. We need automatic language translation that supports multiple languages."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: Someone left a blank space in a sentence written in Japanese. Please fill it in by discovering the most suitable word."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: In the context of construction site safety, we want to make sure all workers are wearing hard hats."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: We want to create an audiobook for a Korean novel. What code will we write to convert the given Korean text to speech?"}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: I have a picture and a question related to it. Now, I want to leverage an AI solution that can use both the pictorial and textual information to answer my question."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: Our customer is an online news website, and we need to provide summaries for their Russian articles."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: We need a model that will help our customers to extract relevant information from their invoices by asking questions."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: I have a list of answers that I need to append an answer statement into the question. The matching context to give the model is included in the programming."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: I have some ideas to share for a secret room in a game. Write a convincing story to keep people intrigued."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: We want to create a conversational companion for an online video game. The companion should have a humorous and intelligent personality."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: Predict which mobile plan users are most likely to choose based on their user behavior."}
{"text_id": 250, "text": "document: Mask2Former model trained on COCO instance segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. You can use this particular checkpoint for instance segmentation."}
{"text_id": 250, "text": "query: I am a designer who needs to analyze an image to separate different objects in it. I want to get a mask for each object in the image."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: You are a student working on a research project, and you need to find relevant information related to a specific topic. Rank the passages provided based on their relevance to your research question."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: My company often needs to send emails written in Japanese. Please make a suggestion for an email opening line."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: We are a group of scientists that have built a dataset about carbon dioxide emissions for different projects worldwide. We want to classify these projects into different emission levels."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: As a Chinese language teacher, I need a tool that can guess missing words in a sentence, so I can create a quiz for my students."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: A client needs an artificial intelligence agent to play the Breakout game from the Atari environment. They want the agent to be as good as possible."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: \"Welcome to our voice assistant.\""}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: Analyze a recorded conversation for detecting the presence of voices and overlapping speech."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: \"The stock prices of XYZ company soared after a successful product launch, leading to increased investor confidence.\""}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: Help me translate audio from Hokkien to English and also synthesize the translated audio."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: I want to predict the probability of survival for passengers, given a dataset containing information about their age, gender, and passenger class."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: Create a project that extracts features from given Python code for any Machine Learning-based software analytics problem."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: I am a fashion designer who needs a tool to generate new clothing designs based on the description provided. Create a system that can generate images of clothing designs and download them as image files."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: We want to design a movie review platform that automatically classifies movie reviews as positive or negative based on their content."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: A therapist's client is reporting feelings of anxiety. The therapist would like to analyze the client's emotions during a session using a model trained on speech to better understand and help them."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: A podcast production company needs to remove background noise from their recordings before publishing."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: The marketing team needs a summarization model for blog posts. Please create an API call to make it possible."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We are building an application to read documents and answer questions from that. An example question could be, \"What is the total amount in the document?\"."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: \"I initially liked the movie, but after some thought, I found it disappointing.\""}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Design a banner for our new store launch event. The banner should have a picture of a grand opening with balloons, confetti, and a red ribbon."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Detect and segment buildings in satellite images to assist city planning department."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: We are working on a platform to automatically categorize sports videos to be shared with users according to their preferences."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: One of our directors needs the summaries for a series of company updates written in Spanish. Summarize a given text in Spanish."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: We are developing a text-based programming language tutoring system, and we need to find the most similar code snippets to a given code snippet based on their features."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: As a virtual personal assistant, I should automatically reply to messages in the given context."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: I am building a Chinese language learning application. It would be great to fill in the blanks for the missing words in the sentences."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: Create an audiobook version of a new novel and include realistic character voices."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: I want to create a text to speech system for my website that reads articles out loud. Help me understand how to set it up."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Our company works with law enforcement agencies, and we need a system to predict the likelihood of recidivism based on the COMPAS dataset."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: There is an audio recording from one of our customers during a conference call. We need to transcribe that audio to a text document."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: Communicated across several cultures, I often come up with sentences that do not make sense. I would like my app to verify whether my sentence makes sense, and if not, provide an alternative."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: I am a teacher and I have a table of marks of my students. I want my personal assistant to answer questions about the table."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: Design an interface to help users extract information from documents by asking questions related to the content of the document."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: I need to determine if there is speech in an audio sample and estimate some acoustics properties of the environment where the recording took place."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: We are launching a new security system and we want to ensure that the person speaking is correctly identified by the system."}
{"text_id": 646, "text": "document: FLAN-T5 small is a fine-tuned version of T5 language model on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. The model is designed for research on language models, including zero-shot and few-shot NLP tasks, reasoning, question answering, fairness, and safety research. It has not been tested in real-world applications and should not be used directly in any application without prior assessment of safety and fairness concerns specific to the application."}
{"text_id": 646, "text": "query: \"Experience the ultimate comfort with our premium-quality shoes.\""}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: Develop a system to count how many cats and dogs are in the image."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: I want to make an image processing system that can predict the image type at the time of image upload for an ecommerce website."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: We are an animation company, and we want to create a lineart character based on a text prompt."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: We need to develop a new story for children using a language generator."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: We are a social media monitoring company. We need to analyze the sentiment of our users' comments."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: We are building a music recommendation app. We need to extract features from songs to group them based on their similarity."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: We are working on developing a multilingual voice assistant. We require to transcribe speech into text in multiple languages."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: We are building an automated video conferencing system. Now we need to detect when participants are speaking."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: Develop a model that can detect and label objects in a video sequence. The objects should be bounding boxes and automatically created object labels."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: I have a long document about world history to review. My teacher asked us to find out who started the first world war. Can you find this for me?"}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: Write an imaginative story introduction with a twist, and use no more than 40 words."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: The product management team at a fashion company wants to quickly and accurately classify fashion product images for the website."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: A person wants quick but meaningful responses to their questions in everyday conversation."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: I found this image of an animal and I can't tell if it's a cat, dog, or a fox. Can you help me identify it?"}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: My son is creating a wildlife podcast. Can you please help him convert the written script into a spoken audio? Provide him with a short code to do that."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: A wildlife scientist needs help to identify an image taken in a remote location. They want to segment different objects, including animals and plants, in the image."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: We are working on a project related to global customs. We need to calculate the similarity in meaning between two sentences in different languages."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: I want to learn a good soccer strategy by training a reinforcement learning agent to play SoccerTwos in Unity."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: I am a doctor doing research on medical terms. I need to extract features from medical text for further analysis."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: We want to categorize a news headline based on its domain such as health, politics, entertainment, sports, or technology."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: I need a way to measure the semantic similarity between different news articles. How can I do it?"}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: We are a development team who needs to generate an explanation for a specific python function."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: Our project requires an AI that can extract information from tables and answer questions based on them."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: I am an HR manager, I need help understanding a particular section of a contract. Can you please answer my question about the contract?"}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: We are a robotics company. We want a model to estimate the depth of room images to get 3D dimensions."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: I'm exploring ways to predict carbon emission based on features in our tabular data. Write a script that loads a trained model to predict those values."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: I want to build a speech-to-text algorithm for the Indonesian language."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: The management requires a sales report based on the quarterly sales table. Find out the top-selling product and the corresponding sales for the 3rd quarter."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: A french newspaper is looking for a way to detect the main theme of an article."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: A book cover represents its content very well. We are building tech to generate a book cover from its title and a brief description."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: I need a solution that will understand the context of a given text and help me answer questions based on the context."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: A computer science teacher is giving a lecture online and would like to integrate an AI-based text-to-speech system into the lecture."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: Provide a report about the number of people, organizations, and locations mentioned in a news article."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: A mobile app for plant farmers needs to identify whether a plant leaf is healthy or diseased. Determine a solution to classify the images of plant leaves."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: Develop an application that can recognize in real time the type of exercise people are doing at the gym and automatically logging their activity."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: Our newsroom has many articles available. We need a way to find the most similar articles to a given one."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: Create a software that can transcribe a Chinese conversation from a file"}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: We need to design a Vietnamese speech recognition system for interviews in our organization."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Can you generate an image of a green car based on its description?"}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: Let's create a high-quality image of a model for our advertising campaign."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: Our client needs a tool for processing satellite images of rivers and roads and generating a segmented map to understand the geography of a given area."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: We want to test the capabilities of trained reinforcement learning agents. Specifically, we want to see how well an agent performs while playing Breakout with no frame skipping."}
{"text_id": 872, "text": "document: This model is trained to perform single column regression on carbon emissions data using the AutoTrain framework. It predicts CO2 emissions in grams given the input data."}
{"text_id": 872, "text": "query: Please predict the carbon emissions of a vehicle given its features."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: Please create a way of extracting named entities from unstructured data to help keep track of important details in meeting minutes."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: I am a school principal. We are building a solution to send a summary of long texts to help parents stay updated about school activities."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: I have a photo of a landscape taken during winter. I want to change the landscape style to make it look like it was taken during summer."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: We are looking for a way to create unique visual content for our online education platform using text-to-image generation."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: Our German language department is processing long articles. They need a tool to summarise it."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: Our firm designs merchandise for pet lovers. We need to create a new design of a cat wearing a crown."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: Create a soccer playing AI agent for a video game built on the Unity game engine."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: Our customer is looking for an efficient way to categorize images they took on their trip to a wildlife sanctuary. Help them classify the images."}
{"text_id": 795, "text": "document: A speech-to-speech translation model for converting between languages without using text as an intermediate representation. This model is designed for the task of audio-to-audio translation."}
{"text_id": 795, "text": "query: In a scenario where we want to automatically translate spoken German language content to English language audio, prepare a sample on how we can achieve this."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: A social media app wants to classify images shared by users into categories like landscape, portrait, and animals. We need to help them classify these images."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: Create marketing posters for a dance class that requires human pose estimation images based on a given description, like \"Ballerina performing a grand jete.\""}
{"text_id": 234, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 640x640. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 234, "text": "query: I am a farmer who wants to analyze my field's images to detect and segment different areas and objects for better yield analysis."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: Imagine we are building an application that automatically categorizes sport activities from camera footage. Classify the activity present in a video clip."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: We are building a smart speaker that reads the text out loud. Implement an artificial voice generator using the latest TTS models."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: programming, design, or writing. Analyze their statement for potential insights."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: I am developing an online tool for cutting long audio files into shorter clips based on speaker switches, silent pauses or overlapping speech segments. Can you guide me on how I can achieve this?"}
{"text_id": 626, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. The models are trained to match the performance and sizes of the GPT-3 class of models. The primary goal is to enable reproducible and responsible research at scale and to bring more voices to the table in studying the impact of large language models. OPT-13B is a 13-billion-parameter model trained predominantly with English text, but a small amount of non-English data is still present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective."}
{"text_id": 626, "text": "query: I am a writer trying to use a creative model to come up with a full description of a character based on \"Her name is Ella, and she is a detective.\"."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: Provide a simplified API to extract details from a table based on given questions."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: The task is to automatically predict the age of a person from their uploaded picture."}
{"text_id": 316, "text": "document: TimeSformer is a video classification model pre-trained on Kinetics-400. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 400 possible Kinetics-400 labels."}
{"text_id": 316, "text": "query: A fitness company wants to auto-tag videos of workouts based on the exercise type. Provide a solution for them."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: We need to segment areas in the city to assist with autonomous car navigation."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: We are a gaming company, and we want to implement an AI agent to play our Acrobot-v1 game. Help us to load the existing model from the repo."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: I am doing my homework for which I need  to understand the semantic similarity between sentences. Can I use a model that can help?"}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: I am building a monitoring system for plants; I need to recognize the species of plants from their characteristics."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: \"A cozy living room with a blue sofa, a wooden coffee table, and a large window overlooking a garden.\""}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: Our team wants to filter comments that are not safe for work (NSFW) on our community platform. Help with some code."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: Estimate carbon emissions of a set of facilities based on provided tabular data."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Our virtual assistant team wants to develop a customized customer support chatbot using PersonaGPT."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: We need to isolate the speakers in this audio recording to analyze their speech separately."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: A video game company requires some unique anime-style characters for their new action adventure game. They have provided a description of a character they want."}
{"text_id": 19, "text": "document: Dense Passage Retrieval (DPR) is a set of tools and models for state-of-the-art open-domain Q&A research. dpr-question_encoder-single-nq-base is the question encoder trained using the Natural Questions (NQ) dataset (Lee et al., 2019; Kwiatkowski et al., 2019)."}
{"text_id": 19, "text": "query: My startup's goal is to build a conversational AI capable of answering popular science questions. I need a suitable model to classify the most influential scientists of all time."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: An Indonesian company wants to repurpose a BERT model to assess their social media marketing efforts to make it in their language."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: As a manager, I need to analyze important insights automatically fetched from my clients' reports when asked a question."}
{"text_id": 392, "text": "document: This model is a fine-tuned version of the DistilBERT model to classify toxic comments."}
{"text_id": 392, "text": "query: We are trying to develop a policy in our online community and we want to automatically remove toxic comments."}
{"text_id": 375, "text": "document: Chinese-CLIP-ViT-Large-Patch14 is a large version of the Chinese CLIP model, with ViT-L/14 as the image encoder and RoBERTa-wwm-base as the text encoder. Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It is designed for zero-shot image classification tasks."}
{"text_id": 375, "text": "query: Our company wants to classify images based on their content using a capable model trained on Chinese image-text pairs."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: The company wants to build a smartphone app for a restaurant chain to recommend wine pairings based on the user's food choice. We need a model to classify wine quality."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: We are working on creating a virtual reality game with an in-game depth perception feature."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We are developing an AI language tutor and need to know what language the student is speaking in the recorded audio."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: I am a safety officer, and I need to evaluate the safety measures taken by workers on a construction site. Help me detect if they are wearing hard hats."}
{"text_id": 462, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 462, "text": "query: Temperature in San Francisco at 12PM yesterday?"}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: Provide a tabular regression model to forecast carbon emissions of a construction project."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: Generate a high-resolution image of a park with birds flying and children playing using the text-to-image and upscaling API."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: I would like to get information about movies, which can be found in the database. Could you help me find the highest grossing movie from the table, please?"}
{"text_id": 871, "text": "document: A model trained using AutoTrain for predicting US housing prices. The model is trained on the jwan2021/autotrain-data-us-housing-prices dataset and is a single column regression model with an ID of 1771761511."}
{"text_id": 871, "text": "query: I'd like to make a prediction with the model on a new set of data containing features about houses and get the estimated prices."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: We are working on customer service for a local business in Mumbai. We need to convert our text responses to voice in Marathi."}
{"text_id": 916, "text": "document: DistilGPT2 is an English-language model pre-trained with the supervision of the 124 million parameter version of GPT-2. With 82 million parameters, it was developed using knowledge distillation and designed to be a faster, lighter version of GPT-2. It can be used for text generation, writing assistance, creative writing, entertainment, and more."}
{"text_id": 916, "text": "query: I want to develop a solution for generating resumes for potential candidates applying for jobs. "}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: Your advertising company is looking for a solution that will help them detect objects in images as part of their marketing campaigns."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: In order to improve health and safety in our warehouse, we want to identify hazardous materials and their colors. We need a tool to analyze our warehouse images and answer specific questions about them."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: We are a company that needs to analyze images of a landscape, recognize different areas and objects, and segment them for further analysis."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: A photographer needs to classify their photos automatically by category."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: I have an audio file containing a group call, and I need to find out the duration of each person's speech."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: My team needs a tool that, given two sentences, can tell if they are semantically similar."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: Our company is analyzing aerial images to understand infrastructure development in different locations. We need an AI to classify images of areas such as residential neighborhoods, playgrounds, stadiums, forests, and airports."}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: A user is searching for specific information in a document. Help them find the answers to their questions."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: We are a global company and I want to identify named entities, like location, organization, and person from a text in different languages."}
{"text_id": 30, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. The Stable-Diffusion-v1-4 checkpoint was fine-tuned on 225k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling. This model is intended for research purposes and can be used for generating artworks, design, educational or creative tools, and research on generative models."}
{"text_id": 30, "text": "query: Our customer in the film industry is working on a science fiction movie, and they need concept art to visualize a spaceship controlled by a cat."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: I am a researcher studying Vietnamese data extraction. I want to extract information from a Vietnamese document to answer questions."}
{"text_id": 560, "text": "document: IT5 Base model fine-tuned on news summarization on the Fanpage and Il Post corpora for Italian Language Understanding and Generation."}
{"text_id": 560, "text": "query: Use the model to help summarize an article from an Italian newspaper to share with colleagues."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: Our team is working on automated quality control in our coffee bean production line. We need a machine learning model to recognize and classify different beans."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: Our product works on matching user-generated content like social media. How can we compare the similarity of the sentences generated by different users?"}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: An educational website for a school wants a tool that finds the most appropriate answer to a student's question based on the study materials provided."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: A streaming service is playing video content for users. We would like to automatically generate and apply tags to videos based on their content."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: Create a voice assistant capable of recognizing emotions from audio samples to make suggestions to the user."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We are a language filtering service. We need to identify the language of an audio clip."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: Create a travel chatbot that answers questions about tourist attractions and their features."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: I want to have a software that can automatically predict whether a particular object is adding too much carbon emission in my city."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: We have a short story written in a park environment, please generate a line with a plausible subject related to the present context."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: The company is manufacturing autonomous vehicles, which requires depth estimation for accurate distance detection in the environment. Generate a depth estimation pipeline for a given image."}
{"text_id": 47, "text": "document: Nitro Diffusion is a fine-tuned Stable Diffusion model trained on three artstyles simultaneously while keeping each style separate from the others. It allows for high control of mixing, weighting, and single style use."}
{"text_id": 47, "text": "query: I am a children's book author, and I need an illustration for the main character, who is a space pirate with a pet dragon."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: I'm part of the recruitment team, I have to translate a job posting from English to German."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: We want to analyze the content of a document and answer queries about it."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: Our department needs a program to predict Iris flower species given sepal and petal lengths and widths."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: Our travel website requires a way of categorizing the uploaded images of reviewed properties into indoor or outdoor scenes."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: As a marketing company, we want to monitor customer feedback from social media. Find their sentiments and emotions about our products."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: We want to build a smartphone app that can transcribe voice recordings to text for user's convenience."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: Help an elementary school student proofread their essay to fix grammatical mistakes."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: The executive wants a summary of a research paper for a shareholders' meeting. Provide a template for generating the summary."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: Our company has started a new project of creating an app for visually impaired users to describe images and answer questions about them."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: We got an AI report from one of our team. It's written in a very complex language. We like to know about the model and how efficient is it."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: Analyze images for a new ad campaign and determine key visual features to improve engagement."}
{"text_id": 140, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-large-uncased on an unknown dataset."}
{"text_id": 140, "text": "query: Assist me in providing details about a specific object that we need to investigate after reading a document about a natural history museum."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: To create a better user experience, we are now working on estimating the distance of objects in front of our robots' cameras. "}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: The company's CEO needs to make a public announcement to the French-speaking employees in their preferred language. We need to generate an audio message from the given text."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: I am in the design team of a university learning management system. I want to auto complete phrases in Japanese for better user experience."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: We are creating an automatic text summarization tool that summarizes articles."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: Classify novels into their genres based on their descriptions. Provide the model with a list of genres to choose from."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: Create a binary classification model that predicts the sentiment of movie reviews, either positive or negative."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: I need help solving simple riddles that require a bit of general knowledge."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: Your friend is working on an emotion recognition program and need to classify the emotion in a given voice clip."}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: A world-wide construction company is looking for an AI solution to extract key data from construction project tables. Can you provide them assistance?"}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: Build a multilingual search engine. I need to extract the features from English and Chinese sentences and compare their similarity."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: I'm working on an article and I want to identify the names of all the organizations mentioned in the text."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: I want a tool to make sure that the content generated for my website is appropriate and professional."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: We are developing a robot to balance a pendulum on its fingertip. We need to learn how to use reinforcement learning to control the pendulum."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: We are a Chinese e-commerce company looking to analyze customer reviews and focus on improving aspects of our products. We need to tokenize the Chinese text from the reviews."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We are a company that processes contracts for clients. Design a solution to find the total amount mentioned in the contract."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: I am a chief-editor of a multi-lingual newspaper. My team needs to keep track of news related to prominent individuals and organizations in 10 main languages. Implement an application that extracts this information."}
{"text_id": 2, "text": "document: An unsupervised sentence embedding model trained using the SimCSE approach with a Roberta base architecture."}
{"text_id": 2, "text": "query: My team needs to write a collaborative essay. I need to find the most relevant sentences among all the individual writings of the members. Can I use a model to get the embeddings of the sentences and then compute their similarity?"}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: We are a start-up developing a smartphone app that can differentiate between photos of dogs and photos of food. Implement the required image classifier."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: I am building a computer vision application for video analysis. I need to classify the action in a video clip, and I want to use a pre-trained model to accomplish this task."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: We are an e-commerce company, we need to classify items for improving search results."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: I want to generate the documentation for my Python code."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: Our company provides technical support. We have a lot of documentation on our products. We want to use AI Models to help us answer the questions quickly by providing sections of the document."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: \"\u6b21\u306e\u96fb\u8eca\u306f\u30015\u5206\u5f8c\u306b\u5230\u7740\u3057\u307e\u3059\" (The next train will arrive in 5 minutes)."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: I want to identify Chinese text labels for a picture of a beach."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: Our client has an image of handwritten text, and we need to extract the text from it."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: A tourist agency asks you to translate their advertisement from French to Spanish."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: We are building an app that informs travelers about the probability of surviving a disaster like the Titanic. Implement the model."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: A tourism company wants to transcribe their Japanese spoken testimonials into text format. Help them with your technology."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: I am developing an app to help people improve their workout form by analyzing their exercise videos. Recommend me a tool to classify videos based on exercise type."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: An investment firm is interested in processing financial news to understand the market sentiment. They need a solution to classify positive and negative sentiments in the text. "}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: As part of the learning French discussion, please create a model to complete sentences in French."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: The city council needs an application to detect the potholes in the streets. Let's help them with some image recognition."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: I have a number of podcast episodes recorded in various languages, I wish to transcribe the audio files into text using an Automatic Speech Recognition system."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: A company wants to match the description to their images to make sure their products are accurate. Help them by building an image classifier."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: Please explain how to run the pretrained soccer agent using Unity ML-Agents Library."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: I want a conversational model to chat with users and answer their questions about movies, TV shows, and world events."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: I need to create images with my favorite anime characters as I mention their description."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: A children's publisher would like a story illustration that features butterflies. Generate an image presenting cute butterflies."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: Analyze the sentiment of a given sentence to help a user understand if it is negative, neutral, or positive."}
{"text_id": 475, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-cased, fine-tuned using (a second step of) knowledge distillation on SQuAD v1.1."}
{"text_id": 475, "text": "query: I would like to extract information from a document. What do I need to do to obtain the answers I need?"}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: Create a chatbot that can understand and respond to user questions."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: People are talking about a video game that lets you generate custom Minecraft skins. Develop a model that showcases this ability."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: We need to be able to answer questions based on textual and visual information. Please pull up the necessary components."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: Create an NLP pipeline that provides the answers to the question, about in the factory which robot is the tallest located near the CNC machine."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: We have a fashion company and we are looking for a tool that can generate unique images of people for our advertisement campaign."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: Develop a feature for an educational app that can read a given story. The story text needs to be converted into an audio file."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: I want to know the companies mentioned in this news article."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: I'm a Swedish author working on a book. Translate my writing to English for an international audience."}
{"text_id": 464, "text": "document: DistilBERT base uncased distilled SQuAD is a fine-tuned version of DistilBERT-base-uncased for the task of question answering. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark."}
{"text_id": 464, "text": "query: Imagine a nanny bot that can help parents to monitor their kid's contexture, and remind them of important events. This bot will take questions about the situations, and will provide useful information."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: Create a program that extracts named entities (locations, organizations, and persons) from a piece of text."}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: Detect the depth of objects in an image for our robot vacuum cleaner application."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: Write a report about the effects of climate change and have it converted into an audio file."}
{"text_id": 23, "text": "document: SciNCL is a pre-trained BERT language model to generate document-level embeddings of research papers. It uses the citation graph neighborhood to generate samples for contrastive learning. Prior to the contrastive training, the model is initialized with weights from scibert-scivocab-uncased. The underlying citation embeddings are trained on the S2ORC citation graph."}
{"text_id": 23, "text": "query: We are a technology company trying to cluster research papers based on their content for better organization in the database."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: We have just finished building the \"Russia to English\" chat translation model for the communication app we are working on. We need to test it with a given Russian text."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: A Korean company wants to create an Excel spreadsheet for product pricing. They want an AI system that can answer questions on the Excel sheet."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: Find a way to group similar articles together using sentence embeddings and clustering algorithms."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: In a research project, we need to classify news articles as positive, negative, or neutral based on their content."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: We are an AI enterprise, and we've designed a chatbot for customer support in the aviation industry. Please help us paraphrase the conversation between a passenger and the chatbot."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: We want to estimate the carbon emissions of various production processes."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: Develop a speech-to-text application for aiding hearing-impaired users."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: Create a paragraph of text that could be used as the introductory paragraph of a newspaper article describing the recent discovery of a new element."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: We want to generate captions for a set of images that will be used in a travel blog. Find a suitable model and generate captions for these images."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: We are trying to build a chatbot for our website. Please guide us on how to respond to user messages."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: Our customer wants a security system that tracks airplane activity. We will need to develop a plane detection system using artificial intelligence."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: We are a manufacturing company, and we need to segment the images from the production line for quality control."}
{"text_id": 400, "text": "document: DistilRoBERTa-base is a transformer model that performs sentiment analysis. I fine-tuned the model on transcripts from the Friends show with the goal of classifying emotions from text data, specifically dialogue from Netflix shows or movies. The model predicts 6 Ekman emotions and a neutral class. These emotions include anger, disgust, fear, joy, neutrality, sadness, and surprise."}
{"text_id": 400, "text": "query: Develop a movie recommendation system which suggests movies based on the emotional content of their dialogues."}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: I have a blurry photo of a vintage car, and I want to try and make the image clearer by upscaling it."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: Sally desires to send regards to her Arabic speaking clients. She asks us to translate 'Hello friends! How are you?' into Arabic for her."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: We want to create a text-to-speech application to convert a Spanish text into a human-like voice."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: Design an application that identifies a person's voice from a given audio file, and then categorize the speaker based on pre-defined categories."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: Write me a Russian to English code to translate a birthday card for my friends birthday."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: A company is setting up a website that will be able to translate text to multiple languages."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: We own a news website and we want to give user suggestions based on what they have searched."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: We are a robotics company working with drones, and we need to estimate the depth of objects within the drone's field of view."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: Create a solution to generate portraits for a virtual art gallery."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: Our security team needs an AI model to detect intruders from the CCTV camera feed."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: Design an automatic speech recognition system for an audio file that helps us transcribe the contents."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: I am working as an auditor and I need to extract the total amount from an invoice using a question-answering model."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: Our team recently integrated cameras into our robots that patrol the company parking lot. We want the robots to be able to identify actions performed by individuals."}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: A user provides two distinct email responses. We need to check which one the email is most relevant to his previous enquiry."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: Create a transcript of an audio file that includes both speech and punctuation."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: We are a company working with personal medical devices. We need to extract medical features from free text from device manuals."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: Develop an AI system that can describe objects and answer questions about an image when provided with an appropriate question."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: I need a model that translates Chinese legal documents into English for my law firm."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: We are developing a mobile application for capturing spoken words from meetings and transcribing them for recordkeeping purposes."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: A history teacher is having trouble finding an answer for when the Mongol Empire was founded. Please assist the teacher."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: The biology institute needs high-quality images of butterflies for their website."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: Please convert a photograph of a hat shop found online into a textual description that can be used for a blog article."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: For a project, an application needs to extract features from a medical text to perform some analysis."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: Your boss asked you to organize some of the files in the shared document drive. However, some of the files are not well-named. Can you develop a way to get context from these documents and answer questions about their content?"}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: I need to transcribe an interview recording. Please recommend me an API."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: As a financial consultant, I need to have quick answers about investment strategies for my clients. Can you help me to answer their questions?"}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: My cat is very curious about biology. Specifically, he wants to know how photosynthesis works."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: I need a digital illustration for my next children's book. The illustration should feature a kid playing with a cat."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: Narrate the given text in French."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: Compare the similarity of the plots of three different movies. Identify the most similar pair of movies."}
{"text_id": 884, "text": "document: Baseline Model trained on tips9y0jvt5q to apply regression on tip. The model uses Ridge(alpha=10) and is trained with dabl library as a baseline. For better results, use AutoTrain."}
{"text_id": 884, "text": "query: A restaurant owner wants to predict the tip amount that customers leave based on the total bill amount to understand their potential earnings better."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: The newspaper media company is requesting a system to recognize entities in the text of their articles."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: We are designing a robotic system that needs to estimate distances between objects. Generate the code to do that."}
{"text_id": 14, "text": "document: A tiny random mt5 model for text generation"}
{"text_id": 14, "text": "query: We have a web app for students and want our model to generate creative story ideas for them."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: A popular IT blog equipped with a treasure trove of information has asked our team to pull content from an image with embedded-text so that it can be used for reading purposes."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: The media company I own analyzes videos and categorizes them based on their content to improve their recommendation engine."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: I'd like to have an AI application to translate English to Russian for my website content."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: \"La vida \u00e9s un somni i els somnis, somnis s\u00f3n.\""}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: A team of botanists needs assistance in analyzing a new dataset containing information on plant species. They want to determine the classifications of these species based on their feature set."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: Develop a voice assistant that recognizes digits from zero to nine in spoken language and sorts them in ascending order."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: Our company is in the process of creating a virtual tour guide that translates spoken language in real time. We want a model that can transform Romanian spoken language to English spoken language."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: Our user research team wants to know whether we can create video for advertisement by just describing the advertisement."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: I am a researcher working on analyzing historical documents. I need to identify named entities in these documents to better understand their content."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: We are asked by a travel agency to write them an app that estimates the volume of articles in a working paper, we want to focus on planning new trips"}
{"text_id": 782, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising + dereverberation) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 782, "text": "query: Our customer requires an upgraded conference call system that can filter out unnecessary noises. Implement a solution to enhance audio quality."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: Can you give me the answer to a question about a given movie review?"}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: Create a model to predict the specific class of an object in an image, uploaded from a URL."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: Prepare a model to help us fill the missing words in bio-medical texts."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: Design a video recommendation system that considers the content of the video rather than using collaborative filtering."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: As an Auditor in a company, I need a tool capable of transcribing recorded conversations to text and respecting the vocabulary used. How can I do this?"}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: Write an imaginary tale about a group of travelers who discovered a hidden city under the ocean."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: We are trying to develop an app that will convert a scenery description into an image."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: We are working with an autonomous vehicle company. They need a depth estimation model for their cars' camera systems."}
{"text_id": 74, "text": "document: BLIP-2 model, leveraging OPT-6.7b (a large language model with 6.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 74, "text": "query: Create a chatbot that can generate descriptions or answer questions about a given image."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: Our company is trying to reduce its carbon emissions, so we need to predict the carbon emission of every machine on the floor."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: Provide a solution for the CEO who needs a summary of a long article on her mobile phone."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: Create a solution to answer questions based on the data available in a table."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: We are a book publishing company looking to generate a continuation of a given sentence for our new storybook."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: Develop an AI that can identify emotions in German reviews left by guests at hotels."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: Our marketing team wants to launch an advertising campaign in Germany, but they only have English copy. We need to have it translated into German."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: I am building an application to extract organization names from news articles for a finance company. How can I do this?"}
{"text_id": 239, "text": "document: SegFormer model fine-tuned on ATR dataset for clothes segmentation."}
{"text_id": 239, "text": "query: The company is developing a fashion application which needs to identify the clothing items in pictures."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: Analyze provided data to predict the housing prices in the US."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We are a sports analytics company. We want to simulate soccer matches using AI models. Provide instructions on using the AI model in Unity."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: We are working on a project to analyze football games and we need to detect helmets in the footage."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: We need a code to cluster a list of text and identify the similarity between each text."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: I want to build a translator that can convert English language text to French, using a pre-trained T5 model."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: Our legal team needs to extract information from various legal documents by asking questions. Provide a solution to accomplish this task."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: The project manager has requested to create a metadata tagging system for images hosted on the company's website. Implement a solution to segment images into their constituent parts and label them for metadata purposes."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: A company specializing in SEO would like to check the similarity between a set of blog titles to avoid content duplication issues."}
{"text_id": 174, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration."}
{"text_id": 174, "text": "query: I want to build an image classification tool for an e-commerce website to categorize images of their new products like electronics, clothes, and books based on their domain."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: Write a program to generate a summary from a given text article."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Make use of Computer Vision techniques to extract tables from a provided image of a document."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: Can you help me build a program that can translate English text to Chinese text?"}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: We have just moved into our new office. It is a multi-use space. We need to make floor plans for each area by identifying furniture and utilities."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: A client needs help finding information from a scanned document. Please provide extracted information accordingly."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: A movie recommendation system needs to categorize movies by genres based on new movies' data like title, director, runtime, and box office numbers."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: Generate a 15-second video for an advertisement campaign promoting a new eco-friendly car."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: Our company focuses on autonomous vehicles, now we need to estimate the depth from a single image."}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: We need to find a salesperson's total revenue by finding the revenue for each product sold by him last month."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: I am working on a project for our company's weekly newsletter, and I need a summarized version of a recent news article."}
{"text_id": 635, "text": "document: Google's T5 base fine-tuned on News Summary dataset for summarization downstream task. The dataset consists of 4515 examples and contains Author_name, Headlines, Url of Article, Short text, Complete Article. Time period ranges from February to August 2017."}
{"text_id": 635, "text": "query: I need to create summaries of news articles that are approximately 150 words long."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: I am interested in finding the similarity between different job postings to detect duplicate job announcements."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive (CS:GO) game images, and we would like to detect players in the images and label them."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: I'm implementing a safety-alert application for workers in construction sites. I need a video classification model to analyze CCTV footage."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: I want to have an AI on my app to answer questions about software documentation based on a given context."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: We want to improve our English writing. Figure out a way to automatically fix grammatical mistakes."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: We have a document with a diagram and some text, and we would like to know the answer to the question, \"What are the main components of the diagram?\""}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: I want to generate a list of questions from my study material so that I can practice for exams."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: Design a system that transcribes Portuguese-language audio files for a language learning app."}
{"text_id": 426, "text": "document: This is the standard 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 426, "text": "query: I'm building a customer service chatbot and need to extract necessary information. Identify all the named entities from the customer feedback given in text format."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: We are building a music application, and I want to separate vocals from instruments."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: We have a voice assistant project, and our team is Middle Eastern people that mostly speak Arabic. We need to convert our Arabic speech to English for further development."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: Create a tool to extract named entities like person, organization, and location from texts in different languages."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: As an entomologist, I want to generate images of butterflies to use for educational purposes."}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: I am a PR manager in a Japanese manga production team. There are a lot of captions and texts in the manga that are not easily recognized by English speakers. Help me generate a transcript of the Manga so that it can be translated into English."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: We want to create an app where users can generate or modify images based on some text input."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: We want to analyze customer reviews and categorize them based on their similarity."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: My company's security team wants to classify video footage of intruders."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: A company specializing in computer-generated imagery for films needs realistic human faces for their next project. Generate a high-quality synthetic image of a human face."}
{"text_id": 420, "text": "document: This is a BERT-large-cased model fine-tuned on the CoNLL-03 dataset for token classification tasks."}
{"text_id": 420, "text": "query: We are writing articles for our website, and we need to analyze the text to extract important entities like names, places, and organizations."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: We want to train an agent that will help us accomplish lunar landing and make the highest scores possible."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: Construct a model to calculate carbon emissions for vehicles based on their specifications."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: Any suggestions on how to summarize financial news articles? We are building a chat platform for the financial sector."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: We want to search for similar research articles so our writers can refer to them while writing their own articles."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: I am creating an educational platform that classifies the subject related to each question posted by users. Classify the question's subject."}
{"text_id": 396, "text": "document: Trained to add the feature for classifying queries between Question Query vs Statement Query using classification in Haystack"}
{"text_id": 396, "text": "query: We want to improve our search engine by distinguishing user queries as questions or statements before processing them for answer generation."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: We want to create a model for a sports news application that can answer user queries about statistics from a given table."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: Your friend wants to know how they can convert a given text into an audio file using AI. Help them understand the process and give an example."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: Generate a photorealistic image of a cherry blossom tree next to a lake during sunset."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: Our company requires an intelligent system that processes scanned invoices and answers questions about their contents."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: We have Swedish customers sending us emails, and we would like to see if the bot can answer their questions by automating the translation process."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: Can you recommend me a well-known language model for an AI-based text generator that can generate creative promotional sentences for various businesses?"}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: I need to create a personalized greeting message for a Russian friend using their name. The message should say \"Hello, [Friend's Name]. Welcome to my home!\""}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: We need to develop a program to extract information from tables based on given questions in plain English."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: The marketing team wants to analyze whether a customer's reviews are similar to the product description. Find the similarity between customer reviews and product descriptions."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: I manage a shipping company, and we need to annotate the images of our shipping yard for warehouse management. We would like the different sections and types of objects to be segmented and labeled."}
{"text_id": 363, "text": "document: This model is a zero-shot image classification model based on OpenCLIP. It can be used for classifying images into various categories without any additional training."}
{"text_id": 363, "text": "query: We are looking for an AI system that could identify plants species from images snapped by mobile phones."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: One of our clients is a botanist. She needs to identify the type of Iris species based on the flower's features."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: Help me find the most relatable answer from a list of candidate answers to the question \"What is the significance of the rainforest?\""}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: We are creating a computer vision system to classify objects in images using a pre-trained model. Which model should we use and how can we classify an image?"}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: I need a chatbot that can help me answer questions about a wide range of topics."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: The goal of our mobile app is to allow users to snap a picture of their surroundings, identify different objects in the image, and create a corresponding list of those objects."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: An economic analyst needs help finding average unemployment rates in 2020 amongst different countries mentioned in a table."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: Develop a text code analyzer that can identify different programming languages and named entities in a given StackOverflow post text."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: Develop a system to help visually impaired individuals by answering questions related to images."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: We need a system that automatically classifies videos for our streaming platform according to their content."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Our development team needs chatbot to be equipped with its own personality of a sports enthusiast, to engage customers in conversations about sports."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: The customer is an online platform for language learning. They want to provide an audio transcription service, which should include proper punctuation to enhance user experience."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: I'm building a news aggregator app, and I need a system to categorize news articles into topics like 'politics', 'sports', 'entertainment', 'technology', 'economy', 'health', and 'world'."}
{"text_id": 669, "text": "document: CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It is available on Hugging Face in 6 different versions with varying number of parameters, amount of pretraining data, and pretraining data source domains. It can be used for Fill-Mask tasks."}
{"text_id": 669, "text": "query: I am an aspiring French author with writer's block. I need help generating appropriate words to fill in the blanks in a sentence from my novel."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: We developed an image uploading feature for our app. The app allows users to pick a category for their image, but it's prone to incorrect categorization. Implement a model to detect and classify the uploaded images into correct categories."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: As a financial advisor, I need to extract the total amount from a client's invoice to analyze their expenses."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: We are making the wallpaper for a website. Generate a high-resolution image reflecting the text \"a beautiful mountain scene with a sparkling night sky\"."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: We are developing an app to transcribe Esperanto speech for educational purposes."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: I'm writing a demographics report, and I can't remember the capital of Canada. Can you complete the sentence for me? \"The capital of Canada is _____.\""}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: I'm a teacher working on a bilingual web page that provides language learning resources. I need to translate English sentences to Spanish."}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: Write a dialog between a person who just attended the EMNLP Conference in Abu Dhabi and his friend, who wants to know about the person's experience."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: Our company offers customer support services. We need a solution that translates English audio files to French audio files for our bilingual agents."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: Our company wants to translate a user manual from Italian to English. The manual is stored in a file. Translate that for us."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: Write the beginning of a fairy tale or science fiction story that starts with \"It was a dark and stormy night.\""}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: Please tell me the procedure to create a solution for controlling a pendulum using a learning-based approach."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: We need to develop an AI chatbot for our customer support service. Can you create a code snippet for a conversation with multiple user inputs?"}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: Our client is a travel blog. They want to create a poster with an image of a waterfall surrounded by lush green forest."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: A news company wants to classify news articles to identify whether they are influenced by AI-generated content or not."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: \"Science is constantly <mask> new discoveries and challenging our understanding of the universe.\""}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: We need to improve the search functionality on our website by converting texts into features that can be used for semantic similarity comparisons."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: Use the provided NLI model to classify whether a text snippet contains information about technology, sports, or politics."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are building a robotic leg that moves efficiently. We need an algorithm to optimize the movement pattern."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: Design a German text-to-speech program that would convert the sentence \"Guten Morgen, wie geht es Ihnen heute?\" into an audio file."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: A home automation company wants to detect the distance of objects from their smart cameras for effective display of data in the smart home."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: I work in a robotics lab, and I'm trying to represent a scientific article's title with a specific embedding."}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: Produce sentence embeddings for our company's customer support system to help them better understand customer inquiries and responses."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: Our client is building a security system in a warehouse, and we want to classify each video content captured by CCTV accordingly."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: We have a library of videos and need to categorize them into educational, sports, or news videos. In order to achieve the best accuracy, we would like to use a pre-trained model."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: A startup is building a home automation system that understands those objects which are visible in the room like TV, sofa, and table."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: We received a support request from a customer. Their message is written in a Romance language. Help us translate it to English."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: Create a video recommendation system that suggests related videos after watching a video."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: Our client wants to automatically categorize images of city infrastructure (residential areas, playgrounds, stadiums, forests, airports). Implement a model for this task."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: We are planning to deploy an app that estimates the relative depth of objects within an image. How can we build this?"}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: Create a conversational bot that generates responses similar to Elon Musk on Twitter."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: Generate an image that reflects a calm and peaceful beach including palm trees and white sand, but without people or animals in the scene."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: Our company needs to communicate with partners from Latin America. Translate a German text for us.###"}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: We have a customer report in German. We want to classify some main topics based on the report."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: Your company runs a science blog. Someone from the tech team wants to know how certain content should be labeled."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: I want to predict which species of iris a flower belongs to, based on values measured on the petals and sepals."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: I am working on online photo gallery where my clients can upload their photographs with different type of contents. Set up an image classifier based on the pretrained BEiT model that can identify the content within them."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: Our company is designing software for basketball coaching, and we want to leverage the power of video classification to analyze the players' performance during the game."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: Our company wants to create artificial bedroom images. Create a method for generating high-quality images of bedroom using a pre-trained DDPM model."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: How would you go about extracting text from an old handwritten document?"}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: My company would like to find a user-friendly solution to transcribe customer calls. We need to convert recorded audio to text from call recordings."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: Our therapist app wishes to identify the client's emotions within an audio recording during a session."}
{"text_id": 588, "text": "document: A GPT-4 model for generating conversational responses in a dialogue setting."}
{"text_id": 588, "text": "query: We need an AI system for handling customer support inquiries. This system should generate responses for specific customer questions."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: We have aerial images of a city and we want to analyze them by segmenting different areas."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: Create a text classifier to check whether the given text is gibberish or not."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: Our company needs the ability to extract information from scanned documents. Could you provide me with information on how to use LayoutLMv2 to extract answers from documents?"}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: We want to visualize a futuristic city described in the story we're writing. Our story has flying cars, tall glass buildings and parks with vertical gardens."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: I want to analyze data on Olympic Games cities and years. I have a table of Olympic Games with columns \"Year\" and \"City\". I would like to know which year Beijing hosted the Olympic Games."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: Develop a program to recognize and label objects in a given image with bounding boxes."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: Develop a customer service chat system to address inquiries about our furniture store's products, refunds, and delivery updates."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: Provide a summary of a news article on improving air quality in cities."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: \"Just watched the movie. It was absolutely amazing! #movienight #greatfilm\"."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: Our company website wants to provide a summary of our meeting transcripts. As an example, find a summary for the following meeting transcript:"}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: Our company is designing a mobile application to help users predict whether certain products have high or low carbon emissions. We need a machine learning model to classify them."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: The company wants a program to transcribe call center audio files, detailing the time when each sentence is spoken."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: semantic, instance, and panoptic segmentations."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: A customer asked us to write a summary for their conversation about electric cars."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: I am the CEO of a construction company, I need a summary of what major changes will happen in the construction industry in the future."}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: We are developing an image generation tool for customer needs where we need to generate an image based on customer's text description."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: Detect license plates from car images and calculate percentage of recognized plates."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: The manager wants to organize a meeting with the employees. Help them find the best time and coordinate the meeting based on the given data."}
{"text_id": 754, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 754, "text": "query: Our company has developed an app for converting speech to text. We want to use a pre-built machine learning model to transcribe speech recordings."}
{"text_id": 260, "text": "document: This version of Stable Diffusion has been fine tuned from CompVis/stable-diffusion-v1-4-original to accept CLIP image embedding rather than text embeddings. This allows the creation of image variations similar to DALLE-2 using Stable Diffusion."}
{"text_id": 260, "text": "query: Our company is developing a catalog where we present variations of products. We want to create different visualizations for a single image."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: We are a clean energy company and we want to predict if a given set of environmental data will have high carbon emissions."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: A teacher needs help grading language homework, and she needs to analyze students' sentences for their part-of-speech tags."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: We are a startup company looking to identify new partner companies. Extract company names from the given article."}
{"text_id": 373, "text": "document: This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details)."}
{"text_id": 373, "text": "query: Build a tool to analyze the general sentiment of my audience on social media platforms."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: We are an electronic manufacturing company, can you build a tool for us to identify PCB defects in the quality control process?"}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: We are creating an AI with the ability to learn how to keep the pole in CartPole upright using deep reinforcement learning."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: We are developing an app that can generate descriptions for user interface elements on mobile applications. We need to utilize Pix2Struct to achieve this function."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: An app has recently been launched which captures a picture of a wine and predicts its quality. Our company wants to examine how the backend does this?"}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: Design a chatbot that promotes tourism on an Island named \"Thinkston\". It needs to be able to provide information about the island and its attractions."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: We are a company that filters out NSFW content for various platforms. We need to assess the safety of text data."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: Our company needs a system to separate the spoken words from background noise in recorded customer service calls to improve the quality of transcriptions."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: We are working on a wildlife conservation project and we need to classify animals in the provided photos."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: As a medical researcher, I need to read a lot of scientific papers every day. I need a tool to help me summarize the abstract of these papers so that I can quickly determine if the paper is relevant to my research."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: We are creating an app for mental health. We want to analyze the audio of users and detect their emotional state."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: We have a robot moving in a room; we want to measure the depth of the objects in that room using a pre-trained model."}
{"text_id": 900, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 900, "text": "query: We intend to create an AI playing strategy based on playing SoccerTwos."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: My friend just told me about a new camera that he bought, and he sent a picture. What's the color of the camera? "}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: Our organization has a vast number of printed documents that need to be digitized. We require a system that can automatically process the images and extract text."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: A creator is building a game simulation and wants to train an AI to make decisions in the game based on different states. The AI should be able to make decisions while hopping in an environment with varying conditions."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: Can you write a query which translates the words \"I love programming\" from English to German?"}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: A student who wants to study biology needs a collection of butterfly images to gain better insights. Can you create some quality butterfly images for them?"}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: I am building an autonomous car for a project and I need to find out how far objects in the images are in order to avoid any obstacles and navigate safely."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: Let's build a tool for a company to automatically follow Q&A sessions performed in Chinese during a technical webinar. They need the questions and answers delivered in the language you design."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: We are working on an application that identifies natural pauses in speech. Please help us by providing a voice-activity-detection solution."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: I have an article I need to translate from English to French and then summarize it for a brief presentation."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: Our company wants to create a phone application that can classify digit pronunciation from audio files."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: Create a Disney-style video for a magical princess playing guitar."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: Determine if a video contains violence or not."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: How to build a question answering system on an article?"}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: I would like to analyze the emotions contained in a piece of text."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: Create a program that analyzes reviews in multiple languages and classifies the sentiment into 1 to 5 stars."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: Our company is producing cars and we need to know if the engine sound is normal or if it indicates a problem."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: I want to analyze the emotions in an audio clip by using the pretrained Hubert model."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: I intend to create a program that engages in multi-turn conversations with visitors on my site in English language."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: I have a table with various project details and I would like to know the project manager for project \"A\"."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: We have a table of population data of different countries. Let's figure out which country has the highest population."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: We are building a classifier for our software service that helps users extract important events from a given text."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: I want to build an application that helps users to auto-complete sentences by predicting the missing words."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: I need a script to generate high-resolution profile images of people for a website that we are building."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: \"The stock market experienced a significant drop today.\""}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: Our goal is to create a chatbot that can carry a conversation between various users on different topics such as movies, music, and technology."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: Users often send chat messages to the customer support team. Develop a chatbot that can assist the support team with answering the user questions."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: Help a musician that wants to separate the vocals and instruments from a mixed track in their music studio."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: We aim to capture people's emotions while they are speaking with a customer service representative. Help us classify the customer's emotion."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: Organize a learning-based agent to play Breakout without skipping any frames."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: I want an assistant to read out an article in a Taiwanese Hokkien accent."}
{"text_id": 39, "text": "document: Dreamlike Photoreal 2.0 is a photorealistic model based on Stable Diffusion 1.5, made by dreamlike.art. It can be used to generate photorealistic images from text prompts."}
{"text_id": 39, "text": "query: We want to create a realistic image of a serene beach with a wooden hut, under a sunset."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: We are building an app for Chinese language students. Among other things, the app should analyze and breakdown Chinese sentences with automatic tokenization and part-of-speech tagging."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: I want to assist people in making 3D images. How can I use deep learning to estimate depth from 2D images?"}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: We need to create an audio file for an eBook in English. The audio will be generated from the text."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: Our school wants a chatbot that can generate sentences for writing exercises for students. Please describe the pipeline required to create such a model and how to use it."}
{"text_id": 527, "text": "document: A Russian to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Transformer-align architecture and trained on the OPUS dataset. The model can be used for translation and text-to-text generation tasks."}
{"text_id": 527, "text": "query: We have an application whose user support system is in Russian. We need to translate support messages to English."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: We are building an application for summarization of news articles in the Korean language. We would like to utilize the pretrained model."}
{"text_id": 109, "text": "document: This is an unoffical mirror of the model weights for use with https://github.com/OFA-Sys/OFA. The original link is too slow when downloading from outside of China."}
{"text_id": 109, "text": "query: I am building a home automation system. Whenever my guests or family ask questions, the system should answer by analyzing the images in the room."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: I want to extract features from a medical document written in English. The physician mentions symptoms and medical conditions in the text."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: I need a system that can automatically caption images and videos."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: We need to create a painting of a forest scene with a river flowing in it."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: Our Germany-based company needs a solution to classify submitted customer texts into categories like \"Crime\", \"Tragedy\", and \"Stealing\"."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: Create a program that can answer questions about any recent documents on COVID-19."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: Make a fill in the blank exercise for learning the Chinese language. It should complete the missing words in a given sentence."}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: A lawyer needs to convert some audio files from a court session into text for analysis. Automate the process for transcription."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: My daughter loves anime and wants a new wallpaper for her computer. Help me generate a new anime-style image following her description of a warrior girl in the jungle."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: I would like to have a conversation with an AI about an upcoming birthday party."}
{"text_id": 212, "text": "document: Deformable DETR model with ResNet-50 backbone trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper Deformable DETR: Deformable Transformers for End-to-End Object Detection by Zhu et al. and first released in this repository."}
{"text_id": 212, "text": "query: We have a security application that watches the videos and take pictures when any issues need to detect objects."}
{"text_id": 68, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on COCO. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 68, "text": "query: We are making a tourist app that needs to suggest what tourists could do based on an image they take."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: The company needs to identify the objects and their count in images. Use the multimodal model to identify the objects and their number from API call."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: As a writer for a French news agency, we need a system to generate abstracts from our news articles."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: Write me an example code for extracting a specific data point from scanned invoices using named-entity recognition techniques. "}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: Design a chatbot for customer service that understands Korean language."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: Can you help me create a chatbot using the 'Zixtrauce/JohnBot' model from Hugging Face Transformers?"}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: I have a very long academic article that I want to summarize quickly."}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: I want to get information about the population of cities from a tabular dataset."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: Working in a job platform, making a short text understanding tool to categorize the jobs according to the emotions expressed in the job description."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: animal, plant, or artifact."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: Our team is developing an application to help people identify plants. We want to use an image classification model to recognize various plants from the images provided by the users."}
{"text_id": 738, "text": "document: A pretrained Text-to-Speech model based on the ESPnet framework, fine-tuned on the LJSpeech dataset. This model is capable of converting text input into synthesized speech."}
{"text_id": 738, "text": "query: During a presentation, our computer-based virtual assistant will read aloud the text through automatically generated speech. The text is \"Welcome to the annual technology conference.\""}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: We're building a historical data analysis tool, plan on using the Titanic dataset to predict survival of passengers."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: Create a feature extractor for text content from the Korean web."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: The company is building a drone for indoor navigation. We need this drone to estimate the depth of objects in its surroundings so that it can avoid any obstacles in its path."}
{"text_id": 144, "text": "document: A tiny random DPT model for depth estimation using Hugging Face Transformers library."}
{"text_id": 144, "text": "query: Our team is working on developing autonomous vehicles. We need to integrate a depth estimation model to perceive its surroundings."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: A sound engineer wants to separate vocal tracks from an audio mix for remix purposes."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: We have a new database containing company information. We need a tool to automatically locate people's name, organization, and location mentioned in the text."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I'm a researcher trying to understand the impact of climate change on the migration of birds to answer a question related to the effect of temperature on average migration distance."}
{"text_id": 846, "text": "document: This API provides speaker diarization functionality using the pyannote.audio framework. It is capable of processing audio files and outputting speaker diarization results in RTTM format. The API supports providing the number of speakers, minimum and maximum number of speakers, and adjusting the segmentation onset threshold."}
{"text_id": 846, "text": "query: We need to process a conference call recording to find out how many speakers were involved and separate their speech segments."}
{"text_id": 67, "text": "document: PromptCap is a captioning model that can be controlled by natural language instruction. The instruction may contain a question that the user is interested in. It achieves SOTA performance on COCO captioning (150 CIDEr) and knowledge-based VQA tasks when paired with GPT-3 (60.4% on OK-VQA and 59.6% on A-OKVQA)."}
{"text_id": 67, "text": "query: We want to launch a new platform where user can get image description by providing a prompt like \"What piece of clothing is this person putting on?\"."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: Find if a person is talking in an audio recording, and if multiple people are talking at the same time."}
{"text_id": 850, "text": "document: Use TensorFlow's Gradient Boosted Trees model in binary classification of structured data. Build a decision forests model by specifying the input feature usage. Implement a custom Binary Target encoder as a Keras Preprocessing layer to encode the categorical features with respect to their target value co-occurrences, and then use the encoded features to build a decision forests model. The model is trained on the US Census Income Dataset containing approximately 300k instances with 41 numerical and categorical variables. The task is to determine whether a person makes over 50k a year."}
{"text_id": 850, "text": "query: As an HR consultant, we need to develop a salary predictor using employees' demographical information."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: Develop a feature where users can upload images and get depth estimation for those images in order to improve our app's 3D experience."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: We are building an app that helps tourists communicate with locals by translating their native language to the local language directly through speech-to-speech."}
{"text_id": 311, "text": "document: Example Fine-Tuned Model for Unit 2 of the Diffusion Models Class"}
{"text_id": 311, "text": "query: For our company's 10 year celebration, we want to create a vintage theme on social media around our employees. Generate a vintage image for this purpose."}
{"text_id": 532, "text": "document: Neural machine translation model for translating from English (en) to Portuguese (pt). This model is part of the OPUS-MT project, an effort to make neural machine translation models widely available and accessible for many languages in the world."}
{"text_id": 532, "text": "query: I'm working on a project that requires translating multiple English sentences into Portuguese. Kindly provide a snippet to utilize this model."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: I have a long French text document that needs to be summarized into a short paragraph without losing the main points."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: Generate a concise and informative summary of a text from a book,"}
{"text_id": 708, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384-dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 708, "text": "query: How can we find the most relevant answers to a specific question using similar content questions and answers data?"}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: We need to build a surveillance system to detect suspicious behavior in public places. Create a video classification tool for that."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: Our company is planning to build a video management system. We want to be able to classify user-uploaded videos automatically."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: Our client wants a tool that can query financial data tables in natural language so that they can get specific information effortlessly."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: A fashion magazine company has approached us to design a text-driven fashion categorization system for various fashion apparel."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: Construct an audio file of a Korean children's story for bedtime and ensure the generated audio is easy to understand and has a natural Korean tone."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: In a multilingual customer support system, we want to extract information including name and location details from the customer query."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: Recommend a solution to detect objects in an image and segment the pixels appropriately."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: We want to analyze images of birds and classify them based on their species. Please suggest a suitable model."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: I am a budding YouTuber from India and I want to transcribe my videos from Hindi to English before uploading it to my channel."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: I need an image classifier to categorize images of animals. Help me implement a system that can automatically classify images based on their content."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: I'm creating a chatbot for my game. I need a virtual friend character who loves going on adventures and exploring new places. Can't wait to talk to players about their quests."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: Make a software that can generate a caption for any uploaded image."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: Detect the active speakers in a meeting recording and differentiate the periods of silence."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: We are fascinated with manuscripts. We are now working on recognizing handwritten text."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: We want to develop a chatbot with emotion detection capabilities. Provide a code snippet to detect the emotions in the user's input."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: Our company is working on a customer service bot. We need to classify incoming inquiries from customers."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: Our company needs assistance in processing images with text and converting it into a digital text format for easy management and access."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: My company deals with cats, need an AI to classify images of cats."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: A Chinese manager needs to find which email in their inbox has a similar content to a specific reference email."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: I am a language teacher. I wanted to automatically generate 5 interesting English sentences start with \"The man worked as a\"."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: A friend of mine loves role-playing games, and I think it would be fun to have an AI Dungeon Master. Can the model play the character of a mysterious wizard who gives out quests?"}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: We need to analyze city planning, and for this we want to segment buildings from satellite images."}
{"text_id": 92, "text": "document: A Hugging Face model for converting Persian and English text into video."}
{"text_id": 92, "text": "query: \"Join us for a night of fantastic Persian films! Don't miss the chance to experience the magic of Iranian cinema.\""}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: Develop an interactive speech-driven program to recognize numbers spoken by users."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: We are working on constructing cities and analyzing the land use. Our team needs to segment satellite images of the city."}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: We are running an online newspaper and want to summarize a long article into a short paragraph."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: We are working on a project to reduce carbon emissions. We need to predict the emission levels for different industries."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: Help me develop an application that can process a picture of a living room and answer questions about it in Polish, like \"how many chairs are there?\" or \"what color is the couch?\"."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: A nonprofit organization needs a statement describing their mission to eradicate poverty through education."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: We need a classification model to predict the customer\u2019s inclination towards the newly launched product."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: We are building a mobile app that allows users to gather information about events happening in a multiplayer online game. We need you to detect players and objects in images from the game."}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: Our company is in language translation. We need to analyze two translated texts to identify their similarity."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: To build the recommendation engine, I need to give a sentiment score to movie reviews to classify which movie the users will like."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: We are starting a platform where we match blog authors and readers with similar topics. How can we use this to find similar content?"}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: Our client needs to show images of their products in higher resolution to better showcase their features on their website. Enhance the images' resolution."}
{"text_id": 240, "text": "document: Mask2Former model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 240, "text": "query: Implement this Mask2Former model to be used in our autonomous vehicle project for image segmentation in real-time."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: I am interested in constructing a chatbot. I need to understand how can we use the RoBERTa model to generate completions for sentences with masked words."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: Devise an agent that can work on reinforcement learning tasks for robotics and navigation."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: We need to create analog-style images for our online store displaying various types of clothing."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: We'd like to build an application that takes a prerecorded audio file and detects all the instances of voice activity using a pretrained model. The application should also be able to handle overlapped speech detection and resegmentation tasks."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: We need a solution for enlarging low-resolution images without losing quality for our photo album website."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: In my chat application, whenever users query any weather information, I want my application to have a conversation with the user and give them useful information."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: We have a shipment center, and we want a program that can automatically identify and count how many containers there are."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: I want a way to compare two texts in order to deduce the similarity between them."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: I have a table filled with upcoming movies. I need to find which are the highest-grossing film of the year 2023."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: An audio engineering team is working on speech enhancement for noisy recorded audio files. Assist them with a solution to improve audio clarity."}
{"text_id": 686, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xxlarge model with 48 layers, 1536 hidden size. The total parameters are 1.5B and it is trained with 160GB raw data."}
{"text_id": 686, "text": "query: We need a software that can complete sentences for us."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Can you predict a textual description of an image given the image's URL?"}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: Build a tool that can translate spoken language from Spanish to English."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: We need to identify different types of speech commands in audio files. Develop a tool to achieve this goal."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: I have a list of DVD features and prices. I need a model to be able to answer questions like \"What is the price of the DVD with the highest resolution?\" based on the provided table."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: I am building a web UI to convert speech to text in Arabic. Can you tell me which model is suitable for Arabic language?"}
{"text_id": 746, "text": "document: Text-to-Speech (TTS) with Tacotron2 trained on a custom german dataset with 12 days voice using speechbrain. Trained for 39 epochs (english speechbrain models are trained for 750 epochs) so there is room for improvement and the model is most likely to be updated soon. The hifigan vocoder can fortunately be used language-independently."}
{"text_id": 746, "text": "query: Currently, we are a software company that is building a German language learning app. We want to generate audio files for teaching purposes."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: An online gaming platform wants to integrate a pre-trained agent to play CartPole with the player for testing purpose."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: My boss asked me to build an Internet of Things (IoT) device to recognize objects in my office and store the information for later analysis."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: Write a script that samples birthday congratulations."}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: Nowadays, misinformation is a significant concern. We need to build a tool to detect if a piece of text was generated by an AI, specifically GPT-2."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: We are working on a French news app, and we need to provide French summaries of the long articles for our users."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: The company needs to communicate with Arabic-speaking clients. Develop a system to translate English text into Arabic."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: I am building an app for office work productivity. I need a mechanism to answer questions based on a given document."}
{"text_id": 844, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. It provides voice activity detection, overlapped speech detection, and resegmentation functionalities."}
{"text_id": 844, "text": "query: Our meeting transcription software needs to distinguish speakers and identify silent pauses. We also want the software to be able to handle overlapping speech."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: I have a collection of images, and I want to know if there are any humans in them. Build me a solution that can detect the presence of humans in images using a zero-shot-object-detection model."}
{"text_id": 610, "text": "document: The SantaCoder models are a series of 1.1B parameter models trained on the Python, Java, and JavaScript subset of The Stack (v1.1) (which excluded opt-out requests). The main model uses Multi Query Attention, was trained using near-deduplication and comment-to-code ratio as filtering criteria and using the Fill-in-the-Middle objective. In addition there are several models that were trained on datasets with different filter parameters and with architecture and objective variations."}
{"text_id": 610, "text": "query: I am a developer, I have a Python class that needs a method to calculate the area_coverage. Please generate the Python code for that method."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: I am creating a software to analyze business deals. Adapt an API to help us understand if two given sentences contradict, entail, or are neutral to each other."}
{"text_id": 135, "text": "document: A LayoutLM model for document question answering."}
{"text_id": 135, "text": "query: We need to categorize various invoices based on the questions we want to answer. For instance, we need to extract the total amount and the due date from an invoice."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: In order to build a better navigation system, the company needs to estimate the depth of objects in the environment."}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: Our startup company is working on a Chinese language audiobook reader. Design a system to read Chinese text and process it into audio."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: We need to create a short story to demonstrate our AI understanding a prompt with a rich context."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: The manager needs a solution that can quickly provide answers for questions related to a train schedule."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Global Offensive'. They need a way to identify players in the game images."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: Our company provides customer support across different regions. We need to translate Finnish customer complaints into English."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: A project requires an AI-based narrator to provide an audio representation of a given text. Create a method that produces a spoken audio file of the input text."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: I am a content creator for websites, and I need to identify the language of the given texts to create subtitles for multilingual content."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: An environmental organization needs to forecast carbon emission levels for a given set of data points. What can we use to help them?"}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: A factory measures CO2 emissions in three levels. I need an AI model that can predict the emission level given a specific set of input features."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: \"A dog plays with a ball in a park.\""}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: We are building a mobile application to classify food items. Design a program to predict the class of an image."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: Our client wants us to generate images of beautiful church architecture."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: We need to develop a summary generating tool for our organization. This will reduce the time spent on reviewing documents."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: Generate an engaging and coherent conversation with a chatbot that can discuss various topics and display knowledge, empathy, and personality."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We are a company focused on image analysis. We want to classify unseen product images into various categories. Can you help us to do zero-shot image classification for a variety of images?"}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: A web-enabled application is being developed for tourists to ask questions about the photos they upload. The system must be multilingual."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: I want to estimate the human posture from an image of a person doing yoga."}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: A German publishing house needs to categorize opinions from social media posts into three categories - crime, tragedy, and stealing. Automate this categorization process."}
{"text_id": 833, "text": "document: Brouhaha is a joint voice activity detection, speech-to-noise ratio, and C50 room acoustics estimation model. It is based on the PyTorch framework and uses the pyannote.audio library."}
{"text_id": 833, "text": "query: Implement a solution to process a given audio file and detect speech activity, estimate the speech-to-noise ratio, and the C50 room acoustics."}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: I am a developer, and I would like to build an app that helps users to identify birds in images they provide. Guide me through creating a model and classifying the birds."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: Build a system to improve customer service by analyzing user sentiments from their tweets."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: We have a FAQ page on our website. We want to add an AI assistant to automatically answer user questions."}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: Our marketing team has an image feed and wants to trigger content related to their conversations about images. We require a model to embed both images and text into the embedding to generate text in response to those images."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: Our organization focuses on document analysis, help us extract information from images of documents through a question-answering model."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: You are working for a game company and need to create believable dialogues for a game character."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: An article summarization tool requires a model to detect if the summarized article's statement is a direct logical conclusion based on the original article's text."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: Classify a news headline as clickbait or not. Make sure to indicate the confidence level for each label."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: I have a vast collection of images with animal species and I need you to sort them into categories such as 'dogs', 'cats', 'birds', 'fish', and 'reptiles'."}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: We need a way to summarize patients' medical history within our medical software."}
{"text_id": 860, "text": "document: A tabular classification model trained on the Iris dataset using XGBoost and AutoTrain. The model is capable of multi-class classification and has an accuracy of 86.67%."}
{"text_id": 860, "text": "query: An agriculture company needs to classify different types of plants using data collected from measurements of their properties."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: I need to determine the part of speech for each word in a sentence."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: As an accountant in a sports club, you are going through a database of players' information. You need to find out when was the last time an athlete had a medical check-up."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: Our accounting department needs a solution to extract the total amount due from a series of invoice documents."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: I need to paraphrase some sentences about travel to promote my travel agency. It should be more appealing and engaging."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: Develop an application for a museum where visitors can upload pictures of butterflies, and the application will generate new, similar images."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: Develop a search engine using visual question answering to make search results more specific."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: Design a program to predict the prices of houses using the given model."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: There is a dating app that requires an age estimation feature that can recognize the age of a person in a photo."}
{"text_id": 429, "text": "document: This is the standard 4-class NER model for German that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 429, "text": "query: I want to use an advanced NLP system to extract named entities from a German text."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: Our new AI-powered product automatically generates profile pictures for users. We need to generate a profile picture for a user who loves cats."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: Our customer is a legal firm who needs to search specific information from various documents quickly. We are considering an AI solution to solve this problem."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: We need to compare multiple text variations for an marketing email subject. Can you please find the most similar ones to the original?"}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: Create a tool to transcribe audio recordings of meetings which automatically include punctuation."}
{"text_id": 442, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab."}
{"text_id": 442, "text": "query: Create a solution to answer questions about various olympic events using the provided data in a table format."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: In the medical sector, we are building a product to autocomplete a sentence about certain diseases."}
{"text_id": 117, "text": "document: This is a fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens (because they predict the start and end of a sequence), this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 117, "text": "query: Our client is a bookkeeping company who wants to extract relevant information, such as company name, dates, and amounts, from receipts and invoices."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: Our company is dealing with multilingual clients, so we need a classifier to understand our multilingual customer's feedback."}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: I'm working on a project that performs image segmentation. I need a pre-trained model that can handle semantic, instance, and panoptic segmentation tasks."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: We are developing a virtual assistant product. We need a feature that can identify the language spoken in the user's audio message."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: We need to translate a Hokkien audio speech into English and generate an English audio speech."}
{"text_id": 932, "text": "document: TAPAS large model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 932, "text": "query: Analyze the covid-19 statistics from the data table and explain the best country to travel safely considering the lowest number of new cases."}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: Our customer support team needs to be able to find relevant information quickly in the knowledge base. We're looking for an information retrieval solution."}
{"text_id": 763, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition tasks."}
{"text_id": 763, "text": "query: We need to develop a voice-controlled home automation system. We will first transcribe users' voice commands to texts."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: I want a model that can tell if an image is a muffin, beignet, dachshund, toaster, or stapler."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: We want to implement an AI-based video surveillance system for our company that classifies human activities in the surveillance footage."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: I am creating an app for a fitness coach that records videos of athletes performing different exercises. The app should identify which exercise the athlete is doing."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: We have an incomplete sentence and we need to fill in the blank with the correct word."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: The company needs a voiceover for their advertisement video. Generate the audio from the script provided."}
{"text_id": 625, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. OPT models are trained to roughly match the performance and sizes of the GPT-3 class of models, while also applying the latest best practices in data collection and efficient training. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 625, "text": "query: I have an innovative idea for a children's book, and I need your help writing a captivating introduction based on the theme \"the adventurous journey of a fearless rabbit.\""}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: The manager needs to share one of the most important documents about machine learning. There is a condition that a summary in German language (at least 100 words) must be provided for this document."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: We want to generate an image for a blog post about an astronaut riding a horse on Mars."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: As an English-speaking tour guide in Spain, I often need quick translations between Catalan and Spanish. Can you help me with a language model for this task?"}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: Your company needs to automate the extraction of relevant data from invoices. Identify important information from the invoice."}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: We need to enhance the clarity of a low-quality image by deblurring it, and after that, process the image to be used in a gallery show."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: A customer wants us to create an image describing \"A colorful sunset over a mountain range\" using text-to-image generation."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: The local government is trying to predict criminal recidivism using data from people who are charged with a crime. Please help them identify which individuals are more likely to commit another crime."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: Translate a paragraph from Hindi to Chinese using a reliable model."}
{"text_id": 530, "text": "document: Helsinki-NLP/opus-mt-es-en is a machine translation model trained to translate from Spanish to English using the Hugging Face Transformers library. The model is based on the Marian framework and was trained on the OPUS dataset."}
{"text_id": 530, "text": "query: The company needs translations of a report originally written in Spanish to be distributed among English-speaking employees."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: Our environment company is working on a project to decrease carbon emissions. We would like to predict carbon emissions based on various factors."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: We are an artist collective, we need to draw an image of a bag resting on the grass."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: Implement a program to detect if the given text input is gibberish or not."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: Develop an algorithm that will find which category to put product reviews in."}
{"text_id": 767, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and was trained on either English-only data or multilingual data."}
{"text_id": 767, "text": "query: I run a podcast and I need to transcribe episodes automatically so that listeners who prefer reading can access the text version."}
{"text_id": 917, "text": "document: A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. It enables researchers to better understand and explore zero-shot, arbitrary image classification. The model can be used for zero-shot image classification, image and text retrieval, among others."}
{"text_id": 917, "text": "query: The company needs to automatically categorize images in their database. Help them find the right model and usage instructions."}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: We want to extract named entities for all languages. Can you build a text processing tool for us?"}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: We are building a traffic monitoring system, and we need to categorize vehicles by type."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: We are a medical institute that needs to classify medical records into categories."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: Jimmy is looking for a program that can segment long Chinese sentences into words and phrases. Can you help him build a model?"}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: Our news portal is in need of an application to find the similarity between articles and display the top 5 related articles. How can we do that?"}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: I am transcribing a conference call for work, where people sometimes talk over one another. I would like to identify when these overlapping speech instances occur in the audio file."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: Offer me a way to compare the similarity of two sentences based on the semantic meaning of words."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: We are developing a new game similar to football and need an artificial intelligence agent to control the players."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: Find me an assistant that can extract information from tables with questions."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: We are working on a project to predict CO2 emissions of a car, the cars and properties are already saved in the data.csv file."}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: We need to automatically categorize user-uploaded images based on their content for a social media platform."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: Please find an appropriate text summarization model for me that can summarize the email conversation happening at work."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: Can you help me create a Python script to extract sentence embeddings for a list of Russian sentences?"}
{"text_id": 203, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting tables in documents. Introduced in the paper PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents by Smock et al."}
{"text_id": 203, "text": "query: Develop a system to help an accountant in detecting tables within a scanned document. The model should identify tables and any graphical representation to enhance the quality of the representation."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We have an artificial intelligence conference to attend, and we need a generated image of a church to use in our presentation."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: Our company is working on a social media app and we want to analyze the content of images posted by users. Can you help us identify objects, animals, and scenes in the images?"}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: We are a market research startup. We need a simple reporting tool that takes text and read it out loud with a female English voice."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: Help me make an automatic cropping tool for my app. I need the app to detect the location of products in food images and make a box around them for cropping."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: The client is launching a new shoe brand and needs a video ad showing a person jumping rope while wearing their shoes."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: Our company is developing a security system for public places. We need a tool to detect violent situations in real-time using the live video feed from the CCTV cameras."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: I need to generate some creative one-liners related to pets."}
{"text_id": 259, "text": "document: YOLOv8s model for PCB defect segmentation. The model is trained to detect and segment PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 259, "text": "query: An electronics inspection company needs to detect and segment defective components on printed circuit boards."}
{"text_id": 55, "text": "document: Vintedois (22h) Diffusion model trained by Predogl and piEsposito with open weights, configs and prompts. This model generates beautiful images without a lot of prompt engineering. It can also generate high fidelity faces with a little amount of steps."}
{"text_id": 55, "text": "query: We need a unique and detailed illustration for our science fiction book cover, specifically a futuristic city with flying cars."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: Extract descriptive text about an artwork which needs to be added in our online museum catalog."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: A news company wants to develop a system that automatically creates brief summaries of news articles. Help them with the task."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: Create an AI system to automatically generate an accurate caption of an image we provide."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: A healthcare startup needs to extract features from medical terms for their app's search functionality. They asked for your help."}
{"text_id": 91, "text": "document: A Text-to-Video model using Hugging Face Transformers library. Model is capable of generating video content based on the input text."}
{"text_id": 91, "text": "query: Our client is a filmmaker who wants to create short videos for social media based on popular quotes. Can you convert the quote, \"The only way to do great work is to love what you do,\" into a short video?"}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: We have a support chatbot for the users of a mobile app who have questions about its features. Help them manage and answer their questions with given chatbot."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: My publication generates a lot of medical articles. I would like to build an AI program that automatically answers readers' questions based on the content of the medical articles."}
{"text_id": 325, "text": "document: VideoMAE model pre-trained for 2400 epochs in a self-supervised way and fine-tuned in a supervised way on Something-Something-v2. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 325, "text": "query: We are building a video player, and we need to categorize user-uploaded videos."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: The HR department would like to use available employees information in a table to decide who should be assigned responsibility for a project. The project will run for one month and needed people with less talkative attitude."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: Create a conversational agent that can handle queries and engage in small talk with the users."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: We need to develop a system for classifying sports video clips."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: We want to predict the carbon emissions of different actions based on a variety of factors, such as energy usage and location."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: Create a multilingual script that will easily identify named entities from any language."}
{"text_id": 169, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset. It is used for depth estimation in computer vision applications."}
{"text_id": 169, "text": "query: Our client is a construction company. They would like us to design a robotic application that estimates the depth of objects in their building site from a single image."}
{"text_id": 321, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al."}
{"text_id": 321, "text": "query: I want to help movie producers to understand what genre their movie fits in by applying AI to their trailers."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: We are building an AI-driven chatbot and want to find the most relevant answer based on user input."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: We're building an AI assistant that can provide semantically relevant movie synopsis based on a given query about the movie's plot or theme."}
{"text_id": 188, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. It is trained on ImageNet-1k at resolution 224x224 and can be used for image classification."}
{"text_id": 188, "text": "query: I have an image of food here, and I want to know what type of cuisine it is. Can you tell me the model to do so?"}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: I am building a product to help tourists travelling to Spain. Their spoken English needs to sound more like Spanish for effective communication."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: We have an email from our Dutch-speaking client and need to translate it into English to discuss the matter with our multinational team."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: A construction company needs a safety monitoring system. Is there any hard hat detection model we can use?"}
{"text_id": 519, "text": "document: T5-Base is a Text-To-Text Transfer Transformer (T5) model with 220 million parameters. It is designed to perform various NLP tasks, including machine translation, document summarization, question answering, and text classification. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be used with the Transformers library."}
{"text_id": 519, "text": "query: We want to summarize the findings of our recent scientific paper in a single paragraph."}
{"text_id": 748, "text": "document: This checkpoint is a wav2vec2-large model that is useful for generating transcriptions with punctuation. It is intended for use in building transcriptions for TTS models, where punctuation is very important for prosody. This model was created by fine-tuning the facebook/wav2vec2-large-robust-ft-libri-960h checkpoint on the libritts and voxpopuli datasets with a new vocabulary that includes punctuation."}
{"text_id": 748, "text": "query: I am a voice actor, I need to transcribe my script with proper punctuation before my recording."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: Our podcast is using audio previews with automated voices. Generate a sample for an upcoming episode."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: We need to create a voice-over for our animation video, and we want to use a Text-to-Speech API for this task."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: An essay was just submitted. We need to understand if the essay is about travel, cooking, or dancing."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: We are having a meeting in office. Implement a pipeline that detects when someone speaks during the meeting."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: Design a smart vending machine that can tell products apart just by taking a picture of them."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: I need help answering complex questions about my COVID symptoms to provide a more in-depth understanding of my health."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: Analyze the given text and identify entities such as names, organizations, and locations in it."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: We are working on a new health and safety application for a factory, we need a model that identifies a sequence of working actions using video inputs to validate whether the action conforms to the established safety regulations."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: Our organization wants to develop a project to provide users with images based on the text description they provide."}
{"text_id": 907, "text": "document: This is a trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 907, "text": "query: Design an agent that can play SoccerTwos using the ML-Agents framework."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: We plan to build a  question-answering feature for our customers. Analyze if a given answer is relevant to the specific question."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: Our client needs to analyze public opinions on a stock they are about to invest in. We want to know if the sentiment is positive or negative."}
{"text_id": 583, "text": "document: Pygmalion 2.7B is a proof-of-concept dialogue model based on EleutherAI's gpt-neo-2.7B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, including real and partially machine-generated conversations. The model is intended for use in generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 583, "text": "query: I'm a game developer. I want to create a chatbot for a medieval knight character in my game. The knight is brave, loyal and follows the code of chivalry."}
{"text_id": 471, "text": "document: A pre-trained RoBERTa model for question answering tasks, specifically trained on the SQuAD v2 dataset. It can be used to answer questions based on a given context."}
{"text_id": 471, "text": "query: Our web-app users can't find certain information on different webpages. Can you help them by developing a search system that can answer the questions users will provide?"}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: I want a way to compare a list of sentences in different languages and measure similarity directly."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: We are a company developing drones. Find out the distances of various objects from the drone's camera."}
{"text_id": 590, "text": "document: JohnBot is a conversational model based on the gpt2 architecture and trained using the Hugging Face Transformers library. It can be used for generating text responses in a chat-based interface."}
{"text_id": 590, "text": "query: We are designing an online surfing forum. We need a chatbot to help guid the new users."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: We are an AI-based anime creator. We want to utilize text prompts for creating high-quality anime images."}
{"text_id": 804, "text": "document: The model is a fine-tuned version of jonatasgrosman/wav2vec2-large-xlsr-53-english for a Speech Emotion Recognition (SER) task. The dataset used to fine-tune the original pre-trained model is the RAVDESS dataset. This dataset provides 1440 samples of recordings from actors performing on 8 different emotions in English, which are: emotions = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']."}
{"text_id": 804, "text": "query: Our company is building a voice assistant that can detect emotion. We want to use a pre-trained model to recognize emotions in speech and give us the probability of each emotion."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: The company requires an effective information retrieval system to quickly and accurately search through their internal knowledge base and documentation."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: The marketing team wants to analyze a customer dataset to know more about their purchase habits. Help them answer questions about the dataset."}
{"text_id": 770, "text": "document: Facebook's Hubert-Large-Finetuned is an Automatic Speech Recognition model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. It is based on the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. The model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech and Libri-light benchmarks with various fine-tuning subsets."}
{"text_id": 770, "text": "query: I am building a virtual assistant and need to convert a short sample of a voice message to text."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: I am working on a product and want to analyze customers feedbacks. Classify each feedback into an emotion in our survey."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: I have a collection of old photos, and I found out that some of them have handwritten texts. I'd like to convert the handwritten texts in the images into digital texts."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: A social networking platform wants to utilize a vision Transformer that can classify the age of a person in a photo. The goal is to find a pretrained model that can perform this task."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: Develop a system that can generate short video clips from a given textual description of a scene."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: Our marketing department needs an application to analyze customer reviews and determine their sentiment, such as positive, negative, or neutral."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: A game development company has just launched a new game called CartPole. Tell me how I can create an AI agent to play this game and achieve a high score."}
{"text_id": 145, "text": "document: A depth estimation model based on the DPT architecture."}
{"text_id": 145, "text": "query: Our latest project involves computer vision tasks, and we need to build a model for depth estimation. We are particularly interested in a large-scale and accurate DPT architecture."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: We are an energy management company and we want to forecast carbon emissions."}
{"text_id": 726, "text": "document: This model was trained by mio using fate recipe in espnet. It is a text-to-speech model that can convert text input into speech output."}
{"text_id": 726, "text": "query: I want to create a personal assistant that uses Text-to-Speech, sample a text to be converted to speech."}
{"text_id": 773, "text": "document: Vietnamese end-to-end speech recognition using wav2vec 2.0. Pre-trained on 13k hours of Vietnamese youtube audio (un-label data) and fine-tuned on 250 hours labeled of VLSP ASR dataset on 16kHz sampled speech audio."}
{"text_id": 773, "text": "query: Imagine we are a transcription company and want to provide audio transcription services for the Vietnamese market."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: Our client, a sports analytics company, has a database of Olympic Games data, including the host city and year. They want to know in which year Beijing hosted the Olympic Games."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: We need a system that can answer questions from the data in our company's sales spreadsheet."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: As a photo retouching company, we need to remove unwanted objects from images and fill the removed portions with suitable content."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: We have developed a new AR-based application in which users can ask questions about objects and images using different languages. We need a model capable of answering the questions based on the image."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: very good, good, average, bad, very bad."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: Automatically, tell me what I'm seeing in this photo from our last vacation. \"-Describe the objects in the photo and their colors.\""}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Determine whether the given image contains either a cat or a dog."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: I would like to detect a dog, cat, and some bikes in an image url."}
{"text_id": 878, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 878, "text": "query: We are an automobile company and want to predict carbon emissions for our upcoming car models. Provide the required code."}
{"text_id": 249, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 249, "text": "query: Please create a solution for identifying road infrastructure objects in an image using semantic image segmentation."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: I want to ask \"What is the process of photosynthesis?\" and have a list of possible answers in which the most similar sentence is on top."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: Build a function that receives an image URL and a list of descriptions. The function should return the probabilities for each description matching the image."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: I am a doctor trying to detect platelets, red blood cells, and white blood cells in images. What model do you recommend for that?"}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: Create a translation system for translating English text to French using Hugging Face."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: You are designing an AI system for a company that wants to automatically apply color to sketched images. They want a way for the software to understand user-drawn sketches and colorize the images using the theme provided."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: Analyze the image to identify the primary object and its category."}
{"text_id": 378, "text": "document: FinBERT is a pre-trained NLP model to analyze sentiment of financial text. It is built by further training the BERT language model in the finance domain, using a large financial corpus and thereby fine-tuning it for financial sentiment classification. Financial PhraseBank by Malo et al. (2014) is used for fine-tuning."}
{"text_id": 378, "text": "query: A customer has a collection of news articles and wants to determine the sentiment of the articles related to the finance domain. Implement a solution using the FinBERT model."}
{"text_id": 543, "text": "document: A Swedish to English translation model trained on the OPUS dataset using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece."}
{"text_id": 543, "text": "query: A Swedish customer is getting error and has raised a ticket. We need to translate the ticket into English before fixing it."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: We are a company specializing in promotional graphics. Our client would like an upscaled image of their server room for use in marketing materials."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: I would like to know how much carbon my car emits with the given features using the available model."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: There is a customer wanting to detect cats and dogs in the images uploaded to their website."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: Design a software that will read the Spanish language for an audiobook targeted for Spanish native speakers."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: I have an article which is too long. Can you help me to summarize the content?"}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: The local newspaper is looking for a way to automatically create short summaries of lengthy news articles."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: I want to build a webpage about city landscape. To build the webpage, I want to find a model that can segment buildings from aerial and satellite images."}
{"text_id": 134, "text": "document: A document question answering model based on LayoutLMv2, which can be used to extract answers from images with text and layout information."}
{"text_id": 134, "text": "query: The company we are working with has a collection of scanned documents. We need to retrieve specific information from these documents upon request."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: I am a data scientist working on the Pokemon dataset, and I need to predict the HP of a new Pokemon based on its input features."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: We are creating an application to work with scientific journals. We need to extract text from scanned journal pages so we can analyze it later."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: We are nutritionists trying to get insights from a list of food items and their nutritional values in a table. Extract information about the nutrient content of the food according to our customers' requirements."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: The company is developing an AI-powered code editor. How can we integrate a code completion feature for various programming languages?"}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: I am currently working on a research project and need to classify some text data into different categories."}
{"text_id": 329, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is trained for video classification task, specifically for RealLifeViolenceSituations."}
{"text_id": 329, "text": "query: Our security company needs to analyze real-time video footage to identify violence in certain situations. What can we do using the given API?"}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We are developing a system to classify and organize videos based on their content. We need the assistant to help us with this."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: I need an automated system to monitor the sounds in our laboratory and identify any potentially hazardous noise."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: joy, sadness, anger, fear, neutral."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: We've been monitoring server performance metrics, and we need to be alerted when the data points to anomalous behavior. Design an automatic anomaly detection system."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: We want to segment cityscape images and analyze different objects in the image."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: We are focusing on organizing images of cell tissues in a hospital. We want to extract the features of these images and classify them."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: We are building an AI assistant for the web. Write some interesting facts about the moon for our user."}
{"text_id": 35, "text": "document: This model is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It is designed to be used with the diffusers library and can be integrated into existing workflows by including a vae argument to the StableDiffusionPipeline. The model has been finetuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets and has been evaluated on COCO 2017 and LAION-Aesthetics 5+ datasets."}
{"text_id": 35, "text": "query: Have a new startup focusing on cloud services. I want to create marketing materials with images based on key phrases like \"cloud computing,\" \"secure data storage,\" \"high-speed internet,\" and \"scalable solutions.\" Can you generate images based on these phrases?"}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: Our social media platform needs a moderation tool to filter out inappropriate contents from user posts."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: As a media company targeting the eastern markets, we need help identifying the content of Chinese texts and images."}
{"text_id": 489, "text": "document: Multilingual XLM-RoBERTa large model for extractive question answering on various languages. Trained on SQuAD 2.0 dataset and evaluated on SQuAD dev set, German MLQA, and German XQuAD."}
{"text_id": 489, "text": "query: A user is asking about the importance of model conversion in AI. Use the given context to provide an appropriate answer."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: We need to convert some audio recordings to text to analyze customer feedback for an e-commerce company."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: We are a power plant that needs to predict carbon emissions. We would like to use the model to make predictions based on our data."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: A marketing agency requires a detailed image generated based on the description provided. It includes a man wearing a futuristic outfit in a digital cityscape with neon lights."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: Create a system that can identify names, locations, organizations, and miscellaneous entities from a paragraph of text."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: We would like to see an example of a dream bedroom interior design using computer-generated images."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: I have the answer \"42\" and its context is from a passage where it is mentioned as the ultimate answer to life, the universe, and everything. Generate a suitable question for this answer."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: We are authors collaborating on a sci-fi novel. We need an AI's insight to create a space travel concept."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: We are building an application that searches through large documents to find answers to questions. Develop a solution that can parse text and answer questions accurately."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: I want to build an application that identifies objects in images using computer vision."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: Our company requires a voice assistant that can read a list of items in different supported languages."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: Can you help me predict the quality of wine based on the provided features for a boutique winery we are working with?"}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: Our company works on digitizing handwritten documents, and we need to convert these images into text."}
{"text_id": 478, "text": "document: This model is a distilled version of deepset/bert-large-uncased-whole-word-masking-squad2, trained on the SQuAD 2.0 dataset for question answering tasks. It is based on the BERT-medium architecture and uses the Hugging Face Transformers library."}
{"text_id": 478, "text": "query: We are organizing a research group to discuss articles of different topics. We need to extract given answers to specific questions from the articles."}
{"text_id": 515, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on the majority of NLU tasks with 80GB training data. This is the DeBERTa large model fine-tuned with MNLI task."}
{"text_id": 515, "text": "query: My company is planning on using natural language processing to classify support tickets. How can I apply this API for that purpose?"}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: A web media company needs to design banners for their upcoming event. How should they use this model to generate creative images?"}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: We are developing an AI system for the artist community. They need us to classify artworks based on the images provided."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: Create a program to play the video game Pong using a trained reinforcement learning model."}
{"text_id": 481, "text": "document: This is Roberta Base trained to do the SQuAD Task. This makes a QA model capable of answering questions."}
{"text_id": 481, "text": "query: As an e-learning app, we want to provide instant answers to the questions related to computer programming that our users might ask. To achieve this, we need to add a question-answering feature to our app."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: I am interested in translating an audio file from Hokkien to English."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: Write a report about cars carbon emissions, I will feed you the data of cars engine and other features that I know."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: \"John went to Harvard and later worked at Microsoft.\""}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: We want to build an app that can tell if an image is of a dog or food. We need help in predicting the image category."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: We need to create a Japanese natural language processing model. It will help us to fill in the blanks in sentences in Japanese."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: We are a startup that builds language learning apps for users who want to learn different languages. We want to fill a missing word in the sentence for the exercise."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: Analyze an investment table containing company names, sectors, market capitalization, and P/E ratios, and generate a short summary."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We have a scanned document with an image of the text required to provide details about the current phone model of a person. Extract the phone model information from the text."}
{"text_id": 594, "text": "document: BlenderBot-1B is a large-scale open-domain chatbot model that can engage in conversations, ask and answer questions, and display knowledge, empathy, and personality. This distilled version is smaller and faster than the original 9.4B parameter model, making it more accessible for use."}
{"text_id": 594, "text": "query: Plan an email to a coworker that reminds them about a report deadline, which is tomorrow, and they need to send it to the manager."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: Identify people's names in a piece of text."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: Can you help me identify the role of this person in the picture, here is the question \"Who is the person wearing a red shirt in the image?\"?"}
{"text_id": 70, "text": "document: BLIP-2 model, leveraging Flan T5-xl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, giving the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 70, "text": "query: As an application builder in a video content company, I am helping to build a video suggestion product. We need to know which content is the most attractive."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Our marketing department needs a catchy slogan based on the existing slogan \"Delivering Happiness\". Can you help out?"}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: Find the names of the companies that are mentioned in the given text."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: We are developing an application to test if dog owners unknowingly feed their pets inordinate amounts of human food. Implement an image classifier that can identify dogs and food in photos."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: I want to create a machine learning model to predict tips from restaurant customers, considering their bill and other related factors."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Our literary club is organizing a brainstorming session where we need to construct a hypothetical conversation between a futuristic alchemist and an AI assistant."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: As a school teacher, I have to grade the assignments. So, I want the model to compare similarity between my model answer and the answers from students, which will help me to grade them."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: In a virtual world environment, we need to convert a landscape to a scenic Greenery Scenery, while maintaining the overall structure."}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: We are a content creator and are analyzing comments on our video's. See if the user comments are positive or negative."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: In my data science project, I have to predict CO2 emissions of vehicles based on provided data. Can you show me the code to use a pretrained model for this task?"}
{"text_id": 382, "text": "document: RoBERTa base OpenAI Detector is the GPT-2 output detector model, obtained by fine-tuning a RoBERTa base model with the outputs of the 1.5B-parameter GPT-2 model. The model can be used to predict if text was generated by a GPT-2 model."}
{"text_id": 382, "text": "query: I need to identify if the given text is generated by GPT-2, as I suspect an AI has written this article."}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: I need to generate a text description for an image."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: We need to help the user to get the answer to the question based on the given context."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: Our business is expanding worldwide. We want to build an automated translation system that handles human translations comparing the sentences' similarities across multiple languages."}
{"text_id": 184, "text": "document: A tiny-vit-random model for image classification using Hugging Face Transformers."}
{"text_id": 184, "text": "query: I am building a mobile app for my startup, and I need a model that can perform image classification using low-resource architecture."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: We need to count the different blood cells in a given microscopic image to help the medical team analyze the patient's tests."}
{"text_id": 552, "text": "document: This model is a DistilBART-based text summarization model trained on the SAMsum dataset. It can be used to generate summaries of conversational text."}
{"text_id": 552, "text": "query: Your team is developing a game that tells a story based on user actions and decisions. Your current task is to create a summary generator that can condense the dialogue text and provide a brief overview of the story progression."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: A synthetic company wants its model to automatically create a set of 256x256 images to be included in their website. They want to resemble celebrity faces but be out of their provided database."}
{"text_id": 118, "text": "document: A model for Document Question Answering based on the LayoutLMv2 architecture, fine-tuned on the DocVQA dataset."}
{"text_id": 118, "text": "query: A bank customer has recieved a scanned paper document as a PDF, which contains information about his loan details. He wants to know the total loan amount without going through the entire document."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: I'm a German reporter and I need to summarize a long article quickly. Can you help me to build a tool to complete this task?"}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: We want to create a RL agent that can perform well in a \"Hopper\" environment."}
{"text_id": 805, "text": "document: This model is trained on the JTES v1.1 dataset for speech emotion recognition. It uses the Wav2Vec2 architecture for audio classification and can recognize emotions like anger, disgust, fear, happiness, and sadness."}
{"text_id": 805, "text": "query: I want to identify emotions in audio clips provided by my customers over a hotline."}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: A customer needs a fast way to convert short English sentences into German for their travel startup company. Establish a means to accomplish this translation task."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: Our company is working on autonomous vehicles. In order to drive safely, we have to be able to segment every object in the images acquired by the car."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: I want to analyze and segment the images of a city. Build a model to analyze an image."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: I need a model to complete sentences related to medical texts, such as \"Antibiotics are used to treat [MASK] infections.\""}
{"text_id": 454, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data."}
{"text_id": 454, "text": "query: Recently, we found a set of tables containing data about each country's GDP growth rate, pollution, and human development index. We want to find the GDP growth rate of Brazil for the year 2020."}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: I have a lengthy article in French and need a brief summary."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: We're a design firm that wants to create a concept art for a movie based on a futuristic cityscape. Generate an image based on the description \"analog style futuristic cityscape\"."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: A publishing company wants to generate cover images for a new fantasy book series. "}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: Convert a scanned image of a document into text."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: Design a personal assistant that listens to my conversation with my friends in Hokkien language and translates it to English."}
{"text_id": 150, "text": "document: Global-Local Path Networks (GLPN) model trained on NYUv2 for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 150, "text": "query: I need to calculate the depth of an image from the given URL to detect distances in the scene."}
{"text_id": 360, "text": "document: This model is a fine-tuned CLIP by OpenAI. It is designed with an aim to improve zero-shot image classification, text-to-image and image-to-image retrieval specifically on remote sensing images."}
{"text_id": 360, "text": "query: I work for a real estate company, and I need to automatically classify aerial images of properties into categories like residential area, playground, stadium, forest, or airport."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: I am making a website for a Spanish book selling service. I need to create a short summary for the book descriptions. "}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: I want to transcribe the speeches in a video recording into text using a model."}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: As an educational content creator, I need a transcription service for my videos. I want the extracted text to subdub my content for a broader audience."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Build me a system that can separate the audio of two people speaking at the same time in a recorded audio file."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: An article writer is looking for the most similar content on the Internet. Now they need to determine which link is more similar between the test sentence and the two paragraphs given."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: We want to create a 3D model from a photo of our latest product. The idea is to estimate the normal map of the model based on the image."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: I need a conversational AI to create a chatbot that helps users get nutrition facts from an image of food."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: I have a paper written in English, and I need it translated to French."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: Develop a solution to help an animal shelter differentiate between photos of dogs and photos of food for daily updates on their website."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: Could you make a recommendation for designing a homepage banner which includes an image of a butterfly?"}
{"text_id": 751, "text": "document: Facebook's Wav2Vec2 base model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It is designed for automatic speech recognition and can transcribe audio files."}
{"text_id": 751, "text": "query: I've recorded a series of product reviews in audio format, and I need to create text transcripts for them to be published on our website."}
{"text_id": 709, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 709, "text": "query: Let's build a recommendation system for the users who read blog posts. We want to recommend similar blog posts to the users based on the content they are reading."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: A person wants to create an interactive virtual scenario where they will be conversing with a character named John. Please help them get a response as John that is aware of his persona."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: I want to add sound effects to the video game I am developing, based on the type of audio events happening in the gameplay. Whip up a system of audio classification that can detect distinct types of audio events."}
{"text_id": 608, "text": "document: LLaMA-7B is an auto-regressive language model based on the transformer architecture. It is designed for research on large language models, including question answering, natural language understanding, and reading comprehension. The model is trained on various sources, including CCNet, C4, GitHub, Wikipedia, Books, ArXiv, and Stack Exchange, with the majority of the dataset being in English."}
{"text_id": 608, "text": "query: You are developing content for a game with a medieval setting. Write a short story that takes place in a fantasy world."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: \"Cosa sta succedendo oggi nell'economia mondiale?\""}
{"text_id": 170, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 170, "text": "query: The car company wants to test the effect of different models on the perception of distance. They are now asking for a way to estimate the depth of an image."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: We need a system for fast image recognition in our inventory management software that can recognize products based on their images."}
{"text_id": 172, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 172, "text": "query: There is a construction company. They need to develop a system to estimate the depth of a building before starting the construction. The system needs to analyze the photograph of the building and estimate the depth of it."}
{"text_id": 320, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository. The model can be used for video classification into one of the 600 possible Kinetics-600 labels."}
{"text_id": 320, "text": "query: We are working on a platform that can automatically categorize videos by their content. Now we want to identify what kind of video this is."}
{"text_id": 883, "text": "document: A tabular regression model trained with AutoTrain for predicting carbon emissions."}
{"text_id": 883, "text": "query: A research team is working on sustainable emissions management, and they need help in predicting CO2 emissions of vehicles."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: I want to make a short educational video about photosynthesis for kids. Describe the steps to generate the video using the text-to-video model."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: Our team is building a language model to auto-complete or suggest the next part in a piece of code. Your task is to provide us the right API for this purpose."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: We are building a web application that features a search bar in Chinese. We have to make sure that similar queries return relevant results."}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: Implement a speech recognition system that can transcribe an audio in any language."}
{"text_id": 498, "text": "document: DeBERTa-v3-base fine-tuned with multi-task learning on 520 tasks of the tasksource collection. This checkpoint has strong zero-shot validation performance on many tasks, and can be used for zero-shot NLI pipeline (similar to bart-mnli but better)."}
{"text_id": 498, "text": "query: We run a platform that connects freelancers to employer projects. We need a tool to match the user skills in their profile to the skills required for a given project."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: We need to create a question answering system that can give correct answers based on a table containing data."}
{"text_id": 876, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions based on input features."}
{"text_id": 876, "text": "query: Our company is working on a project to reduce carbon emissions. We would like to predict carbon emissions based on specific features."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: In our electronics manufacturing plant, we need to quickly detect and segment defects in printed circuit boards (PCBs) for quality control."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: We have an image dataset, and we need to generate descriptions for each image for our online marketplace."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: My team and I are building a twitter bot to respond to customer complaints automatically. We are training it with several positive/negative examples, but we need to validate the sentiment of the tweets we are analyzing."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: We are a consulting firm, and our legal department needs an effective way to extract information from various legal documents. Make use of a document question answering model to help them."}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: Detect the named entities in a given piece of text."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: Our company is developing a voice-controlled fitness app. We need to incorporate a model capable of understanding and differentiating spoken commands from users."}
{"text_id": 861, "text": "document: Multi-class Classification Model for Carbon Emissions"}
{"text_id": 861, "text": "query: Help me implement a solution to predict the carbon emissions for different models of vehicles using a pre-trained model."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: Assist the user to find answers to questions in Korean text."}
{"text_id": 524, "text": "document: Helsinki-NLP/opus-mt-fr-en is a machine translation model trained to translate from French to English. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 524, "text": "query: To make our user manual accessible to everyone, we need to translate it from French to English."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: The botanist I am working with just sent me this table containing iris flower features. What do you say? Does it belong to setosa, versicolor, or virginica?"}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We are an online platform, and we need to get answers for sports-related queries from tables."}
{"text_id": 209, "text": "document: detr-doc-table-detection is a model trained to detect both Bordered and Borderless tables in documents, based on facebook/detr-resnet-50."}
{"text_id": 209, "text": "query: You are a scanning company. Your main service is scanning files, books and documents. We need to identify tables in these scanned documents."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: I need to extract features from a dataset consisting of product reviews in order to use them in a recommender system."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: We want to find the semantic similarity of a group of sentences."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: For a social media campaign, analyze the sentiment of tweets mentioning our brand with keywords \"product,\" \"new version,\" and \"feedback.\""}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Urban planners need an image analysis tool to automatically segregate buildings, roads, objects, and natural features in an image of a cityscape."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: I need a chatbot. Can you show me how to create one that can have a conversation with users?"}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: Our company builds virtual spaces for people to explore through a VR headset. We need to create a 3D image of a spaceship on the moon's surface using text prompts."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: The company has a customer service department and wants to analyze calls of distressed customers better. Create an emotion recognition system to help identify the emotions expressed by customers."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: Summarize an article in French about economics."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: Prepare a system that will answer questions about statistical information in tabular data."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: Our chatbot system needs to generate human-like responses to user input. We require an implementation to provide the chatbot with the capability to generate those responses."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: Our team is building a robot for a research and rescue mission. We need to calculate real-world distances."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: A Korean doctor will use the model to classify diseases resarch from the given medical image."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: A mobile app company is working on improving the search functionality of their app. The search should be able to recognize the category of a particular image provided by the user."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: As a researcher, I want to compare the similarity of research paper abstracts so I can find papers that are closely related to my topic."}
{"text_id": 124, "text": "document: Donut model fine-tuned on DocVQA. It consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings, after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 124, "text": "query: Alex is working in the warehouse of a shipping company. He needs a tool to read and understand orders in the documents easily."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: As a student, I need to extract relevant information from my scanned textbook pages. I will provide the contents of the page in text form and a question related to the text."}
{"text_id": 556, "text": "document: This model is a fine-tuned version of Einmalumdiewelt/T5-Base_GNAD on an unknown dataset. It is intended for German text summarization."}
{"text_id": 556, "text": "query: Summarize the German article to get the main points."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query:  \u0645\u0631\u062d\u0628\u064b\u0627 \u060c \u0647\u0630\u0627 \u0627\u062e\u062a\u0628\u0627\u0631 \u062a\u0634\u063a\u064a\u0644."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: I am building an application to help users extract specific information from their scanned documents. Design a system to achieve this task."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: I want to build an application that can detect animals in a picture. It requires an image classification model that concentrates on species like cats, dogs, birds, and fish."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: How can I use a model that translates English spoken language into French spoken language?"}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: We need a solution to extract the text contents from the images provided by our suppliers. They contain crucial product information."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: Our project is to make a website that has a painterly effect on the users' uploaded profile pictures. Show me how to apply this style on photos."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: A customer needs help choosing a new phone, and wants a conversational AI model to provide recommendations."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: I am a software engineer working for a cybersecurity company, and I need to detect if a specific audio clip is from a known hacker by comparing it to other audio files."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: I want to develop a speech-to-speech translation application that helps tourists understand and communicate with locals in different languages."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: Your friend has an audio recording of a conference call and she needs a transcribed text version of it."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: We need to identify household items to automate the home inventory process."}
{"text_id": 880, "text": "document: A tabular regression model trained using AutoTrain to predict CO2 emissions (in grams)."}
{"text_id": 880, "text": "query: Our CEO wants to know the CO2 emissions generated by our company's vehicle lineup. Please predict the CO2 levels now."}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: I own a travel agency and would like to create a flyer that showcases beautiful scenery. I have a few photos, but I'd like to change their style to make them more visually appealing. Can you assist me in transforming the input images into a different style?"}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: Provide me with a solution that can help us distinguish the speaker's voice from background noises in a recorded meeting."}
{"text_id": 630, "text": "document: Parrot is a paraphrase based utterance augmentation framework purpose built to accelerate training NLU models. It offers knobs to control Adequacy, Fluency, and Diversity as per your needs. It mainly focuses on augmenting texts typed-into or spoken-to conversational interfaces for building robust NLU models."}
{"text_id": 630, "text": "query: \"Artificial intelligence has the potential to revolutionize various industries, including healthcare and transportation.\""}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: Can you create a model to help me recognize the type of sound in an audio file?"}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: We are the marketing department for a new product launch. Can you write a sample promotional text for our product?"}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: My client has an ecommerce website. She wants to automatically detect and classify the type of footwear in a given image."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: We have agents who speak English and need them to be able to communicate with French-speaking customers on the phone."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: Our company is trying to develop a chatbot to interact with customers. We want to implement a conversational AI into our application."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: I need a model that will help me segment different objects in images for creating better virtual reality experiences."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: I am researching historical documents and need to transcribe handwritten texts. Can you help me?"}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: We are aiming to predict the stock closing prices tomorrow for our investment research. Predict the closing price for given data."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: An astrophysics student wants to generate creative images of universes for her final project. How can she use your model?"}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Develop a solution to classify images into different categories based on zero-shot classification using natural language descriptions."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: We are an Indian health company looking to expand our services. Translate our documents from Hindi to Chinese."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: Create a software function to translate a Dutch review of the restaurant to examine customer feedback."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: Please help me to build an AI model that can take speech input of a language and transform it into speech in another language."}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: Our audiobook company needs a quick way to convert text from books to speech."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: I want the AI to create a painting inspired by Sunset, Ocean, Seagulls, and Palm Trees."}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: Our startup is working on a project that allows users to easily find information from tables. Please help us extract relevant information based on a user's question."}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: We are working on a language learning app, and would like to perform speech-to-speech translation of English audio to Hokkien audio."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: There is a transcript of a conversation in French. Punctuate it correctly."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: Create a voice alert system that reads a warning message in Arabic. The message is \"\u0627\u0646\u062a\u0628\u0647! \u0646\u0638\u0627\u0645 \u0627\u0644\u0625\u0646\u0630\u0627\u0631 \u0642\u062f \u0627\u0646\u062e\u0641\u0636.\""}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: Develop a weather report application that provides the user with a spoken weather forecast for the day."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: We are a company focusing on building products for sports simulations. We need to understand the player's actions from a video and make predictions."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: We have an image and a set of text descriptions. We need to find the text description that best represents the given image."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: Our team wants to predict the energy-critical materials we are working with, categorize them, and identify potential candidates for further study."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: Our company is building a robotic vacuum cleaner, and we need to estimate the depth of objects in the room in real-time."}
{"text_id": 467, "text": "document: This is a bert-large model, fine-tuned using the SQuAD2.0 dataset for the task of question answering. It is designed for extractive question answering and supports English language."}
{"text_id": 467, "text": "query: Emily is curious about how water is distributed around earth. Use our question answering API to find an appropriate response to help her."}
{"text_id": 3, "text": "document: SapBERT is a pretraining scheme that self-aligns the representation space of biomedical entities. It is trained with UMLS 2020AA (English only) and uses microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext as the base model. The input should be a string of biomedical entity names, and the [CLS] embedding of the last layer is regarded as the output."}
{"text_id": 3, "text": "query: Given a set of biomedical terms, find their vector embeddings that capture meaningful relationships between them."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: The manager needs a translation service that can translate an English text to multiple languages."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: We are building an online meeting app, and we need to detect when participants are speaking during meetings."}
{"text_id": 631, "text": "document: Google's T5 fine-tuned on CommonGen for Generative Commonsense Reasoning. CommonGen is a constrained text generation task, associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts; the task is to generate a coherent sentence describing an everyday scenario using these concepts."}
{"text_id": 631, "text": "query: I want to create short sentences based on input words but in complete sense for understanding. The words provided are \"tree\", \"plant\", \"ground\", \"hole\", \"dig\"."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: As a teacher, I want to transcribe my lectures into text format to provide students with additional written material."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: A conference is being held and there are participants speaking very softly. We need to improve the speech quality for people to understand."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: We need a realistic image of an astronaut riding a horse through a forest area. Can you generate one for us using a text-to-image generator?"}
{"text_id": 449, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It can be used for answering questions related to a table."}
{"text_id": 449, "text": "query: The marketing team of our company is having its meeting tomorrow. They will need accurate answers to the questions related to the data in a table."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: We need to detect the structure of tables in a document, specifically identifying rows and columns."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We have developed a GTA5 game AI model and now want to apply it for traffic prediction of GTA5."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: We are building a platform to enable non-programmers to create basic Python programs through natural language instructions. Kindly implement a solution to generate Python code."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: I am working in a fashion e-commerce startup and I want to classify an image and its description into different categories."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: A professor wants to analyze the grammatical structures used by famous authors in their novels. Extract the part-of-speech tags for a given text passage."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: I own an e-commerce shop and have multiple images of products with different categories. I need to categorize these images automatically to manage them efficiently."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: We are building an application requiring high-resolution human face images. Let's generate a high-quality face image."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: Can you help rephrase a conversation so that it makes it hard or impossible for someone to tell which person is talking?"}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: We are a creative digital marketing agency. We want to create advertisements based on an input image and text guidance for our client."}
{"text_id": 274, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on instruct pix2pix images."}
{"text_id": 274, "text": "query: A company wants to use image manipulation techniques for their marketing campaign. Help them to generate a creative image from the text \"happy summer\"."}
{"text_id": 667, "text": "document: This model has been pre-trained for Chinese, training and random input masking has been applied independently to word pieces (as in the original BERT paper). It can be used for masked language modeling."}
{"text_id": 667, "text": "query: I am a bilingual translator from a Chinese and English speaking community. I need to predict the missing characters in a Chinese phrase."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: I want to create a recipe recommendation application that identifies food items in an image, can you help me in creating a model for detecting food items?"}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: I need an application that can create realistic human speech from text. The text will be created by a speech recognition software."}
{"text_id": 613, "text": "document: TODO card. Mix of (GPT-J-6B-Janeway + PPO_HH_GPT-J) + Pygmalion-6b-DEV (V8 / Part 4). At a ratio of GPT-J-6B-Janeway - 20%, PPO_HH_GPT-J - 20%, Pygmalion-6b DEV (V8 / Part 4) - 60%."}
{"text_id": 613, "text": "query: The advertising company now needs a catchy slogan for their client's product. Please generate a creative slogan."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: You are part of a team that is designing an audiobook app. The app must be able to convert text to speech for Korean content."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: I have recorded an audio file of a conversation between me and a friend, and I need an assistant to transcribe the spoken words into text."}
{"text_id": 649, "text": "document: ByT5 is a tokenizer-free version of Google's T5 and generally follows the architecture of MT5. ByT5 was only pre-trained on mC4 excluding any supervised training with an average span-mask of 20 UTF-8 characters. Therefore, this model has to be fine-tuned before it is usable on a downstream task. ByT5 works especially well on noisy text data, e.g., google/byt5-small significantly outperforms mt5-small on TweetQA."}
{"text_id": 649, "text": "query: I want to build a news headline generator that can write a concise headline based on the given article summary."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: Develop a solution to extract information from complex documents with multiple elements like tables, images, and text."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: I am organizing an event. I need to analyze and sort twitter messages by their sentiment - either positive, negative, or neutral."}
{"text_id": 562, "text": "document: This repository contains the mT5 checkpoint finetuned on the 45 languages of XL-Sum dataset. It is a multilingual abstractive summarization model that supports text-to-text generation for 43 languages."}
{"text_id": 562, "text": "query: Our company wants a short headline of the news on the current situation of COVID-19 vaccine misinformation."}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: We received a request to convert a Telugu script into a male voice sound file. Can you help us with this?"}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: I am an eSports coach and I want to identify the categories of video clips that best represent the skills of my players."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: The marketing team needs to create a summary of our latest product's key features and benefits for press releases."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: Create a translation from English article about climate change to Russian language."}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: I want to generate Python code based on a description of what my code should do, such as \"create a function that reverses a given string\"."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: I got stuck with one of my history projects, and I need a precise answer to a question. How can I make use of AI to solve this situation?"}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: We are an educational institution that wants to know which student has the highest total grades."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: I have an audio recording of my meeting that I want to transcribe into text."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: We are an industrial company making robots. We need to generate depth maps for the visual inputs that our robot's camera receives for enabling better navigation."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: Analyze the sentiment of a product review and break down the emotions such as anger, joy, worry, sadness, love, and surprise."}
{"text_id": 685, "text": "document: LEGAL-BERT is a family of BERT models for the legal domain, intended to assist legal NLP research, computational law, and legal technology applications. This is the light-weight version of BERT-BASE (33% the size of BERT-BASE) pre-trained from scratch on legal data, which achieves comparable performance to larger models, while being much more efficient (approximately 4 times faster) with a smaller environmental footprint."}
{"text_id": 685, "text": "query: Help me generate advice on a legal matter involving intellectual property protections by filling in the given text \"As the <mask> of your company's intellectual property, it is important to take necessary steps to protect it.\""}
{"text_id": 349, "text": "document: A zero-shot image classification model based on OpenCLIP, which can classify images into various categories without requiring any training data for those categories."}
{"text_id": 349, "text": "query: The company is cataloging new images for the website. We need to categorize these images into different sections."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: Help me summarize Russian dialogues with a model."}
{"text_id": 775, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Chinese. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Chinese using the train and validation splits of Common Voice 6.1, CSS10 and ST-CMDS."}
{"text_id": 775, "text": "query: I want to transcribe Chinese spoken audio to text. Build me something that can help."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: We are building an application that generates art from text descriptions. Users provide text prompts, and we want to display art inspired by what they write."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: We got a recording from an event, but there's a lot of background noise. Can you separate the main speaker from the rest of the noise?"}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: Help me transcribe some random Japanese audios in my project."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: The AI chatbot needs to return the translated text for the given input when asked."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: Our client wants to use a shoe-generator model for generating potential sneaker designs for their new product line."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: I developed a model to balance the pendulum in simulation, what should I do?"}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: We need a model to transcribe audio files in Arabic. The audio comes in different formats and we want to obtain transcriptions from audio files."}
{"text_id": 578, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 578, "text": "query: I am a doctor, and I need a chatbot that helps me answer automation questions about hospital issues."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: We are a team of engineers working on a multimodal Visual Question Answering system. We are building an application to answer questions based on images."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: I am building AI application which can automatically detect exercises in the gym with the user providing recorded video of exercises, create a model to detect different exercises in a given video."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: Design a language translation system that takes English text as input, and translates it to German."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: We are building a flower delivery service website, and we want to show suggestions to users about what kind of iris flower they might like based on some given features."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: I have a picture of an animal that I do not know what it is. I need to identify the animal in this photo."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: I am building a system to help users when submitting a document, using AI to extract table data from the document automatically. What model can provide a solution?"}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: I want to build a service that can translate a message from one language to another. What do I need to do?"}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: I just recorded a podcast with multiple guests. I need to identify each speaker with a classifier."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: I need a personal assistant which can understand 10 different languages to answer my questions based on provided context."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: Create a children's story download feature based on the generated line \"Once there was a magical tree in the enchanted forest.\" The feature should generate an image according to the given line."}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: Create an AI-based social media post scheduler that fills in the missing word in a given sentence to make it engaging and interesting."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: Nowadays, urban planning agencies are prioritizing smart city development. We want to develop an application that allows segmentation of outdoor city images."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: Our client is an e-commerce website that sells art pieces. We want to use AI to remove watermarks from their preview images."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: A touristic agency is receiving pictures from their clients, and they want to convert these images into textual descriptions, so they can use these descriptions in their website."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: Create a model to predict the survival of passengers in the Titanic tragedy based on their personal information."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: A streaming service would like to automatically classify music genres based on their audio. Help them build a model that can classify audio files."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: I have created a new sign-up page and I want a system to verify if the typed input is gibberish or valid before allowing users to sign up."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: Create a code snippet to classify a news article into politics, economy, entertainment, or environment using zero-shot classification."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: Develop a solution for a social network to analyze the sentiment of user posts."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: We are building a game engine to control a hopper. We want a pre-trained model to help navigate the environment."}
{"text_id": 525, "text": "document: A Chinese to English translation model developed by the Language Technology Research Group at the University of Helsinki. It is based on the Marian NMT framework and trained on the OPUS dataset."}
{"text_id": 525, "text": "query: I have an e-commerce business in China, and I need to translate customer messages from Chinese to English. Please create a model to do that."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: I want to build a tool for helping users complete Japanese sentences by predicting missing words."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: Develop a monitoring tool to analyze camera live feed and estimate the depth of objects in the scene."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: Our company is developing an art application, and we want to generate a church image using Google's DDPM model."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: Our company wants to develop an application that can notify users about their home security system status by identifying keywords in the audio recordings."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: We need to extract important features from sentences in order to classify them into appropriate categories based on semantics."}
{"text_id": 541, "text": "document: A Hugging Face model for translation between Catalan (ca) and Spanish (es) languages, based on the OPUS dataset and using the transformer-align architecture. The model has been pre-processed with normalization and SentencePiece."}
{"text_id": 541, "text": "query: We have a multilingual website and need to translate text between Catalan and Spanish."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: I am working on a construction site safety compliance project. I need a solution to automatically analyze images of the site and identify if workers are wearing hard hats."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Customers need to extract invoice information by uploading an image of the invoice. The system should answer specific questions about the invoice."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: We are trying to build a system for writing Japanese emails. We need a model to complete sentence fragments."}
{"text_id": 158, "text": "document: This model is a fine-tuned version of vinvino02/glpn-kitti on the diode-subset dataset."}
{"text_id": 158, "text": "query: Our company is working on an autonomous car project, and we need an accurate depth estimation model."}
{"text_id": 202, "text": "document: A MobileNet-v3 image classification model. Trained on ImageNet-1k in timm using recipe template described below. Recipe details: RandAugment RA recipe. Inspired by and evolved from EfficientNet RandAugment recipes. Published as B recipe in ResNet Strikes Back. RMSProp (TF 1.0 behaviour) optimizer, EMA weight averaging. Step (exponential decay w/ staircase) LR schedule with warmup."}
{"text_id": 202, "text": "query: A mobile application's developer wants to add a feature that involves identifying the object captured by the camera."}
{"text_id": 28, "text": "document: Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}
{"text_id": 28, "text": "query: I want to build a model that can generate an image of a beautiful mountain view with a river flowing at its base and birds flying in the sky."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: A Science Fiction enthusiast wants to write a short story about the possible future impact of Artificial Intelligence."}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: Design an algorithm that measures how similar two movie reviews are to help a recommendation system find movies with similar themes."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: I have an audio file with multiple speakers overlapping in a conversation. I need to separate their voices for better understanding."}
{"text_id": 341, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It is used for video classification tasks."}
{"text_id": 341, "text": "query: We were requested to build a video recommendation system that classifies videos based on their content in order to target users' preferences more accurately. We need to group them into related categories such as sports, technology, and animals."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: We are having a brainstorming session for a mobile application that involves generating images of butterflies. Can you search for a pretrained model that can generate unique, high-quality images of butterflies?"}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: In an app, when users input a prompt, we want to generate images based on the description."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: We are hosting a podcast application, and we need to detect the voice activity, overlaps, and resegmentation in the submitted audio file."}
{"text_id": 554, "text": "document: PEGASUS is a pre-trained model for abstractive summarization, developed by Google. It is based on the Transformer architecture and trained on both C4 and HugeNews datasets. The model is designed to extract gap sentences and generate summaries by stochastically sampling important sentences."}
{"text_id": 554, "text": "query: Summarize the news article I am reading on the website."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: I run an advertising agency and want to generate high-quality, unique images for a marketing campaign."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: Predict the housing price in California considering various factors such as population, average income, median house age, etc."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We are an e-commerce company exploring how we can extract tables from invoices in a more efficient manner."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: We are working with an e-commerce platform to classify their products to enhance their customer search experience. Identify the product category based on the sample image."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: We stumbled upon an invoice from a supplier that we need to further process. Can you help us extract the invoice number from it?"}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: We need to find some similar sentences from a text. Text is about comparative politics and we want to find sentences on similar topics."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: I got a call recording, and the background noise is intolerable. I want to improve the recording quality."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: I have a news dataset, I want to classify if that news falls under sports, politics or entertainment category."}
{"text_id": 739, "text": "document: Transformer text-to-speech model from fairseq S^2. French, single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 739, "text": "query: We have an AI translator that translates texts to different languages, and we would like to implement a text-to-speech feature for the translated text."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: I need to extract the main points of a large text document and generate a concise summary."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: Design a photo-sharing app that categorizes images based on the content in the image."}
{"text_id": 123, "text": "document: This is pretrained LayoutLMv3 from Microsoft hub and fine-tuned on Multipage DocVQA (MP-DocVQA) dataset. This model was used as a baseline in Hierarchical multimodal transformers for Multi-Page DocVQA."}
{"text_id": 123, "text": "query: As a scientist, I want a model that analyzes the content of a document and answers questions about it. The document will be provided as an image, and the context and question will be in text format."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: Our client needs a conference tool that can translate speech in English into different languages in real-time."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: An educational website wants to provide an option to have the content on the website, available in multiple languages, spoken aloud at the user's request."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: On an article discussion board, we want to automatically detect and manage rumors without additional human resources. Make sure whether an statement is true or false."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: Our company is organizing a film festival. We want to create short promotional videos from the text descriptions of the films being shown."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: I am competing in a coding challenge held by my local programming community. I want my AI to help me by generating some Python code when I describe the task."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: Write a summary on whether \"Putin faces pressures on food prices and gas shortages.\""}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: We are working in the field of journalism. Can you extract features from the texts written by the journalists in Russian language?"}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: Build an AI model to answer customer inquiries by analyzing product images and customer questions."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: A car manufacturer is launching a new line of products and needs a guideline on the types of cars to be produced concerning their carbon emission levels."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: Our customer is a writer who wants to generate ideas for their next book series. They need a tool that can give them a list of possible book series ideas."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: I am writing a blog related to Finnish culture and need to translate it to English. What are the steps?"}
{"text_id": 44, "text": "document: Stable Diffusion v2 is a latent diffusion model that generates and modifies images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is developed by Robin Rombach and Patrick Esser. The model works with English language prompts and is intended for research purposes only."}
{"text_id": 44, "text": "query: We are an architect firm, and want to create a conceptual design of a building with a modern touch using text prompts."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: We're making a multilingual website for an international event planning company. It is crucial to be able to match user requests to event descriptions. We need to extract features from sentences in multiple languages."}
{"text_id": 439, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). It is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia and fine-tuned on SQA. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 439, "text": "query: Our product needs to answer questions based on data tables. Recommend an API that can do that."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: A high school art student needs a tool to turn their digital sketches into more realistic images. Develop a piece of software that can help transform a simple drawing into an intricate painting."}
{"text_id": 623, "text": "document: LLaMA-13B is an auto-regressive language model based on the transformer architecture developed by the FAIR team of Meta AI. It is designed for research purposes, such as question answering, natural language understanding, and reading comprehension. The model has been trained on a variety of sources, including web data, GitHub, Wikipedia, and books in 20 languages. It has been evaluated on several benchmarks, including BoolQ, PIQA, SIQA, HellaSwag, WinoGrande, ARC, and OpenBookQA."}
{"text_id": 623, "text": "query: I want to generate a compelling story about an adventurous rabbit having only \"Once upon a time in a large forest...\" as a prompt."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: Create a model instance using the provided api_call and set the model to evaluate mode."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: The company wants to improve its environmental footprint by analyzing the carbon emissions of different activities. Implement a solution to make predictions."}
{"text_id": 728, "text": "document: A text-to-speech model trained on multiple datasets including mtedx, covost2, europarl_st, and voxpopuli. Supports English, Spanish, French, and Italian languages."}
{"text_id": 728, "text": "query: Our company is developing a language learning app. We want to integrate text-to-speech functionality to help users with pronunciation in English, Spanish, French, and Italian."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: My teammate has designed a poster for our new product launch event. I want to confirm if the poster has the correct launch date. Determining the launch date from the poster, answer the question:"}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: Our customer is an e-commerce company in the Middle-East. They want to translate their product descriptions from English to Arabic."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: I have a lot of Indonesian text that I need to extract features from. How can I do this using a pre-trained model?"}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: I want to calculate the depth information about the objects in an image from a specific URL and then save the output depth map as an image."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: A client wants to build an application that can answer questions in legal documents. Can you build me a simple text-based question-answer model?"}
{"text_id": 720, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English single-speaker female voice trained on LJSpeech."}
{"text_id": 720, "text": "query: Our team needs to create an AI voice assistant to read the texts sent to us."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: I need a system to detect named entities in an English text like person names, organizations or locations."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: A video game developer wants to come up with new game characters. Can you create a character image based on the description \"A fierce warrior who has an affinity for nature and animals\"?"}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: I want to create an OCR system to recognize text in Japanese manga images."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: Our team needs a solution to convert Korean text into speech for an e-learning application, which reads out educational content."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: 'sports', 'language', or 'animals'."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: We have a robot operating in an unknown environment. I want to estimate the depth of the environment the robot is navigating in."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: Help me to detect the emotion of a person in an audio file."}
{"text_id": 768, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning."}
{"text_id": 768, "text": "query: We need to convert our recorded customer service phone calls to texts for later analysis."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: Our customer support team wants to add a chatbot feature to their website. They need a model that can interact with users."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: I am creating an application for detecting the presence of planes in aerial images. I need to use a pre-trained model to identify the planes."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: We have written an article about the health benefits of owning a dog, but people don't have time to read it. We need to summarize it."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: We are building an AI-based quality controller system for electronic PCB manufacturing. Identify defects on the PCB."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We are a gaming company and we need an AI that will perform in-game tasks in Grand Theft Auto 5 (GTA5). It should be able to learn by playing the game with a capped data usage."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We have a large collection of historical documents with tables summarising contents on various topics. We would like to extract the tables to analyze the data."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Our customer is a graphics designer who is looking for inspiration for their next butterfly illustration project."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: We are a digital art marketplace, and we need to differentiate between anime art drawn by artists and those created by AI algorithms."}
{"text_id": 196, "text": "document: A BEiT classifier to see if anime art was made by an AI or a human."}
{"text_id": 196, "text": "query: Create a software system that can distinguish whether an anime artwork is created by human or generated by AI."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: Help me to analyze sentiment of customer reviews written in Indonesian language."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: We need a video of a magical princess playing guitar in modern Disney style."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: Write a code to classify a given audio clip into a category based on its content, such as music, speech, or environmental sounds."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: A real estate agency has started a collection of house image to analyze and categorize their style of architecture such as contemporary, modern, and traditional. They need your help with an AI model."}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: We have an online blood test software. We want to detect blood cells from microscope captured images."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: I have a recorded audio file, which was noisy. I plan to separate the noise from the audio using a model trained on noisy audios."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: A digital assistant embedded in the phone would transcribe an audio file into text, so that it could be easily shared at a later point."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: Our customer service team is having difficulties understanding callers in noisy environments. We need a tool to enhance the voice quality."}
{"text_id": 573, "text": "document: Blenderbot is a chatbot model that provides engaging talking points and listens to their partners, both asking and answering questions, and displaying knowledge, empathy, and personality appropriately, depending on the situation."}
{"text_id": 573, "text": "query: A user wants to chat with our AI regarding their favorite film, which they cannot seem to decide on."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: I am an artist who wants to create a photorealistic image of a medieval castle scenery based on a text description."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: At the company, we are working on a drug discovery project to develop new medicines for treating diseases. Please provide us with useful information from the Graphormer-based model."}
{"text_id": 483, "text": "document: BERT-base uncased model fine-tuned on SQuAD v1. This model is case-insensitive and does not make a difference between english and English."}
{"text_id": 483, "text": "query: I need to identify the answer to the question \"What is the capital of France?\" from the text \"France, in Western Europe, is famous for its history, culture, and picturesque landscapes. Its capital, Paris, is known for its fashion houses, museums, and romantic ambiance.\"."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: We need to develop a program that can answer questions about a given image."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: Our company specializes in creating virtual environments for video games and wants to estimate depth from 2D images to assist in making the games more realistic."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: We want to create an app to convert written text into audio content to help visually impaired individuals."}
{"text_id": 575, "text": "document: This is a model for abstractive Russian summarization, based on cointegrated/rut5-base-multitask and fine-tuned on 4 datasets."}
{"text_id": 575, "text": "query: We have a large volume of Russian text and we need to summarize it to a smaller length."}
{"text_id": 104, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is trained on visual question answering with a base architecture (using ViT base backbone)."}
{"text_id": 104, "text": "query: We have a tool for visually impaired people that describes images. We need to answer user's questions about the images."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: Identify the character's action in a thumbnail image while watching their favorite TV series."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: We are a document managing company. We are trying to get an intelligent answer to client question about document."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: As a mobile app for automatic dialog translation, the background noise needs to be reduced."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: An e-learning company needs a digital assistant that can convert written text into audio for language learning purposes."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: We need to develop a system to read messages in Taiwanese Hokkien accent for a customer support hotline."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: We are trying to answer various student questions about a Vietnamese textbook which has a content of full text and some images. "}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: Our company is working on a project to help people find relevant articles by inputting a sentence. Create a model to check semantic similarity between a given sentence and various articles."}
{"text_id": 344, "text": "document: This model was trained from scratch on an unknown dataset."}
{"text_id": 344, "text": "query: I have a collection of images, and I want a system to automatically tag and categorize them."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: A web user uploads an image and wants to classify it into one of the 1000 pretrained categories."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: Explain how to find similar hotel reviews within a large number of reviews."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: Build a software agent that recognizes emotions in speech, enabling an intelligent AI to respond to the input accordingly."}
{"text_id": 557, "text": "document: This model was fine-tuned on a novel financial news dataset, which consists of 2K articles from Bloomberg, on topics such as stock, markets, currencies, rate and cryptocurrencies. It is based on the PEGASUS model and in particular PEGASUS fine-tuned on the Extreme Summarization (XSum) dataset: google/pegasus-xsum model. PEGASUS was originally proposed by Jingqing Zhang, Yao Zhao, Mohammad Saleh and Peter J. Liu in PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization."}
{"text_id": 557, "text": "query: I want to build an application that takes long financial news and generates short summaries to help users track the market trends quickly."}
{"text_id": 217, "text": "document: A YOLOv8 model for table extraction in documents, capable of detecting bordered and borderless tables. Trained on the table-extraction dataset, the model achieves a mAP@0.5 of 0.984 on the validation set."}
{"text_id": 217, "text": "query: Extract information about tables present in an image and visualize the results."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: We need to analyze a table and answer questions based on the information given in it."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: Develop an AI that can separate human voices from the background noise in an audio file to help businesses with transcription services."}
{"text_id": 339, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-large-finetuned-kinetics on an unknown dataset."}
{"text_id": 339, "text": "query: I would like to classify the actions in my videos. Can you integrate this model from Hugging Face to classify the videos?"}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: We are a group of artists working on transforming text into anime-style images using artificial intelligence."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: We need to segment images of buildings to support an evaluation of the urban landscape."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: We are planning to create a podcast application. As a result, we want to enhance the audio quality of our podcasts."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: Build a system that generates images of galaxies using the diffusion model 'myunus1/diffmodels_galaxies_scratchbook'."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: The botanic research center needs a quick way to classify different types of Iris flowers when each has measurements about its petals and sepals. How can we devise a reliable system for them?"}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: We are participating in a reinforcement learning competition involving the Ant-v3 environment. We need a starting point for training our agent."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: A researcher wants to use a zero-shot object detection model. Explain how it can be used to analyze an image of a city with cars and people."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: Our organization wants to improve the quality of our customer support chatbot. We are looking for a way to determine whether a paraphrased response is appropriate and relevant."}
{"text_id": 295, "text": "document: We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN."}
{"text_id": 295, "text": "query: We need to generate an image of a bedroom for a new advertisement campaign."}
{"text_id": 823, "text": "document: This model is a fine-tuned version of microsoft/unispeech-sat-base on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0123, Accuracy: 0.9979."}
{"text_id": 823, "text": "query: A client wants us to build a program that can classify audio files based on digit command (0-9). Provide the necessary implementation."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: Help me make a system that answers questions based on given context information."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: Create an application for users to ask questions about existing tables to retrieve specific pieces of information they need."}
{"text_id": 317, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches."}
{"text_id": 317, "text": "query: We need a method to identify several sports in short video clips."}
{"text_id": 401, "text": "document: This model was trained on the MS Marco Passage Ranking task. It can be used for Information Retrieval: Given a query, encode the query with all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. The training code is available here: SBERT.net Training MS Marco."}
{"text_id": 401, "text": "query: I am building the product which needs information retrieval based on queries, by ranking the passages enclosures which simplifies or justifies query."}
{"text_id": 707, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 707, "text": "query: We are building a recommendation engine and we need to find related sentences for better information retrieval."}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: \"AI models can be utilized for tasks such as\"."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: We are a multimedia production company, and we need to create a video based on a script. Can we use a GPT to get this generated?"}
{"text_id": 337, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 337, "text": "query: Our company is developing an exercise app, and we need to identify the types of exercises performed in user-submitted videos."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: The company wants to generate realistic images of churches for a virtual tour application."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: A furniture company wants to design a 3D visualization of their products using depth estimation."}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: A friend sent me a photo of animals, help me find out if it's a cat or a dog."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: I want to develop an app to generate high-quality images of people for fashion advertisement purposes."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: Our Real Estate client wants a computer vision model to predict the depth of rooms in indoor images."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: As a language model trainer, I want to be able to use a smaller and more efficient model to categorize a series of sentences into pre-defined classes without losing much performance."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: Analyze the features of text written in Korean for a better understanding of the context and emotion."}
{"text_id": 288, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images using discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. The model is trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 288, "text": "query: Generate random cat images using denoising diffusion probabilistic models for an upcoming cat exhibition."}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: Build a tool that can remove the background in images with multiple objects."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: Predict whether passengers on the Titanic survival using a pre-trained model with features like passenger class, age, sex, fare and more."}
{"text_id": 189, "text": "document: A Vision Transformer model for image classification, pretrained on ImageNet-21k and fine-tuned on ImageNet-1k."}
{"text_id": 189, "text": "query: An e-commerce owner wants to identify the items in the uploaded pictures. Are there any pre-trained models that can be used for this task in a few lines of code?"}
{"text_id": 636, "text": "document: A tiny English to German translation model using the Marian framework in Hugging Face Transformers."}
{"text_id": 636, "text": "query: Translate an English product description to German for our e-commerce website."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: I have a paragraph in Finnish and I want it translated to English."}
{"text_id": 66, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 66, "text": "query: Design a system to generate descriptions of images for a news agency's website. "}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: We have received several printed documents scanned in JPG format. Identify the text in those images and extract it."}
{"text_id": 873, "text": "document: A model trained using AutoTrain for predicting US housing prices with single column regression. The model is based on the jwan2021/autotrain-data-us-housing-prices dataset and has a CO2 Emissions of 50.5369 grams."}
{"text_id": 873, "text": "query: Let's say a business has just been operating and they need to predict the housing price given a single column data."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: Develop a tool using deep learning to predict a normal map from an input image."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: A game development company needs an image of a beautiful church to set as a background for their upcoming classic RPG game."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: My company wants to develop an AI-powered chatbot, and I'm looking for a lightweight model to easily deploy on a device with low resources."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: We are a startup developing an app for kids to explore and learn different animals. We'd like to recognize animal images from a given list of classes."}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: Develop a department store intercom system that announces sales and promotions in English."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: Help a business analyze the sentiment towards their products by analyzing reviews left by customers."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: I need a method to convert an audio speech file with speakers discussing business topics into text."}
{"text_id": 908, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 908, "text": "query: I want to create an AI Football game. Generate a configuration to train a team using reinforcement learning."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: We are now developing a game, and we need the characters to have different dialogues. Generate a dialogue for a wise old wizard character."}
{"text_id": 210, "text": "document: YOLOS model fine-tuned on COCO 2017 object detection (118k annotated images). It was introduced in the paper You Only Look at One Sequence: Rethinking Transformer in Vision through Object Detection by Fang et al. and first released in this repository. YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN)."}
{"text_id": 210, "text": "query: We have a large collection of images that need to be sorted by the objects present in them. We want to identify objects in them easily."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: I want our smart speaker to recognize simple speech commands like \"play\", \"pause\", \"stop\", \"next\", and \"previous\"."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: Translate the Dutch phrase \"Hallo, hoe gaat het met je?\" into English for our international clients."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: We have received many customer reviews and would like to extract sentiment from them. We need to classify the reviews as positive, negative, or neutral."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: Our customer is an e-commerce company that wants to add automatic caption generation for their product images."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: In an online dating application, how can I find similarities between profile descriptions?"}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: We are conducting an analysis on COVID-19 vaccinations and we would like you to answer questions based on the given data tables."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: I want to predict the missing word in the given sentence, \"The weather is really [MASK] today. Can you help me?\""}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We are an interior design company, and we want to design a room inspired by a church. Generate an image of a church to serve as the foundation for our design."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: I am interested in environmental measurements, I want to measure the depth of the objects in the given image."}
{"text_id": 821, "text": "document: This model is a fine-tuned version of facebook/hubert-base-ls960 on the None dataset. It achieves an accuracy of 0.9973 on the evaluation set."}
{"text_id": 821, "text": "query: I have an application that performs user authentication based on voice commands. I want to identify the spoken numbers (0 to 9) from the audio files."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: Our finance team needs to predict the closing price of a particular stock. We require a simple baseline model for the task."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: A restaurant chain is trying to identify and address customer complaints. Analyze restaurant reviews to determine whether they are positive or negative."}
{"text_id": 647, "text": "document: This is a T5-base model trained for end-to-end question generation task. Simply input the text and the model will generate multiple questions. You can play with the model using the inference API, just put the text and see the results!"}
{"text_id": 647, "text": "query: Analyze a piece of text and create a set of questions to test a reader's comprehension of the main points."}
{"text_id": 318, "text": "document: TimeSformer model pre-trained on Kinetics-600. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 318, "text": "query: We\u2019re building a video recommendation system and require a model that can classify the content of videos into various categories."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: A startup studio is building an AI-driven project that detects and filters inappropriate scenes from video clips. We need a solution to segment and identify the content within the frames."}
{"text_id": 822, "text": "document: Wav2Vec2-Base for Keyword Spotting (KS) task in the SUPERB benchmark. The base model is pretrained on 16kHz sampled speech audio. The KS task detects preregistered keywords by classifying utterances into a predefined set of words. The model is trained on the Speech Commands dataset v1.0."}
{"text_id": 822, "text": "query: We are developing a voice-controlled device. It needs to detect certain keywords."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: I am a South Korean cultural center that organizes projects with multiple NGOs. We want to build a question-answering system to answer questions related to Korea."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: Our e-commerce company is expanding with an AI system that generates product descriptions from their images."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: We want to get the sentence embeddings for our marketing campaign using the sberbank-ai/sbert_large_mt_nlu_ru model."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: We need a unique shoe design created automatically for the upcoming fashion show."}
{"text_id": 648, "text": "document: A T5 model trained on the MS MARCO dataset for generating queries from documents."}
{"text_id": 648, "text": "query: I have a Bible passage text and I need to find a relevant question for the given text."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: I have a scanned document and need to extract information from it. Help me extract the desired information by answering questions about the document."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: We need to classify news articles accurately for a user-friendly experience. I need you to tell me the category for \"Angela Merkel is a politician in Germany and leader of the CDU.\""}
{"text_id": 683, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data. This is the DeBERTa V2 xlarge model with 24 layers, 1536 hidden size. The total parameters are 900M and it is trained with 160GB raw data."}
{"text_id": 683, "text": "query: I'm trying to build an AI chatbot that can fill in the blanks in a sentence."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: The school is having a talent competition, and we have to analyze the videos of the participants. Classify the type of action being performed in a given video."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: In our business meeting recording, we need to identify the segments where our company leader speaks."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: Develop a tool that helps people to detect and count objects in an image from a URL."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: We are building an application for robotic motion planning. We need a depth map from an image of the environment."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: operations, marketing, finance, or technology."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: Our company publishes a daily news digest email. Create a summary of the news article below:"}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: Create a recommendation model to choose the best quality wine for dinner guests."}
{"text_id": 666, "text": "document: ALBERT Base v2 is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It was introduced in this paper and first released in this repository. This model, as all ALBERT models, is uncased: it does not make a difference between english and English."}
{"text_id": 666, "text": "query: I have recieved a text with some missing words that I want to complete using Artificial intelligence. Please suggest a way."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: I need to extract the data about student grades from a digital grade book and answer questions about the grades such as finding the highest or lowest grade."}
{"text_id": 671, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. It can be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 671, "text": "query: \"The moon is <blank>, but it does not have <blank>.\""}
{"text_id": 232, "text": "document: This model detects blood cells in images, specifically Platelets, RBC, and WBC. It is based on the YOLOv8 architecture and trained on the blood-cell-object-detection dataset."}
{"text_id": 232, "text": "query: Our health center specializes in blood testing, and we want to automate the process of detecting blood cells from the images captured by the microscope."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: Our team is trying to predict the sentiment of movie reviews in the IMDB dataset."}
{"text_id": 414, "text": "document: A token classification model trained using AutoTrain for entity extraction. The model is based on the distilbert architecture and trained on the ismail-lucifer011/autotrain-data-company_all dataset. It can be used to identify and extract company names from text."}
{"text_id": 414, "text": "query: I need to monitor news articles and find mentions of company names to analyze their public relations."}
{"text_id": 736, "text": "document: Transformer text-to-speech model from fairseq S^2. Russian single-speaker male voice. Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 736, "text": "query: Our client is planning an international conference. To greet Russian speakers, we need to convert a text message to speech in Russian language."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Let's say I recorded a conversation in German and I want to know the emotions in this conversation. I need a model capable of recognizing emotions in the German language from audio."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: There is a song in another language, and we want to generate its translation in English using a machine learning model."}
{"text_id": 225, "text": "document: An object detection model trained to detect hard hats and no-hard hats in images. The model is based on YOLOv8 architecture and can be used for safety applications."}
{"text_id": 225, "text": "query: We are working on an AI surveillance system for a construction site. We need to scan images and identify people who are not wearing hard hats."}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: We are working on a project to calculate the distance of objects in real-time from the camera feed. We need to have depth estimation for this purpose."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: Develop an automated transcription service for a call center."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: Write a Python code to deploy a chatbot that responds to user inputs."}
{"text_id": 829, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The base model is wav2vec2-base, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 829, "text": "query: We have provided an audio file that has an unknown speaker. Identify some characteristics about the speaker."}
{"text_id": 156, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 156, "text": "query: We are building a mobile app that helps users park their car safely. In order to provide a great user experience, we need to estimate the distance between the car and various objects."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: speech, music, or background noise."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I am an organization with many suppliers, and I need to automate the proccess of understanding which supplier has sent an invoice. Can the model be queried to understand that?"}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I have a smart speaker and want to add a knowledge base Q&A Engine. The user will ask the speaker any question in natural language form, and the smart speaker will provide the appropriate answer."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: A multinational corporation needs an assistant to provide answers quickly and accurately. We need to provide answers from the given financial data."}
{"text_id": 0, "text": "document: A pre-trained ConvBERT model for feature extraction provided by YituTech, based on the Hugging Face Transformers library."}
{"text_id": 0, "text": "query: We are a human resources company and need to build a classifier to identify the most suitable applicants for the available job positions. Extract features from a given text."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: We are building an audio-visual radio app and want to use an Asteroid model for denoising audios of radio broadcasts."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: Design a smart thermostat's temperature control algorithm that can minimize the carbon emissions from the heating system."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: Our client is an investment company. They want to analyze news articles to make better decisions. Help us classify financial texts."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: Create a chatbot that can be asked on-demand about any language translations needed."}
{"text_id": 740, "text": "document: Hokkien unit HiFiGAN based vocoder from fairseq. Trained with TAT-TTS data with 4 speakers in Taiwanese Hokkien accent."}
{"text_id": 740, "text": "query: Developers are creating a language learning app for students who want to learn Hokkien. We want to integrate text-to-speech for Hokkien phrases."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: \"Good morning everyone, I hope you are all doing well.\""}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: We are developing an application for a baby monitoring service, and the baby's emotion should be monitored based on the sound recordings."}
{"text_id": 545, "text": "document: DistilBART is a distilled version of BART, a model for text summarization. This specific checkpoint, 'sshleifer/distilbart-cnn-12-6', is trained on the cnn_dailymail dataset and provides a fast and effective way to generate summaries of text. The model can be loaded using the Hugging Face Transformers library."}
{"text_id": 545, "text": "query: The user needs a summary of the latest news article they just read."}
{"text_id": 862, "text": "document: A multi-class classification model for predicting carbon emissions."}
{"text_id": 862, "text": "query: We are working on a project for reducing the carbon emissions of our company. Now we need to predict the carbon emissions of various departments."}
{"text_id": 874, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 874, "text": "query: Can you create a model to predict carbon emissions based on the building age, area, number of electric devices?"}
{"text_id": 581, "text": "document: DialoGPT model that talks like Elon Musk, trained on Twitter tweets by Elon Musk. This model will spew meaningless shit about 40% of the time. Trained on 8 epochs. But with a larger dataset this time. The AI can now use more emojis, I think."}
{"text_id": 581, "text": "query: Now we want the chatbot to boost users' mood by discussing innovative technologies and ideas."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: We are an accounting firm that needs a better way of reading tables from image files. Detect tables in the image."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: A new project is analyzing a large set of images for object classification. The team uses an image classification model to identify and categorize objects present in the image."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: We are building a content generation tool and need a model to predict the missing words in the sentences to improve the overall quality of the writing."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: We need to include image classification in our software to identify objects in photos."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: Analyze an image and answer the question about it in Polish."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: As an interior designer, I want to generate images of bedroom designs to inspire my creativity."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: Use machine learning to perform wine quality classification based on a chemical analysis of a red wine sample."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: A restaurant needs to understand mentions of food in customer reviews on social media. They have several dishes and want to know which dish is mentioned the most."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: We are a startup developing an online meeting platform. We need to identify when different people speak during a meeting."}
{"text_id": 820, "text": "document: This model is a fine-tuned version of openai/whisper-medium on the FLEURS subset of the google/xtreme_s dataset. It is used for language identification in audio classification tasks."}
{"text_id": 820, "text": "query: As an AI curriculum planner, utilize a language identification system to ensure the audio recordings of each lesson are in the appropriate language."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: You are developing an app to provide the distance of objects present in an image. Implement a depth estimation module to predict depths in a given image."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: A list of costs and revenues for different departments in a company are provided in a tabular format. Identify which department generated the most revenue."}
{"text_id": 919, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on AudioSet. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 919, "text": "query: A mobile app is in development to identify the predominant sound sources in a given environment. We need to classify the sounds using suitable tools for sound recognition."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: Users want to engage in a conversation with a fictional character based on their persona. This conversation will be used as part of a script for an animation series."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: Write an article summary based on the given input text."}
{"text_id": 103, "text": "document: Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2. It was introduced in the paper ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision by Kim et al. and first released in this repository."}
{"text_id": 103, "text": "query: We have an AI voice assistant that can detect objects in photos. We need this model to answer questions about the objects in the image it detects."}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: Tell me if these tweets are in support, oppose or neutral to the government policies. Analyze their sentiment using a transformer model."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: Our company wants to find the year when a specific city hosted the Olympics."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: A social media platform wants to provide personalized content for their users. We want to analyze the images users post and classify them into interest categories."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: Analyze the sentiment of the given financial report statements to determine if they have a positive, negative, or neutral tone."}
{"text_id": 484, "text": "document: A VisualBERT model for Visual Question Answering."}
{"text_id": 484, "text": "query: Design a system to answer questions asked about an image."}
{"text_id": 86, "text": "document: TrOCR pre-trained only model. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Next, the Transformer text decoder autoregressively generates tokens."}
{"text_id": 86, "text": "query: I have a scanned image of an old document, and require the text extracted from it."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: Help me generate a creative description for a dreamy moonlit night sky as a setting for a fantasy novel."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: We are a video platform streaming service. We want to automatically categorize our video library. Please guide us."}
{"text_id": 490, "text": "document: This is an ONNX conversion of the deepset/roberta-base-squad2 model for extractive question answering. It is trained on the SQuAD 2.0 dataset and is compatible with the Transformers library."}
{"text_id": 490, "text": "query: Predict the answer to a question based on the given text."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: In order to sell our products in Korea, we need to recognize Korean food and drinks in a picture for advertising purposes."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: We need a tool to help us answer questions about our company's promotional images."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: We are integrating OCR capabilities to our inventory management system, and we need to read scanned receipts."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: As a real estate developer, we need to predict the prices of houses in California based on the given attributes."}
{"text_id": 662, "text": "document: BERT multilingual base model (cased) is pretrained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. The model is case sensitive and can be used for masked language modeling or next sentence prediction. It is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 662, "text": "query: Our client needs to correct sentences from formal diplomatic documents that are missing words or have typographical errors. We'd like you to provide an example of how the model can predict the missing word."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: As a language researcher, I need to find the similarity between sentences to cluster them by similarity. What kind of API call should I make?"}
{"text_id": 670, "text": "document: This model is a distilled version of the BERT base multilingual model. It is trained on the concatenation of Wikipedia in 104 different languages. The model has 6 layers, 768 dimension and 12 heads, totalizing 134M parameters. On average, this model, referred to as DistilmBERT, is twice as fast as mBERT-base."}
{"text_id": 670, "text": "query: Our company is developing a natural language processor that can fill gaps in sentences with appropriate words. We need to establish the best model for this purpose."}
{"text_id": 453, "text": "document: TAPAS mini model fine-tuned on WikiTable Questions (WTQ). It is pretrained on a large corpus of English data from Wikipedia and can be used for answering questions related to a table."}
{"text_id": 453, "text": "query: To offer customization options to our users we need to extract data from their sales report. Design a solution to extract data from their sales report."}
{"text_id": 333, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 333, "text": "query: We want to develop an app to automatically classify types of workouts in user-submitted videos. Kindly provide instructions."}
{"text_id": 794, "text": "document: This model is a speech-to-speech translation model trained by Facebook. It is designed for translating English speech to French speech."}
{"text_id": 794, "text": "query: Convert the English speech of this recorded meeting to French so that our French speakers can follow it."}
{"text_id": 214, "text": "document: A YOLOv5 model for license plate detection trained on a custom dataset. The model can detect license plates in images with high accuracy."}
{"text_id": 214, "text": "query: Our client wants to detect and read license plates from images. Please provide a code snippet for license plate detection in Python."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: We are a company that creates AI-based game models. Deploy a pre-trained model to simulate a cartpole balancing game environment."}
{"text_id": 696, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 696, "text": "query: We want to check if two documents are containing the same ideas with different words. How can we do that?"}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: To summarize meeting notes, we are building an application for internal use in the company."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: Our company conducts customer support calls. To improve our customers' experiences, we need to transcribe the calls and analyze them."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: Can you convert and transcribe this spoken English song into text format?"}
{"text_id": 244, "text": "document: OneFormer model trained on the ADE20k dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 244, "text": "query: A client needs help to process a picture of a landscape, and they want us to split the objects in the scene with their respective categories."}
{"text_id": 367, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-B/16 as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 367, "text": "query: We are a Chinese research team focusing on analyzing the visual features and zero-shot classification of Chinese food. "}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: We're a social media website and have an image sharing service. Please suggest a way to categorize user-uploaded images into animals, vehicles, and landmarks categories."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: I have a game in the arcade space genre, and I need to generate alternative sentences to describe it for marketing purposes."}
{"text_id": 278, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5. This checkpoint corresponds to the ControlNet conditioned on MLSD images."}
{"text_id": 278, "text": "query: I want to be able to generate artistic photographs based on the text description."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: I need to improve a chatbot that I'm developing, it needs to generate paraphrases for a given text using Parrot."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: We want to develop a website that creates realistic images of human faces from scratch."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: You are a real estate developer who is hiring an architect. Develop a blueprint design for commercial buildings based on image segmentation."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: Create an advertisement image for a new luxury watch brand using a text prompt."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: I want to know how to use an AI library and check which statement from a list is more similar to a given query."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: We are a green tech company involved in solar panel installations. We need to segment images captured by drones to analyze the solar panels and roofs."}
{"text_id": 126, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It achieves the following results on the evaluation set: Loss: 0.1239, Precision: 0.9548, Recall: 0.9602, F1: 0.9575, Accuracy: 0.9819"}
{"text_id": 126, "text": "query: Our team needs to extract information from a complex document with a mixture of tables, images, and text. Use a pre-trained model for this purpose."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: We are developing a podcast app, and we need to enhance the quality of some audios."}
{"text_id": 616, "text": "document: GPT-Neo 2.7B is a transformer model designed using EleutherAI's replication of the GPT-3 architecture. It was trained on the Pile, a large scale curated dataset created by EleutherAI for the purpose of training this model. This model is best suited for generating texts from a prompt and can be used directly with a pipeline for text generation."}
{"text_id": 616, "text": "query: Create a system that automatically generates creative and informative content about new technology products."}
{"text_id": 197, "text": "document: This model is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}
{"text_id": 197, "text": "query: Figure out a way to develop a model for an agricultural research company that needs to classify plants as healthy or infected."}
{"text_id": 856, "text": "document: A model trained for binary classification of carbon emissions using AutoTrain."}
{"text_id": 856, "text": "query: We have data about the carbon emissions of different companies. We are trying to determine if a company is responsible for high or low carbon emissions based on this data."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: We are a gaming company that wants to create random images for our game based on a pre-trained model."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: A developer in our team needs help with extracting named entities and code snippets from StackOverflow text. Design a solution to assist them."}
{"text_id": 8, "text": "document: KoBART is a Korean encoder-decoder language model trained on over 40GB of Korean text using the BART architecture. It can be used for feature extraction and has been trained on a variety of data sources, including Korean Wiki, news, books, and more."}
{"text_id": 8, "text": "query: Our company intends to deal with reviews from our Korean clients, and we need to extract important features from the texts to perform further analysis."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: Help a creative team generate a short video according to a given English text description."}
{"text_id": 714, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 1024 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 714, "text": "query: We have thousands of scientific articles and want to find similar articles based on their content. Please suggest a way to achieve that using sentence similarity."}
{"text_id": 634, "text": "document: FLAN-T5 large is a language model fine-tuned on over 1000 tasks and multiple languages. It achieves state-of-the-art performance on several benchmarks, including 75.2% on five-shot MMLU. The model is based on pretrained T5 and fine-tuned with instructions for better zero-shot and few-shot performance. It can be used for research on language models, zero-shot NLP tasks, in-context few-shot learning NLP tasks, reasoning, question answering, and advancing fairness and safety research."}
{"text_id": 634, "text": "query: One of my friends just sent me a message in English, and I would like to have it translated into German."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: I need help with my English assignments as I commit many grammatical mistakes. Can you build a tool that checks and corrects them for me? "}
{"text_id": 408, "text": "document: distilbert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned Distiled BERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 408, "text": "query: We want to analyze news articles for named entities. Focus on detecting important people, locations, and organizations mentioned in the articles."}
{"text_id": 777, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WSJ0-2Mix dataset."}
{"text_id": 777, "text": "query: We are a phone company with many customers. There are sometimes background noises when the customers speak on phone. We provide a method to help them reduce these noises."}
{"text_id": 687, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 687, "text": "query: We have a database with a large amount of articles, and we want to group them based on their similarity."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: \"A head full of roses\""}
{"text_id": 784, "text": "document: SpeechT5 model fine-tuned for voice conversion (speech-to-speech) on CMU ARCTIC. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. It is designed to improve the modeling capability for both speech and text. This model can be used for speech conversion tasks."}
{"text_id": 784, "text": "query: I have a speech analytics software and need to convert the voice of a person into a desired voice output."}
{"text_id": 5, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 5, "text": "query: I want to analyze the sentiments of my novel's main character over time. Please help me generate the sentiment scores for each chapter."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: I'm working on customer reviews analysis. I want to classify the review as positive or negative."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: We have developed a game similar to soccer. We want to train a learning agent to play the game with soccer-like skills."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: We want to create a short animated video based on the text prompt \"A rocket launching into space.\""}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: To be used for video-based search, the company developed a service that needs to be automized for categorizing videos into classes."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: Write a script that uses the BigBird API to summarize scientific articles."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: We are building a product to digitize book pages in a fast and efficient way. Let's build an OCR system based on TrOCR technology."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: Please answer the question about the provided table."}
{"text_id": 157, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 157, "text": "query: We are designing a safety system for our vehicles. We want to know the depth of objects in a road scene."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: I need a tool to predict coloring on scribbled images based on the given texts. Help me to create a model for that."}
{"text_id": 699, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 699, "text": "query: We need to identify similar news headlines in order to personalize our website according to the interests of readers."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: We are launching an online comic magazine. Our plan is to generate a lifelike character image to attract the audience."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: We are building an online document editor. We need a feature to extract tables from PDF. The program should be able to detect both bordered and borderless tables."}
{"text_id": 372, "text": "document: Twitter-roBERTa-base for Sentiment Analysis. This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis with the TweetEval benchmark. This model is suitable for English."}
{"text_id": 372, "text": "query: I have a Twitter bot and I need to analyze the sentiment of incoming tweets to notify me if I receive positive or negative feedback."}
{"text_id": 925, "text": "document: This model is a fine-tuned version of google/vit-base-patch16-224 on the None dataset. It is designed for image classification tasks, specifically for diabetic retinopathy detection."}
{"text_id": 925, "text": "query: Build a retinal image classification system that determines if a person has diabetic retinopathy or not."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: Create a system to rank insights extracted from news articles in different categories such as technology, sports, and politics."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: A technology company wants to detect objects in an image based on custom text queries. Provide instructions on how to do that with the pre-trained model."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: We are developing AI based emotions recognizer. Train the model to recognize emotions based on a human's speech."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: Our customer is a travel agency, and they need a creative image based on \"vacation on a beautiful island\" to use in their advertisement."}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: We are a construction safety company. We are interested in checking whether our workers are wearing their safety helmets."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: We are building an advanced search tool that needs a quick way of matching user queries to a list of documents."}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: I want to create a digital assistant that can help me understand the content of old documents. The assistant should be able to answer my questions based on the provided text."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Our company wants to autonomously drive their vehicles in the city. We need a solution to estimate the depth of the surroundings using images taken by the vehicle's cameras."}
{"text_id": 167, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 167, "text": "query: I am working on a robotics project and I need to estimate the depth information from a single image to assist in obstacle detection."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: We are organizing an event for a client. Extract names and locations mentioned in the email they sent us."}
{"text_id": 356, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 356, "text": "query: Assess the age of a tree for environmental awareness; create a classifier to identify trees as young, middle-aged, or old depending on their images."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: A biology teacher needs to create a question and answer service to help their students learn. They need a text-based question answering model that is capable of understanding complex biological information."}
{"text_id": 772, "text": "document: s2t-medium-librispeech-asr is a Speech to Text Transformer (S2T) model trained for automatic speech recognition (ASR). The S2T model was proposed in this paper and released in this repository."}
{"text_id": 772, "text": "query: I have an audio file containing an interview with a scientist and I would like to convert the speech into a text transcript."}
{"text_id": 486, "text": "document: BERT large model (cased) whole word masking finetuned on SQuAD. This model is cased and trained with a new technique: Whole Word Masking. After pre-training, this model was fine-tuned on the SQuAD dataset."}
{"text_id": 486, "text": "query: Create a question-answering model with pre-trained BERT architecture and fine-tuned with SQuAD data."}
{"text_id": 129, "text": "document: A LayoutLMv2 model for document question answering."}
{"text_id": 129, "text": "query: Our legal department needs to extract specific information from scanned documents. They want to retrieve answers to their questions based on the content of these documents."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: Build a voice-controlled smart home system that recognizes keyword commands like \"lights on,\" \"lights off,\" \"music on,\" etc."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Translate a scanned invoice into text and find the invoice number."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: The light was [MASK] in the room."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: I am working on a project about missing words in a sentence. I need a prompt completion."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: I want to generate descriptive textual output for an image to help visually impaired individuals understand images."}
{"text_id": 901, "text": "document: This is a trained model of a PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 901, "text": "query: We need an artificial intelligence that will play the CartPole game and never lose. Make an agent that will achieve this."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: Last week we went to the zoo, and now we want to classify the pictures of the animals."}
{"text_id": 892, "text": "document: This is a trained model of a PPO agent playing Pendulum-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 892, "text": "query: Design a system to play with to optimize energy consumption based on the pendulum movements from a dataset."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: We have a database of Olympic games and years, and we are creating an application to answer user's questions about it."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: I am a city engineer that wants to automatically detect potholes on roads and provide the specific area of the detected potholes."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: We have a text that describes the client's request. Extract the necessary information regarding the persons, locations, organizations and miscellaneous entities to create a document summary."}
{"text_id": 899, "text": "document: This is a trained model of a DQN agent playing Acrobot-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 899, "text": "query: I want to replicate the results of the Acrobot-v1 trained model, and I need to know how to load and use the model."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: We are hosting a gaming contest where people need to play the Pong game without frameskip. We want to train an agent with an optimized score."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: Please implement a tool to classify the contents of images for us."}
{"text_id": 369, "text": "document: Chinese CLIP is a simple implementation of CLIP on a large-scale dataset of around 200 million Chinese image-text pairs. It uses ViT-L/14@336px as the image encoder and RoBERTa-wwm-base as the text encoder."}
{"text_id": 369, "text": "query: Find the representative text for different images about animals through the available Chinese texts."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: A news website wants to categorize its articles automatically into topics such as technology, sports, and politics. Find a model that can help them."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: I have just taken a picture of my new shoes. Help me to understand what a model may infer from the picture."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: Let's create a baseline model for a restaurant that wants to predict tips based on features such as total bill, sex, smoker, day, time, and table size."}
{"text_id": 673, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization. Additionally, the model is trained with the whole word masking enabled for the masked language modeling (MLM) objective."}
{"text_id": 673, "text": "query: Can you provide a practical example of how to use this Japanese language model to fill in the missing word in a Japanese sentence?"}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: We have a blog platform and want to find similar posts automatically."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: We are designing a chatbot that speaks fluently. Please provide a feature that will generate a more fluent, paraphrased version of an input sentence."}
{"text_id": 893, "text": "document: A trained model of a poca agent playing SoccerTwos using the Unity ML-Agents Library."}
{"text_id": 893, "text": "query: Can you walk me through implementing a Reinforcement Learning agent to control a soccer-playing robot using the ML-Agents framework?"}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: Our company is building an app that changes the background of indoor images. We need to identify the region of a given image."}
{"text_id": 838, "text": "document: FSMN-VAD model for Voice Activity Detection using Hugging Face Transformers library."}
{"text_id": 838, "text": "query: We are organizing an online conference call. We'd like to get voice activity detection during the live call."}
{"text_id": 542, "text": "document: A Dutch to English translation model based on the OPUS dataset, using a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 542, "text": "query: We received an email from a Dutch client. Help us translate it into English."}
{"text_id": 219, "text": "document: A YOLOv8 model trained for head detection in American football. The model is capable of detecting helmets, blurred helmets, difficult helmets, partial helmets, and sideline helmets."}
{"text_id": 219, "text": "query: We want to detect and visualize all the heads of individuals in an image we have in a football game by using an API."}
{"text_id": 335, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 335, "text": "query: We need to create a news segment on fitness. Help us identify interesting sections of exercise videos."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: An anime producer is looking to create a concept art for their new anime based on a short description of a character."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: I am creating a game that generates game assets based on the description of the scene, such as \"creepy forest with a haunted house\"."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: A colleague of mine has collected a dataset containing the answers to many commonly asked questions. I want to sort these answers based on my dataset to provide the suitable answer to specific queries."}
{"text_id": 427, "text": "document: This is the fast version of the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 427, "text": "query: A journalist writing a breaking story needs to quickly identify the main named entities (like person names, organizations, locations, etc.) in a given piece of text."}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: Create a function to generate Python code based on a given English description."}
{"text_id": 376, "text": "document: This model is a fine-tuned version of xlm-roberta-base on the Language Identification dataset. It is an XLM-RoBERTa transformer model with a classification head on top, and can be used as a language detector for sequence classification tasks. It supports 20 languages including Arabic, Bulgarian, German, Greek, English, Spanish, French, Hindi, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Swahili, Thai, Turkish, Urdu, Vietnamese, and Chinese."}
{"text_id": 376, "text": "query: Your task is to build a language detector tool that analyses the given text and determines in which language it is written."}
{"text_id": 660, "text": "document: DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrained with three objectives: Distillation loss, Masked language modeling (MLM), and Cosine embedding loss. This model is uncased and can be used for masked language modeling or next sentence prediction, but it's mostly intended to be fine-tuned on a downstream task."}
{"text_id": 660, "text": "query: Assist me in completing my email draft by predicting the appropriate words to fill in the blanks in the sentences."}
{"text_id": 510, "text": "document: This model was trained on 782 357 hypothesis-premise pairs from 4 NLI datasets: MultiNLI, Fever-NLI, LingNLI and ANLI. The base model is DeBERTa-v3-xsmall from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective."}
{"text_id": 510, "text": "query: I am writing an automatic essay scorer. I want to identify if the given essay contradicts the provided prompt statement or not."}
{"text_id": 928, "text": "document: A pretrained BERT model for Named Entity Recognition (NER) on uncased text. It can be used to extract entities such as person names, locations, and organizations from text."}
{"text_id": 928, "text": "query: We received a complaint and we need to gather crucial information from the email's text in order to process it faster."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: I bought a robot dog, and I expect the robot to understand the walking actions of the robot dog in the environment."}
{"text_id": 627, "text": "document: BLOOMZ & mT0 are a family of models capable of following human instructions in dozens of languages zero-shot. Finetuned on the crosslingual task mixture (xP3), these models can generalize to unseen tasks & languages. Useful for tasks expressed in natural language, such as translation, summarization, and question answering."}
{"text_id": 627, "text": "query: The visitor wants to translate a French sentence into English. Additionaly, perform an analysis on the fidelity of the translation."}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: Let's say you're building a virtual reality application and you need to estimate the depth of objects in a given scene."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Analyze the accident images, identify the vehicles involved, and describe the interacting entities."}
{"text_id": 535, "text": "document: T5-3B is a Text-To-Text Transfer Transformer (T5) model with 3 billion parameters. It is designed for various NLP tasks such as translation, summarization, question answering, and sentiment analysis. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on multiple supervised and unsupervised tasks."}
{"text_id": 535, "text": "query: Our company needs to translate a user manual from English to French."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: I need to build a filter that prevents NSFW content from being posted on a social media platform. Help me classify the content."}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: Add an automatic transcription service to our conference call application."}
{"text_id": 24, "text": "document: BERT large model multitask (cased) for Sentence Embeddings in Russian language."}
{"text_id": 24, "text": "query: We want to make sure we are notified if any potentially harmful content is being sent to our social media profiles. Implement a model to compute embeddings for messages."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: Write a piece of literature with emotion. We would like to include a mysterious character in the beginning."}
{"text_id": 222, "text": "document: A YOLOv8 model for plane detection trained on the keremberke/plane-detection dataset. The model is capable of detecting planes in images with high accuracy."}
{"text_id": 222, "text": "query: I work for an airline service provider. We need to detect planes in images captured from the airport tarmac."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: We are looking for a way to translate ad copies for our product promotion from English to different Romance languages."}
{"text_id": 691, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 691, "text": "query: Create a program to check the similarity between two sentences in the same email."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: Write an AI-based dinner party script involving four characters and a surprising event."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: We need a model to automatically generate descriptions for Python functions in our codebase to help our development team."}
{"text_id": 776, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 776, "text": "query: I am working on a podcast. I would like to improve the sound quality and remove some background noises."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: We are building a project recommendation system that can recommend new code repositories based on users' previous interaction with programming languages. Extract features from the code and description using a pre-trained model."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: Our company is providing car rental services. We have a table representing the car selection available and the rental price. We need to analyze renters' questions and provide answers to their queries about our cars."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: We need to design a tool to recognize activities in a security video feed. How can we solve it using a pre-trained model?"}
{"text_id": 50, "text": "document: Dreamlike Diffusion 1.0 is SD 1.5 fine tuned on high quality art, made by dreamlike.art."}
{"text_id": 50, "text": "query: I am creating a virtual reality game and I want an image of a fierce dragon fighting a brave knight within a dark forest while surrounded by mystical creatures."}
{"text_id": 521, "text": "document: T5-Small is a Text-To-Text Transfer Transformer (T5) model with 60 million parameters. It is designed to perform a variety of NLP tasks, including machine translation, document summarization, question answering, and classification tasks. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and can be fine-tuned for specific tasks."}
{"text_id": 521, "text": "query: My boss wants a summarized version of a legal document that we received from our clients."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: We own an antique store and want to create an automated system to classify the type of items we have in our warehouse."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: Identify the emotion expressed in a given text, such as happiness, sadness, anger, surprise, or fear."}
{"text_id": 798, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq for Hokkien-English. Trained with supervised data in TED, drama, TAT domain, and weakly supervised data in drama domain."}
{"text_id": 798, "text": "query: My friend is planning to give a speech in Hokkien, but would like me to understand it. Please help translate the speech from Hokkien to English."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: We want a model that can predict the sentiment of code and its comments. This could help to improve or refactor the code based on its sentiment."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: I am working on a book club app that recommends new books. We receive images of book covers, and they usually contain the title and author name. Extract the title and author name from the book cover image."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: We need an algorithm to sort images based on their similarity to each other in a large dataset."}
{"text_id": 781, "text": "document: A speech-to-speech translation model that can be loaded on the Inference API on-demand."}
{"text_id": 781, "text": "query: Translate this English podcast's audio file into a German text transcript."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: To provide personalized news suggestions, I want to make sure that the suggested articles are related to the user's preferences."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: Calculate carbon emissions given the input data for evaluating a city's environmental impact."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: You are building a code editor tool that needs to autocomplete code snippets for a developer."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: You are hired by a research team working on robotic locomotion. They require to train a control policy for a robot by leveraging a pre-trained model."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: We are launching an e-commerce website. The website needs a model to identify the appropriate category for each uploaded product image."}
{"text_id": 445, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiTableQuestions dataset."}
{"text_id": 445, "text": "query: An education company needs a tool to extract specific information from tables in their courses."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: A friend sent you a mixed audio-recorded file where two people were speaking at the same time, and you need to separate the speakers for clearer understanding."}
{"text_id": 729, "text": "document: This model was trained by lakahaga using novelspeech recipe in espnet. It is designed for Korean text-to-speech tasks."}
{"text_id": 729, "text": "query: We need to provide an audiobook version for our newly published Korean novel for accessibility purposes."}
{"text_id": 512, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying mDeBERTa-v3-base model was pre-trained by Microsoft on the CC100 multilingual dataset with 100 languages. The model was then fine-tuned on the XNLI dataset and on the multilingual-NLI-26lang-2mil7 dataset. Both datasets contain more than 2.7 million hypothesis-premise pairs in 27 languages spoken by more than 4 billion people."}
{"text_id": 512, "text": "query: A researcher from our company wants to classify the field that a given paper belongs to. They provided the paper's abstract."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: I want to automatically annotate the syntax roles of the words in a given English sentence using the best available API."}
{"text_id": 248, "text": "document: A YOLOv8 model for building segmentation in satellite images. It can detect and segment buildings in the input images."}
{"text_id": 248, "text": "query: The product is used in the marketing agency to detect buildings in satellite imagery of cities for their clients."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: We are an AI chatbot company, and we wish to improve our chatbot's sentence understanding by filling in missing words."}
{"text_id": 693, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 693, "text": "query: An environmentalist group needs to find tweets most relevant to their work from a massive dataset. They need a model to quickly sort out the most relevant information from the pool to save time."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: Let's detect all objects inside the image file and output the objects coordinates, name, and their confidence score."}
{"text_id": 428, "text": "document: A BERT model fine-tuned for Part-of-Speech (POS) tagging in English text."}
{"text_id": 428, "text": "query: We have many users in a chat application. We want to automatically identify the parts of speech in user's messages to improve the quality of our natural language understanding efforts."}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: We, an IT support company, are thinking of providing solutions to software installation problems. We want to generate help responses for users facing issues during software installation."}
{"text_id": 801, "text": "document: A speech-to-speech translation model for Romanian to English developed by Facebook AI"}
{"text_id": 801, "text": "query: Our company is working on a mobile application that translates speech from Romanian to English in real-time for tourists visiting the country."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: I need help predicting the closing price of a stock given its opening price, high price, low price, and trading volume."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: Our client is an interior designer, and they want to create a 3D model of a room based on an image and guidance text provided by the client."}
{"text_id": 537, "text": "document: A German to Spanish translation model based on the OPUS dataset and trained using the transformer-align architecture. The model is pre-processed with normalization and SentencePiece tokenization."}
{"text_id": 537, "text": "query: Let's create a German to Spanish translation system for the tourism industry that would help tourists easily understand hotel and restaurant information."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: We want to build an AI system that monitors the visitors' age in our amusement park."}
{"text_id": 859, "text": "document: A K-Nearest Neighbors (KNN) model trained on the Iris dataset for multi-class classification. The model is trained using AutoTrain and has an accuracy of 0.9."}
{"text_id": 859, "text": "query: I need to classify the category of a flower given the sepal length, sepal width, petal length, and petal width. Build me a flower classifier."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: Our organization aims to assess environmental impact. We need to predict the carbon emissions for different operations in our facilities."}
{"text_id": 305, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 305, "text": "query: Generate an image of cute butterflies without any input and present it back."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: It's important for our project that we can let German-speaking users read English content. We need to translate English text into German."}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: I am riding a motorcycle, I wanted to find out if there are any pot holes in front me."}
{"text_id": 236, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 236, "text": "query: As a company specializing in self-driving vehicles, we want to segment images to identify road features, like lanes, cars, pedestrians, and traffic signs."}
{"text_id": 238, "text": "document: MaskFormer model trained on COCO panoptic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 238, "text": "query: I need to identify different objects and their boundaries in an image from a URL."}
{"text_id": 447, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. This model is the tapex-base model fine-tuned on the WikiSQL dataset."}
{"text_id": 447, "text": "query: I want to analyze a table of Olympic events held in various years and cities. And I want to find out when Beijing hosted the Olympic Games."}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: We've just conducted a survey and have collected the data in a structured table format. We want to answer a specific question based on data in the table."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: The company is specializing in corporate event planning. They make use of tables to manage various documents. They need to extract information from tables in a  natural language query format."}
{"text_id": 199, "text": "document: RegNet model trained on imagenet-1k. It was introduced in the paper Designing Network Design Spaces and first released in this repository."}
{"text_id": 199, "text": "query: We want our robot-arm producer to generate a robot that can recognize and categorize kitchen appliances."}
{"text_id": 569, "text": "document: Spanish BERT2BERT (BETO) fine-tuned on MLSUM ES for summarization"}
{"text_id": 569, "text": "query: How can I create a Spanish summary for a news article about a political event?"}
{"text_id": 85, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 85, "text": "query: My product needs to help tourists navigate art galleries. I want them to snap a picture and get contextual explanations of the artwork."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: I am working on a project where I need to detect my specified objects in the image. I want to detect a cat, a dog, and a bicycle."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: In our movie production, we need a realistic promotional image of a celebrity for our upcoming project."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: A historian wants to digitalize a handwritten document. Can you provide a Python program that would convert the image of the document into text using the TrOCR model?"}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: An AI powered customer service chatbot is being built for our company's website. We need to generate responses to users' questions."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: Our team needs to find text chunks from the title for writing a review on a recently published book."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: I need to create an image recognition tool that can help classify images of random objects found on the internet."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: A professor is conducting a study on the importance of model conversions in the world of AI. Help them understand why model conversion is important."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: I wish to alert the drivers of approaching vehicles by detecting license plates in the traffic."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: A user would like a text-to-speech system that can convert text into spoken Arabic with a male voice."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: I have a table with the revenue details of a company. The table contains information about different divisions, and I need to know the total revenue made by the company."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: I want to create an AI assistant that generates image captions for pictures from the internet."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: Our team is working on a smart traffic monitoring system that can detect vehicles on the road. Find a solution to detect vehicles from an image."}
{"text_id": 596, "text": "document: PersonaGPT is an open-domain conversational agent designed to do 2 tasks: decoding personalized responses based on input personality facts (the persona profile of the bot) and incorporating turn-level goals into its responses through action codes (e.g., talk about work, ask about favorite music). It builds on the DialoGPT-medium pretrained model based on the GPT-2 architecture."}
{"text_id": 596, "text": "query: Users want to interact with a conversational bot to find similar preferences and discuss common interests."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: A game developer wants to build a recommendation engine for similar sounding quest titles in their game. They have a list of quest titles in Chinese and want a method to find a similar quest based on the embeddings."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: A product is being launched which generates wallpapers for users based on their text descriptions. We need an anime-style image of a sunny day at the beach with a girl playing volleyball."}
{"text_id": 443, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 443, "text": "query: Determine the year in which the Olympics were held in Beijing based on the given table."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: We have a retail store and we want to analyze our sales data. There are millions of rows of data, and we want to answer questions about top-selling products, revenues and customer demographics."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: We have a facial picture of a suspect but need to generate a clearer outline of some specific facial features of this person."}
{"text_id": 595, "text": "document: DialoGPT Trained on the Speech of a Game Character, Joshua from The World Ends With You."}
{"text_id": 595, "text": "query: Develop a conversational agent for a chatbot to guide users through a video game."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: I need to create a model that can download and classify images of wildlife animals."}
{"text_id": 441, "text": "document: TAPAS small model fine-tuned on Sequential Question Answering (SQA). It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 441, "text": "query: We want to provide details about student's average performance. Calculate the average of Alex, Anna, and George in a given table."}
{"text_id": 340, "text": "document: A tiny random VideoMAE model for video classification."}
{"text_id": 340, "text": "query: A TV station would like to use a model for classifying the video recordings in their archive. They would like to learn if the video is news or entertainment."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: Compose a short story beginning with the phrase \"Once upon a time in a small village...\""}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: We have a project where we are required to transform the scenery images to a different style. The images should be changed on their visual aspects."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: We are now working to complete a novel, but we have been focused on character development. We need help generating content for the story."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: Our company works in the automotive industry. We want to classify the vehicles based on their CO2 emissions."}
{"text_id": 191, "text": "document: A ViT-based image classification model trained on ImageNet-1K and fine-tuned on ImageNet-12K by OpenAI."}
{"text_id": 191, "text": "query: Design an AI system that can identify if an image is of a dog or a cat."}
{"text_id": 49, "text": "document: Analog Diffusion is a dreambooth model trained on a diverse set of analog photographs. It can generate images based on text prompts with an analog style. Use the activation token 'analog style' in your prompt to get the desired output. The model is available on the Hugging Face Inference API and can be used with the transformers library."}
{"text_id": 49, "text": "query: We are making advertisement posters for our clothing line, and we want to generate a vintage-style image using a text description."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: I submitted my report today, and it contains images with text embedded in the graphs. I need to extract the information from the image and answer some of the questions based on the extracted information."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: I am a flight attendant. I want to generate an in-board flight announcement in a female voice for welcoming passengers."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: I am directing a movie and I want to generate a video scene where Spiderman is surfing."}
{"text_id": 108, "text": "document: A Visual Question Answering model fine-tuned on the Polish language."}
{"text_id": 108, "text": "query: I'm building a website to help people learn about different animals. Users can upload a picture and type a question they have about the animal. Avaialbe in Polish language."}
{"text_id": 609, "text": "document: openai-gpt is a transformer-based language model created and released by OpenAI. The model is a causal (unidirectional) transformer pre-trained using language modeling on a large corpus with long-range dependencies."}
{"text_id": 609, "text": "query: A language teacher wants to give her students a few variations of the sentence \"John went to the store to buy some groceries.\""}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: politics, health, entertainment, sports, or fake news."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: Our team has collected some French literature books. Prepare a summarization model for these books."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: Create a language model to analyze the grammar of a paragraph and identify the part of speech for each word."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: I need some help in writing part of the annual report for my company. The theme is sustainability and our focus on renewable energy."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: I have a set of texts from user interviews, and I am trying to extract answers to some of the common questions that are being asked in these interviews."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: Please help me do the speaker diarization of my recorded lecture, I want to know who has spoken in the recording."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: You run a sushi bento delivery service that is highly popular with office workers. Entice them with a brief but captivating introduction text for your menu."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: We have an app that needs to record its users' voices to verify their identity. We need an audio classifier to analyze the user's voice."}
{"text_id": 307, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. It can generate high-quality images, and supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm. On the unconditional CIFAR10 dataset, it achieves an Inception score of 9.46 and a state-of-the-art FID score of 3.17."}
{"text_id": 307, "text": "query: We want to create a synthetic image of a cat using an image generation model."}
{"text_id": 171, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 171, "text": "query: Create an architecture for an autonomous driving system that will monitor the distance between the objects in the driving environment."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: Our construction company needs to estimate the distance of objects from the camera in the photos taken at sites."}
{"text_id": 294, "text": "document: Butterfly GAN model based on the paper 'Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis'. The model is intended for fun and learning purposes. It was trained on 1000 images from the huggan/smithsonian_butterflies_subset dataset, with a focus on low data training as mentioned in the paper. The model generates high-quality butterfly images."}
{"text_id": 294, "text": "query: Our team is trying to display high-quality generated butterfly images for a virtual garden. Provide a way to create images of butterflies."}
{"text_id": 84, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextCaps. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 84, "text": "query: A national newspaper has asked us to identify and name the objects within an image. They have provided us with an image file of the objects."}
{"text_id": 38, "text": "document: A Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) to generate and modify images based on text prompts."}
{"text_id": 38, "text": "query: As a photographer, I want to create a unique digital artwork. I need a high-resolution image of a red dragon breathing fire in a dark cave."}
{"text_id": 299, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics, capable of producing high-quality image synthesis results. The model can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. It obtains an Inception score of 9.46 and a state-of-the-art FID score of 3.17 on the unconditional CIFAR10 dataset."}
{"text_id": 299, "text": "query: As an interior designer, create a random bedroom image using machine learning."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: Recommend a model to analyze an image and identify specific objects in it based on textual descriptions of those objects."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: \"Les chercheurs en IA d\u00e9veloppent des algorithmes pour r\u00e9soudre des probl\u00e8mes complexes.\""}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: We want to improve our parking lot management system by detecting the available free spots. Can we use image segmentation to achieve this?"}
{"text_id": 506, "text": "document: This model is the Multi-Genre Natural Language Inference (MNLI) fine-turned version of the uncased MobileBERT model. It can be used for the task of zero-shot classification."}
{"text_id": 506, "text": "query: Show me how to detect anomalies in the content of short phrases. I want to shortlist phrases that are related to food, health, and nutrition."}
{"text_id": 806, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 806, "text": "query: Create an assistant capable of detecting and classifying various keywords spoken in audio files like 'yes', 'no', 'stop', 'go', 'open', 'close'."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: Our company needs to create marketing slogans for a new line of home appliances. Can you come up with some creative ideas?"}
{"text_id": 664, "text": "document: DistilRoBERTa is a distilled version of the RoBERTa-base model, designed to be smaller, faster, and lighter. It is a Transformer-based language model trained on the OpenWebTextCorpus, which is a reproduction of OpenAI's WebText dataset. The model has 6 layers, 768 dimensions, and 12 heads, totaling 82M parameters. It is primarily intended for fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 664, "text": "query: I need to generate a new sentence by replacing a missing word using the distilroberta-base model. The beginning of the sentence is \"Artificial intelligence is the\", and the last word is \"of future technologies.\""}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: I am a scientific organization trying to generate an introductory paragraph for an article about climate change."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: A researcher requires a summary of an extensive biomedical text. They need to find key takeaways to save time on reading the full text."}
{"text_id": 17, "text": "document: The Vision Transformer (ViT) is a transformer encoder model (BERT-like) pretrained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. and first released in this repository. However, the weights were converted from the timm repository by Ross Wightman, who already converted the weights from JAX to PyTorch. Credits go to him."}
{"text_id": 17, "text": "query: I want a classifier that can identify types of animals in images such as images of dogs, cats, and birds."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: For our Japanese app, we need to autocomplete sentences using artificial intelligence."}
{"text_id": 298, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset. Supports various discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 298, "text": "query: I am an artist and need a random image from which I can draw inspiration for my painting."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: \"Once upon a time, in a kingdom far away, a courageous knight began his perilous journey to save a captive princess.\""}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: Implement a simple program that can compare the similarity of a group of product descriptions, and determine which products are the most similar to each other."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: Please create a chatbot for me that can understand and generate human-like responses in a conversational manner."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: Implement a tool that converts a text-based story into an audiobook using the `mio/tokiwa_midori` model."}
{"text_id": 101, "text": "document: A visual question answering model that takes an image and a question as input and provides an answer based on the visual content of the image and the context of the question."}
{"text_id": 101, "text": "query: As a police investigator, we would like to use this Hugging Face VQA model to extract useful information by asking questions about images without manually looking at each photo."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: I'm an accountant. I need a quick summary of this financial news article to share with my colleagues."}
{"text_id": 9, "text": "document: IndoBERT is a state-of-the-art language model for Indonesian based on the BERT model. The pretrained model is trained using a masked language modeling (MLM) objective and next sentence prediction (NSP) objective."}
{"text_id": 9, "text": "query: We are building a recommendation system that suggests articles to readers. We need a representation of the article texts to recommend related articles."}
{"text_id": 435, "text": "document: A multilingual Named Entity Recognition (NER) model fine-tuned on the WikiNEuRal dataset, supporting 9 languages (de, en, es, fr, it, nl, pl, pt, ru). It is based on the mBERT architecture and trained on all 9 languages jointly. The model can be used with the Hugging Face Transformers pipeline for NER tasks."}
{"text_id": 435, "text": "query: \"Elon Musk's SpaceX was able to land the Falcon 9 rocket at Cape Canaveral, Florida.\""}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: Since my son Tom loves the Pong game, I want to train an agent for him on his behalf to play it."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: I am searching for a great all-around audio model that will work in a variety of specific applications such as audio classification, speaker identification, and emotion recognition."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: We have to detect objects present in a given image URL and classify them using an appropriate pre-trained model."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: A group of friends is creating a podcast, and they want to separate the voice of each participant in the recording."}
{"text_id": 52, "text": "document: Dream Shaper is a text-to-image model that generates artistic images based on the given input text. Read more about this model here: https://civitai.com/models/4384/dreamshaper"}
{"text_id": 52, "text": "query: An art gallery wants to display paintings inspired by the theme \"A serene forest at dawn\". Use DreamShaper to generate an image for them."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: The company is building an educational website for students. We need an assistant to answer questions from students."}
{"text_id": 598, "text": "document: DialoGPT trained on Russian language and fine tuned on my telegram chat. This model was created by sberbank-ai and trained on Russian forums. It has been fine-tuned on a 30mb json file of exported telegram chat data."}
{"text_id": 598, "text": "query: We are developing a chatbot for customer support, which can answer users' questions in Russian. The chatbot needs to have the ability to generate meaningful responses."}
{"text_id": 516, "text": "document: This model was trained on the MultiNLI, Fever-NLI and Adversarial-NLI (ANLI) datasets, which comprise 763 913 NLI hypothesis-premise pairs. This base model outperforms almost all large models on the ANLI benchmark. The base model is DeBERTa-v3-base from Microsoft. The v3 variant of DeBERTa substantially outperforms previous versions of the model by including a different pre-training objective, see annex 11 of the original DeBERTa paper."}
{"text_id": 516, "text": "query: \"We are looking for a talented software engineer with strong programming skills in Python and experience working with cloud technologies.\""}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: I am a content writer for a blog. I have a title \"Advantages of using electric cars\" but I'm having trouble starting the article. Can you provide me with an interesting introductory paragraph?"}
{"text_id": 640, "text": "document: PEGASUS fine-tuned for paraphrasing"}
{"text_id": 640, "text": "query: Convert the provided text into a paraphrased version using language model."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: Prompt the bot to extract information about entities located in an image containing text."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: ###Instruction:I want to develop an application that allows users to input text and then the system generates speech based on the text."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: I need an image description for an e-commerce website with a picture of a green bicycle."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: We have a dataset of timezone:utc_offset mapping, and we would like to know the UTC offset for a specific timezone."}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: We have a data set containing various factors that influence carbon emissions. We wish to predict whether a given set of conditions will result in high or low emissions."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: We have a list of product pictures, please create a personal assistant that can recognize which aisle of the supermarket the product belongs to."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: We are currently restoring historical photographs, and some parts of the image are badly damaged. We need to effectively fill in the missing parts of the image based on the surrounding areas."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: You are an AI company working with restaurants. They are asking for making an AI vision system to detect what kind of dish is shown in a given picture and answer questions."}
{"text_id": 71, "text": "document: BLIP-2 model, leveraging Flan T5-xxl (a large language model). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The model is used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 71, "text": "query: Design a model that can answer questions related to images, such as \"How many animals are in the picture?\" or \"What color is the car?\""}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: We are holding an international event where participants from different countries will be speaking. We need to predict punctuation of transcriptions of the speeches in English, Italian, French, and German."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: We need to generate an image using the diffusion-based text-to-image method and save it."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: Tell me how to implement a pothole detection model for an autonomous vehicle."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: The company we work for is developing a wine recommendation system. They want to determine the quality of a wine based on its characteristics."}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: We want an application that identifies any potholes in an image to help improve driver safety."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: We are a news website, we need to categorize the images under several groups."}
{"text_id": 175, "text": "document: ResNet model trained on imagenet-1k. It was introduced in the paper Deep Residual Learning for Image Recognition and first released in this repository. ResNet introduced residual connections, they allow to train networks with an unseen number of layers (up to 1000). ResNet won the 2015 ILSVRC & COCO competition, one important milestone in deep computer vision."}
{"text_id": 175, "text": "query: We are an ecommerce website that just launched a mobile app for our users. We need to categorize the products users upload based on the images they provide."}
{"text_id": 281, "text": "document: GreeneryScenery/SheepsControlV3 is a model for image-to-image tasks. It can be used to generate images based on the input image and optional text guidance. The model has some limitations, such as the conditioning image not affecting the output image much. Improvements can be made by training for more epochs, using better prompts, and preprocessing the data."}
{"text_id": 281, "text": "query: Design a product that automatically generates personalized holiday cards, adding festive elements to the uploaded images provided by the users."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: We need a program that can caption images, so we can create captivating descriptions for the images we post on social media."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: How do I classify Chinese sentences based on their similarities using the provided pretrained model?"}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: Implement a depth estimation model for our autonomous vehicle navigation system."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: We want to create a high-resolution image of a majestic lion in a landscape by using a low resolution image as base."}
{"text_id": 102, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is a Transformer decoder conditioned on both CLIP image tokens and text tokens. It can be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification."}
{"text_id": 102, "text": "query: Recently, we developed a home automation system. Please provide the suitable code instructions, if we want to integrate a visual question answering pipeline to assist users with their questions about any visual object within their home."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: Imagine you are inputting a custom character personality for your AI. Make the AI flirt with you with a funny pickup line."}
{"text_id": 72, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 72, "text": "query: We need to extract the text that is embedded in a cursive, hand-written image."}
{"text_id": 793, "text": "document: Speech-to-speech translation model with single-pass decoder (S2UT) from fairseq: English-Hokkien. Trained with supervised data in TED domain, and weakly supervised data in TED and Audiobook domain."}
{"text_id": 793, "text": "query: Could you design a small AI system which could let us upload English audio file and it will give us the translated audio in Hokkien language."}
{"text_id": 141, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSCv2. Developed by Microsoft, it is designed for graph classification tasks or graph representation tasks, such as molecule modeling."}
{"text_id": 141, "text": "query: To create a software for analyzing chemical molecules, we should predict their properties with a pre-trained model."}
{"text_id": 422, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 422, "text": "query: The CEO of the marketing company would like to better communicate with Chinese clients. Help him break down his Chinese sentence into tokens."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: Generate a script that will load a trained PPO model and evaluate the model's performance on LunarLander-v2."}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: In order to help our customers find information more quickly, we require a model that can answer their questions based on the given context."}
{"text_id": 421, "text": "document: This is the standard universal part-of-speech tagging model for English that ships with Flair. It predicts universal POS tags such as ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, and X. The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 421, "text": "query: A school project requires students to analyze grammar in a given piece of text. We want to identify the different parts of speech (nouns, verbs, adjectives, etc.) present."}
{"text_id": 681, "text": "document: CodeBERTa is a RoBERTa-like model trained on the CodeSearchNet dataset from GitHub. It supports languages like Go, Java, JavaScript, PHP, Python, and Ruby. The tokenizer is a Byte-level BPE tokenizer trained on the corpus using Hugging Face tokenizers. The small model is a 6-layer, 84M parameters, RoBERTa-like Transformer model."}
{"text_id": 681, "text": "query: I am a software engineer. I want to use a code completion tool that provides suggestions for coding in languages like Python, Java, and JavaScript."}
{"text_id": 417, "text": "document: This is the 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. Based on Flair embeddings and LSTM-CRF."}
{"text_id": 417, "text": "query: Implement a named entity recognition system for an app that will extract names of people, organizations, and monetary values in a given text."}
{"text_id": 301, "text": "document: This model is a diffusion model for unconditional image generation of the universe trained for 1400 epochs."}
{"text_id": 301, "text": "query: As an artist, I want to create a cosmic-themed painting. Show me an example of a cosmic-themed image for inspiration."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Calculate carbon emissions from given data and help a company reduce its overall emissions."}
{"text_id": 574, "text": "document: PEGASUS fine-tuned for summarization"}
{"text_id": 574, "text": "query: I need a text summarization model to generate summaries of my long articles."}
{"text_id": 204, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 204, "text": "query: An e-commerce company wants to build a product that automatically categorizes their products based on the images available on the site."}
{"text_id": 927, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 927, "text": "query: Can you help me describe the contents of a photo I have taken? I want to share it with someone who has a visual impairment."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: You are building an app for urban gardeners to help them recognize the type of bean plant they are growing. Include a feature to identify the specific type of bean based on the uploaded image of the plant."}
{"text_id": 229, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players with supported labels: ['ct', 'cthead', 't', 'thead']."}
{"text_id": 229, "text": "query: Global Offensive. We want an AI-based object detection for tracking from just a screenshot."}
{"text_id": 511, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 511, "text": "query: I am a movie critic, and I want to automatically generate an article. I already have the headline written. I want to add a paragraph and a sentiment into the text."}
{"text_id": 64, "text": "document: BLIP-2 model, leveraging OPT-2.7b (a large language model with 2.7 billion parameters). It was introduced in the paper BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models by Li et al. and first released in this repository. The goal for the model is to predict the next text token, given the query embeddings and the previous text. This allows the model to be used for tasks like image captioning, visual question answering (VQA), and chat-like conversations by feeding the image and the previous conversation as prompt to the model."}
{"text_id": 64, "text": "query: I have an image, and I want the AI to describe what's happening in it."}
{"text_id": 695, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 695, "text": "query: We are trying to build an application with semantic search which leverages a sentence-transformer model for computing sentence embeddings."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: We need a summary of a conversation that happened yesterday at a meeting in Russian."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: I am a student interested in AI art. I am painting a picture and would like an AI-enabled app to correctly read the mix of hand-drawn handwriting and objects from the picture."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: Generate an image of a beautiful forest scene with a clear blue sky and lush green trees based on a text description."}
{"text_id": 572, "text": "document: BlenderBot-400M-distill is a distilled version of the BlenderBot model, trained on the Blended Skill Talk dataset. It is designed for open-domain chatbot tasks and can generate text-to-text responses in a conversational manner. The model is based on the Transformers library and can be used with PyTorch, TensorFlow, and JAX."}
{"text_id": 572, "text": "query: I want to create a conversational AI chatbot that can help me book a hotel room."}
{"text_id": 190, "text": "document: MobileNet V2 model pre-trained on ImageNet-1k at resolution 224x224. It was introduced in MobileNetV2: Inverted Residuals and Linear Bottlenecks by Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 190, "text": "query: I am a college student working on a project to categorize various images. I need some help to classify the objects in a given image."}
{"text_id": 600, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 600, "text": "query: I am building an AI-driven customer support chatbot. We need to generate well-formed and informative responses to customers."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: You are working for a language processing company, and your goal is to suggest some possible words for a masked semantic opening message."}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: We need a model to provide textual descriptions and answers to questions about charts."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: Our client's podcasts need to be transcribed into text files."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: I need a parking management system to locate free parking spaces and analyze the available space."}
{"text_id": 875, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions."}
{"text_id": 875, "text": "query: Create a code to estimate the carbon emissions using data from a sensor in an IoT environment."}
{"text_id": 492, "text": "document: Camembert-base model fine-tuned on french part of XNLI dataset. One of the few Zero-Shot classification models working on French."}
{"text_id": 492, "text": "query: Create a system to determine if a French news article is related to sports, politics, or science."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: Our company works on developing a customer service application and we need to transcribe voice messages in Russian."}
{"text_id": 935, "text": "document: GIT (short for GenerativeImage2Text) model, base-sized version, fine-tuned on VQAv2. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository."}
{"text_id": 935, "text": "query: Create a program that answers questions related to the content of an image."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: I want to parse the part-of-speech (POS) of each word in a given Chinese text using the 'bert-base-chinese-pos' pretrained model."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: The CEO needs a demo for a multimodal AI that takes a textual description of a scene and generates a short video of that scene."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: Create an image segmentation model that identifies and separates objects and background in a photo taken during a walk in the park."}
{"text_id": 310, "text": "document: This model is a diffusion model for unconditional image generation of shoes trained on a custom dataset at 128x128 resolution."}
{"text_id": 310, "text": "query: In my free time, I am designing an AI shoes collection. Generate a random high-style shoe pattern."}
{"text_id": 186, "text": "document: MobileNet V1 model pre-trained on ImageNet-1k at resolution 192x192. It was introduced in MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications by Howard et al, and first released in this repository. MobileNets are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices."}
{"text_id": 186, "text": "query: Create a program to identify objects in images, making use of MobileNet V1 model."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: We have a recorded meeting and we need to separate the speakers in the given meeting."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: We are a customer service team, and our customers asked us a question about our product. Please provide the answer."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: In this eCommerce website database, we have a DataFrame of products and their prices. We want to select all the products that are between $15 and $30 with their prices."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: As a scientist researching important historical documents, I need to extract information from documents to answer my questions about them."}
{"text_id": 43, "text": "document: This is a fine-tuned VAE decoder for the Stable Diffusion Pipeline. It has been fine-tuned on a 1:1 ratio of LAION-Aesthetics and LAION-Humans datasets. The decoder can be used as a drop-in replacement for the existing autoencoder."}
{"text_id": 43, "text": "query: We are trying to develop a storybook for kids using AI-generated images based on the text descriptions. Help us generate an image of a \"blue elephant playing soccer with a red ball\"."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: Design a robot vision system capable of recognizing objects and navigating through an indoor environment, such as an office or a home, to perform specific tasks."}
{"text_id": 818, "text": "document: This model is a fine-tuned version of microsoft/wavlm-base-plus on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0093, Accuracy: 0.9973."}
{"text_id": 818, "text": "query: We are building an interactive toy for children that recognizes numbers from 0 to 9 in spoken language. Please provide a solution for number recognition."}
{"text_id": 828, "text": "document: This repository provides all the necessary tools to perform emotion recognition with a fine-tuned wav2vec2 (base) model using SpeechBrain. It is trained on IEMOCAP training data."}
{"text_id": 828, "text": "query: I am building a software to detect emotions in audio for customer service improvement. Can you give me an example code on how to detect emotions in a single audio file?"}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: I want to design a photo application that will take users' text queries and highlight the specific objects mentioned in the queries in the images."}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: I need a table question-answering system that can extract information from a given table and answer my questions."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: I am a biologist studying cells under a microscope. I have an image of a cell and want to segment it to identify different organelles by leveraging zero-shot image segmentation."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: Your company plans to creating a customer-service chatbot. Get a good idea of how GPT-3 can be useful for you."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: Analyze incoming surveillance video feeds from a traffic camera network. Detect and automatically classify object types like car, truck, bike and pedestrian."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: Our company is developING a mobile app for real estate agents that automatically suggests the type or style of a property based on an image, determine the technology we will use."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: A financial news company needs to determine the sentiment of the daily news headlines to adjust the contents accordingly."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: Create a tool to analyze the sentiment of tweets about the launch of our new product."}
{"text_id": 817, "text": "document: This model is a fine-tuned version of MIT/ast-finetuned-speech-commands-v2 on the None dataset. It achieves the following results on the evaluation set: Loss: 0.0210, Accuracy: 0.9979"}
{"text_id": 817, "text": "query: We are launching an audio-based game and we need to classify vocal commands from 0 to 9, up and down."}
{"text_id": 857, "text": "document: This model is trained for Multi-class Classification on CO2 Emissions dataset. It uses the Hugging Face Transformers framework and is based on the extra_trees algorithm. The model is trained with AutoTrain and has a tabular classification functionality."}
{"text_id": 857, "text": "query: I need to predict the classes of CO2 emissions for a set of samples in a CSV dataset."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: A furniture store is using an image classification model to automatically tag images of furniture products for their website. The products include sofas, tables, chairs, and beds. The model should be able to differentiate among those categories and classify them correctly."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: I want to develop a functionality to generate custom descriptions for images for visually impaired people."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: Our client is a lawyer and needs help extracting essential information from a legal document."}
{"text_id": 279, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on normalbae images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 279, "text": "query: \"It's the little things that make life beautiful.\""}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: Create a machine learning model to predict the quality rating of wines."}
{"text_id": 522, "text": "document: Helsinki-NLP/opus-mt-en-fr is a translation model that translates English text to French using the Hugging Face Transformers library. It is based on the OPUS dataset and uses a transformer-align architecture with normalization and SentencePiece pre-processing."}
{"text_id": 522, "text": "query: Develop a simple script that translates a given English text input to French."}
{"text_id": 882, "text": "document: A tabular regression model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 882, "text": "query: Utilize this model to predict the carbon emission for a set of input data."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: We need a solution to help customers find answers to their questions from a table containing information in Korean. Please create a pipeline using a model that can achieve this."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: I am a sales person, and we make next generation Advanced Driver Assistance Systems for vehicle automation. We have a Japanese customer who needs to build conversational system for automobiles using Natural Language Processing."}
{"text_id": 491, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is designed for zero-shot classification tasks."}
{"text_id": 491, "text": "query: Identify the sentiment of a given movie review as \"positive\", \"neutral\", or \"negative\"."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: I have a text file called conversation.txt that contains a conversation between two people. I want to use the Cadet-Tiny model to generate responses from the AI based on the content of the conversation."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: I have recorded a video clip of a sport activity. Help me identify the sport."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: We are developing an application to identify and categorize different types of animals in images. Using an existing image classification model, help us recognize the animal present in an image."}
{"text_id": 902, "text": "document: This is a trained model of a DQN agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 902, "text": "query: Design an auto-pilot software for a space probe that needs to land successfully and smoothly on the surface of the celestial body."}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: Describe the process of generating a video clip with a scene where a dog is playing with a ball in a park."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: We are asked to generate an image by applying Canny edge detection to an existing image."}
{"text_id": 218, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. It uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. OWL-ViT is trained on publicly available image-caption data and fine-tuned on publicly available object detection datasets such as COCO and OpenImages."}
{"text_id": 218, "text": "query: I want to identify objects in an image based on a set of text conditions."}
{"text_id": 476, "text": "document: This is a BERT base cased model trained on SQuAD v2"}
{"text_id": 476, "text": "query: I am building a job application that matches skills of the applicants with jobs to recommend the perfect fit. How can I ask the model for help?"}
{"text_id": 514, "text": "document: This model has GBERT Large as base model and fine-tuned it on xnli de dataset. The default hypothesis template is in English: This text is {}. While using this model, change it to In deisem geht es um {}. or something different. While inferencing through huggingface api may give poor results as it uses by default english template. Since model is monolingual and not multilingual, hypothesis template needs to be changed accordingly."}
{"text_id": 514, "text": "query: Our company is working on a news aggregator. We need a way to classify German news articles into relevant categories."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: Our company works with medical data. We want to extract specific biomedical entities from patient case reports."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: I have a conversation from a movie script in English that I want to translate into Chinese."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: Develop a service that detects whether a video is related to playing soccer or practicing yoga."}
{"text_id": 645, "text": "document: mBART-50 is a multilingual Sequence-to-Sequence model pre-trained using the 'Multilingual Denoising Pretraining' objective. It was introduced in Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 645, "text": "query: Translate a given English sentence to Romanian to be used in a chat product."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: We are working on improving our customer support services. Find a way to measure how similar customer questions are to our knowledge base articles."}
{"text_id": 120, "text": "document: A Document Question Answering model based on LayoutXLM."}
{"text_id": 120, "text": "query: We are a law firm, and we want to extract information from legal documents to answer our clients' specific questions."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: Our company is launching an online art gallery app, and we need an art categorization system to identify art styles in paintings."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: Our marketing team targets Spanish-speaking audiences. We need to categorize new articles for a better understanding of our audience's interests."}
{"text_id": 15, "text": "document: RuBERT (Russian, cased, 12\u2011layer, 768\u2011hidden, 12\u2011heads, 180M parameters) was trained on the Russian part of Wikipedia and news data. We used this training data to build a vocabulary of Russian subtokens and took a multilingual version of BERT\u2011base as an initialization for RuBERT[1]."}
{"text_id": 15, "text": "query: Help me to extract features from a piece of text in Russian that I can use for further analysis or machine learning tasks."}
{"text_id": 866, "text": "document: A binary classification model for predicting CO2 emissions based on tabular data. Trained using AutoTrain with a model ID of 1780161764."}
{"text_id": 866, "text": "query: Our team is attempting to predict carbon emissions levels based on tabular data."}
{"text_id": 332, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.5482, Accuracy: 0.7298."}
{"text_id": 332, "text": "query: We have a collection of sport videos and we want to automatically tag them with the sport being played in the video."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: Our company is releasing a new AI chatbot, and we need to integrate a text generation model. It should generate engaging and human-like responses for the users."}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: We are a customer support center. We need to analyze phone call recordings and find when the customers are speaking."}
{"text_id": 544, "text": "document: A translation model trained on the OPUS dataset that supports translation between English and various Romance languages. It uses a transformer architecture and requires a sentence initial language token in the form of >>id<< (id = valid target language ID)."}
{"text_id": 544, "text": "query: Design a system to translate our social media content to Italian."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: A company that sells video courses on meditation wants to offer their lectures in different languages, starting with Japanese. We need to detect the content of the lectures."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: Let's build a helper function to autofill incomplete sentences."}
{"text_id": 397, "text": "document: This model is a fine-tuned version of textattack/bert-base-uncased-yelp-polarity on a filtered and manually reviewed Yelp dataset containing restaurant reviews only. It is intended to perform text classification, specifically sentiment analysis, on text data obtained from restaurant reviews to determine if the particular review is positive or negative."}
{"text_id": 397, "text": "query: We are a restaurant reviewing website. We want to determine if a Yelp review is positive or negative."}
{"text_id": 824, "text": "document: This is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-large-ll60k, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 824, "text": "query: I want to build a movie recommendation app that suggests film suggestions based on the emotions contained in the audio samples of the movies."}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: We have an image of a street scene with various elements including traffic signs, vehicles, and pedestrians. I would like to know, is there a zebra crossing in the image?"}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: I am building a new navigation app that needs to understand traffic signals and road signs. Help me create a model for this."}
{"text_id": 497, "text": "document: distilbart-mnli is the distilled version of bart-large-mnli created using the No Teacher Distillation technique proposed for BART summarisation by Huggingface. It is a simple and effective technique with very little performance drop."}
{"text_id": 497, "text": "query: Develop a tool for categorizing social media posts into themes such as sports, politics, travel, or technology according to the user's preferences."}
{"text_id": 395, "text": "document: This model is distilled from the zero-shot classification pipeline on the unlabeled GoEmotions dataset. It is primarily intended as a demo of how an expensive NLI-based zero-shot model can be distilled to a more efficient student, allowing a classifier to be trained with only unlabeled data."}
{"text_id": 395, "text": "query: I am building a wellbeing app. I want to analyze users' emotions by reading their message. Can you help me with a language model to analyze the emotions?"}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: I am a biomedical researcher, and I need to classify an image of a cell into various types of cell stage."}
{"text_id": 725, "text": "document: A text-to-speech model trained on mtedx, covost2, europarl_st, and voxpopuli datasets for English, French, Spanish, and Italian languages. Licensed under cc-by-nc-4.0."}
{"text_id": 725, "text": "query: We are an online language learning platform. We need to convert an article in the form of text into speech for our users who are learning English, French, Spanish, and Italian."}
{"text_id": 513, "text": "document: This model is a Cross-Encoder for Natural Language Inference, trained on the SNLI and MultiNLI datasets. It can be used for zero-shot classification tasks."}
{"text_id": 513, "text": "query: Develop a tool for news classification that can automatically identify the category of an article like sports, technology, or politics."}
{"text_id": 480, "text": "document: This model is a distilled version of deepset/roberta-large-squad2, trained on SQuAD 2.0 dataset for question answering tasks. It is based on the Roberta architecture and has been fine-tuned using Haystack's distillation feature."}
{"text_id": 480, "text": "query: Can you help me to create a personal study assistant that answers questions for my Economics course?"}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: Develop a code to estimate the depth of an image for robotics."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: generate a human-like face as the main poster background and save it as a file named \"movie_poster.png\"."}
{"text_id": 377, "text": "document: FinBERT is a BERT model pre-trained on financial communication text. It is trained on the following three financial communication corpus: Corporate Reports 10-K & 10-Q, Earnings Call Transcripts, and Analyst Reports. This released finbert-tone model is the FinBERT model fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analyst reports. This model achieves superior performance on financial tone analysis task."}
{"text_id": 377, "text": "query: The company is launching a new product. We need to analyze the customer reviews on Amazon to assess if the users are happy with the product."}
{"text_id": 547, "text": "document: PEGASUS model for abstractive summarization, pretrained on the CNN/DailyMail dataset."}
{"text_id": 547, "text": "query: We need to write a summary for a news article on our company website."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: We are designing a website that displays pictures of various products. Upon image upload, we need to identify the top 5 product categories."}
{"text_id": 750, "text": "document: Automatic overlapped speech detection using pyannote.audio framework. The model detects when two or more speakers are active in an audio file."}
{"text_id": 750, "text": "query: We are adding a feature in transcription service where it can detect overlapped speech from an audio file. Can you help us extract those timestamps?"}
{"text_id": 604, "text": "document: COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets (e.g., DailyDialog, BlendedSkillTalk). It is trained on two datasets: SODA and ProsocialDialog. COSMO is especially aiming to model natural human conversations. It can accept situation descriptions as well as instructions on what role it should play in the situation."}
{"text_id": 604, "text": "query: I want to simulate a conversation where I ask the perspective of an AI called Cosmo about its experience at the EMNLP conference in Abu Dhabi."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: A research team in studying urban noise pollution is recording different audios from Russian city streets, and they intend to transcribe those audios into text."}
{"text_id": 314, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 314, "text": "query: Create an application that generates images of butterflies."}
{"text_id": 22, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 22, "text": "query: A news aggregator is looking for a way to group similar articles together. We can suggest using sentence embedding to do this task."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: We are building a voice assistant, and we need to transcribe the user's spoken requests into text."}
{"text_id": 914, "text": "document: This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews in six languages: English, Dutch, German, French, Spanish and Italian. It predicts the sentiment of the review as a number of stars (between 1 and 5)."}
{"text_id": 914, "text": "query: Our company wants to collect customer feedback for products and categorize feedback based on language and sentiment. Analyze the sentiments of the customer reviews."}
{"text_id": 913, "text": "document: This is a trained model of a PPO agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 913, "text": "query: We are playing an arcade game, Breakout, and we need an AI-based agent to be trained for playing it. How should we proceed with it?"}
{"text_id": 619, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The checkpoint included in this repository is denoted as CodeGen-Multi 350M, where Multi means the model is initialized with CodeGen-NL 350M and further pre-trained on a dataset of multiple programming languages, and 350M refers to the number of trainable parameters. The model is capable of extracting features from given natural language and programming language texts, and calculating the likelihood of them. It is best at program synthesis, generating executable code given English prompts, and can complete partially-generated code as well."}
{"text_id": 619, "text": "query: I want to create an AI-powered code generator that completes a partially written Python function that calculates the sum of square values of numbers in a list."}
{"text_id": 399, "text": "document: DistilBERT is a transformer model that performs sentiment analysis. I fine-tuned the model on Reddit posts with the purpose of classifying not safe for work (NSFW) content, specifically text that is considered inappropriate and unprofessional. The model predicts 2 classes, which are NSFW or safe for work (SFW). The model is a fine-tuned version of DistilBERT. It was fine-tuned on 14317 Reddit posts pulled from the Reddit API."}
{"text_id": 399, "text": "query: Our client is responsible for tracking offensive content in user messages. We need to determine if a message is safe for work or not safe for work."}
{"text_id": 553, "text": "document: This CodeTrans model is based on the t5-base model and is trained on tokenized python code functions. It can be used to generate descriptions for python functions or be fine-tuned on other python code tasks. The model works best with tokenized python functions but can also be used on unparsed and untokenized python code."}
{"text_id": 553, "text": "query: We want to create a function in Python to help developers by automatically generating comments/documentation for their functions. Please provide a solution."}
{"text_id": 591, "text": "document: BlenderBot-90M is a conversational AI model developed by Facebook AI. It is trained on the Blended Skill Talk dataset and aims to provide engaging and human-like responses in a multi-turn dialogue setting. The model is deprecated, and it is recommended to use the identical model https://huggingface.co/facebook/blenderbot_small-90M instead."}
{"text_id": 591, "text": "query: John wants to chat with an AI like he is talking to a friend."}
{"text_id": 565, "text": "document: BigBird, is a sparse-attention based transformer which extends Transformer based models, such as BERT to much longer sequences. Moreover, BigBird comes along with a theoretical understanding of the capabilities of a complete transformer that the sparse model can handle. BigBird was introduced in this paper and first released in this repository. BigBird relies on block sparse attention instead of normal attention (i.e. BERT's attention) and can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. It has achieved SOTA on various tasks involving very long sequences such as long documents summarization, question-answering with long contexts."}
{"text_id": 565, "text": "query: In our company, we have discovered numerous scientific papers, and we need to summarize them all to facilitate decision making."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: I want to use a language model to determine how similar two sentences are and then calculate their cosine similarity."}
{"text_id": 849, "text": "document: This model uses self-attention based Transformers structure followed by multiple feed forward layers to serve supervised and semi-supervised learning tasks on tabular data. The model's inputs can contain both numerical and categorical features. Categorical features are encoded into embedding vectors before being fed into a stack of Transformer blocks. The contextual embeddings of the categorical features after the final Transformer layer are concatenated with the input numerical features and fed into a final MLP block. A SoftMax function is applied at the end of the model."}
{"text_id": 849, "text": "query: Your job is to help us create a tool to market products based on a table which lists details regarding customers and their preferences."}
{"text_id": 32, "text": "document: Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask."}
{"text_id": 32, "text": "query: Generate an image of a yellow cat relaxing on a park bench surrounded by cherry blossoms."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: My iPhone is telling me there is an update. Can you identify what it is trying to download from this image of the update screen?"}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: I want my personal assistant to translate text, write summaries, and check grammar for any given text."}
{"text_id": 87, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of DeiT, while the text decoder was initialized from the weights of UniLM."}
{"text_id": 87, "text": "query: I have image containing price information about gadgets, I want to make a python script to extract the text from the image and categorize the gadgets by their prices."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: I am the chief architect at a company building models to generate realistic butterfly images for an upcoming nature documentary. We need a pipeline for this task."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: Develop a system to autonomously navigate a drone indoors, the drone needs to avoid obstacles and measure its distance to them."}
{"text_id": 457, "text": "document: TAPAS mini model fine-tuned on Sequential Question Answering (SQA)"}
{"text_id": 457, "text": "query: We need help from an AI to answer a series of questions based on this table."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: We are a medical support system developing chatbots for doctors. We require keywords and intensity of each sentence related to medical terminology."}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: A design studio needs to generate images from text to help with their visual projects."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: We have descriptions for each image that we want to create. Transform descriptions into images with a high-quality output."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: I am doing a presentation about my travels. Could you prepare a script for the short title \"Traveling through Europe\"."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: Detect similar questions in an FAQ dataset to avoid repetitive inquiries."}
{"text_id": 815, "text": "document: This repository provides all the necessary tools to extract speaker embeddings with a pretrained TDNN model using SpeechBrain. The system is trained on Voxceleb 1+ Voxceleb2 training data."}
{"text_id": 815, "text": "query: Our customer analyzing company needs a technology that helps our operators to verify speakers' identity."}
{"text_id": 534, "text": "document: A transformer model for Italian to English translation trained on the OPUS dataset. It can be used for translating Italian text to English."}
{"text_id": 534, "text": "query: We have an Italian travel blog. We would like to translate it to English."}
{"text_id": 402, "text": "document: bert-base-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC). Specifically, this model is a bert-base-cased model that was fine-tuned on the English version of the standard CoNLL-2003 Named Entity Recognition dataset."}
{"text_id": 402, "text": "query: Our company is working on a digital assistant for booking hotels. We need to extract the names of users, cities, and organizations from messages."}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: The company's HR department needs to analyze employee data and answer various questions related to it."}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: Please provide instructions on classifying objects in images for an app that helps visually impaired users recognize objects around them."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: As a news agency, write a code to automatically translate the most important breaking news texts to French."}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: \"Introducing our new product line, available now in stores and online.\""}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: Create a speech security system that uses speaker verification."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: I am a journalist, and I'd like to categorize news articles into various sections like technology, sports, and politics."}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: We are a healthcare research organization in need of generating suggestions to complete a sentence where a word is missing."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: Please help me create an image classifier to recognize different dog breeds, such as golden retriever, german shepherd, labrador retriever, and poodle."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: The product I'm developing aims to identify the style of an artwork. I need a model that can classify it into abstract, expressionist, impressionist, or surrealist categories."}
{"text_id": 287, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN, obtaining state-of-the-art FID score of 3.17 and Inception score of 9.46."}
{"text_id": 287, "text": "query: Recommend a model for creating procedurally generated avatars for the users of our app."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: Create a text announcement for the launch of a new technology product."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: We are a company that specializes in digital art. We want to extract features from images using machine learning models."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: I need to predict the closing price of a stock, based on a given dataset."}
{"text_id": 83, "text": "document: DePlot is a model that translates the image of a plot or chart to a linearized table. It decomposes the challenge of visual language reasoning into two steps: (1) plot-to-text translation, and (2) reasoning over the translated text. The output of DePlot can then be directly used to prompt a pretrained large language model (LLM), exploiting the few-shot reasoning capabilities of LLMs."}
{"text_id": 83, "text": "query: Understand the content of an image-based chart we have received and provide the underlying data table."}
{"text_id": 448, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 448, "text": "query: Your company wants to track customer satisfaction rate based on specific factors. They have a dataset in the form of a table, and you need to create a system that can run SQL queries on the table."}
{"text_id": 160, "text": "document: This AI model is designed to train on the MNIST dataset with a specified data cap and save the trained model as an .onnx file. It can be attached to the GTA5 game process by PID and checks if the targeted application is running. The model is trained on a GPU if available."}
{"text_id": 160, "text": "query: We're developing a game that plays like Grand Theft Auto 5, and we need an AI model to intelligently perform game actions."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: I want a translation tool that translates text between English, Chinese, and Russian."}
{"text_id": 910, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 910, "text": "query: Our company is developing an autonomous robot to navigate the office and pick up objects. Implement a model for visual understanding."}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: Our online store sells various products. Customers provide reviews for these products. We need a classifier model to predict the sentiment of those reviews based on the text."}
{"text_id": 477, "text": "document: ELECTRA_large_discriminator language model fine-tuned on SQuAD2.0 for question answering tasks."}
{"text_id": 477, "text": "query: I have so many meetings and I want to get answers about the details from the mails. In a meeting invitation mail, could you tell the venue of the meeting?"}
{"text_id": 721, "text": "document: This repository provides all the necessary tools for using a HiFIGAN vocoder trained with LJSpeech. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram. The sampling frequency is 22050 Hz."}
{"text_id": 721, "text": "query: \"Welcome to our podcast! Today, we will discuss the latest trends in technology.\" Create an audio snippet with this text."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: As an illustrator looking for inspiration, I'd like to generate an anime image from a text prompt."}
{"text_id": 142, "text": "document: The Graphormer is a graph Transformer model, pretrained on PCQM4M-LSC, and which got 1st place on the KDD CUP 2021 (quantum prediction track). Developed by Microsoft, this model should be used for graph classification tasks or graph representation tasks; the most likely associated task is molecule modeling. It can either be used as such, or finetuned on downstream tasks."}
{"text_id": 142, "text": "query: A pharmaceutical company wants to predict quantum properties of molecules. Guide them on the approach with the requirements."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: Develop an application that listens to Russian speech and recommends a song with a similar emotion."}
{"text_id": 586, "text": "document: BrandonBot4Epochs is a conversational model trained on the GPT-2 architecture for text generation. It can be used to generate responses in a chatbot-like interface."}
{"text_id": 586, "text": "query: In our customer support system, we need an AI to chat with people when there aren't any customer support agents available."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: The managers at our call center need to have a tool that helps them differentiate between when there's an actual voice on a call and when there's silence or background noise. How can we help them with this?"}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: We are building a smart home system specifically for Russian households, and it needs to be able to recognize different emotions in users' speech."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: The finance team is analyzing stock-related comments. Help us predict the sentiment of these comments."}
{"text_id": 904, "text": "document: This is a trained model of a TD3 agent playing Ant-v3 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 904, "text": "query: Our company is in the robotics field and we would like to train a reinforcement learning model to make an ant-like robot walk."}
{"text_id": 761, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Japanese. Trained on Common Voice 6.1, CSS10, and JSUT datasets. Make sure your speech input is sampled at 16kHz."}
{"text_id": 761, "text": "query: We are working on a Japanese education project and we want to test our students' pronunciation. Help us transcribe and record their individual phrases."}
{"text_id": 277, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for lightweight image super resolution."}
{"text_id": 277, "text": "query: A tourist needs to enhance the resolution of a captured image from a vacation."}
{"text_id": 304, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 304, "text": "query: A publishing house wants to include high-quality graphics of butterflies in their upcoming biology book. Generate an unconditional image of a butterfly for them."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: I am preparing an educational book about butterflies. Generate a colorful butterfly image for me."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: Summarize a news article to save reading time."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: I am working on a project where I have a lot of long paragraphs and I need to extract answers based on certain questions I provide. How can I do this?"}
{"text_id": 253, "text": "document: MaskFormer model trained on COCO panoptic segmentation (tiny-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository."}
{"text_id": 253, "text": "query: We want to segment the objects in an image to understand the different parts better."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: Analyze a chat between customers discussing our latest product and give a shortened, concise summary."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: As a sports performance analysis company, we need to analyze the videos of athletes playing various sports."}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: I need a system to answer questions based on a table of statistics about average monthly rainfall for various regions."}
{"text_id": 722, "text": "document: SpeechT5 model fine-tuned for speech synthesis (text-to-speech) on LibriTTS. It is a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. It can be used for a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification."}
{"text_id": 722, "text": "query: We are a startup working on AI voice assistants. We require a text-to-speech system to synthesize our feedback responses."}
{"text_id": 11, "text": "document: CODER: Knowledge infused cross-lingual medical term embedding for term normalization. English Version. Old name. This model is not UMLSBert! Github Link: https://github.com/GanjinZero/CODER"}
{"text_id": 11, "text": "query: We need to analyze medical terms and identify their embeddings to build a medical glossary for an app. Please help in using the appropriate API."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: Our company provides the MaaS (Mobility as a Service) platform. We are developing a prediction model for emission calculation. "}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: Can you identify if my dog is a Labrador Retriever, a Golden Retriever, or a Rottweiler from an image I provide?"}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: Our client is a call center company, and they need to monitor the customer support team automatically via voice."}
{"text_id": 7, "text": "document: Vision Transformer (ViT) model trained using the DINO method. The model is pretrained on a large collection of images in a self-supervised fashion, namely ImageNet-1k, at a resolution of 224x224 pixels. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder. Note that this model does not include any fine-tuned heads."}
{"text_id": 7, "text": "query: Predict the class of objects in a given image using the DINO method on a Vision Transformer model."}
{"text_id": 912, "text": "document: The VC-1 model is a vision transformer (ViT) pre-trained on over 4,000 hours of egocentric videos from 7 different sources, together with ImageNet. The model is trained using Masked Auto-Encoding (MAE) and is available in two sizes: ViT-B and ViT-L. The model is intended for use for EmbodiedAI tasks, such as object manipulation and indoor navigation."}
{"text_id": 912, "text": "query: We are a team of tech enthusiasts that want to build a smart robot. Using the available model to identify nearby objects and decide what to do with them would be helpful. How can we achieve this?"}
{"text_id": 848, "text": "document: A tabular classification model trained using AutoTrain for sentiment analysis on the IMDB dataset. The model has a CO2 emission of 0.0186 grams and an accuracy of 0.487."}
{"text_id": 848, "text": "query: I have data for movie reviews, and I want to classify them into positive, negative, and neutral."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Evaluate satellite images for areas under construction by locating and segmenting regions containing buildings."}
{"text_id": 731, "text": "document: An ESPnet2 TTS model trained by mio using amadeus recipe in espnet."}
{"text_id": 731, "text": "query: \"Welcome to the grand opening of our new store! Enjoy unbeatable prices and amazing discounts.\""}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: An online chatting platform wants to increase its efficiency in helping users find conversation partners by gauging the similarity of conversation topics."}
{"text_id": 361, "text": "document: The ALIGN model is a dual-encoder architecture with EfficientNet as its vision encoder and BERT as its text encoder. It learns to align visual and text representations with contrastive learning. This implementation is trained on the open source COYO dataset and can be used for zero-shot image classification and multi-modal embedding retrieval."}
{"text_id": 361, "text": "query: Carl sent me various pictures of his vacation. I want to know if there are mountains or beaches in those pictures."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: Create an AI agent that uses the Decision Transformer to learn how to navigate a 2D walking environment."}
{"text_id": 412, "text": "document: bert-large-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition and achieves state-of-the-art performance for the NER task. It has been trained to recognize four types of entities: location (LOC), organizations (ORG), person (PER) and Miscellaneous (MISC)."}
{"text_id": 412, "text": "query: My friend from Berlin, Wolfgang, is investigating our history, and we'd like to analyze some text to identify named entities, such as people or places."}
{"text_id": 290, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. DDPM models can use discrete noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference. The model can be used with different pipelines for faster inference and better trade-off between quality and speed."}
{"text_id": 290, "text": "query: Our company is attempting to generate realistic images of churches to assist in architectural design."}
{"text_id": 425, "text": "document: This is the standard part-of-speech tagging model for English that ships with Flair. It predicts fine-grained POS tags based on Flair embeddings and LSTM-CRF."}
{"text_id": 425, "text": "query: In our language application, we want to analyze the grammatical structure of user input sentences. We need to classify words by their part of speech."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: I am leading a team of professionals working on the quality control department of PCB manufacturing. I have developed the latest printed circuit board models but need to ensure the identification of any defects on them."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: Our company develops social media platform. We want to create captions for photos uploaded by users."}
{"text_id": 607, "text": "document: GPT-2 Large is the 774M parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a causal language modeling (CLM) objective."}
{"text_id": 607, "text": "query: We are organizing an eCommerce event for users. Please generate some welcoming messages."}
{"text_id": 584, "text": "document: Pygmalion 1.3B is a proof-of-concept dialogue model based on EleutherAI's pythia-1.3b-deduped. It is designed for generating conversational responses and can be used with a specific input format that includes character persona, dialogue history, and user input message."}
{"text_id": 584, "text": "query: My team is making a movie, and we want to generate some dialogue for a character named Alex, who is a treasure hunter with a mysterious past. Please provide a short dialogue for a scene where Alex is talking about a long-lost treasure with their best friend."}
{"text_id": 221, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that can be used to query an image with one or multiple text queries. OWL-ViT uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features."}
{"text_id": 221, "text": "query: Develop a function that takes an image URL and a set of textual descriptions to automatically detect the presence of objects described by the text in the image."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: Our customer is developing an educational app for learning Spanish. They need to create example audio content from given Spanish words and phrases."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: Generate a Named Entity Recognition model which can process newswire articles and identify named entities in the text."}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: We are developing an AI-powered concierge service for a hotel chain. We need the system to be able to understand and generate human-like responses to guest inquiries."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are working on proposing an AI-driven robotic cheetah. How do we use the pre-trained AI to drive the cheetah?"}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: Our company is developing an AI-driven factory. There are cameras that capture the images of the factory. We need to identify what objects are in these images."}
{"text_id": 632, "text": "document: FLAN-T5 XL is a large-scale language model fine-tuned on more than 1000 tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot and few-shot NLP tasks, such as reasoning, question answering, and understanding the limitations of current large language models."}
{"text_id": 632, "text": "query: Develop a platform for a company that can perform text translations from English to other languages, like French, Spanish, and German."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: We are making an app that extracts handwritten text from images. How can we utilize this model to achieve this?"}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: I am trying to enhance the resolution of an image of a landscape that I took with my phone. What can I do to improve its quality?"}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: I am designing a trivia game and I need to generate questions automatically from a given context and answer."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: \"Represent the Science title\"."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: We are working on building a robotic structure that mimics a cheetah's movement for research purposes. We need to evaluate if the trained model will be suitable for this task."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: Create a text-based description of an AI-generated butterfly picture."}
{"text_id": 877, "text": "document: A tabular regression model trained using AutoTrain for estimating carbon emissions from given features."}
{"text_id": 877, "text": "query: We are running an environmental agency, and part of our job is to estimate carbon emissions. We key this data on a CSV file, and need a practical solution. "}
{"text_id": 835, "text": "document: Example pyannote-audio Voice Activity Detection model using PyanNet. Imported from https://github.com/pyannote/pyannote-audio-hub and trained by @hbredin."}
{"text_id": 835, "text": "query: We want to analyze and transcribe a video conference, but first, we need to know when someone is speaking or not. Recommend a library to detect voice activity."}
{"text_id": 810, "text": "document: Hubert-Base for Emotion Recognition is a ported version of S3PRL's Hubert for the SUPERB Emotion Recognition task. The base model is hubert-base-ls960, which is pretrained on 16kHz sampled speech audio. The model is used for predicting an emotion class for each utterance, and it is trained and evaluated on the IEMOCAP dataset."}
{"text_id": 810, "text": "query: I need to evaluate the performance of an advertising campaign by detecting the emotions elicited by the ad based on the spoken content."}
{"text_id": 783, "text": "document: This repository provides all the necessary tools to perform enhancement and\nrobust ASR training (EN) within\nSpeechBrain. For a better experience we encourage you to learn more about\nSpeechBrain. The model performance is:\nRelease\nTest PESQ\nTest COVL\nValid WER\nTest WER\n22-06-21\n3.05\n3.74\n2.89\n2.80\nWorks with SpeechBrain v0.5.12"}
{"text_id": 783, "text": "query: Our customer is looking to improve the audio quality of their call center recordings."}
{"text_id": 762, "text": "document: Facebook's Data2Vec-Audio-Base-960h model is an Automatic Speech Recognition model pretrained and fine-tuned on 960 hours of Librispeech on 16kHz sampled speech audio. It can be used for transcribing audio files and achieves competitive performance on major benchmarks of speech recognition. The model is based on the Data2Vec framework which uses the same learning method for either speech, NLP, or computer vision."}
{"text_id": 762, "text": "query: The conference organizers would like a transcription of their recorded presentations."}
{"text_id": 324, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 324, "text": "query: You are part of a sports analyzing firm and are required to classify sports activities automatically based on video input."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: \"pneumonia\", \"fracture\", or \"normal\"."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: I need a system that can separate different audio sources from a mixed audio file containing people talking over each other."}
{"text_id": 692, "text": "document: This is a CoSENT(Cosine Sentence) model: shibing624/text2vec-base-chinese. It maps sentences to a 768 dimensional dense vector space and can be used for tasks like sentence embeddings, text matching or semantic search."}
{"text_id": 692, "text": "query: I am creating a chatbot that can suggest similar questions to the user based on their initial question. It needs to function properly for Chinese language questions."}
{"text_id": 579, "text": "document: BlenderBot-3B is a large-scale neural model designed for open-domain chatbot applications. It is trained on the blended_skill_talk dataset and can engage in multi-turn conversations, providing engaging talking points, asking and answering questions, and displaying knowledge, empathy, and personality. The model is available through the Hugging Face Transformers library."}
{"text_id": 579, "text": "query: We need to develop a conversational engine to integrate into our chatbot to answer common business-related questions and engage customers."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: Our company is developing a smart online store that suggests items to the user based on their preferences. Please help to extract features from an image of a product for the recommender system."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We want to create artistic images for the postcards of a church in our city."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: We need to remove the vocals from a song, and only keep the instrumental part."}
{"text_id": 237, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 237, "text": "query: Our customer is a company that uses image recognition to measure the amount of plastic pollution. It needs a model that can identify what objects exist in the image."}
{"text_id": 755, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model that can be used for transcription and translation tasks."}
{"text_id": 755, "text": "query: I'm working on transcribing audio files automatically into text. What model do you suggest for this task?"}
{"text_id": 182, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 224x224."}
{"text_id": 182, "text": "query: Our client is interested in a image recognition system for their wildlife photography project to automatically identify animal species."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: An art curator wants to categorize a newly discovered painting based on its style and elements."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: We are a computer vision startup focused on providing exceptional image-to-text summaries. We need an effective solution to generate both conditional and unconditional captions for images."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: Help me to separate the speech from a noisy audio file."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: culture, society, economy, health, and sports."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: A company wants to solve a game with a deep reinforcement learning model. The model has been trained for CartPole."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: Retrieve information about popular topics from a given Spanish news excerpt."}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: We are going to create a set of 3d images. For that, we need to have the depth estimation."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: The user is developing an app that transcribes audio inputs from users recorded through a smartphone."}
{"text_id": 393, "text": "document: This model was trained for sentiment classification of German language texts. The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews."}
{"text_id": 393, "text": "query: I am looking to analyze the sentiment of customer reviews from a German ecommerce website. The reviews are written in German, and I need to classify the sentiment as positive, negative or neutral."}
{"text_id": 622, "text": "document: A tiny GPT-2 model for text generation, suitable for low-resource environments and faster inference. This model is part of the Hugging Face Transformers library and can be used for generating text given a prompt."}
{"text_id": 622, "text": "query: Design advertisements for our shaving cream product and wants creative and catchy taglines."}
{"text_id": 668, "text": "document: DeBERTa improves the BERT and RoBERTa models using disentangled attention and enhanced mask decoder. It outperforms BERT and RoBERTa on majority of NLU tasks with 80GB training data."}
{"text_id": 668, "text": "query: \"In the year 2022, the Winter Olympics will be held in [MASK].\"."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: We are writing a script for a movie. We want to create a dialogue communication between different characters. Could you please generate a resonse for a character based on the following dialogue history?"}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: Our client needs help reading text from images for their document processing system. Design a solution to help them."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: Devise a method to classify emails under different departments, such as IT, HR, or finance."}
{"text_id": 272, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on openpose images."}
{"text_id": 272, "text": "query: We are building an application for generating images based on textual prompts. The generated images should correspond to the objects and scenes described in the text."}
{"text_id": 555, "text": "document: This model was obtained by fine-tuning facebook/bart-large-xsum on Samsum dataset."}
{"text_id": 555, "text": "query: Summarize the following conversation to extract the main idea."}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: We are a game development studio and need a way to generate normal maps for our assets from photographs."}
{"text_id": 404, "text": "document: An English Named Entity Recognition model, trained on Maccrobat to recognize the bio-medical entities (107 entities) from a given text corpus (case reports etc.). This model was built on top of distilbert-base-uncased."}
{"text_id": 404, "text": "query: \"The patient experienced orthostatic hypotension in the morning. The condition was treated using a vasoconstrictor and increasing fluid intake.\""}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: The user wants to extract important people, organizations, and locations mentioned from an email to input into a CRM system."}
{"text_id": 719, "text": "document: ESPnet JETS Text-to-Speech (TTS) Model for ONNX exported using the espnet_onnx library. Can be used with txtai pipeline or directly with ONNX."}
{"text_id": 719, "text": "query: We need to create an audio file from a given text for our online tutorial."}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Our client is an urban planning agency. We are supposed to create a system to count the number of buildings in a given area."}
{"text_id": 131, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 131, "text": "query: A robot wants to answer questions related to product manuals using the model."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: I'm researching about computer vision image segmentation. I need a model that can analyze images and identify different objects within the image, as well as determine their exact boundaries."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: We need to know how similar two movie descriptions are for a recommendation engine."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: We are trying to build a computer vision-based system to improve the navigation and direction understanding of autonomous vehicles in a complex environment."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: We are launching an app that creates a souvenir from a novel event. The user will type in a brief description of the experience, and the app will generate an image of the event."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: Advise me how to build a program to predict the depth map of an image for indoor robotics."}
{"text_id": 628, "text": "document: A T5 model for paraphrasing sentences"}
{"text_id": 628, "text": "query: I want to build a tool that will help me to paraphrase text for essays and articles."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: We are having a project on predicting the movie critic reviews' sentiment, using a pretrained model that can classify the movie review as positive or negative."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: I have a security camera at the entrance of my house, and I want to detect whether a person or something else is passing by."}
{"text_id": 540, "text": "document: A Transformer-based English to Italian translation model trained on the OPUS dataset. This model can be used for translation tasks using the Hugging Face Transformers library."}
{"text_id": 540, "text": "query: How can the information on a wikipedia page be translated from English to Italian?"}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: I have some PCB images and I want to automate the detection and segmentation of any potential defects in them."}
{"text_id": 834, "text": "document: A model for detecting voice activity in Indian languages."}
{"text_id": 834, "text": "query: I have an audio clip of conversation between two people in the Indian language. I want to segregate individual voices of the speakers."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: As a team working in a trading company on the shipping dock, we manually view the loaded shipping container on each pallet within the shipping container. Extract the shipping manifest in text form."}
{"text_id": 730, "text": "document: A Marathi Male Text-to-Speech model using ESPnet framework."}
{"text_id": 730, "text": "query: I am looking for a text-to-speech system that can convert my Marathi sentences into audio. How do I proceed?"}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: We are a team building a discussion forum. We need to know if user comments contradicts each other or not."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Working at a self-driving car company, we need a depth estimation model to help us process images from the vehicle's camera."}
{"text_id": 780, "text": "document: This model was trained by Manuel Pariente using the wham/DPRNN recipe in Asteroid. It was trained on the sep_clean task of the WHAM! dataset."}
{"text_id": 780, "text": "query: We are building an app for remote meetings. We need to separate the voices of multiple participants in a noisy environment."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: We want to create an app to separate voices from a noisy environment for people suffering from hearing problems like tinnitus."}
{"text_id": 165, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 165, "text": "query: We are designing a mobile app for walking tours around the city. We need to compute the estimated depth of locations in a captured image."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: I want to classify movie reviews as positive or negative. Provide me with code and instructions."}
{"text_id": 592, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 592, "text": "query: To help understand the mental well-being of users, the company would like to accurately reply to users' questions in an empathetic manner by examining their daily life issues."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: Our marketing team needs a tool to create short animated video clips based on text descriptions to use in social media campaigns."}
{"text_id": 216, "text": "document: An object detection model trained to detect Counter-Strike: Global Offensive (CS:GO) players. The model is based on the YOLOv8 architecture and can identify 'ct', 'cthead', 't', and 'thead' labels."}
{"text_id": 216, "text": "query: Our client wants to offer a new species identification service for pets. Help them build it from scratch."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We are a marketing company and we need to classify the contents of images from social media campaigns."}
{"text_id": 915, "text": "document: This is a fine-tuned downstream version of the bert-base-uncased model for sentiment analysis, this model is not intended for further downstream fine-tuning for any other tasks. This model is trained on a classified dataset for text classification."}
{"text_id": 915, "text": "query: I've seen this movie. To me the movie was beyond perfection because of the intense character study. Give a sentiment score to my take."}
{"text_id": 816, "text": "document: Hubert-Large for Speaker Identification. This model is pretrained on 16kHz sampled speech audio and should be used with speech input also sampled at 16Khz. It is used for the SUPERB Speaker Identification task and can classify each utterance for its speaker identity as a multi-class classification."}
{"text_id": 816, "text": "query: We have a sound archive and wish to identify the speaker for each audio file."}
{"text_id": 306, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 306, "text": "query: We are an e-commerce company, and we want a visually appealing image of a person for our new advertising campaign."}
{"text_id": 827, "text": "document: This is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Verification task. The base model is wav2vec2-large-lv60, which is pretrained on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. For more information refer to SUPERB: Speech processing Universal PERformance Benchmark."}
{"text_id": 827, "text": "query: Our team is working on creating a voice recognition system to authenticate users. We need to develop a speaker verfication model."}
{"text_id": 211, "text": "document: DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage). The model is trained on COCO 2017 object detection dataset and achieves an average precision (AP) of 44.9 on the COCO 2017 validation set."}
{"text_id": 211, "text": "query: Provide me with the details of how to build an application that detects the objects in the image to generate interesting inforgraphics and captions."}
{"text_id": 327, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 327, "text": "query: Implement a system that alerts us if any unauthorized activity is detected in the security camera footage."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: Create a function that checks if a number is even or odd and returns a different text message for every result."}
{"text_id": 27, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 27, "text": "query: Our startup is working on a content negotiation system. The application should be able to classify videos by their genre with high accuracy."}
{"text_id": 173, "text": "document: ResNet-50 v1.5 is a pre-trained convolutional neural network for image classification on the ImageNet-1k dataset at resolution 224x224. It was introduced in the paper Deep Residual Learning for Image Recognition by He et al. ResNet (Residual Network) democratized the concepts of residual learning and skip connections, enabling the training of much deeper models. ResNet-50 v1.5 differs from the original model in the bottleneck blocks which require downsampling, v1 has stride = 2 in the first 1x1 convolution, whereas v1.5 has stride = 2 in the 3x3 convolution. This difference makes ResNet50 v1.5 slightly more accurate but comes with a small performance drawback."}
{"text_id": 173, "text": "query: My partner and I want to build an app to categorize our cat images. We have a large collection of cat photos and want to classify them by their cat breeds."}
{"text_id": 89, "text": "document: MGP-STR is a pure vision Scene Text Recognition (STR) model, consisting of ViT and specially designed A^3 modules. It is trained on MJSynth and SynthText datasets and can be used for optical character recognition (OCR) on text images."}
{"text_id": 89, "text": "query: We are developing an application that requires optical character recognition (OCR) to extract text from images. We need a module that can read and understand text in images."}
{"text_id": 261, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Canny edges. It can be used in combination with Stable Diffusion."}
{"text_id": 261, "text": "query: Our art department needs a tool that uses the Canny edge detection algorithm combined with Stable Diffusion to transform images."}
{"text_id": 743, "text": "document: A HiFIGAN vocoder trained on a generated German dataset using mp3_to_training_data. The pre-trained model takes in input a spectrogram and produces a waveform in output. Typically, a vocoder is used after a TTS model that converts an input text into a spectrogram."}
{"text_id": 743, "text": "query: We are producing a series of voice-overs for a German podcast. We need to convert our script to speech in order to support the accent."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: A traffic control system needs to identify individual objects within video feeds of busy city streets to make decisions on traffic light timings."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: I am building an indoor robot for the blind. It can move based on the depth of objects. Can you help me estimate the depth of the surrounding environment?"}
{"text_id": 350, "text": "document: A CLIP ViT-bigG/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. The model is intended for research purposes and enables researchers to better understand and explore zero-shot, arbitrary image classification. It can be used for interdisciplinary studies of the potential impact of such models. The model achieves a 80.1 zero-shot top-1 accuracy on ImageNet-1k."}
{"text_id": 350, "text": "query: I need to identify what kind of food is in a photo. I want to realize if it's sushi, pizza, or a burger."}
{"text_id": 370, "text": "document: This model is a fine-tune checkpoint of DistilBERT-base-uncased, fine-tuned on SST-2. It reaches an accuracy of 91.3 on the dev set (for comparison, Bert bert-base-uncased version reaches an accuracy of 92.7). This model can be used for topic classification."}
{"text_id": 370, "text": "query: I am developing an app to analyze movie reviews. I need to know whether the review is positive or negative."}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: As an engineer, I am developing a product to identify objects in an image that could be used in a search-and-rescue robot."}
{"text_id": 252, "text": "document: A YOLOv8 model for PCB defect segmentation trained on the pcb-defect-segmentation dataset. The model can detect and segment defects in PCB images, such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 252, "text": "query: We need to detect defects in printed circuit board images in order to evaluate the quality of our production."}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: We are trying to develop a product that can answer questions about any given text. We want the product to be a language model."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: Make a Q&A engine for helping students obtain better understanding of the subject they find difficult. "}
{"text_id": 282, "text": "document: SheepsControlV5 is an image-to-image model trained on the poloclub/diffusiondb dataset. It is designed for transforming input images into a different style or representation."}
{"text_id": 282, "text": "query: We have an image and we want to generate a new version of the image, using the SheepsControlV5 model."}
{"text_id": 21, "text": "document: LaBSE (Language-agnostic BERT Sentence Embedding) model for extracting sentence embeddings in multiple languages."}
{"text_id": 21, "text": "query: We are an international charity organization. We need to compare messages in different languages to know if they convey the same meaning."}
{"text_id": 890, "text": "document: A RandomForestRegressor model trained on the California Housing dataset for predicting housing prices."}
{"text_id": 890, "text": "query: Imagine you have been appointed as the head of the data science team for a property sales company in California. Help me predict the price of a house in California based on specific housing features."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: culture, society, economy, health, and sports."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: I am a graphic designer, I want to upscale a low resolution image to have better quality and higher resolution."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: We are working on organizing data into tables. We need to extract useful insights by asking questions from the data in tables using a machine learning model."}
{"text_id": 678, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by character-level tokenization."}
{"text_id": 678, "text": "query: We have a translation app that translates texts from other languages into Japanese. We need to fill in the blanks by predicting the appropriate Japanese character."}
{"text_id": 53, "text": "document: Protogen v2.2 is a text-to-image model that generates high-quality images based on text prompts. It was warm-started with Stable Diffusion v1-5 and fine-tuned on a large amount of data from large datasets new and trending on civitai.com. The model can be used with the Stable Diffusion Pipeline and supports trigger words like 'modelshoot style' to enforce camera capture."}
{"text_id": 53, "text": "query: We are a group of artists and we would like to generate an image of an urban landscape with a vibrant sunset and people walking in the foreground. "}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: Our customer requires a multilingual FAQ chatbot. They want to find the responsive answer for multiple languages."}
{"text_id": 61, "text": "document: BLIP (Bootstrapping Language-Image Pre-training) is a new vision-language pre-training (VLP) framework that transfers flexibly to both vision-language understanding and generation tasks. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones. This model is pre-trained on the COCO dataset with a base architecture (ViT base backbone)."}
{"text_id": 61, "text": "query: Develop an application that can generate captions for images. The app should be capable of describing an image using natural language."}
{"text_id": 227, "text": "document: An object detection model for extracting tables from documents. Supports two label types: 'bordered' and 'borderless'."}
{"text_id": 227, "text": "query: We would like to extract table data from invoice images. We need a suggestion of a transformer model that provides accurate results."}
{"text_id": 790, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 790, "text": "query: A customer has an audio file with a conversation, but there is too much background noise. We want to enhance the quality of the audio by reducing the noise."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: I need to create a system that generates spoken output for given text."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: Generate a high-resolution image of a warrior standing on a mountain at sunset based on a text description."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: A major movie producer needs to classify social media movie reviews for a recently released film. They want to get an idea of which emotional response (anger, disgust, fear, joy, neutral, sadness, or surprise) each review received from fans."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: We are looking to promote our brand among the youth with anime-style images. Generate an image that depicts an \"anime character enjoying a beverage on the beach.\""}
{"text_id": 256, "text": "document: A YOLOv8 model for pothole segmentation. This model detects potholes in images and outputs bounding boxes and masks for the detected potholes."}
{"text_id": 256, "text": "query: I want to build a pothole detection system for a city. Please guide me on how to use this API."}
{"text_id": 507, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 507, "text": "query: I need to create a tool that can help me analyze two sentences and understand if one entails, contradicts, or is neutral to the other."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: Our client is a manga artist. They need a tool to turn their concepts into line art images."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: We are a social networking company. We need to measure how similar two sentences are to detect spam."}
{"text_id": 474, "text": "document: This is the distilled version of the deepset/roberta-base-squad2 model. This model has a comparable prediction quality and runs at twice the speed of the base model."}
{"text_id": 474, "text": "query: We are developing an educational software that encourages the users to ask questions about the software. Answer their questions using a pre-trained model."}
{"text_id": 689, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 689, "text": "query: Given two sentences, are they talking about similar things?"}
{"text_id": 753, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 753, "text": "query: Our client wants to convert the speech content of an audio file to text for further analysis."}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: We have an electrical consumption dataset and we need to predict the consumption of electricity within the next month."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: Our platform is Chinese-language based. We need to process and analyze customer reviews in Chinese. Please separate them by parts of speech."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: I am an antique seller in France looking to expand to the Spanish market. I need help translating my product descriptions to Spanish."}
{"text_id": 680, "text": "document: BERTje is a Dutch pre-trained BERT model developed at the University of Groningen."}
{"text_id": 680, "text": "query: We are designing a Dutch language bot, so we need to fill in the provided blanks in a sentence."}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: A web developer needs descriptions for images on their website to improve accessibility for visually impaired users. We must provide this service."}
{"text_id": 930, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on documents."}
{"text_id": 930, "text": "query: Build a solution to extract invoice details, such as invoice number, invoice date, and total amount, from a given invoice image url."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: Design a chatbot that generates responses in a conversation based on the user's input history."}
{"text_id": 245, "text": "document: Mask2Former model trained on COCO panoptic segmentation (large-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 245, "text": "query: We are a real estate company, and we need to identify different elements within a room from the photos provided by the homeowners."}
{"text_id": 215, "text": "document: A YOLOv8 model for object detection in Valorant game, trained on a custom dataset. It detects dropped spike, enemy, planted spike, and teammate objects."}
{"text_id": 215, "text": "query: We are building a Valorant gaming assistant. It needs to automatically detect objects in the game using computer vision."}
{"text_id": 438, "text": "document: A tiny TAPAS model trained on the WikiTableQuestions dataset for table question answering tasks."}
{"text_id": 438, "text": "query: Build a home automation system that answers questions about the contents of a table."}
{"text_id": 551, "text": "document: Helsinki-NLP/opus-mt-fi-en is a machine translation model for translating Finnish text to English text. It is trained on the OPUS dataset and can be used with the Hugging Face Transformers library."}
{"text_id": 551, "text": "query: We are translating an application from Finnish to English."}
{"text_id": 359, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Base model (convnext_base) as the image tower, and the same text tower as the RN50x4 (depth 12, embed dim 640) model from OpenAI CLIP."}
{"text_id": 359, "text": "query: Design an automatic system to tag new images uploaded to a social network platform by categorizing them into specific categories, e.g., travel, food, friends, nature, etc."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: I am building a robot that helps people understand how far away objects are. I need to estimate the depth of objects in a given image."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: Our customer is a city planner, looking for input to better understand green spaces and structures in a city. We are working on dividing the image captured by a drone into several meaningful semantic regions based on their content."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: Our company wants to build a drone system for terrain mapping. We need to estimate the depth of the terrain."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: The client is building a gaming tool that wants to detect Counter-Strike Global Offensive (CS:GO) players in-game. What is the solution for this?"}
{"text_id": 564, "text": "document: A T5-based summarization model trained on the Samsum dataset. This model can be used for text-to-text generation tasks such as summarization without adding 'summarize' to the start of the input string. It has been fine-tuned for 10K steps with a batch size of 10."}
{"text_id": 564, "text": "query: We are creating a newspaper edition, and I need a summary of this article \"An AI-powered robot, Mia, was unveiled to the public today as the newest addition to a local hospital's fleet of medical support staff. Mia will assist nurses and doctors in their daily tasks, freeing up time for them to focus on their patients. The hospital staff are excited about the potential improvements in productivity and patient care resulting from Mia's presence, and some experts believe this could be the beginning of a new era for the medical industry.\""}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Analyze the message to my taxi driver in an audio file in German and determine the emotion in that clip."}
{"text_id": 95, "text": "document: A multi-stage text-to-video generation diffusion model that inputs a description text and returns a video that matches the text description. The model consists of three sub-networks: text feature extraction model, text feature-to-video latent space diffusion model, and video latent space to video visual space model. It supports English input only and has a wide range of applications."}
{"text_id": 95, "text": "query: A director needs synthetic video clips of various thrilling movie scenes based on the text descriptions he provided."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: Create a system to extract and compare similarity between sentences to find the most relevant ones to a query."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: We are now working on autonomous cars manufacture. We need to estimate the depth of objects in the environment."}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: The company is building a product to recommend videos of cooking tutorials to users based on their preferences. We need to figure out the categories of videos based on their content."}
{"text_id": 677, "text": "document: This is the set of Chinese ALBERT models pre-trained by UER-py on the CLUECorpusSmall dataset. The model can be used for tasks like text generation and feature extraction."}
{"text_id": 677, "text": "query: Help me to complete the Chinese sentences by filling in the blanks with appropriate words."}
{"text_id": 154, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 154, "text": "query: We are designing an autonomous vehicle that can navigate in urban environments. We need a model that can estimate depth from a single image to help the vehicle understand the distances of surrounding objects."}
{"text_id": 701, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 701, "text": "query: I am an artist working on a literature project. I need to find similarities among the different sentences to understand common themes in my literature research."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: I want to analyze videos to detect pedestrian's movement from a massive crowd."}
{"text_id": 41, "text": "document: Anything V4 is a latent diffusion model for generating high-quality, highly detailed anime-style images with just a few prompts. It supports danbooru tags to generate images and can be used just like any other Stable Diffusion model."}
{"text_id": 41, "text": "query: Design an anime-style character that is a combination of Hatsune Miku and a robotic arm."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: She has a blog, and she is always busy. Can you help us with content by fixing the grammar, punctuation and style?"}
{"text_id": 812, "text": "document: This is a spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain. The model uses the ECAPA-TDNN architecture that has previously been used for speaker recognition. It covers 107 different languages."}
{"text_id": 812, "text": "query: We are developing a language learning app and we need a feature to detect users' spoken language to match them with native speakers for language exchange."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: Our customer needs a solution that separates audio tracks containing two speakers into individual streams to have clarity. Provide the information needed."}
{"text_id": 672, "text": "document: BERT large model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}
{"text_id": 672, "text": "query: \"I'm a fan of playing [MASK] games on my PC.\""}
{"text_id": 676, "text": "document: BioBERT is a pre-trained biomedical language representation model for biomedical text mining tasks such as biomedical named entity recognition, relation extraction, and question answering."}
{"text_id": 676, "text": "query: As a part of a new medical research study, we have to analyze biomedical texts. Help us understand the relevant terminology."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: Our company creates custom posters for customers. We need a software that will generate illustrations based on given prompts."}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: Create a chatbot that can answer my questions using given knowledge."}
{"text_id": 387, "text": "document: Model trained with TASS 2020 corpus (around ~5k tweets) of several dialects of Spanish. Base model is BETO, a BERT model trained in Spanish. Uses POS, NEG, NEU labels."}
{"text_id": 387, "text": "query: I'm developing a sentiment analyzer for my customers in Spain. Could you help me categorize a given text as positive, negative, or neutral?"}
{"text_id": 283, "text": "document: MAXIM model pre-trained for image deblurring. It was introduced in the paper MAXIM: Multi-Axis MLP for Image Processing by Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, Yinxiao Li and first released in this repository."}
{"text_id": 283, "text": "query: As a photographer who often takes images in shaky conditions, I want my images to be deblurred automatically."}
{"text_id": 82, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 82, "text": "query: Develop a software system for automatic data entry from printed forms."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: We are developing a phone application to detect the age of a person in a group picture taken at a party."}
{"text_id": 430, "text": "document: TAPAS base model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion, and then fine-tuned on SQA, WikiSQL, and finally WTQ. It can be used for answering questions related to a table."}
{"text_id": 430, "text": "query: I received a table containing my local town's demographic and financial data. Extract the median age and the median household income of this town."}
{"text_id": 300, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. Achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 300, "text": "query: Our designer needs a tool that can generate image samples based on a trained SDE diffusion model. Create a script to generate images using this model."}
{"text_id": 847, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 847, "text": "query: The company is building a wine recommendation app. We need to predict the wine quality."}
{"text_id": 107, "text": "document: A tiny random model for Visual Question Answering using the VILT framework."}
{"text_id": 107, "text": "query: Who is the artist? What inspired it? Can you tell me about the colors used?"}
{"text_id": 255, "text": "document: A YOLOv8 model for building segmentation in satellite images. Trained on the satellite-building-segmentation dataset, it can detect and segment buildings with high accuracy."}
{"text_id": 255, "text": "query: Develop a tool that helps city planners to segment buildings in satellite images."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: A company that specializes in document analysis wants a solution to extract answers to questions from an image."}
{"text_id": 897, "text": "document: This is a trained model of a PPO agent playing LunarLander-v2 using the stable-baselines3 library."}
{"text_id": 897, "text": "query: I want to beat my friend playing a LunarLander game by training and using a machine learning model."}
{"text_id": 111, "text": "document: A multilingual Visual Question Answering model supporting English, Chinese, Japanese, and German languages. It requires the combined use of the Guanaco 7B LLM model and is based on the implementation of MiniGPT-4."}
{"text_id": 111, "text": "query: We are building a robot to understand the contents of an image and answer questions based on that image. The robot needs to support English, Chinese, Japanese, and German languages as input."}
{"text_id": 758, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Russian. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 758, "text": "query: We are building an app that converts spoken Russian language to text. Configure the speech recognition model according to the provided API."}
{"text_id": 826, "text": "document: A model trained to recognize emotions in Russian speech using wav2vec2. It can classify emotions such as anger, disgust, enthusiasm, fear, happiness, neutral, and sadness."}
{"text_id": 826, "text": "query: We want to understand the emotions expressed in customer support calls. Please create a system to recognize emotions in Russian speech."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: Our company is developing an intelligent chatbot in Chinese that can answer questions about a given text passage. Can you help suggest a suitable model?"}
{"text_id": 546, "text": "document: Barthez model finetuned on orangeSum for abstract generation in French language"}
{"text_id": 546, "text": "query: Write an AI bot to create summaries for long French texts. The summaries should be a shorter version of the original content and maintain the main ideas."}
{"text_id": 652, "text": "document: Google's T5 model fine-tuned on SQuAD v1.1 for Question Generation by prepending the answer to the context."}
{"text_id": 652, "text": "query: Generate questions from a text on famous painters."}
{"text_id": 813, "text": "document: Model for Dimensional Speech Emotion Recognition based on Wav2vec 2.0. The model expects a raw audio signal as input and outputs predictions for arousal, dominance and valence in a range of approximately 0...1. In addition, it also provides the pooled states of the last transformer layer. The model was created by fine-tuning Wav2Vec2-Large-Robust on MSP-Podcast (v1.7). The model was pruned from 24 to 12 transformer layers before fine-tuning. An ONNX export of the model is available from doi:10.5281/zenodo.6221127. Further details are given in the associated paper and tutorial."}
{"text_id": 813, "text": "query: We would like to build an app that takes voice input and analyzes the emotion behind the speech. The emotion should be represented by arousal, dominance, and valence scores."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Our marketing team need to attach text descriptions to the images in their image library automatically. Use a model to do this."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: As an ornithologist, I want to classify bird species based on images I have taken with my camera. I need a model that can provide a prediction even if the species has never been seen before."}
{"text_id": 650, "text": "document: This model is a fine-tuned version of philschmid/bart-large-cnn-samsum on an unknown dataset."}
{"text_id": 650, "text": "query: I want to create a chatbot that can generate news summaries based on the information provided in the text."}
{"text_id": 653, "text": "document: mT5 is a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. It leverages a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of multilingual NLP tasks."}
{"text_id": 653, "text": "query: Provide me information on cultural events happening worldwide. I want a brief overview in German language."}
{"text_id": 153, "text": "document: A depth estimation model fine-tuned on the DIODE dataset."}
{"text_id": 153, "text": "query: We are designing an autonomous system to navigate through hallways. This system needs to estimate the distance to obstacles in its environment."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: Create a code to identify the different objects present in the given image URL and segment them into different categories."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: I want to analyze images of modern infrastructure to categorize and catalog different elements, like roads, buildings, and plants, using image segmentation."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: I have a noisy audio recording, and I want to enhance it using this pretrained model."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: We have a table with different variables like income, age, and number of cars. We want to know the average income of people owning more than one car."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: In a city tour app, we have a chat feature where users can make an inquiry about the city. Write a solution to respond to user's inquiries."}
{"text_id": 789, "text": "document: A speech-to-speech translation model with two-pass decoder (UnitY) trained on Hokkien-English data from TED, drama, and TAT domains. It uses Facebook's Unit HiFiGAN for speech synthesis."}
{"text_id": 789, "text": "query: Translate a Hokkien audio file into English and generate a corresponding English audio output."}
{"text_id": 531, "text": "document: NLLB-200 is a machine translation model primarily intended for research in machine translation, especially for low-resource languages. It allows for single sentence translation among 200 languages. The model was trained on general domain text data and is not intended to be used with domain specific texts, such as medical domain or legal domain. The model is not intended to be used for document translation."}
{"text_id": 531, "text": "query: For our customer service team, we need to translate customer complaints from different languages to English."}
{"text_id": 700, "text": "document: This is a port of the LaBSE model to PyTorch. It can be used to map 109 languages to a shared vector space."}
{"text_id": 700, "text": "query: I am writing my thesis and I need summarize it on the thesis defense day. Can you provide me with the closeness between the summary and the main thesis ideas?"}
{"text_id": 452, "text": "document: TAPAS, the model learns an inner representation of the English language used in tables and associated texts, which can then be used to extract features useful for downstream tasks such as answering questions about a table, or determining whether a sentence is entailed or refuted by the contents of a table. It is a BERT-based model specifically designed (and pre-trained) for answering questions about tabular data. TAPAS uses relative position embeddings and has 7 token types that encode tabular structure. It is pre-trained on the masked language modeling (MLM) objective on a large dataset comprising millions of tables from English Wikipedia and corresponding texts."}
{"text_id": 452, "text": "query: Our team is working on building an application in education to help students with answering questions based on tables provided in textbooks. We need to classify types of exercise."}
{"text_id": 808, "text": "document: An audio classification model based on wav2vec2."}
{"text_id": 808, "text": "query: We have a customer support phone call center, and we are looking for a solution that could accurately detect keywords in live phone calls."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: Normal, Intrusion, Theft."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: Create a system that searches for the provided data and answers the given questions."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: We are building a home security system and need to detect suspicious activity in the videos recorded by the camera."}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: We are building a product to automatically detect misplaced items in home kitchens. We need to detect objects in a kitchen image."}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: \"She read a book and goes to the store with her friend.\""}
{"text_id": 752, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Dutch. Fine-tuned on Dutch using the train and validation splits of Common Voice 6.1 and CSS10."}
{"text_id": 752, "text": "query: We want to transcribe interview recordings of several people speaking in Dutch."}
{"text_id": 503, "text": "document: Cross-Encoder for Natural Language Inference trained on the SNLI and MultiNLI datasets. Outputs three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 503, "text": "query: Our team needs to classify news articles based on their content and categorize them into technology, sports, and politics."}
{"text_id": 704, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space. The model was specifically trained for the task of semantic search."}
{"text_id": 704, "text": "query: We are creating an app for finding similar texts for users' input. Can you describe how we could use sentence transformers to help with this task?"}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: We have an AI-driven news aggregator, and we want to ensure that the headlines and articles are logically consistent. Help me analyze the relationship between headlines and article content."}
{"text_id": 121, "text": "document: A model for document question answering using the LayoutLM architecture."}
{"text_id": 121, "text": "query: We have an HR department where we receive CVs, resumes, and job applications. Frequently, we need to find specific details like the person's experience or education within the document."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: We are trying to predict the carbon emissions of different transportations across the world using a tabular data approach."}
{"text_id": 769, "text": "document: Whisper large-v2 model for CTranslate2. This model can be used in CTranslate2 or projets based on CTranslate2 such as faster-whisper."}
{"text_id": 769, "text": "query: I'm the lead developer at a podcast service, and I'm implementing a feature to transcribe audio files. I need to transcribe spoken language into written text."}
{"text_id": 803, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 8k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 803, "text": "query: A sound engineering service needs to be designed to eliminate noise from audio files."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: We have to summarize a news article to be shared on our social media."}
{"text_id": 633, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 633, "text": "query: I want to translate a document from Russian to Spanish. The document is too technical, that's why I a choose a powerful tool like yours."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: Design a health-related application that uses AI to assist physicians in understanding medical reports by filling in masked words."}
{"text_id": 98, "text": "document: Tune-A-Video - Redshift is a text-to-video generation model based on the nitrosocke/redshift-diffusion model. It generates videos based on textual prompts, such as 'a man is skiing' or '(redshift style) spider man is skiing'."}
{"text_id": 98, "text": "query: I want to create a video that shows a robot playing basketball based on the description provided."}
{"text_id": 684, "text": "document: This is a BERT model pretrained on texts in the Japanese language. This version of the model processes input texts with word-level tokenization based on the IPA dictionary, followed by the WordPiece subword tokenization."}
{"text_id": 684, "text": "query: We are developing a Japanese language educational app. In this app, we want to include a feature where the user can complete a sentence with a missing word."}
{"text_id": 885, "text": "document: Baseline Model trained on tips5wx_sbh5 to apply regression on tip"}
{"text_id": 885, "text": "query: We have a data set containing the price of gold prices. We would like to predict the price of gold given features such as the price of silver and the economic index."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: We are developing a robotic grasshopper. The model should assist in its decision-making process while jumping."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: Our team is working on a customer support system. We need to compare customer query with FAQ questions and find the one which is most similar."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: Create a method to carefully fill a blank masked word in a sentence \"Can you structure this article on [MASK] design trends?\""}
{"text_id": 468, "text": "document: DistilBERT base cased distilled SQuAD is a fine-tuned checkpoint of DistilBERT-base-cased, trained using knowledge distillation on SQuAD v1.1 dataset. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT's performances as measured on the GLUE language understanding benchmark. This model can be used for question answering."}
{"text_id": 468, "text": "query: I am a student, and I would like to create a Q&A bot to help me. It should be capable of answering queries from my classmates."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: Our team is working on a project about engineering but we need to figure out the right word to complete the sentence. \"Modern engineers use advanced [MASK] techniques to solve complex problems.\""}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: The advertising team requires a unique design for a new product packaging based on an example that they provided. They have also given a description of the desired design."}
{"text_id": 606, "text": "document: BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a transformer-based language model designed for text generation and as a pretrained base model for fine-tuning on specific tasks. It supports 48 languages and has 7,069,016,064 parameters. The model is trained on a diverse corpus containing 45 natural languages, 12 programming languages, and 1.5TB of pre-processed text."}
{"text_id": 606, "text": "query: My website requires a tool for generating short stories when given a prompt."}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Develop a model for recognizing and classifying objects in images captured by traffic cameras in urban areas."}
{"text_id": 266, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion."}
{"text_id": 266, "text": "query: A game design company needs to create graphics for their game. They have a basic design drawn on paper and want to convert it to a digital artwork."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: Design a tool that can estimate the distance of an object in an image."}
{"text_id": 800, "text": "document: A Fairseq model for audio-to-audio speech-to-speech translation."}
{"text_id": 800, "text": "query: Our business is expanding to a spanish-speaking country. To streamline our phone customer service, we need a solution that translates English spoken messages directly to Spanish spoken messages."}
{"text_id": 659, "text": "document: RoBERTa is a transformers model pretrained on a large corpus of English data in a self-supervised fashion using the Masked language modeling (MLM) objective. This model is case-sensitive and can be fine-tuned on a downstream task."}
{"text_id": 659, "text": "query: Recently we are working with several news articles. We need a model to help us fill in the blanks in some sentences."}
{"text_id": 116, "text": "document: LayoutLMv3 model trained for document question answering task."}
{"text_id": 116, "text": "query: We are working for an insurance company, and we need an AI assistance to get answers to questions related to insurances claim from our documents."}
{"text_id": 69, "text": "document: This is an image captioning model training by Zayn"}
{"text_id": 69, "text": "query: Our content team is busy, we need to use technology to create captions for product images in our online store."}
{"text_id": 334, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base-finetuned-kinetics on an unknown dataset."}
{"text_id": 334, "text": "query: Help design a video surveillance system that has the capability to detect various activities in the videos and alert the proper authorities when needed."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: We are trying to analyze the similarity between the texts of two documents."}
{"text_id": 149, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021). DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation."}
{"text_id": 149, "text": "query: We are a robotics company that needs to estimate the depth of objects from a single image."}
{"text_id": 868, "text": "document: A single column regression model for predicting US housing prices, trained with AutoTrain and using the Joblib framework."}
{"text_id": 868, "text": "query: We want to develop our own application to predict US housing prices. To do this, we need a dataset with a single column of housing prices as input."}
{"text_id": 26, "text": "document: BERT-base model pre-trained on 152 million sentences from the StackOverflow's 10 year archive. It can be used for code and named entity recognition in StackOverflow."}
{"text_id": 26, "text": "query: Extract named entities and code snippets from a piece of technical text from StackOverflow."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: general knowledge, science, and sports."}
{"text_id": 206, "text": "document: DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images). It was introduced in the paper End-to-End Object Detection with Transformers by Carion et al. and first released in this repository."}
{"text_id": 206, "text": "query: Detect and visualize objects from an image taken from an URL."}
{"text_id": 385, "text": "document: Distilbert is created with knowledge distillation during the pre-training phase which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding. It's smaller, faster than Bert and any other Bert-based model. Distilbert-base-uncased finetuned on the emotion dataset using HuggingFace Trainer."}
{"text_id": 385, "text": "query: A company is building an application to help users understand the emotion of the text they're writing or reading. Help them create a model."}
{"text_id": 851, "text": "document: This model is a binary classifier for predicting whether a passenger on the Titanic survived or not, based on features such as passenger class, age, sex, fare, and more."}
{"text_id": 851, "text": "query: I want to predict if a person will survive on a cruise ship depending on features such as passenger class, age, sex, fare, etc."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: A non-profit organization is doing a survey about the main global concern. Analyze the response provided and identify the key interest area of this response."}
{"text_id": 292, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) for high-quality image synthesis. Trained on the unconditional CIFAR10 dataset and 256x256 LSUN. Supports different noise schedulers like scheduling_ddpm, scheduling_ddim, and scheduling_pndm for inference."}
{"text_id": 292, "text": "query: I need to create images for a church based on the state-of-the-art unconditional image generation algorithm."}
{"text_id": 444, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries."}
{"text_id": 444, "text": "query: I am searching for a QA model that is capable of learning from tables. Any help is appreciated."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: We are looking to add an audio accompaniment to our company's website. The audio will greet and instruct visitors on how to navigate the page. Please generate a text-to-speech example."}
{"text_id": 718, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 718, "text": "query: We are an orchestra who wants to play an old piece from Mozart. Can you simulate how that might sound like?"}
{"text_id": 257, "text": "document: A YOLOv8 model for pothole segmentation in images. The model is trained on the pothole-segmentation dataset and achieves high accuracy in detecting potholes."}
{"text_id": 257, "text": "query: Fill the potholes on the roads in our city with proper steps."}
{"text_id": 208, "text": "document: A YOLOv8 model for table extraction in images, capable of detecting both bordered and borderless tables. Trained using the keremberke/table-extraction dataset."}
{"text_id": 208, "text": "query: Our client needs a better way to identify product tables within images they receive from their vendors."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: Implement a model to transcribe Arabic speech to text."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: We are working on an app that helps sports coaches examine the activities of players on the court. The app should be able to classify sports actions from video clips."}
{"text_id": 97, "text": "document: Tune-A-Video is a text-to-video generation model based on the Hugging Face framework. The model generates videos based on textual prompts in a modern Disney style."}
{"text_id": 97, "text": "query: A toy company has asked us to generate a 10-second video of an animated robot playing football."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We have an event organization tool which recommends the most suitable decorations based on an image of the venue. We need to classify the images into different event categories such as weddings, birthdays, or corporate events."}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: I want to complete a story in Portuguese by suggesting the best word to fill the given masked word."}
{"text_id": 809, "text": "document: Distil Audio Spectrogram Transformer AudioSet is an audio classification model based on the Audio Spectrogram Transformer architecture. This model is a distilled version of MIT/ast-finetuned-audioset-10-10-0.4593 on the AudioSet dataset."}
{"text_id": 809, "text": "query: Design a web application that can recognize the sounds in a video and classify the type of sound based on pre-trained models."}
{"text_id": 379, "text": "document: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. The model is suitable for English."}
{"text_id": 379, "text": "query: Our customer is a governmental health organization which needs to analyze the people's sentiment on social media regarding the Covid-19 vaccination campaign."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: Implement a product where clients can ask questions about products or destinations, and the system will provide answers based on contextual information."}
{"text_id": 819, "text": "document: This model is a fine-tuned version of facebook/data2vec-audio-base-960h on the None dataset."}
{"text_id": 819, "text": "query: I am interested in categorizing audio files depending on the content of the audio. Do you have a way to accomplish this task?"}
{"text_id": 431, "text": "document: TAPEX (Table Pre-training via Execution) is a conceptually simple and empirically powerful pre-training approach to empower existing models with table reasoning skills. TAPEX realizes table pre-training by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. TAPEX is based on the BART architecture, the transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder."}
{"text_id": 431, "text": "query: I'm teaching a group of students about table question answering, and I need a model for solving their practice questions."}
{"text_id": 338, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 338, "text": "query: Analyze a video captured by a security camera to classify the type of activity taking place in the video."}
{"text_id": 469, "text": "document: This model is trained for the task of Question Answering on Legal Documents using the CUAD dataset. It is based on the RoBERTa architecture and can be used to extract answers from legal contracts and documents."}
{"text_id": 469, "text": "query: We are developing an application for legal documents contract analysis. We need an AI module to extract answers from these contracts."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: I am an art museum curator, collect a summary of the imagery and meaning behind one of the most famous 18th-century paintings to give a brief introduction to the audience."}
{"text_id": 48, "text": "document: A text-to-image model that generates images from text descriptions."}
{"text_id": 48, "text": "query: Melanie is an illustrator and needs an AI-based tool that can generate rough digital images based on her textual descriptions, so she can use them as a reference for her drawings."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: We want to make the company paperless, we need our documents to be editable by desks, please provide OCR functionality on docs to convert them into texts so we can edit later."}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: Mike's Virtual Gym has asked me to create an application that can display the type of workout the user is performing using a video feed from their home workout cameras."}
{"text_id": 20, "text": "document: One custom ast model for testing of HF repos"}
{"text_id": 20, "text": "query: Identify the most prevalent features of an audio clip to help us analyze and classify different sounds."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: Can you help me find an answer to this question \"What are the benefits of eating apples?\" based on the following context \"Apples are highly nutritious and are rich in fiber, vitamin C, and various antioxidants. Eating apples can promote heart health, aid digestion, and improve mental function. Moreover, they have been linked to better weight management, stronger immunity, and a reduced risk of type 2 diabetes.\""}
{"text_id": 276, "text": "document: Controlnet v1.1 is a diffusion-based text-to-image generation model that controls pretrained large diffusion models to support additional input conditions. This checkpoint corresponds to the ControlNet conditioned on Soft edges. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 276, "text": "query: Design a system that translates a text prompt to a visual image representation, specifically creating the design of \"a beautiful garden with colorful flowers.\""}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: Design an AI system that can retrieve and process information from a table and answer questions related to the content."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: We have an app that identifies animal species by their photos. Find a model that can do this task."}
{"text_id": 839, "text": "document: A Voice Activity Detection model by Eklavya, using the Hugging Face framework."}
{"text_id": 839, "text": "query: We are a home security company and detecting an intruder's voice can provide us with valuable information about a possible break-in. Please use voice activity detection to detect the presence of a human voice."}
{"text_id": 326, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks."}
{"text_id": 326, "text": "query: We are building a machine learning model for our new line of household cleaning products. I need the model to classify household cleaning videos automatically."}
{"text_id": 499, "text": "document: This model is a fine-tuned version of the spanish BERT model with the Spanish portion of the XNLI dataset. You can have a look at the training script for details of the training."}
{"text_id": 499, "text": "query: Our news editor team is publishing articles in Spanish. Classify the articles based on their theme."}
{"text_id": 230, "text": "document: A YOLOv5 based license plate detection model trained on a custom dataset."}
{"text_id": 230, "text": "query: The parking lot manager requests a system that can automatically identify the car's license plate when a vehicle enters the parking lot."}
{"text_id": 612, "text": "document: Cadet-Tiny is a very small conversational model trained off of the SODA dataset. Cadet-Tiny is intended for inference at the edge (on something as small as a 2GB RAM Raspberry Pi). Cadet-Tiny is trained off of the t5-small pretrained model from Google, and is, as a result, is about 2% of the size of the Cosmo-3B model."}
{"text_id": 612, "text": "query: Our startup aims at developing a conversational AI for customer support and we want to run it on our web server. We can't use a large model because of our server limitations."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: Implement a machine-translate function that gets as input a french sentence and outputs its spanish equivalent."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: Our project requires generating a list of similar articles based on the content of a given article."}
{"text_id": 450, "text": "document: TAPAS large model fine-tuned on Sequential Question Answering (SQA). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned on SQA. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 450, "text": "query: We are working on a finance project, and we want our model to answer queries based on the financial dataset."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: I need to develop a reinforcement learning system for a robotic arm to pick up and manipulate objects. It should learn optimal grasping strategies for different objects."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: The customer service department in our organization deals with a high volume of customer email requests. Our task is to help customer service representatives prioritize these emails by grouping them based on similarity."}
{"text_id": 31, "text": "document: Openjourney is an open source Stable Diffusion fine-tuned model on Midjourney images, by PromptHero. It can be used for generating AI art based on text prompts."}
{"text_id": 31, "text": "query: I need an AI artwork as cover art for my upcoming techno album. The album is called \"Cyber Flux\". I want the generated image to feature a futuristic city landscape with neon lights."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: I'm creating a mobile app to help travelers translate phrases in different languages. How can I integrate a model that translates English to Spanish?"}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: I am a content creator, and I need to check some commonly written sentences to make sure it contains legal entity names for a blog post."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: Develop an AI model that generates colored images of anime-style characters based on textual prompts."}
{"text_id": 433, "text": "document: TAPAS medium model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia and uses relative position embeddings. It can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 433, "text": "query: I plan to do table question answering in my system. Help me apply the google/tapas-medium-finetuned-sqa model."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: Our company is developing a food detection AI that analyzes social media posts. We want to identify food items mentioned in the text."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: I record a lot of podcasts and have trouble removing background noise. I need an audio denoising tool."}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: Design an application to repair user's grammar and spelling errors in their text messages."}
{"text_id": 933, "text": "document: Google's T5 Version 1.1 is a state-of-the-art text-to-text transformer model that achieves high performance on various NLP tasks such as summarization, question answering, and text classification. It is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on downstream tasks."}
{"text_id": 933, "text": "query: Social Butterfly Club is planning an event and needs to send out an invitation but lost its words. Generate a short description that'd sell this in a click."}
{"text_id": 231, "text": "document: UperNet framework for semantic segmentation, leveraging a ConvNeXt backbone. UperNet was introduced in the paper Unified Perceptual Parsing for Scene Understanding by Xiao et al. Combining UperNet with a ConvNeXt backbone was introduced in the paper A ConvNet for the 2020s."}
{"text_id": 231, "text": "query: Develop a program to categorize objects in an image taken by a drone."}
{"text_id": 760, "text": "document: Facebook's Wav2Vec2 model pretrained and fine-tuned on 960 hours of Libri-Light and Librispeech on 16kHz sampled speech audio. The model was trained with Self-Training objective. The model is used for Automatic Speech Recognition and can be used as a standalone acoustic model."}
{"text_id": 760, "text": "query: We have a podcast production company. We want to transcribe the audio files of our podcasts for accessibility purposes. "}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: A factory wants to monitor its production line and wants to detect any anomalies in real time."}
{"text_id": 603, "text": "document: BLOOM LM is a large open-science, open-access multilingual language model developed by BigScience. It is a transformer-based language model trained on 45 natural languages and 12 programming languages. The model has 559,214,592 parameters, 24 layers, and 16 attention heads."}
{"text_id": 603, "text": "query: We are a book publisher company. We are now working on a new article about space travel."}
{"text_id": 792, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAMR! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation."}
{"text_id": 792, "text": "query: Need help separating voices from an audio file where multiple people are talking."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: Find the possible classes and their probabilities for the given image URL."}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: Our client needs to extract data from a document related to a question. Please provide a solution."}
{"text_id": 348, "text": "document: A CLIP ViT L/14 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. Intended for research purposes and exploring zero-shot, arbitrary image classification. Can be used for interdisciplinary studies of the potential impact of such model."}
{"text_id": 348, "text": "query: Our entertainment company needs a model that can help classify movie posters into different genres. We want to explore zero-shot image classification."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: We need to estimate the carbon emissions of vehicles and request you to calculate so by giving the input specifications."}
{"text_id": 168, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 168, "text": "query: We are developing an autonomous vehicle which requires a model to estimate the depth of objects in the scene."}
{"text_id": 867, "text": "document: A binary classification model for predicting carbon emissions"}
{"text_id": 867, "text": "query: I want to predict the carbon emissions for a series of buildings using this information."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: The boss wants us to build a tool to help people write fiction. Write a function that takes an input text prompt and generates several narrative continuations."}
{"text_id": 638, "text": "document: Bert base model for Korean, trained on a 70GB Korean text dataset and 42000 lower-cased subwords. Can be used for Text2Text Generation tasks."}
{"text_id": 638, "text": "query: Please help me to create a text summary of a Korean news article."}
{"text_id": 166, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It achieves depth estimation with various performance metrics."}
{"text_id": 166, "text": "query: Our customer is a delivery company. We need to provide a 3D plan of the product in each box."}
{"text_id": 639, "text": "document: FLAN-T5 XXL is a fine-tuned version of the T5 language model, achieving state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. It has been fine-tuned on more than 1000 additional tasks covering multiple languages, including English, German, and French. It can be used for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning and question answering."}
{"text_id": 639, "text": "query: I have a text in English. I want to convert it to German."}
{"text_id": 463, "text": "document: BioM-ELECTRA-Large-SQuAD2 is a fine-tuned version of BioM-ELECTRA-Large, which was pre-trained on PubMed Abstracts, on the SQuAD2.0 dataset. Fine-tuning the biomedical language model on the SQuAD dataset helps improve the score on the BioASQ challenge. This model is suitable for working with BioASQ or biomedical QA tasks."}
{"text_id": 463, "text": "query: Help a student with medical research by answering questions based on the given context."}
{"text_id": 12, "text": "document: Hubert-Large is a self-supervised speech representation learning model pretrained on 16kHz sampled speech audio. It is designed to deal with the unique problems in speech representation learning, such as multiple sound units in each input utterance, no lexicon of input sound units during the pre-training phase, and variable lengths of sound units with no explicit segmentation. The model relies on an offline clustering step to provide aligned target labels for a BERT-like prediction loss."}
{"text_id": 12, "text": "query: We are working on a voice assistant that integrates with various smart devices. The project requires feature extraction from an audio sample to analyze actions."}
{"text_id": 869, "text": "document: This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data. We will use the Numenta Anomaly Benchmark(NAB) dataset. It provides artifical timeseries data containing labeled anomalous periods of behavior. Data are ordered, timestamped, single-valued metrics."}
{"text_id": 869, "text": "query: Our company is working on a project to analyze timeseries data to detect anomalies. We need to predict when unusual behavior is detected."}
{"text_id": 764, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. It is a Transformer-based encoder-decoder model and supports transcription and translation in various languages."}
{"text_id": 764, "text": "query: The manager wants to transcribe an important phone call from a recorded audio file. What steps do I need to follow to transcribe the audio file using this API?"}
{"text_id": 459, "text": "document: TAPAS medium model fine-tuned on WikiTable Questions (WTQ). This model is pretrained on a large corpus of English data from Wikipedia and is used for answering questions related to a table."}
{"text_id": 459, "text": "query: I need to extract data from tables by answering questions on the data."}
{"text_id": 526, "text": "document: T5-Large is a Text-To-Text Transfer Transformer (T5) model with 770 million parameters. It is designed to handle a variety of NLP tasks, including translation, summarization, question answering, sentiment analysis, and regression. The model is pre-trained on the Colossal Clean Crawled Corpus (C4) and fine-tuned on various supervised and unsupervised tasks."}
{"text_id": 526, "text": "query: We are a marketing agency, and we need to summarize a long customer review."}
{"text_id": 269, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart images."}
{"text_id": 269, "text": "query: I want to create a stylized image of a \"Michael Jackson concert\" by using line-art images and applying diffusion models."}
{"text_id": 205, "text": "document: YOLOS is a Vision Transformer (ViT) trained using the DETR loss. Despite its simplicity, a base-sized YOLOS model is able to achieve 42 AP on COCO validation 2017 (similar to DETR and more complex frameworks such as Faster R-CNN). The model is trained using a bipartite matching loss: one compares the predicted classes + bounding boxes of each of the N = 100 object queries to the ground truth annotations, padded up to the same length N (so if an image only contains 4 objects, 96 annotations will just have a no object as class and no bounding box as bounding box). The Hungarian matching algorithm is used to create an optimal one-to-one mapping between each of the N queries and each of the N annotations. Next, standard cross-entropy (for the classes) and a linear combination of the L1 and generalized IoU loss (for the bounding boxes) are used to optimize the parameters of the model."}
{"text_id": 205, "text": "query: We need to improve the efficiency of our security cameras surrounding the building. Please detect objects in the images."}
{"text_id": 315, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 315, "text": "query: Create a pipeline and generate images of cute butterflies using the pre-trained model 'schdoel/sd-class-AFHQ-32'."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. It is fine-tuned on 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model is intended for conversational text generation and can be used to play a character in a dialogue."}
{"text_id": 580, "text": "query: We would like to create a chatbot to handle customer service inquiries. How can we do that?"}
{"text_id": 766, "text": "document: Wav2Vec2-Large-XLSR-53 finetuned on multi-lingual Common Voice for phonetic label recognition in multiple languages. The model outputs a string of phonetic labels, and a dictionary mapping phonetic labels to words has to be used to map the phonetic output labels to output words."}
{"text_id": 766, "text": "query: A call center is interested in transcribing calls between agents and customers. We should process the audio to obtain the transcription."}
{"text_id": 80, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. It is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks."}
{"text_id": 80, "text": "query: Analyze a blueprint image and describe it in plain text."}
{"text_id": 76, "text": "document: Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder. This model is fine-tuned on CORD, a document parsing dataset."}
{"text_id": 76, "text": "query: I have travelled a lot and taken pictures of many places, but I can't remember what those places were. Extract texts from the photograph of a historic monument."}
{"text_id": 624, "text": "document: OPT (Open Pre-trained Transformer Language Models) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters. It was trained on a large corpus of text, predominantly in English, using a causal language modeling (CLM) objective. The model can be used for prompting for evaluation of downstream tasks, text generation, and fine-tuning on a downstream task using the CLM example."}
{"text_id": 624, "text": "query: Develop a model that continues a given story in a natural way."}
{"text_id": 201, "text": "document: A ConvNeXt image classification model pretrained on ImageNet-1k by paper authors. It can be used for image classification, feature map extraction, and image embeddings."}
{"text_id": 201, "text": "query: We are building a system to classify images on the production line. We want to build a machine learning model to do this task."}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: We are a newspaper agency and we want to extract information from images of newspaper articles by answering questions. It will help us to sort the articles and provide relevant answers."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: \"The weather today is sunny and beautiful.\""}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: A film producer wants to get artwork for his upcoming movie. Generate a church-themed image"}
{"text_id": 737, "text": "document: A pre-trained Text-to-Speech model for Chinese language using ESPnet framework. It can be used to convert text input into speech output in Chinese."}
{"text_id": 737, "text": "query: Our company wants to create a smart speaker device for Chinese users. We need a solution that can convert Chinese text into speech."}
{"text_id": 56, "text": "document: Stable Diffusion x4 upscaler is a latent diffusion model trained on a 10M subset of LAION containing images >2048x2048. It can be used to generate and modify images based on text prompts. The model receives a noise_level as an input parameter, which can be used to add noise to the low-resolution input according to a predefined diffusion schedule. The model is trained with English captions and might not work well with other languages."}
{"text_id": 56, "text": "query: Imagine I have started an online art shop where the user enters a text description of their desired image, and I would like to use an AI model that creates 4x upscaled, high-quality images based on those descriptions."}
{"text_id": 195, "text": "document: Swin Transformer v2 model pre-trained on ImageNet-1k at resolution 256x256. It was introduced in the paper Swin Transformer V2: Scaling Up Capacity and Resolution by Liu et al. and first released in this repository. The Swin Transformer is a type of Vision Transformer. It builds hierarchical feature maps by merging image patches in deeper layers and has linear computation complexity to input image size due to computation of self-attention only within each local window. Swin Transformer v2 adds 3 main improvements: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) a log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) a self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images."}
{"text_id": 195, "text": "query: Help me to build a personal shopping assistant that can recognize clothing styles"}
{"text_id": 355, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. These models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. They can be used for zero-shot image classification, image and text retrieval, and other tasks."}
{"text_id": 355, "text": "query: I have an image of an object and I want to know its category, like 'car', 'tree', 'cat', or 'building'."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: Create a software that speaks the weather forecast of Tokyo in Japanese."}
{"text_id": 779, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 779, "text": "query: I have an audio file with a noisy background. I want to separate the speech from the noise."}
{"text_id": 570, "text": "document: DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The model is trained on 147M multi-turn dialogue from Reddit discussion thread."}
{"text_id": 570, "text": "query: I need to create a way for a user to chat with an AI based on the DialoGPT-medium model."}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: I need a customized booking system for a travel agency in both English and Arabic languages. Translate the English sentence \"Thank you for booking with us, we will send you the itinerary shortly.\" to Arabic."}
{"text_id": 658, "text": "document: MBart for Russian summarization fine-tuned for dialogues summarization. This model was firstly fine-tuned by Ilya Gusev on Gazeta dataset. We have fine tuned that model on SamSum dataset translated to Russian using GoogleTranslateAPI. Moreover! We have implemented a ! telegram bot @summarization_bot ! with the inference of this model. Add it to the chat and get summaries instead of dozens spam messages!"}
{"text_id": 658, "text": "query: Summarize a conversation that took place on a community forum in Russian."}
{"text_id": 33, "text": "document: Stable Diffusion v2-1-base is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It is a Latent Diffusion Model that uses a fixed, pretrained text encoder (OpenCLIP-ViT/H). It is intended for research purposes only and can be used in areas such as safe deployment of models, understanding limitations and biases of generative models, generation of artworks, and research on generative models."}
{"text_id": 33, "text": "query: Let us imagine an amazing scenario where an elephant is flying with balloons over the plains of Africa. Create an image to illustrate this myth."}
{"text_id": 602, "text": "document: GPT-2 is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences."}
{"text_id": 602, "text": "query: Our company is launching a blog on sustainable development. We need AI-generated ideas for the blog."}
{"text_id": 536, "text": "document: A translation model for English to Chinese using the Hugging Face Transformers library. It is based on the Marian NMT model and trained on the OPUS dataset. The model requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 536, "text": "query: We are building a travel app to help tourists. We need a function that translates English into Simplified Chinese."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: I have an audio recording with some overlapping background noises. Can you help me separate the audio sources?"}
{"text_id": 599, "text": "document: This generation model is based on sberbank-ai/rugpt3medium_based_on_gpt2. It's trained on large corpus of dialog data and can be used for buildning generative conversational agents. The model was trained with context size 3."}
{"text_id": 599, "text": "query: I want to create a Russian-speaking chatbot that can make restaurant recommendations."}
{"text_id": 523, "text": "document: A German to English translation model trained on the OPUS dataset using the Hugging Face Transformers library."}
{"text_id": 523, "text": "query: A German article needs to be translated into English for our international clients."}
{"text_id": 765, "text": "document: Fine-tuned XLSR-53 large model for speech recognition in Arabic. Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the train and validation splits of Common Voice 6.1 and Arabic Speech Corpus."}
{"text_id": 765, "text": "query: Someone has asked about translating Arabic audio to text for an audio content he owns."}
{"text_id": 418, "text": "document: A Token Classification model trained using AutoTrain for Entity Extraction. The model is based on distilbert and achieves high accuracy, precision, recall, and F1 score."}
{"text_id": 418, "text": "query: We are a machine learning consulting firm. Our client is a bank that needs an entity extraction model to identify transaction details from customers' messages. Can you provide a code snippet?"}
{"text_id": 643, "text": "document: A fine-tuned version of google/flan-t5-large for grammar correction on an expanded version of the JFLEG dataset."}
{"text_id": 643, "text": "query: I want to develop a text editor that emphasizes grammatical correctness like Grammarly. Users can paste in their own raw text and have it automatically corrected."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: The HR department needs an AI assistant to extract specific information from the applicants' resumes. They want it to quickly answer questions about the applicant's profile."}
{"text_id": 744, "text": "document: Transformer text-to-speech model for Arabic language with a single-speaker male voice, trained on Common Voice v7 dataset."}
{"text_id": 744, "text": "query: I want to create an AI application that converts news headlines into spoken Arabic. How can I use a text-to-speech model for Arabic language headlines?"}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: I am looking for an AI solution to find answers in a given text based on the questions asked."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: We are creating a voice-controlled home automation system. We need to translate voice commands from Portuguese into text."}
{"text_id": 46, "text": "document: Stable Diffusion v2-base is a diffusion-based text-to-image generation model trained on a subset of LAION-5B dataset. It can be used to generate and modify images based on text prompts. The model uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is intended for research purposes only."}
{"text_id": 46, "text": "query: I want a chatbot for a customer whose primary purpose is to get images from their textual description."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: A linguistics software company in Esperanto is developing an automatic speech recognition system for its users. The goal is to convert spoken language into written text. "}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: As a content creator in the history field, I have a blog post and need your help to classify the potential historical figures and locations that are mentioned in the text."}
{"text_id": 455, "text": "document: TAPAS base model fine-tuned on Sequential Question Answering (SQA). This model is pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion and can be used for answering questions related to a table in a conversational set-up."}
{"text_id": 455, "text": "query: Our business client needs insights about the sales data. They sent us a table with sales information and want us to answer related questions."}
{"text_id": 181, "text": "document: Vision Transformer (ViT) model pre-trained on ImageNet-21k (14 million images, 21,843 classes) at resolution 224x224, and fine-tuned on ImageNet 2012 (1 million images, 1,000 classes) at resolution 384x384. It was introduced in the paper An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale by Dosovitskiy et al. Images are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds absolute position embeddings before feeding the sequence to the layers of the Transformer encoder."}
{"text_id": 181, "text": "query: Can you please give me a model that can help categorize an image to one of its 1,000 classes?"}
{"text_id": 864, "text": "document: Binary Classification model for Carbon Emissions prediction"}
{"text_id": 864, "text": "query: I need to predict companies that have high carbon emission based on a tabular dataset containing several features."}
{"text_id": 922, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 922, "text": "query: We are creating a safe route for a visually impaired person. Help us to estimate the depth of an indoor scene from an RGB image."}
{"text_id": 651, "text": "document: This model generates a revised version of inputted text with the goal of containing fewer grammatical errors. It was trained with Happy Transformer using a dataset called JFLEG."}
{"text_id": 651, "text": "query: Our team is at the final stage of writing web content in English. The text needs to be error-free. Optimize the text for grammar and syntax."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: Our marketing team has members who speak different Romance languages. Can we translate their work description into English?"}
{"text_id": 923, "text": "document: Donut model fine-tuned on DocVQA. It was introduced in the paper OCR-free Document Understanding Transformer by Geewok et al. and first released in this repository. Donut consists of a vision encoder (Swin Transformer) and a text decoder (BART). Given an image, the encoder first encodes the image into a tensor of embeddings (of shape batch_size, seq_len, hidden_size), after which the decoder autoregressively generates text, conditioned on the encoding of the encoder."}
{"text_id": 923, "text": "query: The company's legal department asked if we could help them find relevant information in a scanned contract document. They are interested in knowing about the termination clause in it."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: We are trying to develop a smart-city app that can perform road condition monitoring. It should be able to detect potholes from an image."}
{"text_id": 128, "text": "document: A document question answering model finetuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 128, "text": "query: Our company needs to analyze a series of documents to answer questions about them. Please provide guidance on how to create a working model to solve this problem."}
{"text_id": 398, "text": "document: A multi-class text classification model for detecting gibberish text. Trained using AutoNLP and DistilBERT."}
{"text_id": 398, "text": "query: The client needs to filter out gibberish user-generated content on their social media platform."}
{"text_id": 517, "text": "document: A German zeroshot classification model based on the German BERT large model from deepset.ai and finetuned for natural language inference using machine-translated nli sentence pairs from mnli, anli, and snli datasets."}
{"text_id": 517, "text": "query: We want to build a program where user can provide text in German for zero-shot classification to identify the topics in a text."}
{"text_id": 657, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It can be used for masked language modeling and is intended to be fine-tuned on a downstream task."}
{"text_id": 657, "text": "query: A foreign language educational platform wants to complete sentences in various languages. Find a solution to help with this task."}
{"text_id": 313, "text": "document: This model is a diffusion model for unconditional image generation of cute \ud83e\udd8b."}
{"text_id": 313, "text": "query: I want to decorate my astronomy room with some high-quality computer-generated images of galaxies. How can I achieve this?"}
{"text_id": 734, "text": "document: A Telugu Male Text-to-Speech model using the ESPnet framework, provided by Hugging Face."}
{"text_id": 734, "text": "query: Create audio for a Telugu story book for children. The input is text in Telugu language."}
{"text_id": 906, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym HalfCheetah environment"}
{"text_id": 906, "text": "query: Our company is developing a gaming product for animal simulation. We want to implement a Reinforcement Learning model that simulates the movement of a half-cheetah based on expert trajectories."}
{"text_id": 642, "text": "document: DialogLED is a pre-trained model for long dialogue understanding and summarization. It builds on the Longformer-Encoder-Decoder (LED) architecture and uses window-based denoising as the pre-training task on a large amount of long dialogue data for further training. Here is a base version of DialogLED, the input length is limited to 16,384 in the pre-training phase."}
{"text_id": 642, "text": "query: Please summarize a long conversation between two employees regarding a project's progress."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: We urgently require a way to remove the dead portions of an interview, such as silent or irrelevant parts, while conserving the main speaking portions."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: We need to estimate the depth of a scene from a single input image. The output should be a depth map that can help robots avoid obstacles."}
{"text_id": 617, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, designed to enable reproducible and responsible research at scale. It was predominantly pretrained with English text, but a small amount of non-English data is present within the training corpus via CommonCrawl. The model was pretrained using a causal language modeling (CLM) objective. OPT can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 617, "text": "query: Generate a text about the history of computers."}
{"text_id": 841, "text": "document: A speaker diarization pipeline that uses pyannote.audio to perform voice activity detection, speaker change detection, and overlapped speech detection. It can handle fully automatic processing with no manual intervention and can be fine-tuned with various hyperparameters."}
{"text_id": 841, "text": "query: Design an application that detects different speakers in an audio conversation and provides the start and end time of each speaker's segment."}
{"text_id": 354, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models utilize the timm ConvNeXt-Large model (convnext_large) as the image tower, a MLP (fc - gelu - drop - fc) head in vision tower instead of the single projection of other CLIP models, and a text tower with same width but 4 layers more depth than ViT-L / RN50x16 models (depth 16, embed dim 768)."}
{"text_id": 354, "text": "query: We are building an app that allows users to upload images and it will automatically identify the object in the image. It can recognize simple objects like a cat, dog, bird, etc., as well as more complex objects like landmarks or specific species of plants."}
{"text_id": 891, "text": "document: This is a trained model of a PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 891, "text": "query: We are a company that needs efficient energy management in our buildings. We would like to obtain a trained model using reinforcement learning that can help us achieve our goals."}
{"text_id": 258, "text": "document: A YOLOv8 model for detecting and segmenting PCB defects such as Dry_joint, Incorrect_installation, PCB_damage, and Short_circuit."}
{"text_id": 258, "text": "query: We recently expanded our electronics production line. We are now building a system to detect and segment PCB defects in the manufacturing process."}
{"text_id": 164, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation tasks."}
{"text_id": 164, "text": "query: As the lead engineer of an autonomous vehicle project, we need to estimate the depth of objects in the environment from camera images."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: Design a system for enhancing the quality of audio files, especially when multiple people are speaking at once."}
{"text_id": 690, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 690, "text": "query: We are building an AI-powered platform for organizing articles. Compare the similarity between two given articles by embedding their content."}
{"text_id": 137, "text": "document: A tiny random LayoutLM model for question answering. This model is not pretrained and serves as an example for the LayoutLM architecture."}
{"text_id": 137, "text": "query: A media organization is looking for a solution to get answers for their queries. We need to parse their documents and provide them with answers."}
{"text_id": 406, "text": "document: This model predicts the punctuation of English, Italian, French and German texts. It was developed to restore the punctuation of transcribed spoken language and trained on the Europarl Dataset provided by the SEPP-NLG Shared Task. The model restores the following punctuation markers: ., ,, ?, -, :."}
{"text_id": 406, "text": "query: I am trying to remember the correct punctuation in this long sentence but I am not sure, give me the correct punctuation."}
{"text_id": 587, "text": "document: BaekBot is a conversational model based on the GPT-2 architecture for text generation. It can be used for generating human-like responses in a chat-like environment."}
{"text_id": 587, "text": "query: I am a student and always want to keep updated about technology. Can we make a conversation that reflects it?"}
{"text_id": 213, "text": "document: A YOLOv8 model for detecting hard hats in images. The model can distinguish between 'Hardhat' and 'NO-Hardhat' classes. It can be used to ensure safety compliance in construction sites or other industrial environments where hard hats are required."}
{"text_id": 213, "text": "query: Write a manual on how to use this model to analyze an image of a construction site for health and safety compliance."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: I'm working on an English Language Learning application and need to implement a text-to-speech function, so users can hear the correct pronunciation of a word."}
{"text_id": 4, "text": "document: BART is a transformer encoder-decoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."}
{"text_id": 4, "text": "query: We need a program that can analyze the sentiment of movie reviews. Build it for us."}
{"text_id": 920, "text": "document: A tiny wav2vec2 model for Automatic Speech Recognition"}
{"text_id": 920, "text": "query: We need to generate a transcript from a recorded meeting audio file."}
{"text_id": 265, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Depth estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 265, "text": "query: Create a software that estimates the depth of an object in an image, which will help in building a 3D model of the object."}
{"text_id": 703, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 703, "text": "query: Help me to create a program that can analyze customer reviews and find out which products and services it is comparing."}
{"text_id": 29, "text": "document: DRAGON+ is a BERT-base sized dense retriever initialized from RetroMAE and further trained on the data augmented from MS MARCO corpus, following the approach described in How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval. The associated GitHub repository is available here https://github.com/facebookresearch/dpr-scale/tree/main/dragon. We use asymmetric dual encoder, with two distinctly parameterized encoders."}
{"text_id": 29, "text": "query: Create a passage retrieval system to find the most relevant passage that answers a given question from a list of passages."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: Our client asked us to build an interactive application for the hotel reservation system. They specifically want their customers to be able to ask questions related to hotel prices and room availability."}
{"text_id": 533, "text": "document: Helsinki-NLP/opus-mt-en-ru is a translation model trained on the OPUS dataset, which translates English text to Russian. It is based on the Marian NMT framework and can be used with Hugging Face Transformers."}
{"text_id": 533, "text": "query: My boss needs a document translated from English to Russian for an important business meeting."}
{"text_id": 749, "text": "document: This API provides an automatic speaker diarization pipeline using the pyannote.audio framework. It can process audio files and output speaker diarization results in RTTM format. The pipeline can also handle cases where the number of speakers is known in advance or when providing lower and/or upper bounds on the number of speakers."}
{"text_id": 749, "text": "query: We would like a system to distinguish audio files and recognize which person is speaking in a conference call."}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Create a robotic arm that can grasp objects based on the trained model."}
{"text_id": 328, "text": "document: VideoMAE model pre-trained for 800 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 328, "text": "query: A friend of yours has a video clip, and they want to have the video categorized."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: A creative designer is working on a prototype for a new video game, and they want to visualize a high-resolution image of a castle on a hill with blue skies and lush green fields."}
{"text_id": 136, "text": "document: A model for document question answering, fine-tuned on the DocVQA dataset using LayoutLMv2-base-uncased."}
{"text_id": 136, "text": "query: I need help extracting information from a scientific research paper. Please create a program that can provide answers to questions I have regarding the paper."}
{"text_id": 889, "text": "document: A tabular regression model trained on the julien-c/kaggle-rounakbanik-pokemon dataset to predict the HP of Pokemon."}
{"text_id": 889, "text": "query: The game company wants to develop a new Pokemon game. However, they need to predict the HP of each Pokemon before releasing them into the game."}
{"text_id": 308, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies trained for 200 epochs."}
{"text_id": 308, "text": "query: As part of a school project, we need to create a virtual environment filled with beautiful butterflies. We require an AI model to generate images of butterflies for us."}
{"text_id": 458, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. neulab/omnitab-large-1024shot (based on BART architecture) is initialized with microsoft/tapex-large and continuously pretrained on natural and synthetic data (SQL2NL model trained in the 1024-shot setting)."}
{"text_id": 458, "text": "query: The marketing department provided us with a dataset of Olympic Games and host cities. Extract the most recent year and host city."}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: Please help me design a system to predict recidivism using available data for a criminal justice agency."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: We are trying to build an AI search function that can recommend articles on COVID-19 based on a given instruction."}
{"text_id": 75, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 75, "text": "query: I would like to extract text from images of handwritten documents."}
{"text_id": 735, "text": "document: FastSpeech 2 text-to-speech model from fairseq S^2. English, 200 male/female voices, trained on Common Voice v4."}
{"text_id": 735, "text": "query: I would like to automatically read a news article to me."}
{"text_id": 243, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (large-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 243, "text": "query: Our infrastructure maintenance team needs to identify and segment various elements from a cityscape picture."}
{"text_id": 589, "text": "document: A DialoGPT model trained for generating human-like conversational responses."}
{"text_id": 589, "text": "query: I want to create an AI conversation with an chatbot to discuss Star Wars Universe"}
{"text_id": 241, "text": "document: Mask2Former model trained on Cityscapes semantic segmentation (large-sized version, Swin backbone). It addresses instance, semantic and panoptic segmentation by predicting a set of masks and corresponding labels. The model outperforms the previous SOTA, MaskFormer, in terms of performance and efficiency."}
{"text_id": 241, "text": "query: Our company's mission is to create autonomous vehicles for smart cities. We need to process street images to better understand road conditions."}
{"text_id": 436, "text": "document: English NER in Flair (Ontonotes large model). This is the large 18-class NER model for English that ships with Flair. It predicts 18 tags such as cardinal value, date value, event name, building name, geo-political entity, language name, law name, location name, money name, affiliation, ordinal value, organization name, percent value, person name, product name, quantity value, time value, and name of work of art. The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 436, "text": "query: I am trying to detect named entities in a text input about a theft event."}
{"text_id": 858, "text": "document: A binary classification model trained on the IMDb sentiment analysis dataset using AutoTrain. The model is capable of predicting sentiment (positive or negative) for movie reviews."}
{"text_id": 858, "text": "query: I want to build a Python script that can predict the sentiment of movie reviews using the Hugging Face IMDb sentiment analysis model."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: As a computer vision researcher, we are exploring different facial features. Generate a human face for our studies."}
{"text_id": 364, "text": "document: A series of CLIP ConvNeXt-XXLarge models trained on LAION-2B (English), a subset of LAION-5B, using OpenCLIP. These models achieve between 79.1 and 79.4 top-1 zero-shot accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 364, "text": "query: Help me identify what kind of animal is depicted in an image."}
{"text_id": 200, "text": "document: A ConvNeXt-V2 image classification model. Pretrained with a fully convolutional masked autoencoder framework (FCMAE) and fine-tuned on ImageNet-1k."}
{"text_id": 200, "text": "query: We are a robotics company that needs to identify food in our environment. Our robots need to be able to determine what type of food it is based on a photo."}
{"text_id": 496, "text": "document: This is the checkpoint for bart-large after being trained on the MultiNLI (MNLI) dataset. The model can be used for zero-shot text classification by posing the sequence to be classified as the NLI premise and constructing a hypothesis from each candidate label. The probabilities for entailment and contradiction are then converted to label probabilities."}
{"text_id": 496, "text": "query: We are developing a blog that categorizes different articles automatically. Detect the category for a given article called \"one day I will see the world\"."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: I am creating an image processing app that recognizes elements on an image and segment them with meaningful names."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: We need a solution to convert Spanish text into clear Spanish male speech."}
{"text_id": 446, "text": "document: A Korean Table Question Answering model finetuned on the korwikitq dataset."}
{"text_id": 446, "text": "query: We are running a Korean board game and one of the players is asking a question \"What is the price of the item X?\". The answers to all the questions can be found in the table from the manual. Can you help us to answer that?"}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: We are working on a project where we have to predict the carbon emissions of different vehicles. We need a solution to predict vehicle emissions."}
{"text_id": 799, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the enh_single task of the Libri1Mix dataset."}
{"text_id": 799, "text": "query: I have an audio file that I need to separate the speaker's voice from the background noise."}
{"text_id": 879, "text": "document: A tabular regression model trained using AutoTrain for predicting carbon emissions. The model is trained on the pcoloc/autotrain-data-dragino-7-7 dataset and has an R2 score of 0.540."}
{"text_id": 879, "text": "query: You are working on a project that requires a regression model to predict carbon emissions. The team needs you to supply the model with data."}
{"text_id": 10, "text": "document: Pretrained weights for CodeBERT: A Pre-Trained Model for Programming and Natural Languages. The model is trained on bi-modal data (documents & code) of CodeSearchNet. This model is initialized with Roberta-base and trained with MLM+RTD objective."}
{"text_id": 10, "text": "query: Our company is building a chatbot for developers that understands and answers coding questions. The chatbot should understand both natural language queries and code samples."}
{"text_id": 887, "text": "document: Baseline Model trained on outhimar_64 to apply regression on Close. Disclaimer: This model is trained with dabl library as a baseline, for better results, use AutoTrain. Logs of training including the models tried in the process can be found in logs.txt."}
{"text_id": 887, "text": "query: We are building an automated stock trading platform. The goal is to predict the closing price of specific stocks."}
{"text_id": 58, "text": "document: An image captioning model that uses transformers to generate captions for input images. The model is based on the Illustrated Image Captioning using transformers approach."}
{"text_id": 58, "text": "query: Develop a service for a photo-sharing app that generates a caption for a user's uploaded picture."}
{"text_id": 368, "text": "document: Korean CLIP model trained by Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation. It is a zero-shot image classification model that can be used to classify images without any training data."}
{"text_id": 368, "text": "query: We are developing a Korean news website, and we need a tool to categorize images based on their content without any specific training data. Obtain the suitable API and prepare an example code to test it."}
{"text_id": 732, "text": "document: Speech-to-speech translation model from fairseq S2UT (paper/code) for Spanish-English. Trained on mTEDx, CoVoST 2, Europarl-ST, and VoxPopuli."}
{"text_id": 732, "text": "query: We are building a multilingual smart speaker and want to translate English speech to Spanish, French, and Italian speech."}
{"text_id": 568, "text": "document: The PEGASUS model is designed for abstractive summarization. It is pretrained on a mixture of C4 and HugeNews datasets and stochastically samples important sentences. The model uses a gap sentence ratio between 15% and 45% and a sentencepiece tokenizer that encodes newline characters."}
{"text_id": 568, "text": "query: We are trying to build a pharmaceutical application to help us summarize the most recent research papers for our users. We need to figure out a proper way to call an API to summarize these research papers."}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: I am organizing an AI conference, I have to recommend papers based on a selected paper's abstract. Suggest me papers based on their abstract similarity."}
{"text_id": 482, "text": "document: This is the deberta-v3-base model, fine-tuned using the SQuAD2.0 dataset. It's been trained on question-answer pairs, including unanswerable questions, for the task of Question Answering."}
{"text_id": 482, "text": "query: We're working on a self-learning app prototype for students. We need to create an educational feature that can answer their questions related to a particular topic from a given context."}
{"text_id": 918, "text": "document: T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and for which each task is converted into a text-to-text format. It can be used for translation, text-to-text generation, and summarization."}
{"text_id": 918, "text": "query: I want to translate English text to French using T5."}
{"text_id": 177, "text": "document: BEiT model pre-trained in a self-supervised fashion on ImageNet-22k - also called ImageNet-21k (14 million images, 21,841 classes) at resolution 224x224, and fine-tuned on the same dataset at resolution 224x224. It was introduced in the paper BEIT: BERT Pre-Training of Image Transformers by Hangbo Bao, Li Dong and Furu Wei and first released in this repository."}
{"text_id": 177, "text": "query: I am a farmer and I need to identify various plants in my field. Help me catalogue images of the plants."}
{"text_id": 466, "text": "document: BERT large model (uncased) whole word masking finetuned on SQuAD. The model was pretrained on BookCorpus and English Wikipedia. It was trained with two objectives: Masked language modeling (MLM) and Next sentence prediction (NSP). This model should be used as a question-answering model."}
{"text_id": 466, "text": "query: I am the founder of a tutoring company, I want a question and answer system to help my students."}
{"text_id": 233, "text": "document: SegFormer model fine-tuned on ADE20k at resolution 512x512. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 233, "text": "query: We are developing a navigation system for autonomous vehicles which requires semantic segmentation of the road and environmental objects. Implement a SegFormer model to process street images."}
{"text_id": 226, "text": "document: Yolov5s-v7.0 is an object detection model trained on the COCO dataset. It can detect objects in images and return their bounding boxes, scores, and categories."}
{"text_id": 226, "text": "query: Help me to quantize the above-mentioned model architecture for YOLOv5."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: We need to convert a text message into speech for our virtual assistant."}
{"text_id": 724, "text": "document: Transformer text-to-speech model from fairseq S^2. Simplified Chinese, Single-speaker female voice, Pre-trained on Common Voice v7, fine-tuned on CSS10."}
{"text_id": 724, "text": "query: We have a podcast about Chinese culture, and we need to create an introduction in Simplified Chinese."}
{"text_id": 844, "text": "document: A pre-trained model for speaker segmentation, voice activity detection, overlapped speech detection, and resegmentation using the pyannote.audio framework."}
{"text_id": 844, "text": "query: I am writing an audio processing application that will automatically analyze audio recordings of telephone conversations. I want to separate the voice tracks of each speaker and identify if they are talking simultaneously. Please provide a code example of how I can achieve this."}
{"text_id": 520, "text": "document: This is the DeepPavlov/rubert-base-cased fine-tuned to predict the logical relationship between two short texts: entailment, contradiction, or neutral."}
{"text_id": 520, "text": "query: There are some emails circulating in our company which are misleading. We need to filter them based on their content against our company policies."}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: We are researching on self-driving cars and would like to estimate the distance of objects from the environments."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: We are a media company working on enhancing the quality of old films. We want to improve the resolution of movie frames."}
{"text_id": 365, "text": "document: A series of CLIP ConvNeXt-Large (w/ extra text depth, vision MLP head) models trained on LAION-2B (english), a subset of LAION-5B, using OpenCLIP. The models are trained at 256x256 image resolution and achieve a 75.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 365, "text": "query: I need to know how to classify images of animals, specifically cats, dogs, and birds."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: Let's build a reporting tool for a sustainability department to predict and monitor the carbon emissions of various activities within the company."}
{"text_id": 42, "text": "document: Openjourney v4 is trained on +124k Midjourney v4 images by PromptHero. It is used for generating images based on text inputs."}
{"text_id": 42, "text": "query: We are building an AI that generates visuals for a children's book. We need the model to create an image of \"a cute dragon playing with a teddy bear.\""}
{"text_id": 79, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captioning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 79, "text": "query: We need a solution to generate descriptions for images of nature and landscapes for a travel website."}
{"text_id": 461, "text": "document: This is the roberta-base model, fine-tuned using the SQuAD2.0 dataset for the task of Question Answering. It's been trained on question-answer pairs, including unanswerable questions."}
{"text_id": 461, "text": "query: We need to create a program that can answer questions based on a given context."}
{"text_id": 352, "text": "document: A CLIP ViT-B/16 model trained with the LAION-2B English subset of LAION-5B using OpenCLIP. This model is intended for research purposes and can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 352, "text": "query: As a parent, I need an automated tool to filter images according to predefined categories, such as cartoons and real animals."}
{"text_id": 504, "text": "document: This multilingual model can perform natural language inference (NLI) on 100 languages and is therefore also suitable for multilingual zero-shot classification. The underlying model was pre-trained by Microsoft on the CC100 multilingual dataset. It was then fine-tuned on the XNLI dataset, which contains hypothesis-premise pairs from 15 languages, as well as the English MNLI dataset."}
{"text_id": 504, "text": "query: We have employees from multiple countries and they sometimes mix languages in their messages. We need a multilingual personal assistant that can sort emails by their priority - high, medium, low."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: Our company needs to get information from tables. Extract specific information given a table and a question."}
{"text_id": 895, "text": "document: This is a trained model of a DQN agent playing MountainCar-v0 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 895, "text": "query: As the chief of a mountain rescue team, I need my helicopter to be able to travel autonomously. Use a reinforcement learning model to have our helicopter learn the required movements."}
{"text_id": 853, "text": "document: This model is trained for binary classification on the Adult dataset using AutoTrain. It is designed to predict CO2 emissions based on input features."}
{"text_id": 853, "text": "query: We are building a tool for the government to estimate individual CO2 emission based on the Adult dataset. They want to classify whether a person is above or below a certain threshold of emissions."}
{"text_id": 280, "text": "document: Swin2SR model that upscales images x4. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository. This model is intended for image super resolution."}
{"text_id": 280, "text": "query: A user wants to upscale a low-resolution photo to a 4x higher resolution. Suggest a model to achieve this task."}
{"text_id": 302, "text": "document: An unconditional image generation model for generating Minecraft skin images using the diffusion model."}
{"text_id": 302, "text": "query: Generate a Minecraft skin image using a model that is capable of creating unique and interesting representations of Minecraft characters."}
{"text_id": 242, "text": "document: OneFormer model trained on the COCO dataset (large-sized version, Swin backbone). It was introduced in the paper OneFormer: One Transformer to Rule Universal Image Segmentation by Jain et al. and first released in this repository. OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 242, "text": "query: Our company is working on developing self-driving cars. We need to segment the objects in the road environment so that the car knows how to avoid obstacles."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: We are a health insurance company, and we need to answer users' questions about COVID-19 based on the information provided to them."}
{"text_id": 561, "text": "document: A fine-tuned version of google/long-t5-tglobal-base on the kmfoda/booksum dataset, which can be used to summarize long text and generate SparkNotes-esque summaries of arbitrary topics. The model generalizes reasonably well to academic and narrative text."}
{"text_id": 561, "text": "query: Our company needs a tool to summarize long articles to provide our users with an effective quick read of the content."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: Our team is working on a German voice assistant and we need to detect emotions from the user's voice input."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: We would like to create an anime character wearing a baseball cap, having aqua eyes, white hair, and a green background."}
{"text_id": 921, "text": "document: This is a proof-of-concept fine-tune of Facebook's OPT-350M model optimized for dialogue, to be used as a stepping stone to higher parameter models. Disclaimer: NSFW data was included in the fine-tuning of this model. Although SFW inputs will usually result in SFW outputs, you are advised to chat at your own risk. This model is not suitable for use by minors."}
{"text_id": 921, "text": "query: Our company's website is lacking in user engagement. We need a conversational assistant to interact with site visitors and improve their experience."}
{"text_id": 136, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on the None dataset."}
{"text_id": 136, "text": "query: I want to extract values from any document images of invoices using a computer vision based model."}
{"text_id": 566, "text": "document: PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization by Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter J. Liu. The model is trained on both C4 and HugeNews datasets and is designed for summarization tasks."}
{"text_id": 566, "text": "query: We are a news agency, and we want to generate a summary of an article."}
{"text_id": 528, "text": "document: The Helsinki-NLP/opus-mt-en-de model is a translation model developed by the Language Technology Research Group at the University of Helsinki. It translates English text to German using the Hugging Face Transformers library. The model is trained on the OPUS dataset and has a BLEU score of 45.2 on the newstest2018-ende.en.de dataset."}
{"text_id": 528, "text": "query: Our company is making a blog for international travelers. We would like to have automatic translation for English text to German."}
{"text_id": 852, "text": "document: A tabular classification model trained on the Titanic survival dataset using Hugging Face AutoTrain. The model predicts whether a passenger survived or not based on features such as age, gender, and passenger class."}
{"text_id": 852, "text": "query: Our client, the owner of a cruise ship company wants to predict the survival likelihood of their passengers in case of an accident, using a model trained on the Titanic dataset. Can you help?"}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: As an admin of a blog, we need to find out whether two texts submitted are paraphrased from each other or not."}
{"text_id": 262, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Human Pose Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 262, "text": "query: Our company develops video games where players perform dance moves using Kinect technology! We want to simulate the characters poses according to the moves."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: I run a bilingual blog with posts in English and Spanish. I want to automatically categorize the new posts by topic, e.g. culture, sports, politics, and technology."}
{"text_id": 702, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space. It can be used for tasks like clustering or semantic search."}
{"text_id": 702, "text": "query: I am writing a book, and I want to avoid redundant sentences. Can you build me a tool to help me find similar sentences?"}
{"text_id": 479, "text": "document: MiniLM-L12-H384-uncased is a language model fine-tuned for extractive question answering on the SQuAD 2.0 dataset. It is based on the microsoft/MiniLM-L12-H384-uncased model and can be used with the Hugging Face Transformers library."}
{"text_id": 479, "text": "query: We want to review the content of our course for consistence. Could you check if the paragraph answers correctly the question \"Why is model conversion important?\""}
{"text_id": 78, "text": "document: Pix2Struct is an image encoder - text decoder model that is trained on image-text pairs for various tasks, including image captionning and visual question answering. The model is pretrained by learning to parse masked screenshots of web pages into simplified HTML. It can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images."}
{"text_id": 78, "text": "query: Our company is working on visual question-answering, and we would like a solution that can analyze chart images and answer questions about the data in the charts."}
{"text_id": 698, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 698, "text": "query: Identify whether two given texts are semantically similar and translate those texts into vectors."}
{"text_id": 593, "text": "document: GODEL is a large-scale pre-trained model for goal-directed dialogs. It is parameterized with a Transformer-based encoder-decoder model and trained for response generation grounded in external text, which allows more effective fine-tuning on dialog tasks that require conditioning the response on information that is external to the current conversation (e.g., a retrieved document). The pre-trained model can be efficiently fine-tuned and adapted to accomplish a new dialog task with a handful of task-specific dialogs. The v1.1 model is trained on 551M multi-turn dialogs from Reddit discussion thread, and 5M instruction and knowledge grounded dialogs."}
{"text_id": 593, "text": "query: Guide me on how to cook the perfect steak based on my collected instructions and previous conversations."}
{"text_id": 59, "text": "document: Stable Diffusion x2 latent upscaler is a diffusion-based upscaler model developed by Katherine Crowson in collaboration with Stability AI. It is designed to upscale Stable Diffusion's latent denoised image embeddings, allowing for fast text-to-image and upscaling pipelines. The model was trained on a high-resolution subset of the LAION-2B dataset and works with all Stable Diffusion checkpoints."}
{"text_id": 59, "text": "query: We need to get a high-resolution image of a city skyline at sunset from a lower resolution input image."}
{"text_id": 903, "text": "document: This is a trained model of a DQN agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 903, "text": "query: We are launching a product that can train a gaming reinforcement learning agent to play CartPole with a user. We need to use the RL Zoo to train the model."}
{"text_id": 251, "text": "document: MaskFormer model trained on ADE20k semantic segmentation (base-sized version, Swin backbone). It was introduced in the paper Per-Pixel Classification is Not All You Need for Semantic Segmentation and first released in this repository. This model addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation."}
{"text_id": 251, "text": "query: As a developer at a company focusing on creating map intelligence software, I need to add building segmentation to our software."}
{"text_id": 716, "text": "document: A Text-to-Speech model trained on the ljspeech dataset using the ESPnet toolkit. This model can be used to convert text input into synthesized speech."}
{"text_id": 716, "text": "query: Our client develops an application for the visually impaired. We need to include text-to-speech functionality for the users of this app."}
{"text_id": 811, "text": "document: A pretrained model for predicting emotion in local audio files using Hubert."}
{"text_id": 811, "text": "query: We need to analyze the emotions expressed in a podcast and want to know the top two emotions for a given audio segment."}
{"text_id": 391, "text": "document: This model was trained on the MS Marco Passage Ranking task. The model can be used for Information Retrieval: Given a query, encode the query will all possible passages (e.g. retrieved with ElasticSearch). Then sort the passages in a decreasing order. See SBERT.net Retrieve & Re-rank for more details. The training code is available here: SBERT.net Training MS Marco"}
{"text_id": 391, "text": "query: The company is developing a smart chatbot to answer users' questions. We are now working on creating a ranking system for the answers provided by the chatbot."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: My company processes a large number of scanned documents every day, and we need to extract printed text from these images to store in our database."}
{"text_id": 176, "text": "document: ConvNeXT is a pure convolutional model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform them. The authors started from a ResNet and 'modernized' its design by taking the Swin Transformer as inspiration. You can use the raw model for image classification."}
{"text_id": 176, "text": "query: As a cataloging system for our library, we need to label books based on their cover images."}
{"text_id": 898, "text": "document: This is a trained model of a PPO agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}
{"text_id": 898, "text": "query: I am building a video game machine learning bot that can play Pong like a human. Train it to do so."}
{"text_id": 717, "text": "document: Instructor is an instruction-finetuned text embedding model that can generate text embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation, etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction, without any finetuning. Instructor achieves state-of-the-art performance on 70 diverse embedding tasks."}
{"text_id": 717, "text": "query: I\u2019m studying astronomy and I want to find similar sentences to \u201cThe gravitational pull of a black hole is so strong that not even light can escape.\u201d"}
{"text_id": 60, "text": "document: Optical character recognition for Japanese text, with the main focus being Japanese manga. It uses Vision Encoder Decoder framework. Manga OCR can be used as a general purpose printed Japanese OCR, but its main goal was to provide a high quality text recognition, robust against various scenarios specific to manga: both vertical and horizontal text, text with furigana, text overlaid on images, wide variety of fonts and font styles, and low quality images."}
{"text_id": 60, "text": "query: Help me extract Japanese text from manga images."}
{"text_id": 163, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}
{"text_id": 163, "text": "query: Help me to create a model for depth estimation in images."}
{"text_id": 357, "text": "document: A series of CLIP ConvNeXt-Base (w/ wide embed dim) models trained on subsets LAION-5B using OpenCLIP. The models achieve between 70.8 and 71.7 zero-shot top-1 accuracy on ImageNet-1k. The models can be used for zero-shot image classification, image and text retrieval, and other related tasks."}
{"text_id": 357, "text": "query: A user is uploading a photo to their online profile and needs it to be categorized. Find out if it's a cat or a dog."}
{"text_id": 254, "text": "document: A YOLOv8 model for pothole segmentation trained on keremberke/pothole-segmentation dataset. It can detect potholes in images and provide segmentation masks for the detected potholes."}
{"text_id": 254, "text": "query: We would like to build a monitoring system for identifying and segmenting potholes on the road using computer vision."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: We have some audio files, we need to separate the vocals and the instruments."}
{"text_id": 183, "text": "document: A pre-trained model for classifying images as either dog or food using Hugging Face's AutoTrain framework."}
{"text_id": 183, "text": "query: I want to sort out pictures in my phone\u2019s gallery by separating images that are of my dog and images that are food."}
{"text_id": 351, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 351, "text": "query: I am building a smartphone application that will let users take photos of their pets and classify the breed."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: Our company produces video ads, and we want to categorize the generated videos into sports, entertainment, or technology."}
{"text_id": 909, "text": "document: Antheia/Hanna is a reinforcement learning model for robotics tasks, trained on the openai/webgpt_comparisons dataset."}
{"text_id": 909, "text": "query: Our team is working on a project that involves programming a robot to organize objects in a warehouse. We need to use the most suitable model for the task."}
{"text_id": 644, "text": "document: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token."}
{"text_id": 644, "text": "query: I have a project meeting with a Spanish-speaking client and I need to translate a paragraph from English to Spanish."}
{"text_id": 285, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on inpaint images."}
{"text_id": 285, "text": "query: We are an online gallery. Our customer sent us a damaged painting. They want us to repair it before putting it online."}
{"text_id": 127, "text": "document: A Document Question Answering model based on layoutlmv2"}
{"text_id": 127, "text": "query: We are a company specialized in document analysis. We would like to extract information from a scanned invoice."}
{"text_id": 493, "text": "document: XLM-RoBERTa-large model finetunned over several NLI datasets, ready to use for zero-shot classification."}
{"text_id": 493, "text": "query: I would like to develop a tool that helps me organize my documents in categories such as travel, cooking, and dancing."}
{"text_id": 894, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Walker2d environment."}
{"text_id": 894, "text": "query: I am working on a robotics project that requires the control of a bipedal walker. We need to use a reinforcement learning model to help control walking in virtual simulation."}
{"text_id": 611, "text": "document: GPT-J 6B is a transformer model trained using Ben Wang's Mesh Transformer JAX. It consists of 28 layers with a model dimension of 4096, and a feedforward dimension of 16384. The model dimension is split into 16 heads, each with a dimension of 256. Rotary Position Embedding (RoPE) is applied to 64 dimensions of each head. The model is trained with a tokenization vocabulary of 50257, using the same set of BPEs as GPT-2/GPT-3. GPT-J 6B was trained on the Pile, a large-scale curated dataset created by EleutherAI."}
{"text_id": 611, "text": "query: Our blog needs a captivating introduction paragraph about the latest advancements in technology."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: \"A dog running happily in the park\"."}
{"text_id": 180, "text": "document: A vision transformer finetuned to classify the age of a given person's face."}
{"text_id": 180, "text": "query: The company is developing a feature for a dating app that recommends potential matches filtered by age group. Implement this feature."}
{"text_id": 271, "text": "document: Controlnet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Scribble images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 271, "text": "query: We are a digital art agency, and we need to generate an image of a \"garden with a pond and a bench\" using the scribbles provided."}
{"text_id": 284, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on lineart_anime images."}
{"text_id": 284, "text": "query: Our company wants to generate artwork for a manga-style comic series. We need to create lineart sketches of characters and scenes based on text descriptions."}
{"text_id": 472, "text": "document: This model is a Roberta-based model fine-tuned on SQuAD-style CORD-19 annotations for the task of extractive question answering in the context of COVID-19. It can be used with the Hugging Face Transformers library for question answering tasks."}
{"text_id": 472, "text": "query: We want to give clients COVID-19 related health advice. The system should be able to answer questions about symptoms, treatment, and more."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: I want an API to generate anime-style character images based on textual descriptions. The API must yield high-quality images."}
{"text_id": 529, "text": "document: A model for translating Romance languages to English, trained on the OPUS dataset. It supports multiple source languages such as French, Spanish, Portuguese, Italian, and Romanian, among others. The model is based on the transformer architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 529, "text": "query: A language education platform needs to translate a text from a Romance language like French to English."}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: Write a prescription for a patient with the side effect of allergies using the knowledge stored in this pretrained model."}
{"text_id": 723, "text": "document: This repository provides all the necessary tools for Text-to-Speech (TTS) with SpeechBrain using a Tacotron2 pretrained on LJSpeech. The pre-trained model takes in input a short text and produces a spectrogram in output. One can get the final waveform by applying a vocoder (e.g., HiFIGAN) on top of the generated spectrogram."}
{"text_id": 723, "text": "query: I want to create an audiobook from a text file. Generate a speech waveform for a given text and save it in a file."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: We are working with surveillance cameras and planning to identify and segment the people in the captured images."}
{"text_id": 742, "text": "document: This model was trained by imdanboy using ljspeech recipe in espnet."}
{"text_id": 742, "text": "query: Our company needs a simple way to convert written instructions into spoken language for visually impaired users."}
{"text_id": 246, "text": "document: Mask2Former model trained on COCO instance segmentation (small-sized version, Swin backbone). It was introduced in the paper Masked-attention Mask Transformer for Universal Image Segmentation and first released in this repository. Mask2Former addresses instance, semantic and panoptic segmentation with the same paradigm: by predicting a set of masks and corresponding labels. Hence, all 3 tasks are treated as if they were instance segmentation. Mask2Former outperforms the previous SOTA, MaskFormer both in terms of performance an efficiency."}
{"text_id": 246, "text": "query: Can you show me how to automatically segment objects in an image?"}
{"text_id": 911, "text": "document: Trained Models for Grasp SE(3) DiffusionFields. Check SE(3)-DiffusionFields: Learning smooth cost functions for joint grasp and motion optimization through diffusion for additional details."}
{"text_id": 911, "text": "query: Our company designs robotic arms for manufacturing. We want to implement a model to improve the grasping ability of the arm to ensure stable grasping of various objects."}
{"text_id": 162, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 162, "text": "query: Our company is creating a smartphone app that uses the camera to estimate the depth of objects in a scene. Implement a solution for this task."}
{"text_id": 152, "text": "document: Dense Prediction Transformer (DPT) model trained on 1.4 million images for monocular depth estimation. Introduced in the paper Vision Transformers for Dense Prediction by Ranftl et al. (2021) and first released in this repository. DPT uses the Vision Transformer (ViT) as backbone and adds a neck + head on top for monocular depth estimation. This repository hosts the hybrid version of the model as stated in the paper. DPT-Hybrid diverges from DPT by using ViT-hybrid as a backbone and taking some activations from the backbone."}
{"text_id": 152, "text": "query: A project needs to estimate the depth of objects in the image then render it in 3D. Help find the code!"}
{"text_id": 323, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 323, "text": "query: We need to classify the given basketball game video footage into different highlights."}
{"text_id": 62, "text": "document: BLIP is a Vision-Language Pre-training (VLP) framework that achieves state-of-the-art results on a wide range of vision-language tasks, such as image-text retrieval, image captioning, and VQA. It effectively utilizes noisy web data by bootstrapping the captions, where a captioner generates synthetic captions and a filter removes the noisy ones."}
{"text_id": 62, "text": "query: Our marketing department requires a technology that automatically generates captions for user-uploaded images."}
{"text_id": 550, "text": "document: A French to Spanish translation model trained on the OPUS dataset using the Hugging Face Transformers library. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing."}
{"text_id": 550, "text": "query: Suggest a way to translate French text to Spanish text for a language learning app."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: I want to feed in an invoice file and get billable amount for the transaction."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: We need to monitor the activities in a zoo via videos. Detect the activity happening in a specific video frame and classify it."}
{"text_id": 614, "text": "document: OPT (Open Pre-trained Transformers) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, trained to roughly match the performance and sizes of the GPT-3 class of models. It can be used for prompting for evaluation of downstream tasks as well as text generation."}
{"text_id": 614, "text": "query: I am a researcher, I want to generate an interesting opening sentence of a sci-fi story related to superhuman abilities."}
{"text_id": 115, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 115, "text": "query: I have a set of textual, handwritten and printed invoices, and I want to extract the total cost from them. How would I do this?"}
{"text_id": 621, "text": "document: CodeGen is a family of autoregressive language models for program synthesis. The models are originally released in this repository, under 3 pre-training data variants (NL, Multi, Mono) and 4 model size variants (350M, 2B, 6B, 16B). The checkpoint included in this repository is denoted as CodeGen-Multi 2B, where Multi means the model is initialized with CodeGen-NL 2B and further pre-trained on a dataset of multiple programming languages, and 2B refers to the number of trainable parameters."}
{"text_id": 621, "text": "query: I am building an employee onboarding app. For this app, create a Python function that calculates an employee's salary based on their hourly rate and hours worked."}
{"text_id": 854, "text": "document: This model is trained for multi-class classification using logistic regression on the iris dataset. It is trained with AutoTrain and has a CO2 emissions of 0.0006300767567816624 grams. The model has an accuracy of 0.9 and can be used with the Hugging Face Inference API."}
{"text_id": 854, "text": "query: I have a set of iris flower measurements in a CSV file. I need to classify them using a logistic regression model."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: I want an AI that will help me translate English text to German. For example, I want to translate \"Hello, how are you?\" in German."}
{"text_id": 460, "text": "document: OmniTab is a table-based QA model proposed in OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering. The original Github repository is https://github.com/jzbjyb/OmniTab. neulab/omnitab-large-1024shot-finetuned-wtq-1024shot (based on BART architecture) is initialized with neulab/omnitab-large-1024shot and fine-tuned on WikiTableQuestions in the 1024-shot setting."}
{"text_id": 460, "text": "query: We need to extract the specific value from this table, where the value will be used for statistical analysis."}
{"text_id": 159, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset."}
{"text_id": 159, "text": "query: Our goal is to create a parking assistance system that will use images to estimate the depth of objects. We need a model capable of depth estimation for images."}
{"text_id": 347, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 347, "text": "query: We are hosting an image content. The company needs to get a verdict whether user-submitted images are cat pictures or dog pictures before they are sent to the judges."}
{"text_id": 706, "text": "document: This is a sentence-transformers model that maps sentences and paragraphs to a 768 dimensional dense vector space and was designed for semantic search. It has been trained on 215M (question, answer) pairs from diverse sources."}
{"text_id": 706, "text": "query: As a corporate business who focus on business insights for other companies, we often receive long articles about economics, policies, and technologies. We need to retrieve the most relevant segment of the article to a specific question."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: A publisher uses articles from freelancers. We want to check similarity of articles to avoid publishing duplicate content."}
{"text_id": 353, "text": "document: FashionCLIP is a CLIP-based model developed to produce general product representations for fashion concepts. Leveraging the pre-trained checkpoint (ViT-B/32) released by OpenAI, it is trained on a large, high-quality novel fashion dataset to study whether domain specific fine-tuning of CLIP-like models is sufficient to produce product representations that are zero-shot transferable to entirely new datasets and tasks."}
{"text_id": 353, "text": "query: Our client is developing an ecommerce platform, and they need an AI solution that can automatically classify images of clothes in their inventory."}
{"text_id": 96, "text": "document: A text-to-video model trained on OpenAssistant/oasst1 dataset."}
{"text_id": 96, "text": "query: Our goal is to turn a text story into a video. What is the API to do so?"}
{"text_id": 637, "text": "document: Sentence doctor is a T5 model that attempts to correct the errors or mistakes found in sentences. Model works on English, German and French text."}
{"text_id": 637, "text": "query: My colleague wrote an email containing an error and I need to correct that error."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: A user composing an email reports a bug and needs guidance on how to proceed. Generate five different sentences to instruct the user on the next steps."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: I am an author with a writer's block and I need some ideas for a story. Can you generate 5 different story starting sentences for me?"}
{"text_id": 440, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. It was pretrained with two objectives: Masked language modeling (MLM) and Intermediate pre-training. Fine-tuning is done by adding a cell selection head and aggregation head on top of the pre-trained model, and then jointly train these randomly initialized classification heads with the base model on SQA and WikiSQL."}
{"text_id": 440, "text": "query: I'm looking for the number of employees working in a company from a given structured data table."}
{"text_id": 194, "text": "document: A model that classifies images as hotdog or not hotdog."}
{"text_id": 194, "text": "query: Develop an application for people at a food festival to differentiate images of hotdogs from other types of foods instantly."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: We are a patent filing company. We need a system that summarizes long patent descriptions to help our clients understand them easily."}
{"text_id": 25, "text": "document: Language-agnostic BERT Sentence Encoder (LaBSE) is a BERT-based model trained for sentence embedding for 109 languages. The pre-training process combines masked language modeling with translation language modeling. The model is useful for getting multilingual sentence embeddings and for bi-text retrieval."}
{"text_id": 25, "text": "query: Our customer support team needs to resolve issues raised by people from multiple countries. They need to check which queries are similar despite being written in three different languages (English, Italian, Japanese). How do we do that?"}
{"text_id": 146, "text": "document: A tiny random GLPN model for depth estimation using the Hugging Face Transformers library."}
{"text_id": 146, "text": "query: We are designing an application to predict the depth of objects in images. Implement a depth estimation model."}
{"text_id": 791, "text": "document: This repository provides all the necessary tools to perform audio source separation with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset, which is basically a version of WSJ0-Mix dataset with environmental noise."}
{"text_id": 791, "text": "query: We're creating an application that can separate speakers from an audio file of a conversation. How do I perform this task?"}
{"text_id": 674, "text": "document: Bio_ClinicalBERT is a model initialized with BioBERT and trained on all MIMIC notes. It can be used for various NLP tasks in the clinical domain, such as Named Entity Recognition (NER) and Natural Language Inference (NLI)."}
{"text_id": 674, "text": "query: We would like the assistant to predict the missing word in a clinical sentence using the Bio_ClinicalBERT model."}
{"text_id": 451, "text": "document: TAPAS is a BERT-like transformers model pretrained on a large corpus of English data from Wikipedia in a self-supervised fashion. This model is fine-tuned on WikiSQL and can be used for answering questions related to a table."}
{"text_id": 451, "text": "query: I need to find the total sales amount for a specific product."}
{"text_id": 711, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 711, "text": "query: The goal is to create a system that can group similar news articles together, arrange news feeds according to these groups, and help users find articles relevant to their interests."}
{"text_id": 713, "text": "document: The model is trained on very large sentence level datasets using a self-supervised contrastive learning objective. It is fine-tuned on a 1B sentence pairs dataset, and it aims to capture the semantic information of input sentences. The sentence vector can be used for information retrieval, clustering, or sentence similarity tasks."}
{"text_id": 713, "text": "query: I want to find semantically similar sentences within reviews of an online course to better understand the common themes."}
{"text_id": 505, "text": "document: This model was fine-tuned on the MultiNLI, Fever-NLI, Adversarial-NLI (ANLI), LingNLI and WANLI datasets, which comprise 885 242 NLI hypothesis-premise pairs. This model is the best performing NLI model on the Hugging Face Hub as of 06.06.22 and can be used for zero-shot classification. It significantly outperforms all other large models on the ANLI benchmark."}
{"text_id": 505, "text": "query: We are an AI-based news generation company. We want to classify news articles into appropriate categories."}
{"text_id": 286, "text": "document: Denoising Diffusion Probabilistic Models (DDPM) is a class of latent variable models inspired by nonequilibrium thermodynamics. It is used for high-quality image synthesis. The model supports different noise schedulers such as scheduling_ddpm, scheduling_ddim, and scheduling_pndm."}
{"text_id": 286, "text": "query: Create a neural network model for generating unique images of houseplants for a gardening website."}
{"text_id": 394, "text": "document: This model ('SiEBERT', prefix for 'Sentiment in English') is a fine-tuned checkpoint of RoBERTa-large (Liu et al. 2019). It enables reliable binary sentiment analysis for various types of English-language text. For each instance, it predicts either positive (1) or negative (0) sentiment. The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance generalization across different types of texts (reviews, tweets, etc.). Consequently, it outperforms models trained on only one type of text (e.g., movie reviews from the popular SST-2 benchmark) when used on new data as shown below."}
{"text_id": 394, "text": "query: Develop a model for my application that can extract sentiment from user reviews."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: Can you offer a solution for a real estate platform? The platform requires a model that can segment images provided by users to identify interior spaces, objects, and elements in the rooms like furniture, walls, windows, etc."}
{"text_id": 567, "text": "document: BigBird, a sparse-attention based transformer, extends Transformer-based models like BERT to much longer sequences. It can handle sequences up to a length of 4096 at a much lower compute cost compared to BERT. BigBird has achieved state-of-the-art results on various tasks involving very long sequences such as long documents summarization and question-answering with long contexts."}
{"text_id": 567, "text": "query: Our company is working on a system to summarize long patent documents. Please use an NLP model designed specifically for summarization tasks on long texts."}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: We are a company creating a multilingual NLP service. We want to restore punctuation to the text obtained from speech recognition results."}
{"text_id": 509, "text": "document: SqueezeBERT is a transformer model designed for efficient inference on edge devices. This specific model, typeform/squeezebert-mnli, is fine-tuned on the MultiNLI dataset for zero-shot classification tasks."}
{"text_id": 509, "text": "query: \"The quick brown fox jumps over the lazy dog.\""}
{"text_id": 539, "text": "document: A Hugging Face Transformers model for English to Arabic translation, trained on the Tatoeba dataset. It uses a transformer architecture and requires a sentence initial language token in the form of '>>id<<' (id = valid target language ID)."}
{"text_id": 539, "text": "query: \"Welcome to our student exchange program! We are excited to have you join us.\""}
{"text_id": 270, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Normal Map Estimation. It can be used in combination with Stable Diffusion."}
{"text_id": 270, "text": "query: I need an image of a car and estimate its 3D normal map using an AI model."}
{"text_id": 788, "text": "document: This repository provides all the necessary tools to perform speech enhancement (denoising) with a SepFormer model, implemented with SpeechBrain, and pretrained on WHAM! dataset with 16k sampling frequency, which is basically a version of WSJ0-Mix dataset with environmental noise and reverberation in 8k."}
{"text_id": 788, "text": "query: I need to clean up an audio file by removing background noise and enhancing the speech."}
{"text_id": 563, "text": "document: This model is a T5 Transformers model (JDBN/t5-base-fr-qg-fquad) that was fine-tuned in French for abstractive text summarization."}
{"text_id": 563, "text": "query: I would like to summarize a long French article that I have typed in a nutshell. I would like the summary to be concise and informative."}
{"text_id": 207, "text": "document: OWL-ViT is a zero-shot text-conditioned object detection model that uses CLIP as its multi-modal backbone, with a ViT-like Transformer to get visual features and a causal language model to get the text features. The model can be used to query an image with one or multiple text queries."}
{"text_id": 207, "text": "query: Create a script to find an image of a cat and a park in it."}
{"text_id": 656, "text": "document: CodeT5 is a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. It supports both code understanding and generation tasks and allows for multi-task learning. The model can be used for tasks such as code summarization, code generation, code translation, code refinement, code defect detection, and code clone detection."}
{"text_id": 656, "text": "query: We want to develop a program to analyze a single code snippet and automatically generate a human-readable summary explaining the purpose of the provided code."}
{"text_id": 558, "text": "document: google/pegasus-large is a pre-trained model for abstractive text summarization based on the PEGASUS architecture. It is trained on a mixture of C4 and HugeNews datasets and uses a sentencepiece tokenizer that can encode newline characters. The model has been fine-tuned for various summarization tasks and achieves state-of-the-art performance on multiple benchmarks."}
{"text_id": 558, "text": "query: I need a solution to automatically summarize news articles so I can read only the important information."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: I want to extract features from unstructured multimodal data like code comments and abstract syntax trees to better understand the code structure."}
{"text_id": 423, "text": "document: This project provides traditional Chinese transformers models (including ALBERT, BERT, GPT2) and NLP tools (including word segmentation, part-of-speech tagging, named entity recognition)."}
{"text_id": 423, "text": "query: My Chinese friend wrote me an email, and I would like to understand the grammar structure. I need a POS tagger for traditional Chinese text."}
{"text_id": 727, "text": "document: This model was trained by mio using amadeus recipe in espnet."}
{"text_id": 727, "text": "query: Our company is developing virtual assistants. We need a Text-to-Speech (TTS) integration to communicate with the users."}
{"text_id": 51, "text": "document: Dreamlike Anime 1.0 is a high quality anime model, made by dreamlike.art. It can be used to generate anime-style images based on text prompts. The model is trained on 768x768px images and works best with prompts that include 'photo anime, masterpiece, high quality, absurdres'. It can be used with the Stable Diffusion Pipeline from the diffusers library."}
{"text_id": 51, "text": "query: I want to develop an app that generates high-quality anime images from text descriptions. Find an appropriate API and usage."}
{"text_id": 840, "text": "document: A multi-class classification model trained with AutoTrain to predict carbon emissions based on input features."}
{"text_id": 840, "text": "query: I need to estimate the carbon emission of a factory based on a set of input features. Could you give me some pointers to do that?"}
{"text_id": 386, "text": "document: This model was trained on the MS Marco Passage Ranking task and can be used for Information Retrieval. Given a query, encode the query with all possible passages, then sort the passages in a decreasing order."}
{"text_id": 386, "text": "query: Our client wants to find the most relevant information from a list of passages. They are looking for information on a specific question."}
{"text_id": 661, "text": "document: mBART-50 many-to-many multilingual machine translation model can translate directly between any pair of 50 languages. It was introduced in the Multilingual Translation with Extensible Multilingual Pretraining and Finetuning paper."}
{"text_id": 661, "text": "query: We need to translate a text from Hindi to French for a multinational company."}
{"text_id": 832, "text": "document: Pyannote Segmentation model fine-tuned on data from CHiME-7 DASR Challenge. Used to perform diarization in the CHiME-7 DASR diarization baseline."}
{"text_id": 832, "text": "query: The client needs an algorithm to detect which portions of their recorded meetings contain speech."}
{"text_id": 296, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and can generate high fidelity images of size 1024 x 1024."}
{"text_id": 296, "text": "query: We are planning to design a series of church-inspired greeting cards, and we need a unique design for the card background."}
{"text_id": 155, "text": "document: A depth estimation model fine-tuned on the DIODE dataset using the GLPN model architecture."}
{"text_id": 155, "text": "query: We want to create a 3D visualization of an indoor environment. Find the depth of objects in an image captured by a sensor."}
{"text_id": 264, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on Image Segmentation. It can be used in combination with Stable Diffusion."}
{"text_id": 264, "text": "query: As a real estate company, we want to create a model that separates the different regions of an image of a house so it's easier to label it with the different parts of the house (roof, walls, windows, etc.)."}
{"text_id": 434, "text": "document: TAPAS small model fine-tuned on WikiTable Questions (WTQ). This model was pre-trained on MLM and an additional step which the authors call intermediate pre-training, and then fine-tuned in a chain on SQA, WikiSQL and finally WTQ. It uses relative position embeddings (i.e. resetting the position index at every cell of the table)."}
{"text_id": 434, "text": "query: We are doing data analysis of the company profit distribution. Help me find out which division contributed the most profit."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: We are trying to build a billboard poster for our company, the design should include a futuristic city skyline at sunset with a modern train speeding along the tracks in the foreground."}
{"text_id": 629, "text": "document: FLAN-T5 is a language model fine-tuned on more than 1000 additional tasks covering multiple languages. It achieves state-of-the-art performance on several benchmarks and is designed for research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering."}
{"text_id": 629, "text": "query: As a content writer, I need a software to help me come up with more creative titles for my article about \"The History of Artificial Intelligence\"."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: \"The fox and the crow were sitting in the forest.\""}
{"text_id": 518, "text": "document: This model is a translation model from English to Spanish using the Hugging Face Transformers library. It is based on the Marian framework and trained on the OPUS dataset. The model achieves a BLEU score of 54.9 on the Tatoeba test set."}
{"text_id": 518, "text": "query: We are a company that will produce articles regarding farming techniques. We need a text translated from English to Spanish."}
{"text_id": 263, "text": "document: ControlNet is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on HED Boundary. It can be used in combination with Stable Diffusion."}
{"text_id": 263, "text": "query: We are looking to create a digital art repository by converting images to oil paintings."}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: We need to recognize whether the uploaded image refers to a cat or a dog."}
{"text_id": 322, "text": "document: TimeSformer model pre-trained on Something Something v2. It was introduced in the paper TimeSformer: Is Space-Time Attention All You Need for Video Understanding? by Tong et al. and first released in this repository."}
{"text_id": 322, "text": "query: Our AI bot is designed to analyze videos and find inappropriate content, such as nudity, violence, or profanity. We need to classify activities in the videos."}
{"text_id": 185, "text": "document: A model trained on the beans dataset, just for testing and having a really tiny model."}
{"text_id": 185, "text": "query: A client has a collection of images and wishes to classify them based on the type of beans present in the images."}
{"text_id": 336, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 336, "text": "query: Can I install a security camera system in my store which can detect possible shoplifting incidents and help me categorize the events by their actions?"}
{"text_id": 615, "text": "document: Cerebras-GPT-111M is a transformer-based language model with 111M parameters, trained on the Pile dataset using the GPT-3 style architecture. It is intended for use in research and as a foundation model for NLP applications, ethics, and alignment research. The model can be fine-tuned for various tasks and is licensed under Apache 2.0."}
{"text_id": 615, "text": "query: Generate a text paragraph on the topic \"Impact of Artificial Intelligence on Healthcare\""}
{"text_id": 424, "text": "document: This is the large 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on document-level XLM-R embeddings and FLERT."}
{"text_id": 424, "text": "query: Our e-commerce platform needs to implement named entity recognition for user-generated reviews and comments."}
{"text_id": 778, "text": "document: MetricGAN-trained model for Enhancement"}
{"text_id": 778, "text": "query: A client has asked us to build a solution to improve the audio quality for his recorded lectures."}
{"text_id": 842, "text": "document: A Simple Example of Scikit-learn Pipeline for Wine Quality classification. Inspired by https://towardsdatascience.com/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976 by Saptashwa Bhattacharyya."}
{"text_id": 842, "text": "query: A company is planning to launch new wine products for their business. We need to predict the quality of each wine product. "}
{"text_id": 675, "text": "document: BERTimbau Base is a pretrained BERT model for Brazilian Portuguese that achieves state-of-the-art performances on three downstream NLP tasks: Named Entity Recognition, Sentence Textual Similarity and Recognizing Textual Entailment. It is available in two sizes: Base and Large."}
{"text_id": 675, "text": "query: We would like to build an application to fill in the missing words in Portuguese texts. The customers are Brazilian students."}
{"text_id": 362, "text": "document: A tiny random CLIPSegModel for zero-shot image classification."}
{"text_id": 362, "text": "query: We are building a product that uses machine learning to guess the character's emotion in an image from a comic."}
{"text_id": 112, "text": "document: A visual question answering model for answering questions related to images using the Hugging Face Transformers library."}
{"text_id": 112, "text": "query: We have a mobile application to which the user can upload images and ask questions about them. Like, What is the color of the car in the picture?"}
{"text_id": 865, "text": "document: A tabular classification model for predicting recidivism using the COMPAS dataset. The model is an imodels.FIGSClassifier trained with Scikit-learn and can be used with the Hugging Face Inference API."}
{"text_id": 865, "text": "query: I am a criminal attorney and I want to use an AI system to predict whether my client has a high or low risk of recidivism."}
{"text_id": 786, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri2Mix dataset."}
{"text_id": 786, "text": "query: Our conference rooms record audio from different microphones. We need a sound system that can separate speaker voices."}
{"text_id": 605, "text": "document: A text generation model from Hugging Face, using the bigscience/test-bloomd-6b3 architecture. It can be used for generating text based on a given input."}
{"text_id": 605, "text": "query: Generate a short story based on the beginning \"Once upon a time in a small village\"."}
{"text_id": 855, "text": "document: A tabular classification model for predicting carbon emissions in grams, trained using AutoTrain."}
{"text_id": 855, "text": "query: Find a way to estimate the carbon emissions from the data provided by an automotive company."}
{"text_id": 756, "text": "document: This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the None dataset. It is designed for Automatic Speech Recognition in Marathi language."}
{"text_id": 756, "text": "query: We are operating a Marathi-language call center and need to transcribe our customer interactions."}
{"text_id": 682, "text": "document: BERT large model (cased) pretrained on English language using a masked language modeling (MLM) objective. It has 24 layers, 1024 hidden dimensions, 16 attention heads, and 336M parameters."}
{"text_id": 682, "text": "query: \"She went to buy some _____.\""}
{"text_id": 319, "text": "document: VideoMAE model pre-trained for 1600 epochs in a self-supervised way and fine-tuned in a supervised way on Kinetics-400. It was introduced in the paper VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training by Tong et al. and first released in this repository."}
{"text_id": 319, "text": "query: We want to integrate our video streaming platform with an AI model that categorizes videos in real-time so our users can find relevant content more easily. How can we set this up?"}
{"text_id": 125, "text": "document: A tiny random LayoutLMv3 model for document question answering. Can be used with the Hugging Face Inference API."}
{"text_id": 125, "text": "query: Design an AI-based news reader that can find and answer questions in the given multimedia publication context."}
{"text_id": 273, "text": "document: Swin2SR model that upscales images x2. It was introduced in the paper Swin2SR: SwinV2 Transformer for Compressed Image Super-Resolution and Restoration by Conde et al. and first released in this repository."}
{"text_id": 273, "text": "query: Develop a product to improve user's online photos to make them look better in profiles."}
{"text_id": 759, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on Portuguese using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 759, "text": "query: We are developing a radio podcast system and want to create a way to transcribe Portuguese speech into text automatically."}
{"text_id": 863, "text": "document: A multi-class classification model trained using AutoTrain to predict CO2 emissions based on tabular data."}
{"text_id": 863, "text": "query: We want to provide our users with personalized recommendations on ways to reduce carbon emissions. We already have a dataset of different activities that reduce emissions. Let's figure out what activities or habits add the most emissions and should be avoided."}
{"text_id": 694, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 512 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 694, "text": "query: We are building a service for recommending hotel reviews to users. Classify the similarity of the provided hotel reviews."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: I want to extract text from an image of a handwritten note. The model must be able to identify characters accurately."}
{"text_id": 312, "text": "document: X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}
{"text_id": 312, "text": "query: I want to create a system that can analyze a video and provide a short textual description. Utilize a model that is trained on both video and text data."}
{"text_id": 407, "text": "document: bert-base-multilingual-cased-ner-hrl is a Named Entity Recognition model for 10 high resourced languages (Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese) based on a fine-tuned mBERT base model. It has been trained to recognize three types of entities: location (LOC), organizations (ORG), and person (PER)."}
{"text_id": 407, "text": "query: We were building a language research app. We need to process a multilingual dataset to find names of people, organizations, and locations in our dataset."}
{"text_id": 413, "text": "document: This model is trained using AutoTrain for entity extraction. It is based on the DistilBert architecture and has a CO2 Emissions of 0.8375653425894861 grams."}
{"text_id": 413, "text": "query: \"Microsoft acquires Github in 2018 for $7.5 billion\"."}
{"text_id": 881, "text": "document: A tabular regression model for predicting carbon emissions using the pcoloc/autotrain-dragino-7-7-max_300m-1861063640 dataset. Trained with AutoTrain."}
{"text_id": 881, "text": "query: We are a green company. We would like to use a Python model to predict the carbon emission for our future operations."}
{"text_id": 654, "text": "document: CodeT5 is a family of encoder-decoder language models for code from the paper: CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation by Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi. The checkpoint included in this repository is denoted as CodeT5-large-ntp-py (770M), which is introduced by the paper: CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning by Hung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, Steven C.H. Hoi."}
{"text_id": 654, "text": "query: We are a startup involved in building code generation systems for basic Python programming. Help us use a pretrained model to convert English text instruction to a Python function."}
{"text_id": 331, "text": "document: VideoMAE is an extension of Masked Autoencoders (MAE) to video. The architecture of the model is very similar to that of a standard Vision Transformer (ViT), with a decoder on top for predicting pixel values for masked patches. Videos are presented to the model as a sequence of fixed-size patches (resolution 16x16), which are linearly embedded. One also adds a [CLS] token to the beginning of a sequence to use it for classification tasks. One also adds fixed sinus/cosinus position embeddings before feeding the sequence to the layers of the Transformer encoder. By pre-training the model, it learns an inner representation of videos that can then be used to extract features useful for downstream tasks: if you have a dataset of labeled videos for instance, you can train a standard classifier by placing a linear layer on top of the pre-trained encoder. One typically places a linear layer on top of the [CLS] token, as the last hidden state of this token can be seen as a representation of an entire video."}
{"text_id": 331, "text": "query: I am creating an app to recognize gestures in sign language videos. What model should I use and how should I preprocess the input data?"}
{"text_id": 934, "text": "document: A finetuned xlm-roberta-base model for punctuation prediction on twelve languages: English, German, French, Spanish, Bulgarian, Italian, Polish, Dutch, Czech, Portugese, Slovak, Slovenian."}
{"text_id": 934, "text": "query: I'm working on a transcription service and I need a way to add punctuation to transcribed text."}
{"text_id": 293, "text": "document: Score-Based Generative Modeling through Stochastic Differential Equations (SDE) for unconditional image generation. This model achieves record-breaking performance on CIFAR-10 and demonstrates high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model."}
{"text_id": 293, "text": "query: We're launching an application that allows users to create stunning profile pictures. Help us integrate an algorithm to generate these pictures."}
{"text_id": 774, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on esperanto using the Common Voice dataset. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 774, "text": "query: Our company is working on building an Esperanto language learning app, and we need to transcribe audios into text for the lessons."}
{"text_id": 745, "text": "document: A pretrained voice activity detection pipeline that detects active speech in audio files."}
{"text_id": 745, "text": "query: Our podcast platform wants a feature that shows when a person is talking during the show. For this purpose, we'd like to implement a function to detect the active speech portions in a podcast audio file."}
{"text_id": 18, "text": "document: UniXcoder is a unified cross-modal pre-trained model that leverages multimodal data (i.e. code comment and AST) to pretrain code representation. Developed by Microsoft Team and shared by Hugging Face. It is based on the RoBERTa model and trained on English language data. The model can be used for feature engineering tasks."}
{"text_id": 18, "text": "query: I want to create an AI-powered code analyzer to help me identify code pieces that need refactoring. I need a model to extract and process important features."}
{"text_id": 712, "text": "document: A Chinese sentence similarity model based on the derivative model of https://huggingface.co/shibing624/text2vec-base-chinese, replacing MacBERT with LERT, and keeping other training conditions unchanged."}
{"text_id": 712, "text": "query: A Chinese literature student wants to see how similar their thoughts are to the original pieces of literature such as \"Journey to the West\"."}
{"text_id": 63, "text": "document: TrOCR model fine-tuned on the SROIE dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository. The TrOCR model is an encoder-decoder model, consisting of an image Transformer as encoder, and a text Transformer as decoder. The image encoder was initialized from the weights of BEiT, while the text decoder was initialized from the weights of RoBERTa."}
{"text_id": 63, "text": "query: Our company needs a system that can automatically read and transcribe handwritten documents into digital text."}
{"text_id": 495, "text": "document: This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages. It is intended to be used for zero-shot text classification, such as with the Hugging Face ZeroShotClassificationPipeline."}
{"text_id": 495, "text": "query: We are a media agency covering the history of football clubs. We want to classify their all-time performance based on various timelines."}
{"text_id": 113, "text": "document: A Visual Question Answering model trained on the GuanacoVQADataset, designed to work on consumer hardware like Colab Free T4 GPU. The model can be used to answer questions about images."}
{"text_id": 113, "text": "query: Tim needs some help with determining the number of fruits in his lunch bowl. Can you help him with that?"}
{"text_id": 715, "text": "document: This is a sentence-transformers model that maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 715, "text": "query: Our company develops an AI-based text similarity tool. We need to know if two sentences have similar meanings."}
{"text_id": 16, "text": "document: WavLM-Large is a large model pretrained on 16kHz sampled speech audio. It is built based on the HuBERT framework, with an emphasis on both spoken content modeling and speaker identity preservation. WavLM is pretrained on 60,000 hours of Libri-Light, 10,000 hours of GigaSpeech, and 24,000 hours of VoxPopuli. It achieves state-of-the-art performance on the SUPERB benchmark and brings significant improvements for various speech processing tasks on their representative benchmarks."}
{"text_id": 16, "text": "query: We are a call center software company and want to perform automated speech recognition on recorded calls."}
{"text_id": 470, "text": "document: A Korean Question Answering model based on Electra and trained on the KorQuAD dataset."}
{"text_id": 470, "text": "query: In Korea, a user has a new job, and he is doing it in Korean. He needs help in answering a question in Korean from a given text."}
{"text_id": 381, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. This model is an ancillary model for Parrot paraphraser."}
{"text_id": 381, "text": "query: We have some paraphrased texts, can you help us to classify if they are adequate or not?"}
{"text_id": 697, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 697, "text": "query: Help me to find similar sentences to the given sentence from a list of sentences."}
{"text_id": 830, "text": "document: This wav2vec2 based emotion detection model is trained on the emo-DB dataset. It can classify emotions in German audio files into seven classes: anger, boredom, disgust, fear, happiness, sadness, and neutral."}
{"text_id": 830, "text": "query: We are building a chatbot for a German company that handles customer support. It would be great if we could detect the emotions of customers to cater to their needs better through audio calls."}
{"text_id": 580, "text": "document: Pygmalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B. The fine-tuning dataset consisted of 56MB of dialogue data gathered from multiple sources, which includes both real and partially machine-generated conversations. The model was initialized from the uft-6b ConvoGPT model and fine-tuned on ~48.5 million tokens for ~5k steps on 4 NVIDIA A40s using DeepSpeed."}
{"text_id": 580, "text": "query: You are at a cocktail party, and you want to know if anyone knows about the recent breakthrough in artificial intelligence. Ask the chatbot something."}
{"text_id": 757, "text": "document: Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning."}
{"text_id": 757, "text": "query: We have multiple lingual audio calls coming from our users to handle in different departments. Convert the audio call into text providing the clean and grammatically correct transcript."}
{"text_id": 54, "text": "document: Counterfeit-V2.5 is a text-to-image model that generates anime-style images based on text prompts. It has been updated for ease of use and can be used with negative prompts to create high-quality images."}
{"text_id": 54, "text": "query: I run an online store that sells custom anime art. I need to generate anime-style images based on my customers' descriptions."}
{"text_id": 559, "text": "document: DistilBART model for text summarization, trained on the CNN/Daily Mail and XSum datasets. It is a smaller and faster version of BART, suitable for summarizing English text."}
{"text_id": 559, "text": "query: A writer wants to quickly summarize articles about AI trends for her blog."}
{"text_id": 473, "text": "document: This is longformer-base-4096 model fine-tuned on SQuAD v1 dataset for question answering task. Longformer model created by Iz Beltagy, Matthew E. Peters, Arman Coha from AllenAI. As the paper explains it, Longformer is a BERT-like model for long documents. The pre-trained model can handle sequences with up to 4096 tokens."}
{"text_id": 473, "text": "query: We need to answer long questions based on longer paragraphs."}
{"text_id": 796, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_clean task of the Libri3Mix dataset."}
{"text_id": 796, "text": "query: An audiobook company approachs us to enhance audio quality of their books. Our job is to separate voices from noise."}
{"text_id": 34, "text": "document: waifu-diffusion is a latent text-to-image diffusion model that has been conditioned on high-quality anime images through fine-tuning."}
{"text_id": 34, "text": "query: Our client wants to generate a visually appealing image of his daughter dressed in a superhero costume, based on a textual description of her features."}
{"text_id": 358, "text": "document: BiomedCLIP is a biomedical vision-language foundation model pretrained on PMC-15M, a dataset of 15 million figure-caption pairs extracted from biomedical research articles in PubMed Central, using contrastive learning. It uses PubMedBERT as the text encoder and Vision Transformer as the image encoder, with domain-specific adaptations. It can perform various vision-language processing (VLP) tasks such as cross-modal retrieval, image classification, and visual question answering."}
{"text_id": 358, "text": "query: The biomedical research department needs to classify microscopy images according to their cell types. We need a system for this."}
{"text_id": 343, "text": "document: This model is a fine-tuned version of MCG-NJU/videomae-base on an unknown dataset. It achieves the following results on the evaluation set: Loss: 0.3992, Accuracy: 0.8645."}
{"text_id": 343, "text": "query: An indoor game management software company needs to identify different types of indoor games played in the videos uploaded by users."}
{"text_id": 620, "text": "document: OPT (Open Pre-trained Transformer) is a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, developed by Meta AI. It is designed to enable reproducible and responsible research at scale and bring more voices to the table in studying the impact of large language models. The pretrained-only model can be used for prompting for evaluation of downstream tasks as well as text generation. It can also be fine-tuned on a downstream task using the CLM example."}
{"text_id": 620, "text": "query: Prepare a script for a YouTube video introducing a new cooking gadget."}
{"text_id": 187, "text": "document: SegFormer encoder fine-tuned on Imagenet-1k. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository. SegFormer consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on semantic segmentation benchmarks such as ADE20K and Cityscapes."}
{"text_id": 187, "text": "query: Create a system to quickly and efficiently classify thousands of images for our image database."}
{"text_id": 73, "text": "document: A proof-of-concept model for the Hugging Face FlaxVisionEncoderDecoder Framework that produces reasonable image captioning results."}
{"text_id": 73, "text": "query: Our mobile app users want to describe the content of the images they capture using their phones. Let's build the image caption generator system."}
{"text_id": 275, "text": "document: ControlNet v1.1 is a neural network structure to control diffusion models by adding extra conditions. This checkpoint corresponds to the ControlNet conditioned on seg images. It can be used in combination with Stable Diffusion, such as runwayml/stable-diffusion-v1-5."}
{"text_id": 275, "text": "query: A designer would like to create an image for a book cover based on a short description. Generate an image that can be used in this context."}
{"text_id": 40, "text": "document: Stable Diffusion v2 is a diffusion-based text-to-image generation model that can generate and modify images based on text prompts. It uses a fixed, pretrained text encoder (OpenCLIP-ViT/H) and is primarily intended for research purposes, such as safe deployment of models with potential to generate harmful content, understanding limitations and biases of generative models, and generation of artworks for design and artistic processes."}
{"text_id": 40, "text": "query: We are an e-commerce website that generates new images of watches using the user's desired design characteristics, such as color, material, and shape. Please provide an image of a watch."}
{"text_id": 665, "text": "document: BERT base model (cased) is a pre-trained transformer model on English language using a masked language modeling (MLM) objective. It was introduced in a paper and first released in a repository. This model is case-sensitive, which means it can differentiate between 'english' and 'English'. The model can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task."}
{"text_id": 665, "text": "query: Our team is building a content creation platform. We want to fix sentences with missing words."}
{"text_id": 500, "text": "document: This model was trained using SentenceTransformers Cross-Encoder class on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 500, "text": "query: An end-user left a review on our website. We would like our language model to classify the topic of the review."}
{"text_id": 147, "text": "document: Global-Local Path Networks (GLPN) model trained on KITTI for monocular depth estimation. It was introduced in the paper Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth by Kim et al. and first released in this repository."}
{"text_id": 147, "text": "query: A company in the automotive industry tries to design an advanced driver-assistance systems (ADAS). To do so, they need to build a depth estimation system to estimate how far away objects are from the camera."}
{"text_id": 710, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 710, "text": "query: The marketing team wants to ensure similarity in the message provided in ad campaigns in different languages."}
{"text_id": 403, "text": "document: This is the fast 4-class NER model for English that ships with Flair. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is based on Flair embeddings and LSTM-CRF."}
{"text_id": 403, "text": "query: Automatically identify people's names in a given text in English."}
{"text_id": 45, "text": "document: EimisAnimeDiffusion_1.0v is a text-to-image model trained with high-quality and detailed anime images. It works well on anime and landscape generations and supports a Gradio Web UI."}
{"text_id": 45, "text": "query: What can this API do for me, and how can I generate high-quality anime-style images from text descriptions?"}
{"text_id": 416, "text": "document: roberta-large-ner-english is an english NER model that was fine-tuned from roberta-large on conll2003 dataset. Model was validated on emails/chat data and outperformed other models on this type of data specifically. In particular, the model seems to work better on entities that don't start with an upper case."}
{"text_id": 416, "text": "query: \"Apple was founded in 1976 by Steve Jobs, Steve Wozniak, and Ronald Wayne to develop and sell Wozniak's Apple I personal computer.\""}
{"text_id": 330, "text": "document: TimeSformer model pre-trained on Kinetics-400 for video classification into one of the 400 possible Kinetics-400 labels. Introduced in the paper 'TimeSformer: Is Space-Time Attention All You Need for Video Understanding?' by Tong et al."}
{"text_id": 330, "text": "query: I have a yacht company and I want to classify the action in the video for video indexing purpose."}
{"text_id": 502, "text": "document: This model is based on microsoft/deberta-v3-base and was trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 502, "text": "query: When the skater moves their arms closer to the body, the spin becomes faster. I want to know if this proves the conservation of angular momentum."}
{"text_id": 870, "text": "document: A tabular regression model trained using AutoTrain to predict carbon emissions (in grams) with an R2 score of 0.013."}
{"text_id": 870, "text": "query: A smart home company wants to make an app that encourages individuals to decrease their carbon emissions. To achieve this, the app needs to predict the amount of carbon dioxide emissions based on related features."}
{"text_id": 235, "text": "document: SegFormer model fine-tuned on CityScapes at resolution 1024x1024. It was introduced in the paper SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers by Xie et al. and first released in this repository."}
{"text_id": 235, "text": "query: Our client is a security company and they want to use our AI solution to automatically detect cars on the street in real-time."}
{"text_id": 896, "text": "document: Decision Transformer model trained on medium trajectories sampled from the Gym Hopper environment."}
{"text_id": 896, "text": "query: At my work, we want to build a robot which can mimic simple demonstrations of human behavior. We have decided to use a reinforcement learning agent with imitation learning as training mechanism."}
{"text_id": 747, "text": "document: Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1. When using this model, make sure that your speech input is sampled at 16kHz."}
{"text_id": 747, "text": "query: Create an application that transcribes speech from multiple audio files at once using the provided model."}
{"text_id": 836, "text": "document: Model from End-to-end speaker segmentation for overlap-aware resegmentation, by Herv\u00e9 Bredin and Antoine Laurent. Online demo is available as a Hugging Face Space."}
{"text_id": 836, "text": "query: We're creating a podcast application and we want to detect when people are speaking in an audio file."}
{"text_id": 741, "text": "document: A Japanese text-to-speech model trained using the ESPnet framework. It is designed to convert text input into natural-sounding speech."}
{"text_id": 741, "text": "query: We need to deliver a Japanese speechbot to facilitate smooth conversion of news text articles into speech."}
{"text_id": 139, "text": "document: This model is a fine-tuned version of microsoft/layoutlmv2-base-uncased on an unknown dataset."}
{"text_id": 139, "text": "query: I am a student needing assistance with my homework. I have a question regarding the contents of a textbook passage.\r"}
{"text_id": 346, "text": "document: The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner."}
{"text_id": 346, "text": "query: Develop an image classifier that can automatically identify pictures of animals and provides the name of the animal in the image."}
{"text_id": 88, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 88, "text": "query: \"A person enjoying a coffee while reading a book at a cozy coffee shop.\""}
{"text_id": 148, "text": "document: This model is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset. It is used for depth estimation in computer vision tasks."}
{"text_id": 148, "text": "query: Our company is designing autonomous vehicles, and we need to estimate the depth of objects in a scene captured by our cameras."}
{"text_id": 845, "text": "document: A tabular classification model using the Scikit-learn framework and Joblib functionality. The model is trained with various hyperparameters and can be used for classification tasks."}
{"text_id": 845, "text": "query: As a company that offers financial services, we need to analyze financial data and categorize it into various risk levels."}
{"text_id": 309, "text": "document: This model is a diffusion model for unconditional image generation of cute butterflies."}
{"text_id": 309, "text": "query: Develop a program to create an image of a butterfly using artificial intelligence."}
{"text_id": 94, "text": "document: This model is based on a multi-stage text-to-video generation diffusion model, which inputs a description text and returns a video that matches the text description. Only English input is supported."}
{"text_id": 94, "text": "query: Create a 5-second video clip of Spiderman surfing."}
{"text_id": 390, "text": "document: Parrot is a paraphrase-based utterance augmentation framework purpose-built to accelerate training NLU models. A paraphrase framework is more than just a paraphrasing model."}
{"text_id": 390, "text": "query: I need to create alternative ways to express the same sentence for a chatbot I'm working on."}
{"text_id": 106, "text": "document: GIT (short for GenerativeImage2Text) model, large-sized version, fine-tuned on TextVQA. It was introduced in the paper GIT: A Generative Image-to-text Transformer for Vision and Language by Wang et al. and first released in this repository. The model is trained using 'teacher forcing' on a lot of (image, text) pairs. The goal for the model is simply to predict the next text token, giving the image tokens and previous text tokens. This allows the model to be used for tasks like: image and video captioning, visual question answering (VQA) on images and videos, and even image classification (by simply conditioning the model on the image and asking it to generate a class for it in text)."}
{"text_id": 106, "text": "query: You found an ancient artifact, you are trying to describe it to an old historian who is blind. The historian can only read braille."}
{"text_id": 289, "text": "document: High quality image synthesis using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics."}
{"text_id": 289, "text": "query: Our dating app wants to generate high-quality images of people for testing purposes."}
{"text_id": 291, "text": "document: Latent Diffusion Models (LDMs) achieve state-of-the-art synthesis results on image data and beyond by decomposing the image formation process into a sequential application of denoising autoencoders. LDMs enable high-resolution synthesis, semantic scene synthesis, super-resolution, and image inpainting while significantly reducing computational requirements compared to pixel-based DMs."}
{"text_id": 291, "text": "query: A toy company wants to generate high-resolution images of human faces for a doll project. Assist them with the generation process."}
{"text_id": 831, "text": "document: Audio Spectrogram Transformer (AST) model fine-tuned on Speech Commands v2. It was introduced in the paper AST: Audio Spectrogram Transformer by Gong et al. and first released in this repository. The Audio Spectrogram Transformer is equivalent to ViT, but applied on audio. Audio is first turned into an image (as a spectrogram), after which a Vision Transformer is applied. The model gets state-of-the-art results on several audio classification benchmarks."}
{"text_id": 831, "text": "query: A chatbot owner requested to assist the users in identifying spoken commands in a given audio file."}
{"text_id": 618, "text": "document: XLNet model pre-trained on English language. It was introduced in the paper XLNet: Generalized Autoregressive Pretraining for Language Understanding by Yang et al. and first released in this repository. XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance for language tasks involving long context."}
{"text_id": 618, "text": "query: I want a powerful AI model for natural language understanding. I'm building a system that has a chatbot feature, and I want it to generate some text."}
{"text_id": 688, "text": "document: This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search."}
{"text_id": 688, "text": "query: A news publications company wants to build a product to automatically detect if two news articles discuss the same topics."}
{"text_id": 577, "text": "document: DialoGPT is a state-of-the-art large-scale pretrained dialogue response generation model for multi-turn conversations. The model is trained on 147M multi-turn dialogues from Reddit discussion threads."}
{"text_id": 577, "text": "query: A multinational corporation's customer care executive needs to have an AI system that can handle customer queries effectively and solve them as a human."}
{"text_id": 415, "text": "document: InstaFoodRoBERTa-NER is a fine-tuned BERT model that is ready to use for Named Entity Recognition of Food entities on informal text (social media like). It has been trained to recognize a single entity: food (FOOD). Specifically, this model is a roberta-base model that was fine-tuned on a dataset consisting of 400 English Instagram posts related to food."}
{"text_id": 415, "text": "query: I am running a food blog and I mention different delicacies in my writing. Help me identify the food items from the text."}
{"text_id": 122, "text": "document: A fine-tuned version of the multi-modal LayoutLM model for the task of question answering on invoices and other documents. It has been fine-tuned on a proprietary dataset of invoices as well as both SQuAD2.0 and DocVQA for general comprehension. Unlike other QA models, which can only extract consecutive tokens, this model can predict longer-range, non-consecutive sequences with an additional classifier head."}
{"text_id": 122, "text": "query: We are developing a finance application, one core feature is to help extract information from received invoices. For example, finding the total amount in the invoice."}
{"text_id": 437, "text": "document: A tiny TAPAS model for table question answering tasks."}
{"text_id": 437, "text": "query: The board members in our company need a way to pull up specific data from tables through questions."}
{"text_id": 494, "text": "document: This is the uncased DistilBERT model fine-tuned on Multi-Genre Natural Language Inference (MNLI) dataset for the zero-shot classification task."}
{"text_id": 494, "text": "query: positive, negative or neutral sentiment."}
{"text_id": 501, "text": "document: Cross-Encoder for Natural Language Inference based on microsoft/deberta-v3-small, trained on the SNLI and MultiNLI datasets. For a given sentence pair, it will output three scores corresponding to the labels: contradiction, entailment, neutral."}
{"text_id": 501, "text": "query: We are designing a chatbot. We need an efficient AI model to infer if two phrases have the same meaning (paraphrase), are contradictory, or have a different meaning (neutral)."}
{"text_id": 465, "text": "document: This model is a BERT (base-multilingual-cased) fine-tuned for multilingual Question Answering on 11 different languages using the XQuAD dataset and additional data augmentation techniques."}
{"text_id": 465, "text": "query: My daughter asked me a question about Charlemagne, but I don't know the answer. Can you figure out when he was born?"}
{"text_id": 888, "text": "document: A RandomForestRegressor model for electricity consumption prediction."}
{"text_id": 888, "text": "query: I own an electricity provider company and I want to know when electricity consumption is highest or lowest in the coming months. I need you to create a machine learning model that will predict the consumption pattern based to my historic consumption data."}
{"text_id": 37, "text": "document: Realistic_Vision_V1.4 is a text-to-image model that generates high-quality and detailed images based on textual prompts. It can be used for various applications such as generating realistic portraits, landscapes, and other types of images."}
{"text_id": 37, "text": "query: As a game developer, I want to generate a specific concept art for the game. I need an image of a dark, haunted forest with a mysterious male figure in tattered clothing, holding a lantern, in the center. No other characters should appear in the image."}
{"text_id": 65, "text": "document: TrOCR model fine-tuned on the IAM dataset. It was introduced in the paper TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Li et al. and first released in this repository."}
{"text_id": 65, "text": "query: The project is about identifying handwritten texts from historical documents to be used in the research of ancient civilizations."}
{"text_id": 411, "text": "document: The XLM-RoBERTa model is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data. This model is XLM-RoBERTa-large fine-tuned with the conll2003 dataset in English. It can be used for token classification tasks such as Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging."}
{"text_id": 411, "text": "query: We need to extract all the named entities from thousands of documents coming from different countries."}
{"text_id": 247, "text": "document: OneFormer is the first multi-task universal image segmentation framework. It needs to be trained only once with a single universal architecture, a single model, and on a single dataset, to outperform existing specialized models across semantic, instance, and panoptic segmentation tasks. OneFormer uses a task token to condition the model on the task in focus, making the architecture task-guided for training, and task-dynamic for inference, all with a single model."}
{"text_id": 247, "text": "query: We are an architecture firm and need to carry out semantic, instance, and panoptic segmentation of construction site images for better planning."}
{"text_id": 380, "text": "document: This model classifies emotions in English text data. It predicts Ekman's 6 basic emotions, plus a neutral class: anger, disgust, fear, joy, neutral, sadness, and surprise. The model is a fine-tuned checkpoint of DistilRoBERTa-base."}
{"text_id": 380, "text": "query: I would like to create an AI assistant capable of detecting emotions in various text messages. The emotions to be detected should include anger, disgust, fear, joy, neutral, sadness, and surprise."}
{"text_id": 929, "text": "document: Table Transformer (DETR) model trained on PubTables1M for detecting the structure (like rows, columns) in tables."}
{"text_id": 929, "text": "query: We need to build an AI to analyze financial documents, read tables, and structure it to give us valuable insights."}
{"text_id": 485, "text": "document: A Chinese MRC roberta_wwm_ext_large model trained on a large amount of Chinese MRC data. This model has significantly improved performance on reading comprehension and classification tasks. It has helped multiple users achieve top 5 results in the Dureader-2021 competition."}
{"text_id": 485, "text": "query: What is the right API to use for a bilingual dictionary, English to Chinese?"}
{"text_id": 13, "text": "document: A pretrained RoBERTa-large model for simple contrastive learning of sentence embeddings. It can be used for feature extraction and has been evaluated on semantic textual similarity (STS) tasks and downstream transfer tasks."}
{"text_id": 13, "text": "query: As an e-commerce website owner, I would like to identify similar product descriptions to recommend them to the customers."}
{"text_id": 6, "text": "document: Vision Transformer (ViT) model trained using the DINO method. It was introduced in the paper Emerging Properties in Self-Supervised Vision Transformers by Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, Armand Joulin and first released in this repository."}
{"text_id": 6, "text": "query: Analyze an image URL and extract features that can be used for image classification."}
{"text_id": 384, "text": "document: This model is fine-tuned with roberta-base model on 3,200,000 comments from stocktwits, with the user-labeled tags 'Bullish' or 'Bearish'."}
{"text_id": 384, "text": "query: An investment company wants to evaluate the user sentiment from StockTwits messages to make investment decisions."}
{"text_id": 905, "text": "document: Decision Transformer model trained on expert trajectories sampled from the Gym Hopper environment"}
{"text_id": 905, "text": "query: Develop a simple control program to make a robotic hopper balance and hop using the pre-trained decision transformer."}
{"text_id": 733, "text": "document: Transformer text-to-speech model from fairseq S^2. Spanish single-speaker male voice trained on CSS10."}
{"text_id": 733, "text": "query: I want to create a Spanish text-to-speech system that converts text inputs into spoken words to produce a natural-sounding male voice."}
{"text_id": 785, "text": "document: This model was trained by Joris Cosentino using the librimix recipe in Asteroid. It was trained on the sep_noisy task of the Libri2Mix dataset."}
{"text_id": 785, "text": "query: I would like to separate the instruments of this song."}
{"text_id": 924, "text": "document: BERT base model (uncased) is a transformer model pretrained on a large corpus of English data using a masked language modeling (MLM) objective. It can be used for masked language modeling, next sentence prediction, and fine-tuning on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 924, "text": "query: We have a text but one word is missing. Help us fill in the missing word."}
{"text_id": 663, "text": "document: XLM-RoBERTa is a multilingual version of RoBERTa pre-trained on 2.5TB of filtered CommonCrawl data containing 100 languages. It is designed for masked language modeling and can be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering."}
{"text_id": 663, "text": "query: \"I have two dogs and one ____(cat) at home.\""}
{"text_id": 93, "text": "document: This model is used for generating videos from text inputs. It is based on the Hugging Face framework and can be used with the transformers library. The model is trained on a variety of text and video datasets, and can be used for tasks such as video summarization, video generation from text prompts, and more."}
{"text_id": 93, "text": "query: A platform for creating personalized video messages needs a tool to generate video content based on user texts."}
{"text_id": 926, "text": "document: CLIPSeg model with reduce dimension 64, refined (using a more complex convolution). It was introduced in the paper Image Segmentation Using Text and Image Prompts by L\u00fcddecke et al. and first released in this repository. This model is intended for zero-shot and one-shot image segmentation."}
{"text_id": 926, "text": "query: Create an image segmentation model to identify objects in a given image using only textual prompts for labels, without any training examples."}
{"text_id": 223, "text": "document: A YOLOv8 model for detecting Counter-Strike: Global Offensive (CS:GO) players. Supports the labels ['ct', 'cthead', 't', 'thead']."}
{"text_id": 223, "text": "query: We are an esports team and we need to analyze our gameplay to understand player position and strategy using computer vision."}
{"text_id": 366, "text": "document: A series of CLIP ConvNeXt-Large models trained on the LAION-2B (english) subset of LAION-5B using OpenCLIP. The models achieve between 75.9 and 76.9 top-1 zero-shot accuracy on ImageNet-1k."}
{"text_id": 366, "text": "query: Design a system that can detect and classify objects in a given image. This should work on classes like cats, dogs, cars, and trees."}
